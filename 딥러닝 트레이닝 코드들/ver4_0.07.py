# FINCH/DLPS â€” Best-Practice Trainer (ACS head, RMSE eval)\n# ---------------------------------------------------------\n# ëª©í‘œ\n#  - ì…ë ¥: 0Â° ê°„ì„­ë¬´ëŠ¬ I0 (ì„¸ê¸° ì´ë¯¸ì§€, 1Ã—HÃ—W)\n#  - ì¶œë ¥: (A, C, S) íŒŒë¼ë¯¸í„° 3ì±„ë„\n#  - í•™ìŠµ: ì˜ˆì¸¡ (Ã‚, Äˆ, Åœ)ë¡œ 90Â°/180Â°/270Â° ì„¸ê¸° í”„ë ˆì„ì„ í•©ì„±(íí˜•ì‹) í›„,\n#          ë¼ë²¨ I90/I180/I270ê³¼ì˜ **ì±„ë„ë³„ RMSE**ë§Œìœ¼ë¡œ í•™ìŠµ (ë…¼ë¬¸ê³¼ ë™ì¼ ì§€í‘œ)\n#  - í‰ê°€: ì±„ë„ë³„ RMSEì™€ í•©ì„ ë¡œê·¸/ë² ìŠ¤íŠ¸ ì €ì¥ (.pth: state_dict)\n#\n# ì™œ ACS?\n#  - I_Î´ = A + C cos Î´ âˆ’ S sin Î´ (í”½ì…€ë³„ PSI í‘œì¤€ì‹) ë¡œ ì„¸ê¸°ë¥¼ íŒŒë¼ë¯¸í„°í™” â†’ í•´ê³µê°„ ì¶•ì†Œ\n#  - ë…¼ë¬¸ë„ ì˜ˆì¸¡/ë¼ë²¨ ëª¨ë‘ intensity í”„ë ˆì„ì´ë¯€ë¡œ ëª¨ìˆœ ì—†ìŒ\n#  - ë³´ê³  ì§€í‘œëŠ” RMSEì´ë¯€ë¡œ ê³µì • ë¹„êµ ê·¸ëŒ€ë¡œ ìœ ì§€\n#\n# ì•ˆì „ ì¥ì¹˜\n#  - degree_to_index = {0:0, 90:1, 180:2, 270:3} (ë²„ê·¸ ë°©ì§€)\n#  - ëˆ„ë½ í”„ë ˆì„ì€ í•™ìŠµì—ì„œ ì œì™¸(ì œë¡œíŒ¨ë”© ê¸ˆì§€)\n#  - ì…ë ¥/ë¼ë²¨ 0~1 ìŠ¤ì¼€ì¼ ê³ ì • (ê°ë§ˆ ë¶ˆëª… ì´ë¯¸ì§€ë¼ë©´ ì‚¬ì „ linearize ê¶Œì¥)\n#\n# ì„ íƒ ê¸°ëŠ¥\n#  - I0 ì¼ê´€ì„±(í•©ì„±í•œ I0ì™€ ì…ë ¥ I0ì˜ RMSE)ì„ ì•„ì£¼ ì‘ì€ ê°€ì¤‘ì¹˜ë¡œ ì¶”ê°€ ê°€ëŠ¥ (ê¸°ë³¸ 0.0=ë„ê¸°)\n#  - ì—…ìƒ˜í”Œ+Convë¡œ ì²´í¬ë³´ë“œ ë°©ì§€ (Deconv ë¯¸ì‚¬ìš©)\n#  - AMP / Gradient Clipping / OneCycleLR ì§€ì›\n\nimport os, glob, math, random\nfrom dataclasses import dataclass\nfrom typing import Dict, Tuple, Optional\n\nimport numpy as np\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# --------------------\n# Utils\n# --------------------\n\ndef set_seed(seed: int = 42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n\n@torch.no_grad()\ndef to_tensor01(img: Image.Image) -> torch.Tensor:\n    """Convert PIL image to float tensor in [0,1], shape (H,W). Support 8/16-bit."""\n    # Preserve linear domain; no gamma.\n    if img.mode in ("I;16", "I;16B", "I"):\n        arr = np.array(img, dtype=np.uint16).astype(np.float32) / 65535.0\n    else:\n        arr = np.array(img.convert('L'), dtype=np.uint8).astype(np.float32) / 255.0\n    return torch.from_numpy(arr)\n\n# --------------------\n# Dataset\n# --------------------\nclass HologramDataset(Dataset):\n    """Expect folder layout:\n    root/\n      train|validation|test/\n        sample_XXXX/phase_0.png  # 0Â°\n                           /phase_1.png  # 90Â°\n                           /phase_2.png  # 180Â°\n                           /phase_3.png  # 270Â°\n    """\n    def __init__(self, root: str, split: str, ensure_all_four: bool = True):\n        self.data_dir = os.path.join(root, split)\n        self.sample_dirs = sorted(glob.glob(os.path.join(self.data_dir, "sample_*")))\n        self.ensure_all_four = ensure_all_four\n        print(f"[{split}] {len(self.sample_dirs)} samples @ {self.data_dir}")\n\n    def __len__(self): return len(self.sample_dirs)\n\n    def __getitem__(self, idx):\n        sd = self.sample_dirs[idx]\n        paths = [os.path.join(sd, f"phase_{i}.png") for i in range(4)]\n        exists = [os.path.exists(p) for p in paths]\n        if self.ensure_all_four and not all(exists):\n            missing = [i for i,b in enumerate(exists) if not b]\n            raise FileNotFoundError(f"Missing phase file(s) {missing} in {sd}")\n        imgs = [to_tensor01(Image.open(p)) for p in paths]\n        # x: I0, y: [I90, I180, I270]\n        x = imgs[0].unsqueeze(0)                 # (1,H,W)\n        y = torch.stack([imgs[1], imgs[2], imgs[3]], dim=0)  # (3,H,W)\n        return x, y\n\nclass Holo3PhaseDataset(Dataset):\n    def __init__(self, root: str, split: str, degree_to_index: Dict[int,int]):\n        self.base = HologramDataset(root, split)\n        self.d2i = dict(degree_to_index)\n        assert self.d2i == {0:0, 90:1, 180:2, 270:3}, \
            f"degree_to_index must be {{0:0,90:1,180:2,270:3}}, got {self.d2i}"\n    def __len__(self): return len(self.base)\n    def __getitem__(self, idx):\n        x, y = self.base[idx]\n        # x: (1,H,W), y: (3,H,W) for (90,180,270) already\n        return x.float(), y.float()\n\n# --------------------\n# Model (UNet-ish, UpSample+Conv, 3ch output = (A,C,S))\n# --------------------\nclass ConvBlock(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_c, out_c, 3, 1, 1, bias=False),\n            nn.GroupNorm(1, out_c),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(out_c, out_c, 3, 1, 1, bias=False),\n            nn.GroupNorm(1, out_c),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n    def forward(self, x): return self.block(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_c, out_c, 3, 2, 1, bias=False),\n            nn.GroupNorm(1, out_c),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n    def forward(self, x): return self.block(x)\n\nclass Up(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv = ConvBlock(in_c, out_c)\n    def forward(self, x, skip):\n        x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, skip], dim=1)\n        return self.conv(x)\n\nclass FINCH_ACS_UNet(nn.Module):\n    def __init__(self, in_channels=1):\n        super().__init__()\n        c1, c2, c3, c4 = 64, 128, 256, 512\n        self.stem = ConvBlock(in_channels, c1)\n        self.d1 = Down(c1, c2)\n        self.d2 = Down(c2, c3)\n        self.d3 = Down(c3, c4)\n        self.u1 = Up(c4 + c3, c3)\n        self.u2 = Up(c3 + c2, c2)\n        self.u3 = Up(c2 + c1, c1)\n        self.head = nn.Conv2d(c1, 3, 3, 1, 1)  # â†’ (A,C,S)\n        self.softplus = nn.Softplus(beta=1.0)  # A â‰¥ 0\n\n    def forward(self, x):\n        s0 = self.stem(x)         # H\n        s1 = self.d1(s0)          # H/2\n        s2 = self.d2(s1)          # H/4\n        s3 = self.d3(s2)          # H/8\n        u1 = self.u1(s3, s2)\n        u2 = self.u2(u1, s1)\n        u3 = self.u3(u2, s0)\n        acs = self.head(u3)\n        A = self.softplus(acs[:, 0:1])\n        C = acs[:, 1:2]\n        S = acs[:, 2:3]\n        return A, C, S\n\n# --------------------\n# Physics: synthesize intensity at given phase in radians\n# --------------------\n@torch.no_grad()\ndef phase_rads(deg: float) -> float:\n    return float(deg * math.pi / 180.0)\n\ndef synth_intensity(A, C, S, delta_rad: float):\n    # I_Î´ = A + C cosÎ´ âˆ’ S sinÎ´\n    return A + C * math.cos(delta_rad) - S * math.sin(delta_rad)\n\n# --------------------\n# Loss & Metrics (RMSE per channel)\n# --------------------\nclass RMSEThree(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, pred3: torch.Tensor, tgt3: torch.Tensor):\n        # pred3,tgt3: (B,3,H,W) for (90,180,270)\n        assert pred3.shape == tgt3.shape\n        rmses = []\n        for c in range(3):\n            mse = F.mse_loss(pred3[:, c], tgt3[:, c], reduction='mean')\n            rmses.append(torch.sqrt(mse + 1e-8))\n        loss = torch.stack(rmses).sum()\n        return loss, {f"rmse_ch{c}": float(rmses[c].detach().cpu()) for c in range(3)} | {"rmse_sum": float(loss.detach().cpu())}\n\n# --------------------\n# Train / Val\n# --------------------\n@dataclass\nclass TrainConfig:\n    dataset_root: str = "./hologram_dataset_images_clean"\n    degree_to_index: Dict[int,int] = None\n    batch_size: int = 8\n    epochs: int = 120\n    lr: float = 1e-3\n    weight_decay: float = 1e-4\n    max_grad_norm: float = 1.0\n    num_workers: int = 4\n    amp: bool = True\n    seed: int = 42\n    patience: int = 15\n    pct_start: float = 0.1\n    lambda_I0_consistency: float = 0.0   # 0.0ì´ë©´ ë” (ê³µì • ë¹„êµìš© ê¸°ë³¸ê°’)\n    save_path: str = "finch_acs_best.pth"\n\ndef make_loaders(cfg: TrainConfig):\n    if cfg.degree_to_index is None:\n        cfg.degree_to_index = {0:0, 90:1, 180:2, 270:3}\n    train_ds = Holo3PhaseDataset(cfg.dataset_root, "train", cfg.degree_to_index)\n    val_ds   = Holo3PhaseDataset(cfg.dataset_root, "validation", cfg.degree_to_index)\n    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,\n                              num_workers=cfg.num_workers, drop_last=True, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False,\n                            num_workers=cfg.num_workers, drop_last=False, pin_memory=True)\n    return train_loader, val_loader\n\n@torch.no_grad()\ndef validate(model: nn.Module, loader: DataLoader, device: torch.device, amp: bool = True) -> float:\n    model.eval()\n    metric = RMSEThree()\n    d90, d180, d270 = map(phase_rads, (90, 180, 270))\n    total, n = 0.0, 0\n    for x, y in loader:  # x: (B,1,H,W), y: (B,3,H,W)\n        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n        with torch.amp.autocast('cuda', enabled=amp):\n            A, C, S = model(x)\n            I90  = synth_intensity(A, C, S, d90)\n            I180 = synth_intensity(A, C, S, d180)\n            I270 = synth_intensity(A, C, S, d270)\n            pred = torch.cat([I90, I180, I270], dim=1)\n            loss, _ = metric(pred, y)\n        total += loss.item() * x.size(0)\n        n += x.size(0)\n    return total / max(1, n)\n\ndef train(cfg: TrainConfig):\n    set_seed(cfg.seed)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f"[Device] {device}")\n    train_loader, val_loader = make_loaders(cfg)\n    steps = len(train_loader)\n    print(f"[Data] steps/epoch={steps}  batch={cfg.batch_size}")\n\n    model = FINCH_ACS_UNet(in_channels=1).to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=(0.9, 0.99))\n    if steps > 0:\n        sched = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=cfg.lr, epochs=cfg.epochs, steps_per_epoch=steps,\n                                                    pct_start=cfg.pct_start, div_factor=25.0, final_div_factor=100.0,\n                                                    anneal_strategy='cos')\n    else:\n        sched = None\n    scaler = torch.amp.GradScaler('cuda', enabled=cfg.amp)\n    metric = RMSEThree()\n    d0, d90, d180, d270 = map(phase_rads, (0, 90, 180, 270))\n\n    best_val, no_imp = float('inf'), 0\n\n    for ep in range(1, cfg.epochs + 1):\n        model.train()\n        run = 0.0\n        for bi, (x, y) in enumerate(train_loader, 1):\n            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n            opt.zero_grad(set_to_none=True)\n            with torch.amp.autocast('cuda', enabled=cfg.amp):\n                A, C, S = model(x)\n                I90  = synth_intensity(A, C, S, d90)\n                I180 = synth_intensity(A, C, S, d180)\n                I270 = synth_intensity(A, C, S, d270)\n                pred = torch.cat([I90, I180, I270], dim=1)\n                loss, det = metric(pred, y)  # pure RMSE (ë…¼ë¬¸ê³¼ ë™ì¼ ì§€í‘œ)\n                # Optional: I0 self-consistency (off by default)\n                if cfg.lambda_I0_consistency > 0.0:\n                    I0 = synth_intensity(A, C, S, d0)\n                    mse0 = F.mse_loss(I0, x, reduction='mean')\n                    rmse0 = torch.sqrt(mse0 + 1e-8)\n                    loss = loss + cfg.lambda_I0_consistency * rmse0\n\n            scaler.scale(loss).backward()\n            if cfg.max_grad_norm and cfg.max_grad_norm > 0:\n                scaler.unscale_(opt)\n                nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n            scaler.step(opt); scaler.update()\n            if sched is not None: sched.step()\n            run += loss.item()\n\n            if bi % 1 == 0:\n                lr = opt.param_groups[0]['lr']\n                print(f"   [Ep {ep:03d} / {cfg.epochs} | {bi:04d}/{steps}] loss={loss.item():.6f} rmse_sum={det['rmse_sum']:.6f} lr={lr:.6f}")\n\n        avg_train = run / max(1, steps)\n        val = validate(model, val_loader, device, cfg.amp)\n        print(f"\nâœ… Epoch {ep:03d} | train={avg_train:.6f}  val={val:.6f}  lr={opt.param_groups[0]['lr']:.6f}")\n\n        if val < best_val - 1e-6:\n            best_val, no_imp = val, 0\n            torch.save(model.state_dict(), cfg.save_path)\n            print(f"   ğŸ† NEW BEST saved â†’ {cfg.save_path}")\n        else:\n            no_imp += 1\n            print(f"   â³ no improve {no_imp}/{cfg.patience}")\n            if no_imp >= cfg.patience:\n                print("\nğŸ›‘ Early stop: patience exceeded")\n                break\n\n    print(f"\nğŸ‰ Done. Best val RMSE-sum: {best_val:.6f}")\n\nif __name__ == "__main__":\n    cfg = TrainConfig(\n        dataset_root = "./hologram_dataset_images_clean",\n        degree_to_index = {0:0, 90:1, 180:2, 270:3},\n        batch_size = 8,\n        epochs = 120,\n        lr = 1e-3,\n        weight_decay = 1e-4,\n        max_grad_norm = 1.0,\n        num_workers = 4,\n        amp = True,\n        seed = 42,\n        patience = 15,\n        pct_start = 0.1,\n        lambda_I0_consistency = 0.0,  # ê³µì •ë¹„êµìš© ê¸°ë³¸ê°’: ì˜¤ì§ RMSEë¡œë§Œ í•™ìŠµ\n        save_path = "finch_acs_best.pth",\n    )\n    print(cfg)\n    train(cfg)\n
