# =============================================================================
# FINCH/DLPS Training Script - Converted from Jupyter Notebook
# =============================================================================

# =============================================================================
# 1. Import Libraries
# =============================================================================
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import numpy as np
import os
from PIL import Image
from torch.optim.lr_scheduler import OneCycleLR

# ë°ì´í„° ì¦ê°• ë° ì „ì²˜ë¦¬ ì„¤ì • (ìˆ˜ì •)
# ë…¸ì´ì¦ˆê°€ ìˆëŠ” í™˜ê²½ì— ê°•ê±´í•˜ë„ë¡ ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²• ì¶”ê°€
phase_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomRotation(degrees=5),
    transforms.RandomHorizontalFlip(),  # ì¢Œìš° ë°˜ì „ ì¶”ê°€
    transforms.RandomVerticalFlip(),    # ìƒí•˜ ë°˜ì „ ì¶”ê°€
    transforms.ToTensor()
])

# =============================================================================
# 2. Device Setup
# =============================================================================
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f'Available device: {device}')

torch.manual_seed(777)
if device == 'cuda':
    torch.cuda.manual_seed_all(777)

# =============================================================================
# 3. Custom Dataset Class
# =============================================================================
class HologramDataset(Dataset):
    def __init__(self, root_dir, split='train'):
        self.root_dir = os.path.join(root_dir, split)
        self.samples = sorted([
            os.path.join(self.root_dir, f) for f in os.listdir(self.root_dir)
            if f.startswith('sample_')
        ])
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample_path = self.samples[idx]

        phases = []
        for i in range(4):
            p = os.path.join(sample_path, f'phase_{i}.png')
            img = Image.open(p)

            # (ì„ íƒ) í¬ê¸° í†µì¼ì´ í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ ë¦¬ì‚¬ì´ì¦ˆ
            img = img.resize((256, 256), resample=Image.BILINEAR)

            arr = np.array(img)
    
            # ë§Œì•½ HxWx3 í˜•íƒœ(ì‹¤ìˆ˜ë¡œ ì»¬ëŸ¬ ì €ì¥)ë©´ ì²« ì±„ë„ë§Œ ì‚¬ìš©
            if arr.ndim == 3:
                arr = arr[..., 0]

            # dtypeë³„ ì •ê·œí™”
            if arr.dtype == np.uint16:
                arr = arr.astype(np.float32) / 65535.0
            elif arr.dtype == np.uint8:
                arr = arr.astype(np.float32) / 255.0
            else:
                arr = arr.astype(np.float32)  # ì´ë¯¸ 0~1ì´ë©´ ê·¸ëŒ€ë¡œ

            phases.append(arr)

        phases = np.stack(phases, axis=0).astype(np.float32)  # (4, H, W)

        input_phase   = torch.from_numpy(phases[0:1])  # (1, H, W)
        target_phases = torch.from_numpy(phases[1:])   # (3, H, W)
        return input_phase, target_phases

# =============================================================================
# 4. Model Architecture Components (stride=2, kernel=3x3 ë°˜ì˜)
# =============================================================================
class EncoderBlock(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_c, out_c, kernel_size=3, stride=2, padding=1, bias=False),
            nn.GroupNorm(32,out_c),
            nn.LeakyReLU(0.2, inplace=False)
        )

    def forward(self, x):
        return self.block(x)

class DecoderBlock(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.block = nn.Sequential(
            nn.LeakyReLU(0.2, inplace=False),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),  # ì—…ìƒ˜í”Œ ë¨¼ì €
            nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, bias=False)  # Conv2dë¡œ í›„ì²˜ë¦¬
        )

    def forward(self, x):
        return self.block(x)

# =============================================================================
# 5. Main Model Architecture (stride=2 ìœ ì§€, ì¶œë ¥ í¬ê¸° ë³µì› í¬í•¨)
# =============================================================================
class FINCH_DLPS_Net(nn.Module):
    def __init__(self, in_channels=1, out_channels=1):
        super().__init__()
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_channels, 64, 3, 2, 1, bias=False),
            nn.GroupNorm(32, 64), nn.LeakyReLU(0.2, inplace=False)
        )
        self.enc2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, 2, 1, bias=False),
            nn.GroupNorm(32, 128), nn.LeakyReLU(0.2, inplace=False)
        )
        self.enc3 = nn.Sequential(
            nn.Conv2d(128, 256, 3, 2, 1, bias=False),
            nn.GroupNorm(32, 256), nn.LeakyReLU(0.2, inplace=False)
        )

        self.dec1 = self._make_decoder()
        self.dec2 = self._make_decoder()
        self.dec3 = self._make_decoder()

    def _make_decoder(self):
        return nn.Sequential(
            DecoderBlock(256, 128),                     # up1
            EncoderBlock(256, 128),                     # conv1 (with skip)
            DecoderBlock(128, 64),                      # up2
            EncoderBlock(128, 64),                      # conv2 (with skip)
            DecoderBlock(64, 64),                       # up3
            nn.Conv2d(64, 1, kernel_size=3, padding=1), # final conv
        )

    def forward(self, x):
        e1 = self.enc1(x)  # (B, 64, H/2, W/2)
        e2 = self.enc2(e1) # (B, 128, H/4, W/4)
        e3 = self.enc3(e2) # (B, 256, H/8, W/8)

        input_shape = x.shape[2:]  # (H, W)

        d1 = self._decode(self.dec1, e1, e2, e3, input_shape)  # predict phase_1
        d2 = self._decode(self.dec2, e1, e2, e3, input_shape)  # predict phase_2
        d3 = self._decode(self.dec3, e1, e2, e3, input_shape)  # predict phase_3

        return d1, d2, d3  # Each is (B, 1, H, W)

    def _decode(self, dec, e1, e2, e3, input_shape):
        x = dec[0](e3)                            # up to H/4
        if x.shape[2:] != e2.shape[2:]:
            x = F.interpolate(x, size=e2.shape[2:], mode='bilinear', align_corners=False)
        x = dec[1](torch.cat([x, e2], dim=1))     # fuse

        x = dec[2](x)                             # up to H/2
        if x.shape[2:] != e1.shape[2:]:
            x = F.interpolate(x, size=e1.shape[2:], mode='bilinear', align_corners=False)
        x = dec[3](torch.cat([x, e1], dim=1))     # fuse

        x = dec[4](x)                             # up to H
        x = dec[5](x)                             # final 1ch
        if x.shape[2:] != input_shape:
            x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)
        return x                                  # linear ì¶œë ¥

# =============================================================================
# 6. Loss Functions - SSIM + RMSE + ìœ„ìƒ ì¼ê´€ì„± ì†ì‹¤ í•¨ìˆ˜
# =============================================================================
def ssim(img1, img2, C1=0.01**2, C2=0.03**2):
    mu1 = F.avg_pool2d(img1, 3, 1, 1)
    mu2 = F.avg_pool2d(img2, 3, 1, 1)
    sigma1_sq = F.avg_pool2d(img1 * img1, 3, 1, 1) - mu1 ** 2
    sigma2_sq = F.avg_pool2d(img2 * img2, 3, 1, 1) - mu2 ** 2
    sigma12 = F.avg_pool2d(img1 * img2, 3, 1, 1) - mu1 * mu2
    ssim_map = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \
               ((mu1 ** 2 + mu2 ** 2 + C1) * (sigma1_sq + sigma2_sq + C2))
    return ssim_map.mean()
    
def improved_physics_loss(output1, target1, output2, target2, output3, target3, epoch=0):
    eps = 1e-8

    # --- RMSE ê³„ì‚° ---
    rmse1 = torch.sqrt(torch.mean((output1 - target1) ** 2) + eps)
    rmse2 = torch.sqrt(torch.mean((output2 - target2) ** 2) + eps)
    rmse3 = torch.sqrt(torch.mean((output3 - target3) ** 2) + eps)
    base_rmse = (rmse1 + rmse2 + rmse3) /3

    if epoch<10:
        return base_rmse, {'rmse': base_rmse.item(), 'consistency':0, 'ssim':0,
                           'weight_consistency':0, 'weight_ssim':0}

    # --- ìœ„ìƒ ì¼ê´€ì„± ì†ì‹¤ (phase consistency) ---
    pred_diff_1 = output1 - output3
    pred_diff_2 = output2 - output3
    target_diff_1 = target1 - target3
    target_diff_2 = target2 - target3
    consistency_loss = F.mse_loss(pred_diff_1, target_diff_1) + F.mse_loss(pred_diff_2, target_diff_2)

    # --- SSIM ì†ì‹¤ ê³„ì‚° ---
    ssim_loss1 = 1 - ssim(output1, target1)
    ssim_loss2 = 1 - ssim(output2, target2)
    ssim_loss3 = 1 - ssim(output3, target3)
    ssim_total = (ssim_loss1 + ssim_loss2 + ssim_loss3) / 3

    consistency_weight = 0.01
    ssim_weight = 0.1

    # --- ì´ loss ---
    total_loss = base_rmse + consistency_weight * consistency_loss + ssim_weight * ssim_total

    # --- NaN ë°©ì§€ ---
    if torch.isnan(total_loss):
        total_loss = base_rmse

    # --- ë¦¬í„´ (loss + ìƒì„¸ì •ë³´) ---
    return total_loss, {
        'rmse': base_rmse.item(),
        'consistency': consistency_loss.item(),
        'ssim': ssim_total.item(),
        'weight_consistency': consistency_weight,
        'weight_ssim': ssim_weight
    }

# =============================================================================
# 7. Training Function
# =============================================================================
def train_model():
    # ë°ì´í„°ì…‹ ì„¤ì •
    dataset_root = 'hologram_dataset_images_clean'
    batch_size = 10  # í™€ë¡œê·¸ë¨ ë°ì´í„°ëŠ” í¬ê¸°ê°€ í¬ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¤„ì„
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    train_dataset = HologramDataset(dataset_root, 'train')
    val_dataset = HologramDataset(dataset_root, 'validation')
    test_dataset = HologramDataset(dataset_root, 'test')

    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    print(f"  - Train: {len(train_dataset)}ê°œ ìƒ˜í”Œ")
    print(f"  - Validation: {len(val_dataset)}ê°œ ìƒ˜í”Œ")
    print(f"  - Test: {len(test_dataset)}ê°œ ìƒ˜í”Œ")

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = FINCH_DLPS_Net().to(device)
    print(f"GPU ì‚¬ìš©: {next(model.parameters()).device}")

    # í›ˆë ¨ ì„¤ì •
    learning_rate = 0.001
    training_epochs = 80
    weight_decay = 0.0001

    print("=== í›ˆë ¨ ì„¤ì • ===")
    print(f"í•™ìŠµë¥ : {learning_rate}")
    print(f"í›ˆë ¨ ì—í¬í¬: {training_epochs}")
    print(f"ê°€ì¤‘ì¹˜ ê°ì†Œ: {weight_decay}")

    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=learning_rate,
        weight_decay=weight_decay,
        betas=(0.9, 0.95),
        eps=1e-8,
        amsgrad=False
    )

    max_batches = min(100, len(train_loader))
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=1e-3,
        steps_per_epoch=max_batches,
        epochs=training_epochs,
        pct_start=0.1
    )

    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}")
    print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"ì´ ë°°ì¹˜ ê°œìˆ˜: {max_batches}")
    print("=" * 60)

    best_loss = float('inf')
    patience_counter = 0
    patience_limit = 15

    # í›ˆë ¨ ë£¨í”„
    for epoch in range(training_epochs):
        model.train()
        running_loss = 0.0
        epoch_rmse_sum = 0.0

        print(f"\nğŸ“Š Epoch {epoch + 1}/{training_epochs} ì‹œì‘...")

        scaler = torch.amp.GradScaler('cuda')  # ìµœì‹  ë²„ì „ ì‚¬ìš©
        
        for i, (input_phase, target_phases) in enumerate(train_loader):
            if i >= max_batches:
                break
            input_phase = input_phase.to(device)         # shape: (B, 1, H, W)
            target_phase1 = target_phases[:, 0:1].to(device)  # shape: (B, 1, H, W)
            target_phase2 = target_phases[:, 1:2].to(device)
            target_phase3 = target_phases[:, 2:3].to(device)

            optimizer.zero_grad()

            with torch.amp.autocast('cuda'):  # ìµœì‹  ë²„ì „ ì‚¬ìš©
                # ëª¨ë¸ ì˜ˆì¸¡
                output1, output2, output3 = model(input_phase)
                # ì†ì‹¤ ê³„ì‚°
                loss, loss_details = improved_physics_loss(
                    output1, target_phase1,
                    output2, target_phase2,
                    output3, target_phase3,
                    epoch=epoch
                )

            # ì—­ì „íŒŒ ë° ì—…ë°ì´íŠ¸
            scaler.scale(loss).backward()
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)
            scaler.step(optimizer)
            scaler.update()
            
            scheduler.step()

            running_loss += loss.item()
            epoch_rmse_sum += loss_details['rmse']

            # ë¡œê·¸ ì¶œë ¥
            print(f"[Epoch {epoch + 1}, Batch {i + 1}/{max_batches}] "
                  f"Loss: {loss.item():.4f} | "
                  f"RMSE: {loss_details['rmse']:.4f} | "
                  f"Consistency: {loss_details['consistency']:.4f} | "
                  f"SSIM: {loss_details['ssim']:.4f} | "
                  f"Grad: {grad_norm:.3f}")

        # ì—í¬í¬ ë§ˆë¬´ë¦¬
        current_lr = optimizer.param_groups[0]['lr']
        avg_loss = running_loss / max_batches
        avg_rmse = epoch_rmse_sum / max_batches

        print(f"âœ… Epoch {epoch + 1} ì™„ë£Œ!")
        print(f"   ğŸ“ˆ í‰ê·  Loss: {avg_loss:.6f}")
        print(f"   ğŸ“Š í‰ê·  RMSE: {avg_rmse:.6f}")
        print(f"   âš™ï¸  í•™ìŠµë¥ : {current_lr:.6f}")

        # ëª¨ë¸ ì €ì¥ ì¡°ê±´
        if avg_loss < best_loss:
            best_loss = avg_loss
            patience_counter = 0
            torch.save(model.state_dict(), 'best_model_noise.pth')
            print(f"   ğŸ† NEW BEST! RMSE: {avg_rmse:.6f}")
        else:
            patience_counter += 1

        # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
        if patience_counter >= patience_limit:
            print(f"ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ! {patience_limit} ì—í¬í¬ ê°œì„  ì—†ìŒ")
            break

        if avg_rmse <= 0.0036:
            print(f"ğŸŠ ëª©í‘œ ë‹¬ì„±! RMSE: {avg_rmse:.6f} <= 0.0036")
            break

        print("-" * 60)
    
    print("ëª¨ë¸ì´ 'best_model_noise.pth'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return model

# =============================================================================
# 8. Main Execution
# =============================================================================
if __name__ == "__main__":
    try:
        model = train_model()
        print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
