# FINCH/DLPS Training (3-Head, 0Â° â†’ 90Â°/180Â°/270Â°) â€” Save `.pth`
# 
# ëª©í‘œ: **0Â°** ì…ë ¥ì—ì„œ **90Â°/180Â°/270Â°** ê°„ì„­ë¬´ëŠ¬ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ **í›ˆë ¨ë§Œ** í•´ì„œ,
# ìµœì  ê°€ì¤‘ì¹˜ë¥¼ **`.pth` ì²´í¬í¬ì¸íŠ¸**ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
# 
# - ì¸ì½”ë”: `Conv(3Ã—3, s=2)` + **LayerNorm**(= `GroupNorm(1,C)`) + `LeakyReLU(0.2)`  
# - ë””ì½”ë”(í—¤ë“œ 3ê°œ): `LeakyReLU â†’ Deconv(5Ã—5, s=2)` Ã— 3, **skip + FuseConv(3Ã—3)**  
# - ì¶œë ¥: 3ì±„ë„(90Â°, 180Â°, 270Â°)  
# - ì†ì‹¤: ì±„ë„ë³„ **RMSE í•©**  
# - ì €ì¥: `save_path`ì— **best model**ì„ `state_dict()`ë¡œ ì €ì¥ (`.pth`)

import os, random
from dataclasses import dataclass
from typing import Tuple, Dict

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms.functional as TF
import glob
from PIL import Image
import numpy as np

def set_seed(seed: int = 42):
    random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)

def exists(x): return x is not None

print("PyTorch:", torch.__version__)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# ---------------------------
# Model blocks
# ---------------------------
class EncoderBlock(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_c, out_c, kernel_size=3, stride=2, padding=1, bias=False),
            nn.GroupNorm(1, out_c),                 # LayerNorm(ì±„ë„ ì „ì²´)ì™€ ë™ë“±
            nn.LeakyReLU(0.2, inplace=False),
        )
    def forward(self, x): return self.block(x)

class FuseConv(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, bias=False),
            nn.GroupNorm(1, out_c),
            nn.LeakyReLU(0.2, inplace=False),
        )
    def forward(self, x): return self.block(x)

class DeconvUp(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.act = nn.LeakyReLU(0.2, inplace=False)
        self.deconv = nn.ConvTranspose2d(in_c, out_c, kernel_size=5, stride=2, padding=2, output_padding=1, bias=True)
    def forward(self, x): return self.deconv(self.act(x))

class ChannelAttention(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.fc = nn.Sequential(
            nn.Conv2d(channels, channels // reduction, 1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels // reduction, channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        return x * self.sigmoid(out)

class DecoderHead(nn.Module):
    def __init__(self):
        super().__init__()
        self.up1   = DeconvUp(256, 128)       # H/8 -> H/4
        self.fuse1 = FuseConv(128+128, 128)   # concat e2 -> 128
        self.att1  = ChannelAttention(128)    # Attention ì¶”ê°€
        
        self.up2   = DeconvUp(128, 64)        # -> H/2
        self.fuse2 = FuseConv(64+64, 64)      # concat e1 -> 64
        self.att2  = ChannelAttention(64)     # Attention ì¶”ê°€
        
        self.up3   = DeconvUp(64, 64)         # -> H
        self.out   = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1, bias=True)

    def forward(self, e1, e2, e3, out_hw: Tuple[int,int]):
        H, W = out_hw
        y = self.up1(e3)
        if y.shape[2:] != e2.shape[2:]:
            y = F.interpolate(y, size=e2.shape[2:], mode='bilinear', align_corners=False)
        y = self.fuse1(torch.cat([y, e2], dim=1))
        y = self.att1(y)  # Attention ì ìš©

        y = self.up2(y)
        if y.shape[2:] != e1.shape[2:]:
            y = F.interpolate(y, size=e1.shape[2:], mode='bilinear', align_corners=False)
        y = self.fuse2(torch.cat([y, e1], dim=1))
        y = self.att2(y)  # Attention ì ìš©

        y = self.up3(y)
        if y.shape[2:] != (H, W):
            y = F.interpolate(y, size=(H, W), mode='bilinear', align_corners=False)
        return self.out(y)

class FINCH_DLPS_3Head(nn.Module):
    def __init__(self, in_channels=1, num_heads=3):
        super().__init__()
        self.enc1 = EncoderBlock(in_channels, 64)  # (B,64,H/2,W/2)
        self.enc2 = EncoderBlock(64, 128)          # (B,128,H/4,W/4)
        self.enc3 = EncoderBlock(128, 256)         # (B,256,H/8,W/8)
        self.heads = nn.ModuleList([DecoderHead() for _ in range(num_heads)])

    def forward(self, x):
        H, W = x.shape[2:]
        e1 = self.enc1(x); e2 = self.enc2(e1); e3 = self.enc3(e2)
        outs = [h(e1, e2, e3, (H, W)) for h in self.heads]  # 3 Ã— (B,1,H,W)
        return torch.cat(outs, dim=1)                       # (B,3,H,W)

# ---------------------------
# Loss: sum of per-channel RMSE
# ---------------------------
def rmse_sum_per_channel(pred: torch.Tensor, tgt: torch.Tensor, channel_weights=None):
    assert pred.shape == tgt.shape, f"shape mismatch: {pred.shape} vs {tgt.shape}"
    
    # ì±„ë„ë³„ ê°€ì¤‘ì¹˜ (90Â°, 180Â°, 270Â°ì— ëŒ€í•´ ì¡°ê¸ˆì”© ë‹¤ë¥¸ ì¤‘ìš”ë„)
    if channel_weights is None:
        channel_weights = [1.0, 1.1, 1.0]  # 180ë„ë¥¼ ì¡°ê¸ˆ ë” ì¤‘ìš”í•˜ê²Œ
    
    rmses = []
    weighted_loss = 0.0
    
    for c in range(pred.shape[1]):
        mse = F.mse_loss(pred[:, c], tgt[:, c], reduction='mean')
        rmse = torch.sqrt(mse + 1e-8)
        rmses.append(rmse)
        weighted_loss += rmse * channel_weights[c]
    
    details = {f"rmse_ch{c}": float(v.detach().cpu()) for c, v in enumerate(rmses)}
    details["rmse_sum"] = float(weighted_loss.detach().cpu())
    return weighted_loss, details

# Dataset wrapper (0Â° â†’ 90Â°/180Â°/270Â°)
# 
# **ì „ì œ**: ë‹¹ì‹ ì˜ `HologramDataset(root, split)`ì´ (x, y)ë¥¼ ë°˜í™˜  
#   - `x`: 0Â° ê°„ì„­ë¬´ëŠ¬ â€” `(1,H,W)` ë˜ëŠ” `(H,W)`  
#   - `y`: ìŠ¤íƒ â€” `(C,H,W)` (ì±„ë„ ìˆœì„œ ì˜ˆ: `[0Â°, 90Â°, 180Â°, 270Â°]`)  
# ì•„ë˜ `degree_to_index`ë¥¼ ì´ìš©í•´ **(90Â°,180Â°,270Â°) â†’ (3,H,W)**ë§Œ ë½‘ì•„ì„œ ì‚¬ìš©.
# **import ê²½ë¡œë§Œ ìˆ˜ì •**í•˜ë©´ ë©ë‹ˆë‹¤.

# â›³ï¸ ì‹¤ì œ ë°ì´í„°ì…‹ import ê²½ë¡œë¡œ ë°”ê¾¸ì„¸ìš”!
# ì˜ˆ: from data.holo_dataset import HologramDataset
# from your_package.your_dataset_module import HologramDataset  # <-- ì—¬ê¸° ìˆ˜ì •

# ê°„ë‹¨í•œ HologramDataset í´ë˜ìŠ¤ ìƒì„±

class HologramDataset(Dataset):
    def __init__(self, root: str, split: str):
        super().__init__()
        self.root = root
        self.split = split
        
        # splitì— ë”°ë¼ í´ë” ê²½ë¡œ ì„¤ì •
        if split == "train":
            self.data_dir = os.path.join(root, "train")
        elif split == "validation":
            self.data_dir = os.path.join(root, "validation")
        elif split == "test":
            self.data_dir = os.path.join(root, "test")
        else:
            raise ValueError(f"Invalid split: {split}")
        
        # sample í´ë”ë“¤ ì°¾ê¸°
        self.sample_dirs = sorted(glob.glob(os.path.join(self.data_dir, "sample_*")))
        print(f"[{split}] Found {len(self.sample_dirs)} samples in {self.data_dir}")
    
    def __len__(self):
        return len(self.sample_dirs)
    
    def __getitem__(self, idx):
        sample_dir = self.sample_dirs[idx]
        
        # phase_0.png (0Â°), phase_1.png (90Â°), phase_2.png (180Â°), phase_3.png (270Â°) ë¡œë“œ
        phases = []
        for i in range(4):
            phase_path = os.path.join(sample_dir, f"phase_{i}.png")
            if os.path.exists(phase_path):
                img = Image.open(phase_path).convert('L')  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
                img_array = np.array(img).astype(np.float32) / 255.0  # 0-1 ì •ê·œí™”
                phases.append(img_array)
            else:
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
                phases.append(np.zeros((1024, 1024), dtype=np.float32))
        
        # x: phase_0.png (0Â° ì…ë ¥)
        # y: [phase_1.png, phase_2.png, phase_3.png] (90Â°, 180Â°, 270Â° íƒ€ê²Ÿ)
        x = phases[0]  # 0Â° ì…ë ¥
        y = np.stack(phases[1:], axis=0)  # 90Â°, 180Â°, 270Â° ìŠ¤íƒ
        
        return x, y

class Holo3PhaseDataset(Dataset):
    def __init__(self, root: str, split: str, degree_to_index: Dict[int,int],
                 target_degrees=(90,180,270), augment=True):
        super().__init__()
        self.base = HologramDataset(root, split)
        self.degree_to_index = dict(degree_to_index)  # ì˜ˆ: {0:0, 90:1, 180:2, 270:3}
        self.target_degrees = tuple(target_degrees)
        self.augment = augment and (split == "train")  # í›ˆë ¨ ì‹œì—ë§Œ ì¦ê°•

    def __len__(self): return len(self.base)

    def __getitem__(self, idx):
        x, y = self.base[idx]                 # x: (1,H,W)/(H,W), y: (C,H,W)/(H,W)
        x = torch.as_tensor(x).float()
        y = torch.as_tensor(y).float()

        if x.dim() == 2: x = x.unsqueeze(0)   # (1,H,W) ê°•ì œ
        assert x.dim()==3 and x.shape[0]==1, f"x must be (1,H,W), got {tuple(x.shape)}"

        if y.dim() == 2:
            # ë§¤ìš° ì˜ˆì™¸ì : ë‹¨ì¼ì¥ ë¼ë²¨ì´ë©´ 3ì¥ ë³µì œ
            y = y.unsqueeze(0).repeat(3,1,1)
        else:
            idxs = [self.degree_to_index[d] for d in self.target_degrees]
            y = torch.stack([y[i] for i in idxs], dim=0)  # (3,H,W)

        # ë°ì´í„° ì¦ê°• (í›ˆë ¨ ì‹œì—ë§Œ)
        if self.augment:
            # ìˆ˜í‰ í”Œë¦¬í•‘ (50% í™•ë¥ )
            if random.random() > 0.5:
                x = TF.hflip(x)
                y = TF.hflip(y)
            
            # ìˆ˜ì§ í”Œë¦¬í•‘ (50% í™•ë¥ )
            if random.random() > 0.5:
                x = TF.vflip(x)
                y = TF.vflip(y)
            
            # 90ë„ íšŒì „ (25% í™•ë¥ )
            if random.random() > 0.75:
                angle = random.choice([90, 180, 270])
                x = TF.rotate(x, angle)
                y = TF.rotate(y, angle)

        return x, y

@dataclass
class TrainConfig:
    dataset_root: str = "./hologram_dataset_images_clean"     # â›³ï¸ ì‹¤ì œ ê²½ë¡œ
    degree_to_index: Dict[int,int] = None               # {0:0, 90:1, 180:2, 270:3}
    target_degrees: Tuple[int,int,int] = (90,180,270)   # ì˜ˆì¸¡ ëŒ€ìƒ
    batch_size: int = 8
    epochs: int = 80
    lr: float = 1e-3
    weight_decay: float = 1e-4
    max_grad_norm: float = 1.0
    pct_start: float = 0.1
    num_workers: int = 4
    amp: bool = True
    seed: int = 42
    patience: int = 12
    save_path: str = "finch_3head_90_180_270.pth"       # â›³ï¸ ì €ì¥í•  .pth ê²½ë¡œ

def make_loaders(cfg: TrainConfig):
    if cfg.degree_to_index is None:
        cfg.degree_to_index = {0:0, 90:0, 180:1, 270:2}  # 90Â°->0, 180Â°->1, 270Â°->2 (3ì±„ë„)

    TrainDS = Holo3PhaseDataset
    train_ds = TrainDS(cfg.dataset_root, "train", cfg.degree_to_index, target_degrees=cfg.target_degrees)
    val_ds = TrainDS(cfg.dataset_root, "validation", cfg.degree_to_index, target_degrees=cfg.target_degrees)

    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,
                              num_workers=cfg.num_workers, drop_last=True, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False,
                            num_workers=cfg.num_workers, drop_last=False, pin_memory=True)
    return train_loader, val_loader

@torch.no_grad()
def validate(model: nn.Module, loader: DataLoader, device: torch.device, amp: bool = True) -> float:
    model.eval()
    total, n = 0.0, 0
    for x, y in loader:
        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)
        with torch.amp.autocast('cuda', enabled=amp):
            pred = model(x)
            loss, _ = rmse_sum_per_channel(pred, y)
        total += loss.item() * x.size(0)
        n += x.size(0)
    return total / max(1, n)

def train(cfg: TrainConfig):
    set_seed(cfg.seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[Device] {device}")

    train_loader, val_loader = make_loaders(cfg)
    steps = len(train_loader)
    print(f"[Data] steps/epoch={steps}  batch={cfg.batch_size}")
    
    # í›ˆë ¨ ìƒí™© ë¸Œë¦¬í•‘ì„ ìœ„í•œ ì„¤ì •
    print("=" * 60)
    print("=== FINCH/DLPS 3-Head Training Configuration ===")
    print(f"Dataset Root: {cfg.dataset_root}")
    print(f"Target Degrees: {cfg.target_degrees}")
    print(f"Batch Size: {cfg.batch_size}")
    print(f"Epochs: {cfg.epochs}")
    print(f"Learning Rate: {cfg.lr}")
    print(f"Weight Decay: {cfg.weight_decay}")
    print(f"Max Gradient Norm: {cfg.max_grad_norm}")
    print(f"Patience: {cfg.patience}")
    print(f"Save Path: {cfg.save_path}")
    print("=" * 60)

    model = FINCH_DLPS_3Head(in_channels=1, num_heads=3).to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr,
                                  weight_decay=cfg.weight_decay, betas=(0.9, 0.999), eps=1e-8)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=10, T_mult=2, eta_min=1e-6
    )
    scaler = torch.amp.GradScaler('cuda', enabled=cfg.amp)

    best_val, no_improve = float("inf"), 0
    
    # í›ˆë ¨ í†µê³„ ì´ˆê¸°í™”
    total_train_loss = 0.0
    total_val_loss = 0.0

    for ep in range(1, cfg.epochs + 1):
        model.train()
        run = 0.0
        epoch_losses = []
        epoch_rmse_details = []
        
        print(f"\nğŸ“Š Epoch {ep:03d}/{cfg.epochs} ì‹œì‘...")
        print(f"   ğŸ”„ ì´ {steps} ë°°ì¹˜ ì²˜ë¦¬ ì¤‘...")
        
        for bi, (x, y) in enumerate(train_loader, start=1):
            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)

            optimizer.zero_grad(set_to_none=True)
            # Forward pass
            with torch.amp.autocast('cuda', enabled=cfg.amp):
                pred = model(x)  # (B,3,H,W)
                loss, details = rmse_sum_per_channel(pred, y)
            
            # Backward pass
            scaler.scale(loss).backward()
            
            # Gradient clipping
            if exists(cfg.max_grad_norm) and cfg.max_grad_norm > 0:
                scaler.unscale_(optimizer)
                grad_norm = nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)

            scaler.step(optimizer); scaler.update(); scheduler.step()
            run += loss.item()
            
            # ë°°ì¹˜ë³„ ì†ì‹¤ ì •ë³´ ì €ì¥
            epoch_losses.append(loss.item())
            epoch_rmse_details.append(details)

            # ìƒì„¸í•œ í›ˆë ¨ ìƒí™© ë¸Œë¦¬í•‘ (ëª¨ë“  ë°°ì¹˜ë§ˆë‹¤ ì¶œë ¥)
            if bi % 1 == 0 or bi == steps:  # ëª¨ë“  ë°°ì¹˜ë§ˆë‹¤ ì¶œë ¥
                current_lr = optimizer.param_groups[0]['lr']
                avg_loss_so_far = sum(epoch_losses) / len(epoch_losses)
                
                # RMSE ìƒì„¸ ì •ë³´ ê³„ì‚°
                avg_rmse_sum = sum(d['rmse_sum'] for d in epoch_rmse_details) / len(epoch_rmse_details)
                avg_rmse_ch0 = sum(d['rmse_ch0'] for d in epoch_rmse_details) / len(epoch_rmse_details)
                avg_rmse_ch1 = sum(d['rmse_ch1'] for d in epoch_rmse_details) / len(epoch_rmse_details)
                avg_rmse_ch2 = sum(d['rmse_ch2'] for d in epoch_rmse_details) / len(epoch_rmse_details)
                
                print(f"   ğŸ“ˆ [Batch {bi:04d}/{steps}] "
                      f"Loss: {loss.item():.5f} | "
                      f"Avg Loss: {avg_loss_so_far:.5f} | "
                      f"RMSE Sum: {details['rmse_sum']:.5f} | "
                      f"LR: {current_lr:.6f}")
                
                if exists(cfg.max_grad_norm) and cfg.max_grad_norm > 0:
                    print(f"      ğŸ“Š RMSE Details - Ch0: {avg_rmse_ch0:.5f}, Ch1: {avg_rmse_ch1:.5f}, Ch2: {avg_rmse_ch2:.5f} | "
                          f"Grad Norm: {grad_norm:.3f}")
                else:
                    print(f"      ğŸ“Š RMSE Details - Ch0: {avg_rmse_ch0:.5f}, Ch1: {avg_rmse_ch1:.5f}, Ch2: {avg_rmse_ch2:.5f}")

        # ì—í¬í¬ ì™„ë£Œ í›„ ê²€ì¦ ë° ìš”ì•½
        avg_train = run / max(1, steps)
        val = validate(model, val_loader, device, cfg.amp)
        
        # í›ˆë ¨ í†µê³„ ì—…ë°ì´íŠ¸
        total_train_loss += avg_train
        total_val_loss += val
        
        print(f"\nâœ… Epoch {ep:03d} ì™„ë£Œ!")
        print(f"   ğŸ“ˆ í›ˆë ¨ Loss: {avg_train:.6f}")
        print(f"   ğŸ§ª ê²€ì¦ Loss: {val:.6f}")
        print(f"   âš™ï¸  í•™ìŠµë¥ : {optimizer.param_groups[0]['lr']:.6f}")
        
        # ì—í¬í¬ë³„ ì§„í–‰ë¥  í‘œì‹œ
        progress_bar = "â–ˆ" * (ep * 20 // cfg.epochs) + "â–‘" * (20 - (ep * 20 // cfg.epochs))
        print(f"   ğŸ“Š ì§„í–‰ë¥ : [{progress_bar}] {ep}/{cfg.epochs} ({ep*100//cfg.epochs}%)")
        
        # í‰ê·  ì†ì‹¤ ì¶”ì´
        avg_train_so_far = total_train_loss / ep
        avg_val_so_far = total_val_loss / ep
        print(f"   ğŸ“Š ì „ì²´ í‰ê·  - í›ˆë ¨: {avg_train_so_far:.6f}, ê²€ì¦: {avg_val_so_far:.6f}")

        if val < best_val - 1e-6:
            best_val, no_improve = val, 0
            torch.save(model.state_dict(), cfg.save_path)   # â† bestë¥¼ .pthë¡œ ì €ì¥
            print(f"   ğŸ† NEW BEST! ê²€ì¦ Loss: {val:.6f} â†’ {cfg.save_path}")
        else:
            no_improve += 1
            print(f"   â³ ê°œì„  ì—†ìŒ ({no_improve}/{cfg.patience})")
            
            if no_improve >= cfg.patience:
                print(f"\nğŸ›‘ ì¡°ê¸° ì¢…ë£Œ! {cfg.patience} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                break

        print("-" * 60)

    # ìµœì¢… í›ˆë ¨ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
    print(f"   ğŸ† ìµœê³  ê²€ì¦ Loss: {best_val:.6f}")
    print(f"   ğŸ’¾ ëª¨ë¸ ì €ì¥: {cfg.save_path}")
    print(f"   ğŸ“Š ì „ì²´ í‰ê·  í›ˆë ¨ Loss: {total_train_loss/cfg.epochs:.6f}")
    print(f"   ğŸ“Š ì „ì²´ í‰ê·  ê²€ì¦ Loss: {total_val_loss/cfg.epochs:.6f}")
    print(f"   â±ï¸  ì´ í›ˆë ¨ ì—í¬í¬: {ep}")
    print("=" * 60)

if __name__ == "__main__":
    # ==== Configure & Train ====
    cfg = TrainConfig(
        dataset_root="./hologram_dataset_images_clean",  # â›³ï¸ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½
        degree_to_index={0:0, 90:0, 180:1, 270:2},     # 90Â°->0, 180Â°->1, 270Â°->2 (3ì±„ë„)
        target_degrees=(90,180,270),                     # 0Â° ì…ë ¥ â†’ 90/180/270 ì˜ˆì¸¡
        batch_size=16,                                   # ë°°ì¹˜ í¬ê¸° ì¦ê°€ (ì„±ëŠ¥ í–¥ìƒ)
        epochs=120,                                      # ì—í¬í¬ ì¦ê°€ (ë” ë§ì€ í•™ìŠµ)
        lr=2e-3,                                         # í•™ìŠµë¥  ì¦ê°€ (ë¹ ë¥¸ ìˆ˜ë ´)
        weight_decay=5e-5,                               # ê°€ì¤‘ì¹˜ ê°ì‡  ê°ì†Œ (ê³¼ì í•© ë°©ì§€í•˜ë©´ì„œ ì„±ëŠ¥ í–¥ìƒ)
        max_grad_norm=0.5,                               # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ ê°•í™”
        pct_start=0.1,                                   # CosineAnnealingWarmRestartsì—ì„œëŠ” ì‚¬ìš©ì•ˆí•¨
        num_workers=6,                                   # ì›Œì»¤ ìˆ˜ ì¦ê°€
        amp=True,
        seed=42,
        patience=20,                                     # ì¸ë‚´ì‹¬ ì¦ê°€ (ë” ë§ì€ ê¸°íšŒ)
        save_path="finch_3head_optimized.pth",          # ìµœì í™”ëœ ëª¨ë¸ëª…
    )
    print(cfg)
    train(cfg)
