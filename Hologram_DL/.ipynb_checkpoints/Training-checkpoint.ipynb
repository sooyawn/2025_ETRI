{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c42c35-b517-4e5c-8f79-033054decfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#현재 실행 중인 커널을 강제로 종료하는 명령어\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1aa2287-5a83-4baa-ac4d-dd1bb9690682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Import Libraries\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# 데이터 증강 및 전처리 설정 (수정)\n",
    "# 노이즈가 있는 환경에 강건하도록 다양한 증강 기법 추가\n",
    "phase_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.RandomHorizontalFlip(),  # 좌우 반전 추가\n",
    "    transforms.RandomVerticalFlip(),    # 상하 반전 추가\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b728a16-8585-4405-bec9-baf378973e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. Device Setup\n",
    "# =============================================================================\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Available device: {device}')\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae7c776-53fd-47cd-b269-61a2a441fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Custom Dataset Class\n",
    "# =============================================================================\n",
    "class HologramDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train'):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.samples = sorted([\n",
    "            os.path.join(self.root_dir, f) for f in os.listdir(self.root_dir)\n",
    "            if f.startswith('sample_')\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_path = self.samples[idx]\n",
    "\n",
    "        phases = []\n",
    "        for i in range(4):\n",
    "            p = os.path.join(sample_path, f'phase_{i}.png')\n",
    "            img = Image.open(p)\n",
    "\n",
    "            # (선택) 크기 통일이 필요하면 여기서 리사이즈\n",
    "            img = img.resize((256, 256), resample=Image.BILINEAR)\n",
    "\n",
    "            arr = np.array(img)\n",
    "    \n",
    "            # 만약 HxWx3 형태(실수로 컬러 저장)면 첫 채널만 사용\n",
    "            if arr.ndim == 3:\n",
    "                arr = arr[..., 0]\n",
    "\n",
    "            # dtype별 정규화\n",
    "            if arr.dtype == np.uint16:\n",
    "                arr = arr.astype(np.float32) / 65535.0\n",
    "            elif arr.dtype == np.uint8:\n",
    "                arr = arr.astype(np.float32) / 255.0\n",
    "            else:\n",
    "                arr = arr.astype(np.float32)  # 이미 0~1이면 그대로\n",
    "\n",
    "            phases.append(arr)\n",
    "\n",
    "        phases = np.stack(phases, axis=0).astype(np.float32)  # (4, H, W)\n",
    "\n",
    "        input_phase   = torch.from_numpy(phases[0:1])  # (1, H, W)\n",
    "        target_phases = torch.from_numpy(phases[1:])   # (3, H, W)\n",
    "        return input_phase, target_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6cf8af-717a-4875-bb3b-9f866b253eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. Model Architecture Components (stride=2, kernel=3x3 반영)\n",
    "# =============================================================================\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.GroupNorm(32,out_c),\n",
    "            nn.LeakyReLU(0.2, inplace=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=False),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),  # 🔹 업샘플 먼저\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, bias=False)  # 🔹 Conv2d로 후처리\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d803ed14-a458-44b1-b18e-b6d4480558c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. Main Model Architecture (stride=2 유지, 출력 크기 복원 포함)\n",
    "# =============================================================================\n",
    "class FINCH_DLPS_Net(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, 3, 2, 1, bias=False),\n",
    "            nn.GroupNorm(32, 64), nn.LeakyReLU(0.2, inplace=False)\n",
    "        )\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 2, 1, bias=False),\n",
    "            nn.GroupNorm(32, 128), nn.LeakyReLU(0.2, inplace=False)\n",
    "        )\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 2, 1, bias=False),\n",
    "            nn.GroupNorm(32, 256), nn.LeakyReLU(0.2, inplace=False)\n",
    "        )\n",
    "\n",
    "        self.dec1 = self._make_decoder()\n",
    "        self.dec2 = self._make_decoder()\n",
    "        self.dec3 = self._make_decoder()\n",
    "\n",
    "    def _make_decoder(self):\n",
    "        return nn.Sequential(\n",
    "            DecoderBlock(256, 128),                     # up1\n",
    "            EncoderBlock(256, 128),                     # conv1 (with skip)\n",
    "            DecoderBlock(128, 64),                      # up2\n",
    "            EncoderBlock(128, 64),                      # conv2 (with skip)\n",
    "            DecoderBlock(64, 64),                       # up3\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1), # final conv\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)  # (B, 64, H/2, W/2)\n",
    "        e2 = self.enc2(e1) # (B, 128, H/4, W/4)\n",
    "        e3 = self.enc3(e2) # (B, 256, H/8, W/8)\n",
    "\n",
    "        input_shape = x.shape[2:]  # (H, W)\n",
    "\n",
    "        d1 = self._decode(self.dec1, e1, e2, e3, input_shape)  # predict phase_1\n",
    "        d2 = self._decode(self.dec2, e1, e2, e3, input_shape)  # predict phase_2\n",
    "        d3 = self._decode(self.dec3, e1, e2, e3, input_shape)  # predict phase_3\n",
    "\n",
    "        return d1, d2, d3  # Each is (B, 1, H, W)\n",
    "\n",
    "    def _decode(self, dec, e1, e2, e3, input_shape):\n",
    "        x = dec[0](e3)                            # up to H/4\n",
    "        if x.shape[2:] != e2.shape[2:]:\n",
    "            x = F.interpolate(x, size=e2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x = dec[1](torch.cat([x, e2], dim=1))     # fuse\n",
    "\n",
    "        x = dec[2](x)                             # up to H/2\n",
    "        if x.shape[2:] != e1.shape[2:]:\n",
    "            x = F.interpolate(x, size=e1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x = dec[3](torch.cat([x, e1], dim=1))     # fuse\n",
    "\n",
    "        x = dec[4](x)                             # up to H\n",
    "        x = dec[5](x)                             # final 1ch\n",
    "        if x.shape[2:] != input_shape:\n",
    "            x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)\n",
    "        return x                                  # 🔸 linear 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2fa75a-d0df-4478-9672-ef835345a04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 완료:\n",
      "  - Train: 3500개 샘플\n",
      "  - Validation: 1000개 샘플\n",
      "  - Test: 500개 샘플\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. Data Loading and Preparation\n",
    "# =============================================================================\n",
    "# 홀로그램 데이터셋 로드\n",
    "dataset_root = 'hologram_dataset_images'\n",
    "batch_size = 10 # 홀로그램 데이터는 크기가 크므로 배치 크기 줄임\n",
    "\n",
    "train_dataset = HologramDataset(dataset_root, 'train')\n",
    "val_dataset = HologramDataset(dataset_root, 'validation')\n",
    "test_dataset = HologramDataset(dataset_root, 'test')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"데이터 로드 완료:\")\n",
    "print(f\"  - Train: {len(train_dataset)}개 샘플\")\n",
    "print(f\"  - Validation: {len(val_dataset)}개 샘플\")\n",
    "print(f\"  - Test: {len(test_dataset)}개 샘플\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95970d42-85fc-4f10-a191-b202cadfed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SSIM + RMSE + 위상 일관성 손실 함수\n",
    "# =============================================================================\n",
    "def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n",
    "    mu1 = F.avg_pool2d(img1, 3, 1, 1)\n",
    "    mu2 = F.avg_pool2d(img2, 3, 1, 1)\n",
    "    sigma1_sq = F.avg_pool2d(img1 * img1, 3, 1, 1) - mu1 ** 2\n",
    "    sigma2_sq = F.avg_pool2d(img2 * img2, 3, 1, 1) - mu2 ** 2\n",
    "    sigma12 = F.avg_pool2d(img1 * img2, 3, 1, 1) - mu1 * mu2\n",
    "    ssim_map = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "               ((mu1 ** 2 + mu2 ** 2 + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "    \n",
    "def improved_physics_loss(output1, target1, output2, target2, output3, target3, epoch=0):\n",
    "    eps = 1e-8\n",
    "\n",
    "    # --- RMSE 계산 ---\n",
    "    rmse1 = torch.sqrt(torch.mean((output1 - target1) ** 2) + eps)\n",
    "    rmse2 = torch.sqrt(torch.mean((output2 - target2) ** 2) + eps)\n",
    "    rmse3 = torch.sqrt(torch.mean((output3 - target3) ** 2) + eps)\n",
    "    base_rmse = (rmse1 + rmse2 + rmse3) /3\n",
    "\n",
    "    if epoch<10:\n",
    "        return base_rmse, {'rmse': base_rmse.item(), 'consistency':0, 'ssim':0,\n",
    "                           'weight_consistency':0, 'weight_ssim':0}\n",
    "\n",
    "    # --- 위상 일관성 손실 (phase consistency) ---\n",
    "    pred_diff_1 = output1 - output3\n",
    "    pred_diff_2 = output2 - output3\n",
    "    target_diff_1 = target1 - target3\n",
    "    target_diff_2 = target2 - target3\n",
    "    consistency_loss = F.mse_loss(pred_diff_1, target_diff_1) + F.mse_loss(pred_diff_2, target_diff_2)\n",
    "\n",
    "    # --- SSIM 손실 계산 ---\n",
    "    ssim_loss1 = 1 - ssim(output1, target1)\n",
    "    ssim_loss2 = 1 - ssim(output2, target2)\n",
    "    ssim_loss3 = 1 - ssim(output3, target3)\n",
    "    ssim_total = (ssim_loss1 + ssim_loss2 + ssim_loss3) / 3\n",
    "\n",
    "    consistency_weight = 0.01\n",
    "    ssim_weight = 0.1\n",
    "\n",
    "    # --- 총 loss ---\n",
    "    total_loss = base_rmse + consistency_weight * consistency_loss + ssim_weight * ssim_total\n",
    "\n",
    "    # --- NaN 방지 ---\n",
    "    if torch.isnan(total_loss):\n",
    "        total_loss = base_rmse\n",
    "\n",
    "    # --- 리턴 (loss + 상세정보) ---\n",
    "    return total_loss, {\n",
    "        'rmse': base_rmse.item(),\n",
    "        'consistency': consistency_loss.item(),\n",
    "        'ssim': ssim_total.item(),\n",
    "        'weight_consistency': consistency_weight,\n",
    "        'weight_ssim': ssim_weight\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b838053d-6736-4296-b2a2-809fcaf6b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용: cuda:0\n",
      "=== 설정 ===\n",
      "학습률: 0.001\n",
      "훈련 에포크: 80\n",
      "가중치 감소: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 모델 초기화 및 옵티마이저/스케줄러 설정\n",
    "# =============================================================================\n",
    "model = FINCH_DLPS_Net().to(device)\n",
    "print(f\"GPU 사용: {next(model.parameters()).device}\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 80\n",
    "weight_decay = 0.0001\n",
    "\n",
    "print(\"=== 설정 ===\")\n",
    "print(f\"학습률: {learning_rate}\")\n",
    "print(f\"훈련 에포크: {training_epochs}\")\n",
    "print(f\"가중치 감소: {weight_decay}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-8,\n",
    "    amsgrad=False\n",
    ")\n",
    "\n",
    "max_batches = len(train_loader)\n",
    "# 변경\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=2e-3,  # 최대로 올릴 학습률\n",
    "    steps_per_epoch=max_batches,\n",
    "    epochs=training_epochs,\n",
    "    pct_start=0.05, # 전체 학습의 10% 구간에서 최대 lr 도달\n",
    "    div_factor=5,\n",
    "    final_div_factor=200,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience_limit = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc7ec154-2ff9-47db-b384-6d0b039220ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수: 3500\n",
      "배치 크기: 10\n",
      "총 배치 개수: 100\n",
      "============================================================\n",
      "\n",
      "📊 Epoch 1/80 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24016\\1380335472.py:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24016\\1380335472.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 1/100] Loss: 0.4421 | RMSE: 0.4421 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 482200.812\n",
      "[Epoch 1, Batch 2/100] Loss: 0.3540 | RMSE: 0.3540 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 482134.750\n",
      "[Epoch 1, Batch 3/100] Loss: 0.2608 | RMSE: 0.2608 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 406817.969\n",
      "[Epoch 1, Batch 4/100] Loss: 0.2230 | RMSE: 0.2230 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 352501.125\n",
      "[Epoch 1, Batch 5/100] Loss: 0.1634 | RMSE: 0.1634 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 258773.078\n",
      "[Epoch 1, Batch 6/100] Loss: 0.1534 | RMSE: 0.1534 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 232451.188\n",
      "[Epoch 1, Batch 7/100] Loss: 0.1705 | RMSE: 0.1705 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 249075.953\n",
      "[Epoch 1, Batch 8/100] Loss: 0.1618 | RMSE: 0.1618 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 249701.281\n",
      "[Epoch 1, Batch 9/100] Loss: 0.1727 | RMSE: 0.1727 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 280285.844\n",
      "[Epoch 1, Batch 10/100] Loss: 0.1504 | RMSE: 0.1504 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 203285.156\n",
      "[Epoch 1, Batch 11/100] Loss: 0.1555 | RMSE: 0.1555 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 230619.453\n",
      "[Epoch 1, Batch 12/100] Loss: 0.1382 | RMSE: 0.1382 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125682.523\n",
      "[Epoch 1, Batch 13/100] Loss: 0.1281 | RMSE: 0.1281 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103971.133\n",
      "[Epoch 1, Batch 14/100] Loss: 0.1174 | RMSE: 0.1174 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139187.203\n",
      "[Epoch 1, Batch 15/100] Loss: 0.1278 | RMSE: 0.1278 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152701.359\n",
      "[Epoch 1, Batch 16/100] Loss: 0.1220 | RMSE: 0.1220 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158461.156\n",
      "[Epoch 1, Batch 17/100] Loss: 0.1169 | RMSE: 0.1169 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128845.070\n",
      "[Epoch 1, Batch 18/100] Loss: 0.1297 | RMSE: 0.1297 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134364.031\n",
      "[Epoch 1, Batch 19/100] Loss: 0.1246 | RMSE: 0.1246 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 176122.703\n",
      "[Epoch 1, Batch 20/100] Loss: 0.1224 | RMSE: 0.1224 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 99604.695\n",
      "[Epoch 1, Batch 21/100] Loss: 0.1231 | RMSE: 0.1231 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147595.000\n",
      "[Epoch 1, Batch 22/100] Loss: 0.1159 | RMSE: 0.1159 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 140040.109\n",
      "[Epoch 1, Batch 23/100] Loss: 0.1125 | RMSE: 0.1125 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143078.922\n",
      "[Epoch 1, Batch 24/100] Loss: 0.1257 | RMSE: 0.1257 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 107549.664\n",
      "[Epoch 1, Batch 25/100] Loss: 0.1113 | RMSE: 0.1113 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 180426.719\n",
      "[Epoch 1, Batch 26/100] Loss: 0.1147 | RMSE: 0.1147 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 66941.391\n",
      "[Epoch 1, Batch 27/100] Loss: 0.1166 | RMSE: 0.1166 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105394.492\n",
      "[Epoch 1, Batch 28/100] Loss: 0.1169 | RMSE: 0.1169 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 66931.859\n",
      "[Epoch 1, Batch 29/100] Loss: 0.1093 | RMSE: 0.1093 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79794.266\n",
      "[Epoch 1, Batch 30/100] Loss: 0.1198 | RMSE: 0.1198 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92052.398\n",
      "[Epoch 1, Batch 31/100] Loss: 0.1213 | RMSE: 0.1213 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143940.906\n",
      "[Epoch 1, Batch 32/100] Loss: 0.1122 | RMSE: 0.1122 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120478.172\n",
      "[Epoch 1, Batch 33/100] Loss: 0.1184 | RMSE: 0.1184 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95029.242\n",
      "[Epoch 1, Batch 34/100] Loss: 0.1034 | RMSE: 0.1034 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119736.562\n",
      "[Epoch 1, Batch 35/100] Loss: 0.1066 | RMSE: 0.1066 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 179669.047\n",
      "[Epoch 1, Batch 36/100] Loss: 0.1001 | RMSE: 0.1001 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87602.133\n",
      "[Epoch 1, Batch 37/100] Loss: 0.1035 | RMSE: 0.1035 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139450.078\n",
      "[Epoch 1, Batch 38/100] Loss: 0.1018 | RMSE: 0.1018 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109368.078\n",
      "[Epoch 1, Batch 39/100] Loss: 0.0993 | RMSE: 0.0993 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129237.797\n",
      "[Epoch 1, Batch 40/100] Loss: 0.1111 | RMSE: 0.1111 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 102259.555\n",
      "[Epoch 1, Batch 41/100] Loss: 0.1113 | RMSE: 0.1113 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 71201.906\n",
      "[Epoch 1, Batch 42/100] Loss: 0.1042 | RMSE: 0.1042 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 59513.062\n",
      "[Epoch 1, Batch 43/100] Loss: 0.1107 | RMSE: 0.1107 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 142122.703\n",
      "[Epoch 1, Batch 44/100] Loss: 0.0985 | RMSE: 0.0985 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 93276.086\n",
      "[Epoch 1, Batch 45/100] Loss: 0.1047 | RMSE: 0.1047 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85782.117\n",
      "[Epoch 1, Batch 46/100] Loss: 0.1077 | RMSE: 0.1077 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 165856.375\n",
      "[Epoch 1, Batch 47/100] Loss: 0.1089 | RMSE: 0.1089 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 141451.375\n",
      "[Epoch 1, Batch 48/100] Loss: 0.1012 | RMSE: 0.1012 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 167421.594\n",
      "[Epoch 1, Batch 49/100] Loss: 0.0967 | RMSE: 0.0967 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119022.133\n",
      "[Epoch 1, Batch 50/100] Loss: 0.1005 | RMSE: 0.1005 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103406.445\n",
      "[Epoch 1, Batch 51/100] Loss: 0.1055 | RMSE: 0.1055 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95115.320\n",
      "[Epoch 1, Batch 52/100] Loss: 0.1094 | RMSE: 0.1094 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146918.625\n",
      "[Epoch 1, Batch 53/100] Loss: 0.1022 | RMSE: 0.1022 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 99163.961\n",
      "[Epoch 1, Batch 54/100] Loss: 0.0989 | RMSE: 0.0989 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 63709.801\n",
      "[Epoch 1, Batch 55/100] Loss: 0.1061 | RMSE: 0.1061 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 187160.344\n",
      "[Epoch 1, Batch 56/100] Loss: 0.1044 | RMSE: 0.1044 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 74180.414\n",
      "[Epoch 1, Batch 57/100] Loss: 0.1020 | RMSE: 0.1020 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121143.195\n",
      "[Epoch 1, Batch 58/100] Loss: 0.1007 | RMSE: 0.1007 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143977.875\n",
      "[Epoch 1, Batch 59/100] Loss: 0.1011 | RMSE: 0.1011 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 93204.195\n",
      "[Epoch 1, Batch 60/100] Loss: 0.1124 | RMSE: 0.1124 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 142351.453\n",
      "[Epoch 1, Batch 61/100] Loss: 0.1030 | RMSE: 0.1030 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 199856.688\n",
      "[Epoch 1, Batch 62/100] Loss: 0.0974 | RMSE: 0.0974 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 110758.992\n",
      "[Epoch 1, Batch 63/100] Loss: 0.1094 | RMSE: 0.1094 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 204858.922\n",
      "[Epoch 1, Batch 64/100] Loss: 0.0912 | RMSE: 0.0912 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146461.156\n",
      "[Epoch 1, Batch 65/100] Loss: 0.1072 | RMSE: 0.1072 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147523.453\n",
      "[Epoch 1, Batch 66/100] Loss: 0.1008 | RMSE: 0.1008 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116747.336\n",
      "[Epoch 1, Batch 67/100] Loss: 0.1053 | RMSE: 0.1053 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 166131.391\n",
      "[Epoch 1, Batch 68/100] Loss: 0.1000 | RMSE: 0.1000 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150913.516\n",
      "[Epoch 1, Batch 69/100] Loss: 0.0999 | RMSE: 0.0999 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109255.469\n",
      "[Epoch 1, Batch 70/100] Loss: 0.1159 | RMSE: 0.1159 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 169645.781\n",
      "[Epoch 1, Batch 71/100] Loss: 0.1097 | RMSE: 0.1097 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126653.477\n",
      "[Epoch 1, Batch 72/100] Loss: 0.1037 | RMSE: 0.1037 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109552.469\n",
      "[Epoch 1, Batch 73/100] Loss: 0.0943 | RMSE: 0.0943 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103948.391\n",
      "[Epoch 1, Batch 74/100] Loss: 0.0971 | RMSE: 0.0971 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 135993.328\n",
      "[Epoch 1, Batch 75/100] Loss: 0.1159 | RMSE: 0.1159 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 123321.219\n",
      "[Epoch 1, Batch 76/100] Loss: 0.0991 | RMSE: 0.0991 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 164109.078\n",
      "[Epoch 1, Batch 77/100] Loss: 0.1002 | RMSE: 0.1002 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 162280.391\n",
      "[Epoch 1, Batch 78/100] Loss: 0.0831 | RMSE: 0.0831 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79410.148\n",
      "[Epoch 1, Batch 79/100] Loss: 0.0938 | RMSE: 0.0938 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 162410.016\n",
      "[Epoch 1, Batch 80/100] Loss: 0.1010 | RMSE: 0.1010 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134914.391\n",
      "[Epoch 1, Batch 81/100] Loss: 0.0956 | RMSE: 0.0956 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 74611.711\n",
      "[Epoch 1, Batch 82/100] Loss: 0.0917 | RMSE: 0.0917 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 51896.914\n",
      "[Epoch 1, Batch 83/100] Loss: 0.0978 | RMSE: 0.0978 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139242.828\n",
      "[Epoch 1, Batch 84/100] Loss: 0.0962 | RMSE: 0.0962 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150258.781\n",
      "[Epoch 1, Batch 85/100] Loss: 0.0959 | RMSE: 0.0959 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 189215.094\n",
      "[Epoch 1, Batch 86/100] Loss: 0.1015 | RMSE: 0.1015 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125823.828\n",
      "[Epoch 1, Batch 87/100] Loss: 0.0983 | RMSE: 0.0983 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 167111.984\n",
      "[Epoch 1, Batch 88/100] Loss: 0.0973 | RMSE: 0.0973 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 195465.438\n",
      "[Epoch 1, Batch 89/100] Loss: 0.0906 | RMSE: 0.0906 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 189952.469\n",
      "[Epoch 1, Batch 90/100] Loss: 0.0926 | RMSE: 0.0926 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 179304.719\n",
      "[Epoch 1, Batch 91/100] Loss: 0.1057 | RMSE: 0.1057 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 215351.844\n",
      "[Epoch 1, Batch 92/100] Loss: 0.0905 | RMSE: 0.0905 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 136138.281\n",
      "[Epoch 1, Batch 93/100] Loss: 0.0899 | RMSE: 0.0899 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121551.453\n",
      "[Epoch 1, Batch 94/100] Loss: 0.0936 | RMSE: 0.0936 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 159967.203\n",
      "[Epoch 1, Batch 95/100] Loss: 0.0910 | RMSE: 0.0910 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 153450.047\n",
      "[Epoch 1, Batch 96/100] Loss: 0.0747 | RMSE: 0.0747 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101032.719\n",
      "[Epoch 1, Batch 97/100] Loss: 0.0937 | RMSE: 0.0937 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116758.977\n",
      "[Epoch 1, Batch 98/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 172293.000\n",
      "[Epoch 1, Batch 99/100] Loss: 0.0966 | RMSE: 0.0966 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 159350.141\n",
      "[Epoch 1, Batch 100/100] Loss: 0.0987 | RMSE: 0.0987 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117294.523\n",
      "✅ Epoch 1 완료!\n",
      "   📈 평균 Loss: 0.117750\n",
      "   📊 평균 RMSE: 0.117750\n",
      "   ⚙️  학습률: 0.000077\n",
      "   🏆 NEW BEST! RMSE: 0.117750\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 2/80 시작...\n",
      "[Epoch 2, Batch 1/100] Loss: 0.0845 | RMSE: 0.0845 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79916.367\n",
      "[Epoch 2, Batch 2/100] Loss: 0.1018 | RMSE: 0.1018 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 68628.438\n",
      "[Epoch 2, Batch 3/100] Loss: 0.0969 | RMSE: 0.0969 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 90449.703\n",
      "[Epoch 2, Batch 4/100] Loss: 0.0909 | RMSE: 0.0909 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91397.273\n",
      "[Epoch 2, Batch 5/100] Loss: 0.0978 | RMSE: 0.0978 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 178516.156\n",
      "[Epoch 2, Batch 6/100] Loss: 0.0880 | RMSE: 0.0880 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125016.234\n",
      "[Epoch 2, Batch 7/100] Loss: 0.1007 | RMSE: 0.1007 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 149796.516\n",
      "[Epoch 2, Batch 8/100] Loss: 0.0990 | RMSE: 0.0990 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 151418.531\n",
      "[Epoch 2, Batch 9/100] Loss: 0.0946 | RMSE: 0.0946 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197156.031\n",
      "[Epoch 2, Batch 10/100] Loss: 0.0924 | RMSE: 0.0924 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92289.586\n",
      "[Epoch 2, Batch 11/100] Loss: 0.0900 | RMSE: 0.0900 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 50366.641\n",
      "[Epoch 2, Batch 12/100] Loss: 0.0958 | RMSE: 0.0958 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 135177.266\n",
      "[Epoch 2, Batch 13/100] Loss: 0.0989 | RMSE: 0.0989 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 171519.859\n",
      "[Epoch 2, Batch 14/100] Loss: 0.0896 | RMSE: 0.0896 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197440.875\n",
      "[Epoch 2, Batch 15/100] Loss: 0.0984 | RMSE: 0.0984 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116327.883\n",
      "[Epoch 2, Batch 16/100] Loss: 0.0841 | RMSE: 0.0841 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113099.555\n",
      "[Epoch 2, Batch 17/100] Loss: 0.0966 | RMSE: 0.0966 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 179498.000\n",
      "[Epoch 2, Batch 18/100] Loss: 0.0906 | RMSE: 0.0906 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108433.539\n",
      "[Epoch 2, Batch 19/100] Loss: 0.0786 | RMSE: 0.0786 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128022.242\n",
      "[Epoch 2, Batch 20/100] Loss: 0.0806 | RMSE: 0.0806 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95276.852\n",
      "[Epoch 2, Batch 21/100] Loss: 0.0934 | RMSE: 0.0934 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 140465.250\n",
      "[Epoch 2, Batch 22/100] Loss: 0.0960 | RMSE: 0.0960 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129576.688\n",
      "[Epoch 2, Batch 23/100] Loss: 0.0923 | RMSE: 0.0923 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130358.234\n",
      "[Epoch 2, Batch 24/100] Loss: 0.0864 | RMSE: 0.0864 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118172.883\n",
      "[Epoch 2, Batch 25/100] Loss: 0.0986 | RMSE: 0.0986 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 132683.797\n",
      "[Epoch 2, Batch 26/100] Loss: 0.0874 | RMSE: 0.0874 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85364.656\n",
      "[Epoch 2, Batch 27/100] Loss: 0.0940 | RMSE: 0.0940 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119570.719\n",
      "[Epoch 2, Batch 28/100] Loss: 0.0856 | RMSE: 0.0856 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 173276.172\n",
      "[Epoch 2, Batch 29/100] Loss: 0.0959 | RMSE: 0.0959 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148466.875\n",
      "[Epoch 2, Batch 30/100] Loss: 0.0910 | RMSE: 0.0910 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 169214.812\n",
      "[Epoch 2, Batch 31/100] Loss: 0.1004 | RMSE: 0.1004 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124294.438\n",
      "[Epoch 2, Batch 32/100] Loss: 0.0864 | RMSE: 0.0864 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121475.695\n",
      "[Epoch 2, Batch 33/100] Loss: 0.0859 | RMSE: 0.0859 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143022.094\n",
      "[Epoch 2, Batch 34/100] Loss: 0.0945 | RMSE: 0.0945 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 145458.516\n",
      "[Epoch 2, Batch 35/100] Loss: 0.0886 | RMSE: 0.0886 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 155242.859\n",
      "[Epoch 2, Batch 36/100] Loss: 0.0926 | RMSE: 0.0926 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125431.047\n",
      "[Epoch 2, Batch 37/100] Loss: 0.0918 | RMSE: 0.0918 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 173386.922\n",
      "[Epoch 2, Batch 38/100] Loss: 0.0933 | RMSE: 0.0933 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 217696.578\n",
      "[Epoch 2, Batch 39/100] Loss: 0.0796 | RMSE: 0.0796 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 168114.234\n",
      "[Epoch 2, Batch 40/100] Loss: 0.0919 | RMSE: 0.0919 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104752.422\n",
      "[Epoch 2, Batch 41/100] Loss: 0.0946 | RMSE: 0.0946 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152277.812\n",
      "[Epoch 2, Batch 42/100] Loss: 0.0952 | RMSE: 0.0952 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 221400.750\n",
      "[Epoch 2, Batch 43/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 202898.203\n",
      "[Epoch 2, Batch 44/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138580.734\n",
      "[Epoch 2, Batch 45/100] Loss: 0.0913 | RMSE: 0.0913 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197824.906\n",
      "[Epoch 2, Batch 46/100] Loss: 0.0950 | RMSE: 0.0950 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 225041.906\n",
      "[Epoch 2, Batch 47/100] Loss: 0.0926 | RMSE: 0.0926 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 240773.312\n",
      "[Epoch 2, Batch 48/100] Loss: 0.0938 | RMSE: 0.0938 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127014.195\n",
      "[Epoch 2, Batch 49/100] Loss: 0.0812 | RMSE: 0.0812 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103874.227\n",
      "[Epoch 2, Batch 50/100] Loss: 0.0972 | RMSE: 0.0972 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91545.656\n",
      "[Epoch 2, Batch 51/100] Loss: 0.0952 | RMSE: 0.0952 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 201565.641\n",
      "[Epoch 2, Batch 52/100] Loss: 0.0845 | RMSE: 0.0845 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128057.453\n",
      "[Epoch 2, Batch 53/100] Loss: 0.0933 | RMSE: 0.0933 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95610.906\n",
      "[Epoch 2, Batch 54/100] Loss: 0.0909 | RMSE: 0.0909 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120501.117\n",
      "[Epoch 2, Batch 55/100] Loss: 0.0965 | RMSE: 0.0965 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158463.016\n",
      "[Epoch 2, Batch 56/100] Loss: 0.0924 | RMSE: 0.0924 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108468.188\n",
      "[Epoch 2, Batch 57/100] Loss: 0.0864 | RMSE: 0.0864 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128886.086\n",
      "[Epoch 2, Batch 58/100] Loss: 0.1026 | RMSE: 0.1026 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 222787.750\n",
      "[Epoch 2, Batch 59/100] Loss: 0.1217 | RMSE: 0.1217 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 284149.406\n",
      "[Epoch 2, Batch 60/100] Loss: 0.0925 | RMSE: 0.0925 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 171573.125\n",
      "[Epoch 2, Batch 61/100] Loss: 0.0862 | RMSE: 0.0862 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158979.062\n",
      "[Epoch 2, Batch 62/100] Loss: 0.0940 | RMSE: 0.0940 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 176968.016\n",
      "[Epoch 2, Batch 63/100] Loss: 0.0980 | RMSE: 0.0980 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 164182.984\n",
      "[Epoch 2, Batch 64/100] Loss: 0.0970 | RMSE: 0.0970 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 174218.906\n",
      "[Epoch 2, Batch 65/100] Loss: 0.1016 | RMSE: 0.1016 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 177444.234\n",
      "[Epoch 2, Batch 66/100] Loss: 0.0933 | RMSE: 0.0933 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121947.734\n",
      "[Epoch 2, Batch 67/100] Loss: 0.0764 | RMSE: 0.0764 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126664.359\n",
      "[Epoch 2, Batch 68/100] Loss: 0.0884 | RMSE: 0.0884 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113817.562\n",
      "[Epoch 2, Batch 69/100] Loss: 0.0808 | RMSE: 0.0808 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 78384.102\n",
      "[Epoch 2, Batch 70/100] Loss: 0.0900 | RMSE: 0.0900 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 162781.078\n",
      "[Epoch 2, Batch 71/100] Loss: 0.0817 | RMSE: 0.0817 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 100338.305\n",
      "[Epoch 2, Batch 72/100] Loss: 0.0872 | RMSE: 0.0872 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111369.109\n",
      "[Epoch 2, Batch 73/100] Loss: 0.1021 | RMSE: 0.1021 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158735.078\n",
      "[Epoch 2, Batch 74/100] Loss: 0.0872 | RMSE: 0.0872 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 189955.109\n",
      "[Epoch 2, Batch 75/100] Loss: 0.0939 | RMSE: 0.0939 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 244127.281\n",
      "[Epoch 2, Batch 76/100] Loss: 0.0869 | RMSE: 0.0869 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126387.891\n",
      "[Epoch 2, Batch 77/100] Loss: 0.0884 | RMSE: 0.0884 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 107978.992\n",
      "[Epoch 2, Batch 78/100] Loss: 0.0877 | RMSE: 0.0877 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 58420.289\n",
      "[Epoch 2, Batch 79/100] Loss: 0.0867 | RMSE: 0.0867 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 163975.688\n",
      "[Epoch 2, Batch 80/100] Loss: 0.0989 | RMSE: 0.0989 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 225109.812\n",
      "[Epoch 2, Batch 81/100] Loss: 0.0892 | RMSE: 0.0892 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104146.398\n",
      "[Epoch 2, Batch 82/100] Loss: 0.0816 | RMSE: 0.0816 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85430.891\n",
      "[Epoch 2, Batch 83/100] Loss: 0.0847 | RMSE: 0.0847 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104526.750\n",
      "[Epoch 2, Batch 84/100] Loss: 0.0797 | RMSE: 0.0797 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 157099.750\n",
      "[Epoch 2, Batch 85/100] Loss: 0.0842 | RMSE: 0.0842 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124575.797\n",
      "[Epoch 2, Batch 86/100] Loss: 0.0913 | RMSE: 0.0913 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161258.875\n",
      "[Epoch 2, Batch 87/100] Loss: 0.0758 | RMSE: 0.0758 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97595.844\n",
      "[Epoch 2, Batch 88/100] Loss: 0.0928 | RMSE: 0.0928 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 203525.156\n",
      "[Epoch 2, Batch 89/100] Loss: 0.1021 | RMSE: 0.1021 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 191122.062\n",
      "[Epoch 2, Batch 90/100] Loss: 0.0978 | RMSE: 0.0978 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 173281.484\n",
      "[Epoch 2, Batch 91/100] Loss: 0.1046 | RMSE: 0.1046 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 210652.656\n",
      "[Epoch 2, Batch 92/100] Loss: 0.0978 | RMSE: 0.0978 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161955.906\n",
      "[Epoch 2, Batch 93/100] Loss: 0.0810 | RMSE: 0.0810 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126009.156\n",
      "[Epoch 2, Batch 94/100] Loss: 0.0906 | RMSE: 0.0906 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 145056.781\n",
      "[Epoch 2, Batch 95/100] Loss: 0.0987 | RMSE: 0.0987 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 191478.281\n",
      "[Epoch 2, Batch 96/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 178584.000\n",
      "[Epoch 2, Batch 97/100] Loss: 0.1035 | RMSE: 0.1035 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 241746.703\n",
      "[Epoch 2, Batch 98/100] Loss: 0.0914 | RMSE: 0.0914 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 133756.500\n",
      "[Epoch 2, Batch 99/100] Loss: 0.0886 | RMSE: 0.0886 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158907.641\n",
      "[Epoch 2, Batch 100/100] Loss: 0.0883 | RMSE: 0.0883 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152802.281\n",
      "✅ Epoch 2 완료!\n",
      "   📈 평균 Loss: 0.091708\n",
      "   📊 평균 RMSE: 0.091708\n",
      "   ⚙️  학습률: 0.000181\n",
      "   🏆 NEW BEST! RMSE: 0.091708\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 3/80 시작...\n",
      "[Epoch 3, Batch 1/100] Loss: 0.1013 | RMSE: 0.1013 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 211374.531\n",
      "[Epoch 3, Batch 2/100] Loss: 0.0870 | RMSE: 0.0870 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 217220.656\n",
      "[Epoch 3, Batch 3/100] Loss: 0.0908 | RMSE: 0.0908 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129354.938\n",
      "[Epoch 3, Batch 4/100] Loss: 0.0909 | RMSE: 0.0909 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146319.953\n",
      "[Epoch 3, Batch 5/100] Loss: 0.0827 | RMSE: 0.0827 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111891.164\n",
      "[Epoch 3, Batch 6/100] Loss: 0.0887 | RMSE: 0.0887 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 175595.703\n",
      "[Epoch 3, Batch 7/100] Loss: 0.0901 | RMSE: 0.0901 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 182058.859\n",
      "[Epoch 3, Batch 8/100] Loss: 0.0863 | RMSE: 0.0863 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 183312.438\n",
      "[Epoch 3, Batch 9/100] Loss: 0.0962 | RMSE: 0.0962 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 164833.078\n",
      "[Epoch 3, Batch 10/100] Loss: 0.0727 | RMSE: 0.0727 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 151058.703\n",
      "[Epoch 3, Batch 11/100] Loss: 0.0714 | RMSE: 0.0714 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 82527.750\n",
      "[Epoch 3, Batch 12/100] Loss: 0.0872 | RMSE: 0.0872 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130162.758\n",
      "[Epoch 3, Batch 13/100] Loss: 0.0832 | RMSE: 0.0832 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 110526.547\n",
      "[Epoch 3, Batch 14/100] Loss: 0.0910 | RMSE: 0.0910 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104721.500\n",
      "[Epoch 3, Batch 15/100] Loss: 0.0907 | RMSE: 0.0907 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170183.594\n",
      "[Epoch 3, Batch 16/100] Loss: 0.0844 | RMSE: 0.0844 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 162561.359\n",
      "[Epoch 3, Batch 17/100] Loss: 0.0908 | RMSE: 0.0908 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118975.328\n",
      "[Epoch 3, Batch 18/100] Loss: 0.0878 | RMSE: 0.0878 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 83624.586\n",
      "[Epoch 3, Batch 19/100] Loss: 0.0859 | RMSE: 0.0859 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129711.039\n",
      "[Epoch 3, Batch 20/100] Loss: 0.0858 | RMSE: 0.0858 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148345.688\n",
      "[Epoch 3, Batch 21/100] Loss: 0.0841 | RMSE: 0.0841 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150623.484\n",
      "[Epoch 3, Batch 22/100] Loss: 0.0858 | RMSE: 0.0858 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 142337.797\n",
      "[Epoch 3, Batch 23/100] Loss: 0.0891 | RMSE: 0.0891 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150337.500\n",
      "[Epoch 3, Batch 24/100] Loss: 0.0842 | RMSE: 0.0842 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 106955.406\n",
      "[Epoch 3, Batch 25/100] Loss: 0.0795 | RMSE: 0.0795 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 168527.531\n",
      "[Epoch 3, Batch 26/100] Loss: 0.1015 | RMSE: 0.1015 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170559.641\n",
      "[Epoch 3, Batch 27/100] Loss: 0.0936 | RMSE: 0.0936 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197805.312\n",
      "[Epoch 3, Batch 28/100] Loss: 0.0967 | RMSE: 0.0967 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146929.422\n",
      "[Epoch 3, Batch 29/100] Loss: 0.0937 | RMSE: 0.0937 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143775.297\n",
      "[Epoch 3, Batch 30/100] Loss: 0.0999 | RMSE: 0.0999 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170617.375\n",
      "[Epoch 3, Batch 31/100] Loss: 0.0837 | RMSE: 0.0837 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 171078.094\n",
      "[Epoch 3, Batch 32/100] Loss: 0.0941 | RMSE: 0.0941 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 164382.531\n",
      "[Epoch 3, Batch 33/100] Loss: 0.0932 | RMSE: 0.0932 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 131425.641\n",
      "[Epoch 3, Batch 34/100] Loss: 0.0925 | RMSE: 0.0925 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197238.406\n",
      "[Epoch 3, Batch 35/100] Loss: 0.0977 | RMSE: 0.0977 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 167734.125\n",
      "[Epoch 3, Batch 36/100] Loss: 0.0892 | RMSE: 0.0892 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 206407.312\n",
      "[Epoch 3, Batch 37/100] Loss: 0.0855 | RMSE: 0.0855 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 190686.516\n",
      "[Epoch 3, Batch 38/100] Loss: 0.0813 | RMSE: 0.0813 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 57302.129\n",
      "[Epoch 3, Batch 39/100] Loss: 0.0856 | RMSE: 0.0856 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 196304.844\n",
      "[Epoch 3, Batch 40/100] Loss: 0.0911 | RMSE: 0.0911 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 180816.906\n",
      "[Epoch 3, Batch 41/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 163191.031\n",
      "[Epoch 3, Batch 42/100] Loss: 0.0922 | RMSE: 0.0922 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150504.484\n",
      "[Epoch 3, Batch 43/100] Loss: 0.1026 | RMSE: 0.1026 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 198426.906\n",
      "[Epoch 3, Batch 44/100] Loss: 0.0934 | RMSE: 0.0934 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 189990.922\n",
      "[Epoch 3, Batch 45/100] Loss: 0.0905 | RMSE: 0.0905 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129383.469\n",
      "[Epoch 3, Batch 46/100] Loss: 0.0834 | RMSE: 0.0834 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128213.648\n",
      "[Epoch 3, Batch 47/100] Loss: 0.0902 | RMSE: 0.0902 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 141340.328\n",
      "[Epoch 3, Batch 48/100] Loss: 0.0898 | RMSE: 0.0898 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 258802.781\n",
      "[Epoch 3, Batch 49/100] Loss: 0.0905 | RMSE: 0.0905 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 202199.062\n",
      "[Epoch 3, Batch 50/100] Loss: 0.0948 | RMSE: 0.0948 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 211390.719\n",
      "[Epoch 3, Batch 51/100] Loss: 0.0958 | RMSE: 0.0958 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 232663.297\n",
      "[Epoch 3, Batch 52/100] Loss: 0.0887 | RMSE: 0.0887 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 151862.828\n",
      "[Epoch 3, Batch 53/100] Loss: 0.0970 | RMSE: 0.0970 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 165457.062\n",
      "[Epoch 3, Batch 54/100] Loss: 0.0771 | RMSE: 0.0771 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 174967.375\n",
      "[Epoch 3, Batch 55/100] Loss: 0.0923 | RMSE: 0.0923 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 203458.328\n",
      "[Epoch 3, Batch 56/100] Loss: 0.0865 | RMSE: 0.0865 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 144839.031\n",
      "[Epoch 3, Batch 57/100] Loss: 0.0769 | RMSE: 0.0769 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146929.344\n",
      "[Epoch 3, Batch 58/100] Loss: 0.0888 | RMSE: 0.0888 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127799.094\n",
      "[Epoch 3, Batch 59/100] Loss: 0.0817 | RMSE: 0.0817 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158627.984\n",
      "[Epoch 3, Batch 60/100] Loss: 0.0891 | RMSE: 0.0891 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156434.984\n",
      "[Epoch 3, Batch 61/100] Loss: 0.0968 | RMSE: 0.0968 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 237623.797\n",
      "[Epoch 3, Batch 62/100] Loss: 0.0891 | RMSE: 0.0891 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 225489.703\n",
      "[Epoch 3, Batch 63/100] Loss: 0.0953 | RMSE: 0.0953 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 177210.500\n",
      "[Epoch 3, Batch 64/100] Loss: 0.0749 | RMSE: 0.0749 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 166178.125\n",
      "[Epoch 3, Batch 65/100] Loss: 0.0800 | RMSE: 0.0800 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170456.656\n",
      "[Epoch 3, Batch 66/100] Loss: 0.0806 | RMSE: 0.0806 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 172642.094\n",
      "[Epoch 3, Batch 67/100] Loss: 0.1015 | RMSE: 0.1015 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 214517.453\n",
      "[Epoch 3, Batch 68/100] Loss: 0.0881 | RMSE: 0.0881 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 200997.422\n",
      "[Epoch 3, Batch 69/100] Loss: 0.0803 | RMSE: 0.0803 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114929.711\n",
      "[Epoch 3, Batch 70/100] Loss: 0.0841 | RMSE: 0.0841 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124584.594\n",
      "[Epoch 3, Batch 71/100] Loss: 0.0916 | RMSE: 0.0916 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 195673.234\n",
      "[Epoch 3, Batch 72/100] Loss: 0.0810 | RMSE: 0.0810 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138317.547\n",
      "[Epoch 3, Batch 73/100] Loss: 0.0741 | RMSE: 0.0741 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 84866.352\n",
      "[Epoch 3, Batch 74/100] Loss: 0.0827 | RMSE: 0.0827 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 145227.672\n",
      "[Epoch 3, Batch 75/100] Loss: 0.0803 | RMSE: 0.0803 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 149642.625\n",
      "[Epoch 3, Batch 76/100] Loss: 0.0865 | RMSE: 0.0865 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87429.086\n",
      "[Epoch 3, Batch 77/100] Loss: 0.0897 | RMSE: 0.0897 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138716.578\n",
      "[Epoch 3, Batch 78/100] Loss: 0.0794 | RMSE: 0.0794 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 141269.297\n",
      "[Epoch 3, Batch 79/100] Loss: 0.0826 | RMSE: 0.0826 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 149961.219\n",
      "[Epoch 3, Batch 80/100] Loss: 0.0801 | RMSE: 0.0801 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137739.422\n",
      "[Epoch 3, Batch 81/100] Loss: 0.0947 | RMSE: 0.0947 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 200070.219\n",
      "[Epoch 3, Batch 82/100] Loss: 0.0823 | RMSE: 0.0823 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 166313.250\n",
      "[Epoch 3, Batch 83/100] Loss: 0.0812 | RMSE: 0.0812 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 88129.602\n",
      "[Epoch 3, Batch 84/100] Loss: 0.0751 | RMSE: 0.0751 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 208074.969\n",
      "[Epoch 3, Batch 85/100] Loss: 0.0949 | RMSE: 0.0949 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 220522.469\n",
      "[Epoch 3, Batch 86/100] Loss: 0.0798 | RMSE: 0.0798 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139400.172\n",
      "[Epoch 3, Batch 87/100] Loss: 0.0781 | RMSE: 0.0781 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125905.477\n",
      "[Epoch 3, Batch 88/100] Loss: 0.0888 | RMSE: 0.0888 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 98980.711\n",
      "[Epoch 3, Batch 89/100] Loss: 0.0809 | RMSE: 0.0809 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 199219.297\n",
      "[Epoch 3, Batch 90/100] Loss: 0.0784 | RMSE: 0.0784 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 177081.578\n",
      "[Epoch 3, Batch 91/100] Loss: 0.0861 | RMSE: 0.0861 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 55185.551\n",
      "[Epoch 3, Batch 92/100] Loss: 0.0821 | RMSE: 0.0821 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 180569.531\n",
      "[Epoch 3, Batch 93/100] Loss: 0.0914 | RMSE: 0.0914 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 194433.672\n",
      "[Epoch 3, Batch 94/100] Loss: 0.0839 | RMSE: 0.0839 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120873.820\n",
      "[Epoch 3, Batch 95/100] Loss: 0.0828 | RMSE: 0.0828 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 206201.422\n",
      "[Epoch 3, Batch 96/100] Loss: 0.0790 | RMSE: 0.0790 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91557.203\n",
      "[Epoch 3, Batch 97/100] Loss: 0.0728 | RMSE: 0.0728 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152758.172\n",
      "[Epoch 3, Batch 98/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 212219.469\n",
      "[Epoch 3, Batch 99/100] Loss: 0.0759 | RMSE: 0.0759 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 140553.453\n",
      "[Epoch 3, Batch 100/100] Loss: 0.0774 | RMSE: 0.0774 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128706.398\n",
      "✅ Epoch 3 완료!\n",
      "   📈 평균 Loss: 0.086912\n",
      "   📊 평균 RMSE: 0.086912\n",
      "   ⚙️  학습률: 0.000337\n",
      "   🏆 NEW BEST! RMSE: 0.086912\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 4/80 시작...\n",
      "[Epoch 4, Batch 1/100] Loss: 0.0768 | RMSE: 0.0768 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 149890.828\n",
      "[Epoch 4, Batch 2/100] Loss: 0.0759 | RMSE: 0.0759 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143688.109\n",
      "[Epoch 4, Batch 3/100] Loss: 0.0774 | RMSE: 0.0774 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 163658.219\n",
      "[Epoch 4, Batch 4/100] Loss: 0.0778 | RMSE: 0.0778 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 160097.156\n",
      "[Epoch 4, Batch 5/100] Loss: 0.0777 | RMSE: 0.0777 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 202020.891\n",
      "[Epoch 4, Batch 6/100] Loss: 0.0763 | RMSE: 0.0763 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 172228.625\n",
      "[Epoch 4, Batch 7/100] Loss: 0.0892 | RMSE: 0.0892 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 253189.719\n",
      "[Epoch 4, Batch 8/100] Loss: 0.0853 | RMSE: 0.0853 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 200326.562\n",
      "[Epoch 4, Batch 9/100] Loss: 0.0773 | RMSE: 0.0773 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 131135.312\n",
      "[Epoch 4, Batch 10/100] Loss: 0.0882 | RMSE: 0.0882 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 198732.766\n",
      "[Epoch 4, Batch 11/100] Loss: 0.0889 | RMSE: 0.0889 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 182818.688\n",
      "[Epoch 4, Batch 12/100] Loss: 0.0887 | RMSE: 0.0887 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121145.023\n",
      "[Epoch 4, Batch 13/100] Loss: 0.0823 | RMSE: 0.0823 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156672.000\n",
      "[Epoch 4, Batch 14/100] Loss: 0.0833 | RMSE: 0.0833 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 149214.672\n",
      "[Epoch 4, Batch 15/100] Loss: 0.0988 | RMSE: 0.0988 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 247673.656\n",
      "[Epoch 4, Batch 16/100] Loss: 0.0971 | RMSE: 0.0971 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 175736.031\n",
      "[Epoch 4, Batch 17/100] Loss: 0.0940 | RMSE: 0.0940 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 174519.453\n",
      "[Epoch 4, Batch 18/100] Loss: 0.0955 | RMSE: 0.0955 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122108.914\n",
      "[Epoch 4, Batch 19/100] Loss: 0.0710 | RMSE: 0.0710 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143442.453\n",
      "[Epoch 4, Batch 20/100] Loss: 0.0831 | RMSE: 0.0831 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 163843.500\n",
      "[Epoch 4, Batch 21/100] Loss: 0.0772 | RMSE: 0.0772 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 142577.703\n",
      "[Epoch 4, Batch 22/100] Loss: 0.0836 | RMSE: 0.0836 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 176367.031\n",
      "[Epoch 4, Batch 23/100] Loss: 0.0769 | RMSE: 0.0769 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 188829.703\n",
      "[Epoch 4, Batch 24/100] Loss: 0.0831 | RMSE: 0.0831 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134789.156\n",
      "[Epoch 4, Batch 25/100] Loss: 0.0841 | RMSE: 0.0841 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 159732.875\n",
      "[Epoch 4, Batch 26/100] Loss: 0.0872 | RMSE: 0.0872 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 153520.828\n",
      "[Epoch 4, Batch 27/100] Loss: 0.0819 | RMSE: 0.0819 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 190218.516\n",
      "[Epoch 4, Batch 28/100] Loss: 0.0813 | RMSE: 0.0813 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120428.312\n",
      "[Epoch 4, Batch 29/100] Loss: 0.0826 | RMSE: 0.0826 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148128.875\n",
      "[Epoch 4, Batch 30/100] Loss: 0.0966 | RMSE: 0.0966 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 173523.891\n",
      "[Epoch 4, Batch 31/100] Loss: 0.0789 | RMSE: 0.0789 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 186435.750\n",
      "[Epoch 4, Batch 32/100] Loss: 0.0840 | RMSE: 0.0840 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 89528.070\n",
      "[Epoch 4, Batch 33/100] Loss: 0.0859 | RMSE: 0.0859 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 195333.469\n",
      "[Epoch 4, Batch 34/100] Loss: 0.0891 | RMSE: 0.0891 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 165735.750\n",
      "[Epoch 4, Batch 35/100] Loss: 0.0853 | RMSE: 0.0853 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 204909.547\n",
      "[Epoch 4, Batch 36/100] Loss: 0.0878 | RMSE: 0.0878 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154349.609\n",
      "[Epoch 4, Batch 37/100] Loss: 0.0905 | RMSE: 0.0905 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 188879.281\n",
      "[Epoch 4, Batch 38/100] Loss: 0.1051 | RMSE: 0.1051 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 254867.031\n",
      "[Epoch 4, Batch 39/100] Loss: 0.0916 | RMSE: 0.0916 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138370.766\n",
      "[Epoch 4, Batch 40/100] Loss: 0.0962 | RMSE: 0.0962 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 205736.203\n",
      "[Epoch 4, Batch 41/100] Loss: 0.0954 | RMSE: 0.0954 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 234849.906\n",
      "[Epoch 4, Batch 42/100] Loss: 0.0878 | RMSE: 0.0878 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 195632.516\n",
      "[Epoch 4, Batch 43/100] Loss: 0.0904 | RMSE: 0.0904 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 166450.328\n",
      "[Epoch 4, Batch 44/100] Loss: 0.0915 | RMSE: 0.0915 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 229956.953\n",
      "[Epoch 4, Batch 45/100] Loss: 0.0787 | RMSE: 0.0787 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 204988.750\n",
      "[Epoch 4, Batch 46/100] Loss: 0.0898 | RMSE: 0.0898 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 252735.188\n",
      "[Epoch 4, Batch 47/100] Loss: 0.0781 | RMSE: 0.0781 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158318.641\n",
      "[Epoch 4, Batch 48/100] Loss: 0.0902 | RMSE: 0.0902 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 189818.344\n",
      "[Epoch 4, Batch 49/100] Loss: 0.0869 | RMSE: 0.0869 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138715.250\n",
      "[Epoch 4, Batch 50/100] Loss: 0.0901 | RMSE: 0.0901 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 144674.266\n",
      "[Epoch 4, Batch 51/100] Loss: 0.0821 | RMSE: 0.0821 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 195913.438\n",
      "[Epoch 4, Batch 52/100] Loss: 0.0885 | RMSE: 0.0885 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 217739.719\n",
      "[Epoch 4, Batch 53/100] Loss: 0.0744 | RMSE: 0.0744 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79818.844\n",
      "[Epoch 4, Batch 54/100] Loss: 0.0945 | RMSE: 0.0945 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 207226.188\n",
      "[Epoch 4, Batch 55/100] Loss: 0.0854 | RMSE: 0.0854 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 153108.109\n",
      "[Epoch 4, Batch 56/100] Loss: 0.0715 | RMSE: 0.0715 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170838.484\n",
      "[Epoch 4, Batch 57/100] Loss: 0.0698 | RMSE: 0.0698 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 131592.359\n",
      "[Epoch 4, Batch 58/100] Loss: 0.0829 | RMSE: 0.0829 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150796.953\n",
      "[Epoch 4, Batch 59/100] Loss: 0.0878 | RMSE: 0.0878 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 186978.844\n",
      "[Epoch 4, Batch 60/100] Loss: 0.0960 | RMSE: 0.0960 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 179923.453\n",
      "[Epoch 4, Batch 61/100] Loss: 0.0846 | RMSE: 0.0846 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 184579.328\n",
      "[Epoch 4, Batch 62/100] Loss: 0.0935 | RMSE: 0.0935 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 233955.156\n",
      "[Epoch 4, Batch 63/100] Loss: 0.0850 | RMSE: 0.0850 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197143.391\n",
      "[Epoch 4, Batch 64/100] Loss: 0.0782 | RMSE: 0.0782 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 164478.922\n",
      "[Epoch 4, Batch 65/100] Loss: 0.0735 | RMSE: 0.0735 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 202014.625\n",
      "[Epoch 4, Batch 66/100] Loss: 0.0638 | RMSE: 0.0638 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 84946.039\n",
      "[Epoch 4, Batch 67/100] Loss: 0.0860 | RMSE: 0.0860 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 196417.859\n",
      "[Epoch 4, Batch 68/100] Loss: 0.0730 | RMSE: 0.0730 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 98120.641\n",
      "[Epoch 4, Batch 69/100] Loss: 0.0856 | RMSE: 0.0856 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 185252.938\n",
      "[Epoch 4, Batch 70/100] Loss: 0.0913 | RMSE: 0.0913 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 206487.984\n",
      "[Epoch 4, Batch 71/100] Loss: 0.0792 | RMSE: 0.0792 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126319.305\n",
      "[Epoch 4, Batch 72/100] Loss: 0.0756 | RMSE: 0.0756 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150765.531\n",
      "[Epoch 4, Batch 73/100] Loss: 0.0808 | RMSE: 0.0808 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170051.812\n",
      "[Epoch 4, Batch 74/100] Loss: 0.1024 | RMSE: 0.1024 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 236564.969\n",
      "[Epoch 4, Batch 75/100] Loss: 0.0754 | RMSE: 0.0754 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154927.281\n",
      "[Epoch 4, Batch 76/100] Loss: 0.0859 | RMSE: 0.0859 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 167659.938\n",
      "[Epoch 4, Batch 77/100] Loss: 0.1090 | RMSE: 0.1090 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 194254.141\n",
      "[Epoch 4, Batch 78/100] Loss: 0.1019 | RMSE: 0.1019 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 167878.188\n",
      "[Epoch 4, Batch 79/100] Loss: 0.0890 | RMSE: 0.0890 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137085.188\n",
      "[Epoch 4, Batch 80/100] Loss: 0.0802 | RMSE: 0.0802 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161743.031\n",
      "[Epoch 4, Batch 81/100] Loss: 0.0827 | RMSE: 0.0827 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 155973.938\n",
      "[Epoch 4, Batch 82/100] Loss: 0.0865 | RMSE: 0.0865 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 169169.125\n",
      "[Epoch 4, Batch 83/100] Loss: 0.0828 | RMSE: 0.0828 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 182915.031\n",
      "[Epoch 4, Batch 84/100] Loss: 0.0824 | RMSE: 0.0824 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 136357.938\n",
      "[Epoch 4, Batch 85/100] Loss: 0.0860 | RMSE: 0.0860 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156414.875\n",
      "[Epoch 4, Batch 86/100] Loss: 0.0817 | RMSE: 0.0817 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129893.797\n",
      "[Epoch 4, Batch 87/100] Loss: 0.0829 | RMSE: 0.0829 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150403.672\n",
      "[Epoch 4, Batch 88/100] Loss: 0.0749 | RMSE: 0.0749 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154914.156\n",
      "[Epoch 4, Batch 89/100] Loss: 0.0809 | RMSE: 0.0809 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115673.773\n",
      "[Epoch 4, Batch 90/100] Loss: 0.0828 | RMSE: 0.0828 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 177286.344\n",
      "[Epoch 4, Batch 91/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170735.641\n",
      "[Epoch 4, Batch 92/100] Loss: 0.0774 | RMSE: 0.0774 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154328.703\n",
      "[Epoch 4, Batch 93/100] Loss: 0.0814 | RMSE: 0.0814 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143094.375\n",
      "[Epoch 4, Batch 94/100] Loss: 0.0950 | RMSE: 0.0950 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 200221.656\n",
      "[Epoch 4, Batch 95/100] Loss: 0.0913 | RMSE: 0.0913 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 183368.203\n",
      "[Epoch 4, Batch 96/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 178323.016\n",
      "[Epoch 4, Batch 97/100] Loss: 0.1031 | RMSE: 0.1031 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 220400.812\n",
      "[Epoch 4, Batch 98/100] Loss: 0.0888 | RMSE: 0.0888 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154242.922\n",
      "[Epoch 4, Batch 99/100] Loss: 0.0933 | RMSE: 0.0933 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161024.031\n",
      "[Epoch 4, Batch 100/100] Loss: 0.1127 | RMSE: 0.1127 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 235839.812\n",
      "✅ Epoch 4 완료!\n",
      "   📈 평균 Loss: 0.085559\n",
      "   📊 평균 RMSE: 0.085559\n",
      "   ⚙️  학습률: 0.000521\n",
      "   🏆 NEW BEST! RMSE: 0.085559\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 5/80 시작...\n",
      "[Epoch 5, Batch 1/100] Loss: 0.1045 | RMSE: 0.1045 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 181933.500\n",
      "[Epoch 5, Batch 2/100] Loss: 0.1030 | RMSE: 0.1030 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 219443.609\n",
      "[Epoch 5, Batch 3/100] Loss: 0.0878 | RMSE: 0.0878 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 186510.906\n",
      "[Epoch 5, Batch 4/100] Loss: 0.0893 | RMSE: 0.0893 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 162869.219\n",
      "[Epoch 5, Batch 5/100] Loss: 0.0787 | RMSE: 0.0787 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 163997.344\n",
      "[Epoch 5, Batch 6/100] Loss: 0.0732 | RMSE: 0.0732 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 141519.109\n",
      "[Epoch 5, Batch 7/100] Loss: 0.0938 | RMSE: 0.0938 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 205229.328\n",
      "[Epoch 5, Batch 8/100] Loss: 0.0653 | RMSE: 0.0653 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103956.422\n",
      "[Epoch 5, Batch 9/100] Loss: 0.0914 | RMSE: 0.0914 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197146.703\n",
      "[Epoch 5, Batch 10/100] Loss: 0.0898 | RMSE: 0.0898 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 197393.922\n",
      "[Epoch 5, Batch 11/100] Loss: 0.0763 | RMSE: 0.0763 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109047.992\n",
      "[Epoch 5, Batch 12/100] Loss: 0.0883 | RMSE: 0.0883 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152248.031\n",
      "[Epoch 5, Batch 13/100] Loss: 0.0900 | RMSE: 0.0900 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170645.422\n",
      "[Epoch 5, Batch 14/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 123023.211\n",
      "[Epoch 5, Batch 15/100] Loss: 0.0811 | RMSE: 0.0811 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 160507.844\n",
      "[Epoch 5, Batch 16/100] Loss: 0.0803 | RMSE: 0.0803 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119172.312\n",
      "[Epoch 5, Batch 17/100] Loss: 0.0881 | RMSE: 0.0881 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 174703.156\n",
      "[Epoch 5, Batch 18/100] Loss: 0.0755 | RMSE: 0.0755 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 83817.594\n",
      "[Epoch 5, Batch 19/100] Loss: 0.0857 | RMSE: 0.0857 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 169196.641\n",
      "[Epoch 5, Batch 20/100] Loss: 0.0793 | RMSE: 0.0793 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152775.203\n",
      "[Epoch 5, Batch 21/100] Loss: 0.0725 | RMSE: 0.0725 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 123061.203\n",
      "[Epoch 5, Batch 22/100] Loss: 0.0765 | RMSE: 0.0765 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 100909.594\n",
      "[Epoch 5, Batch 23/100] Loss: 0.0704 | RMSE: 0.0704 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127319.703\n",
      "[Epoch 5, Batch 24/100] Loss: 0.0743 | RMSE: 0.0743 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134913.094\n",
      "[Epoch 5, Batch 25/100] Loss: 0.0978 | RMSE: 0.0978 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 183428.375\n",
      "[Epoch 5, Batch 26/100] Loss: 0.0712 | RMSE: 0.0712 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126435.766\n",
      "[Epoch 5, Batch 27/100] Loss: 0.0802 | RMSE: 0.0802 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 63076.363\n",
      "[Epoch 5, Batch 28/100] Loss: 0.0751 | RMSE: 0.0751 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 160518.516\n",
      "[Epoch 5, Batch 29/100] Loss: 0.0798 | RMSE: 0.0798 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150415.953\n",
      "[Epoch 5, Batch 30/100] Loss: 0.0716 | RMSE: 0.0716 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103153.352\n",
      "[Epoch 5, Batch 31/100] Loss: 0.0904 | RMSE: 0.0904 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 180647.266\n",
      "[Epoch 5, Batch 32/100] Loss: 0.0802 | RMSE: 0.0802 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130179.977\n",
      "[Epoch 5, Batch 33/100] Loss: 0.0780 | RMSE: 0.0780 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115476.398\n",
      "[Epoch 5, Batch 34/100] Loss: 0.0868 | RMSE: 0.0868 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 89123.219\n",
      "[Epoch 5, Batch 35/100] Loss: 0.0786 | RMSE: 0.0786 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127880.766\n",
      "[Epoch 5, Batch 36/100] Loss: 0.0741 | RMSE: 0.0741 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128484.961\n",
      "[Epoch 5, Batch 37/100] Loss: 0.0801 | RMSE: 0.0801 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 174084.188\n",
      "[Epoch 5, Batch 38/100] Loss: 0.0827 | RMSE: 0.0827 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 153828.875\n",
      "[Epoch 5, Batch 39/100] Loss: 0.0796 | RMSE: 0.0796 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103077.234\n",
      "[Epoch 5, Batch 40/100] Loss: 0.0734 | RMSE: 0.0734 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87176.648\n",
      "[Epoch 5, Batch 41/100] Loss: 0.0703 | RMSE: 0.0703 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129563.578\n",
      "[Epoch 5, Batch 42/100] Loss: 0.0689 | RMSE: 0.0689 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105116.023\n",
      "[Epoch 5, Batch 43/100] Loss: 0.0770 | RMSE: 0.0770 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126108.461\n",
      "[Epoch 5, Batch 44/100] Loss: 0.0793 | RMSE: 0.0793 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137944.391\n",
      "[Epoch 5, Batch 45/100] Loss: 0.0804 | RMSE: 0.0804 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158397.141\n",
      "[Epoch 5, Batch 46/100] Loss: 0.0830 | RMSE: 0.0830 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 144230.125\n",
      "[Epoch 5, Batch 47/100] Loss: 0.0668 | RMSE: 0.0668 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 54223.441\n",
      "[Epoch 5, Batch 48/100] Loss: 0.0671 | RMSE: 0.0671 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105669.453\n",
      "[Epoch 5, Batch 49/100] Loss: 0.0680 | RMSE: 0.0680 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 67625.219\n",
      "[Epoch 5, Batch 50/100] Loss: 0.0786 | RMSE: 0.0786 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104804.602\n",
      "[Epoch 5, Batch 51/100] Loss: 0.0866 | RMSE: 0.0866 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 157510.391\n",
      "[Epoch 5, Batch 52/100] Loss: 0.0830 | RMSE: 0.0830 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115337.555\n",
      "[Epoch 5, Batch 53/100] Loss: 0.0778 | RMSE: 0.0778 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143524.391\n",
      "[Epoch 5, Batch 54/100] Loss: 0.0767 | RMSE: 0.0767 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137625.234\n",
      "[Epoch 5, Batch 55/100] Loss: 0.0799 | RMSE: 0.0799 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 67835.992\n",
      "[Epoch 5, Batch 56/100] Loss: 0.0862 | RMSE: 0.0862 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 135136.141\n",
      "[Epoch 5, Batch 57/100] Loss: 0.0897 | RMSE: 0.0897 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 82994.578\n",
      "[Epoch 5, Batch 58/100] Loss: 0.0777 | RMSE: 0.0777 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 50643.227\n",
      "[Epoch 5, Batch 59/100] Loss: 0.0924 | RMSE: 0.0924 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125744.070\n",
      "[Epoch 5, Batch 60/100] Loss: 0.0788 | RMSE: 0.0788 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127436.500\n",
      "[Epoch 5, Batch 61/100] Loss: 0.0822 | RMSE: 0.0822 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 90385.836\n",
      "[Epoch 5, Batch 62/100] Loss: 0.1039 | RMSE: 0.1039 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 175084.938\n",
      "[Epoch 5, Batch 63/100] Loss: 0.0957 | RMSE: 0.0957 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111094.406\n",
      "[Epoch 5, Batch 64/100] Loss: 0.0899 | RMSE: 0.0899 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 132993.781\n",
      "[Epoch 5, Batch 65/100] Loss: 0.0924 | RMSE: 0.0924 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 172480.797\n",
      "[Epoch 5, Batch 66/100] Loss: 0.0797 | RMSE: 0.0797 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114147.352\n",
      "[Epoch 5, Batch 67/100] Loss: 0.0999 | RMSE: 0.0999 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156998.938\n",
      "[Epoch 5, Batch 68/100] Loss: 0.0857 | RMSE: 0.0857 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138498.688\n",
      "[Epoch 5, Batch 69/100] Loss: 0.0879 | RMSE: 0.0879 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119189.984\n",
      "[Epoch 5, Batch 70/100] Loss: 0.0726 | RMSE: 0.0726 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91516.664\n",
      "[Epoch 5, Batch 71/100] Loss: 0.0731 | RMSE: 0.0731 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 77623.766\n",
      "[Epoch 5, Batch 72/100] Loss: 0.0847 | RMSE: 0.0847 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148490.438\n",
      "[Epoch 5, Batch 73/100] Loss: 0.0731 | RMSE: 0.0731 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79489.430\n",
      "[Epoch 5, Batch 74/100] Loss: 0.0771 | RMSE: 0.0771 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 72963.805\n",
      "[Epoch 5, Batch 75/100] Loss: 0.1096 | RMSE: 0.1096 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 171391.609\n",
      "[Epoch 5, Batch 76/100] Loss: 0.1181 | RMSE: 0.1181 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 201778.750\n",
      "[Epoch 5, Batch 77/100] Loss: 0.0866 | RMSE: 0.0866 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 131916.969\n",
      "[Epoch 5, Batch 78/100] Loss: 0.0893 | RMSE: 0.0893 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122486.539\n",
      "[Epoch 5, Batch 79/100] Loss: 0.0782 | RMSE: 0.0782 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161450.766\n",
      "[Epoch 5, Batch 80/100] Loss: 0.0891 | RMSE: 0.0891 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113642.461\n",
      "[Epoch 5, Batch 81/100] Loss: 0.0823 | RMSE: 0.0823 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 145699.531\n",
      "[Epoch 5, Batch 82/100] Loss: 0.0775 | RMSE: 0.0775 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 136392.188\n",
      "[Epoch 5, Batch 83/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 68135.062\n",
      "[Epoch 5, Batch 84/100] Loss: 0.0779 | RMSE: 0.0779 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147261.703\n",
      "[Epoch 5, Batch 85/100] Loss: 0.0656 | RMSE: 0.0656 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 73719.062\n",
      "[Epoch 5, Batch 86/100] Loss: 0.0795 | RMSE: 0.0795 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139429.922\n",
      "[Epoch 5, Batch 87/100] Loss: 0.0810 | RMSE: 0.0810 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129520.219\n",
      "[Epoch 5, Batch 88/100] Loss: 0.0685 | RMSE: 0.0685 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117390.031\n",
      "[Epoch 5, Batch 89/100] Loss: 0.0674 | RMSE: 0.0674 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 93783.828\n",
      "[Epoch 5, Batch 90/100] Loss: 0.0916 | RMSE: 0.0916 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 173237.844\n",
      "[Epoch 5, Batch 91/100] Loss: 0.0832 | RMSE: 0.0832 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143320.672\n",
      "[Epoch 5, Batch 92/100] Loss: 0.0809 | RMSE: 0.0809 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 90478.656\n",
      "[Epoch 5, Batch 93/100] Loss: 0.0656 | RMSE: 0.0656 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119012.688\n",
      "[Epoch 5, Batch 94/100] Loss: 0.0651 | RMSE: 0.0651 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 74614.625\n",
      "[Epoch 5, Batch 95/100] Loss: 0.0666 | RMSE: 0.0666 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 40686.473\n",
      "[Epoch 5, Batch 96/100] Loss: 0.0838 | RMSE: 0.0838 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116641.430\n",
      "[Epoch 5, Batch 97/100] Loss: 0.0844 | RMSE: 0.0844 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138942.031\n",
      "[Epoch 5, Batch 98/100] Loss: 0.0730 | RMSE: 0.0730 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94211.750\n",
      "[Epoch 5, Batch 99/100] Loss: 0.0692 | RMSE: 0.0692 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94900.977\n",
      "[Epoch 5, Batch 100/100] Loss: 0.0838 | RMSE: 0.0838 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 81051.617\n",
      "✅ Epoch 5 완료!\n",
      "   📈 평균 Loss: 0.081489\n",
      "   📊 평균 RMSE: 0.081489\n",
      "   ⚙️  학습률: 0.000705\n",
      "   🏆 NEW BEST! RMSE: 0.081489\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 6/80 시작...\n",
      "[Epoch 6, Batch 1/100] Loss: 0.0823 | RMSE: 0.0823 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 48297.531\n",
      "[Epoch 6, Batch 2/100] Loss: 0.0944 | RMSE: 0.0944 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 194481.703\n",
      "[Epoch 6, Batch 3/100] Loss: 0.1022 | RMSE: 0.1022 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 193473.594\n",
      "[Epoch 6, Batch 4/100] Loss: 0.0808 | RMSE: 0.0808 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 96139.406\n",
      "[Epoch 6, Batch 5/100] Loss: 0.0850 | RMSE: 0.0850 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130988.898\n",
      "[Epoch 6, Batch 6/100] Loss: 0.0754 | RMSE: 0.0754 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87549.609\n",
      "[Epoch 6, Batch 7/100] Loss: 0.0763 | RMSE: 0.0763 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127355.156\n",
      "[Epoch 6, Batch 8/100] Loss: 0.0766 | RMSE: 0.0766 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113386.719\n",
      "[Epoch 6, Batch 9/100] Loss: 0.0805 | RMSE: 0.0805 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128737.859\n",
      "[Epoch 6, Batch 10/100] Loss: 0.0785 | RMSE: 0.0785 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 77790.453\n",
      "[Epoch 6, Batch 11/100] Loss: 0.0718 | RMSE: 0.0718 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 107565.773\n",
      "[Epoch 6, Batch 12/100] Loss: 0.0780 | RMSE: 0.0780 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121857.297\n",
      "[Epoch 6, Batch 13/100] Loss: 0.0812 | RMSE: 0.0812 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128411.719\n",
      "[Epoch 6, Batch 14/100] Loss: 0.0871 | RMSE: 0.0871 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114692.383\n",
      "[Epoch 6, Batch 15/100] Loss: 0.0772 | RMSE: 0.0772 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87582.836\n",
      "[Epoch 6, Batch 16/100] Loss: 0.0739 | RMSE: 0.0739 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 110490.266\n",
      "[Epoch 6, Batch 17/100] Loss: 0.0794 | RMSE: 0.0794 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 96761.820\n",
      "[Epoch 6, Batch 18/100] Loss: 0.0961 | RMSE: 0.0961 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147310.547\n",
      "[Epoch 6, Batch 19/100] Loss: 0.0872 | RMSE: 0.0872 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95688.820\n",
      "[Epoch 6, Batch 20/100] Loss: 0.0738 | RMSE: 0.0738 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103390.789\n",
      "[Epoch 6, Batch 21/100] Loss: 0.0824 | RMSE: 0.0824 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139182.219\n",
      "[Epoch 6, Batch 22/100] Loss: 0.0774 | RMSE: 0.0774 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118166.422\n",
      "[Epoch 6, Batch 23/100] Loss: 0.0650 | RMSE: 0.0650 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 112443.250\n",
      "[Epoch 6, Batch 24/100] Loss: 0.0762 | RMSE: 0.0762 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111932.906\n",
      "[Epoch 6, Batch 25/100] Loss: 0.0765 | RMSE: 0.0765 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 132075.344\n",
      "[Epoch 6, Batch 26/100] Loss: 0.0788 | RMSE: 0.0788 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91274.969\n",
      "[Epoch 6, Batch 27/100] Loss: 0.0660 | RMSE: 0.0660 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 70212.258\n",
      "[Epoch 6, Batch 28/100] Loss: 0.0878 | RMSE: 0.0878 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122589.125\n",
      "[Epoch 6, Batch 29/100] Loss: 0.0716 | RMSE: 0.0716 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 74688.406\n",
      "[Epoch 6, Batch 30/100] Loss: 0.0870 | RMSE: 0.0870 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147077.328\n",
      "[Epoch 6, Batch 31/100] Loss: 0.0797 | RMSE: 0.0797 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120791.500\n",
      "[Epoch 6, Batch 32/100] Loss: 0.0749 | RMSE: 0.0749 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 90107.688\n",
      "[Epoch 6, Batch 33/100] Loss: 0.0814 | RMSE: 0.0814 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 88696.781\n",
      "[Epoch 6, Batch 34/100] Loss: 0.0879 | RMSE: 0.0879 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113556.445\n",
      "[Epoch 6, Batch 35/100] Loss: 0.0937 | RMSE: 0.0937 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134178.625\n",
      "[Epoch 6, Batch 36/100] Loss: 0.0819 | RMSE: 0.0819 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130079.055\n",
      "[Epoch 6, Batch 37/100] Loss: 0.0846 | RMSE: 0.0846 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 112710.711\n",
      "[Epoch 6, Batch 38/100] Loss: 0.0673 | RMSE: 0.0673 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 64026.863\n",
      "[Epoch 6, Batch 39/100] Loss: 0.1054 | RMSE: 0.1054 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 144885.719\n",
      "[Epoch 6, Batch 40/100] Loss: 0.0853 | RMSE: 0.0853 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114429.914\n",
      "[Epoch 6, Batch 41/100] Loss: 0.0803 | RMSE: 0.0803 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91692.500\n",
      "[Epoch 6, Batch 42/100] Loss: 0.0773 | RMSE: 0.0773 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143406.734\n",
      "[Epoch 6, Batch 43/100] Loss: 0.0897 | RMSE: 0.0897 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111977.258\n",
      "[Epoch 6, Batch 44/100] Loss: 0.0895 | RMSE: 0.0895 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 83479.039\n",
      "[Epoch 6, Batch 45/100] Loss: 0.0849 | RMSE: 0.0849 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 63620.016\n",
      "[Epoch 6, Batch 46/100] Loss: 0.0765 | RMSE: 0.0765 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113154.328\n",
      "[Epoch 6, Batch 47/100] Loss: 0.0815 | RMSE: 0.0815 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 144539.281\n",
      "[Epoch 6, Batch 48/100] Loss: 0.0735 | RMSE: 0.0735 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 78541.641\n",
      "[Epoch 6, Batch 49/100] Loss: 0.0799 | RMSE: 0.0799 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114261.078\n",
      "[Epoch 6, Batch 50/100] Loss: 0.0944 | RMSE: 0.0944 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139966.062\n",
      "[Epoch 6, Batch 51/100] Loss: 0.0910 | RMSE: 0.0910 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152576.234\n",
      "[Epoch 6, Batch 52/100] Loss: 0.0866 | RMSE: 0.0866 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87492.484\n",
      "[Epoch 6, Batch 53/100] Loss: 0.0929 | RMSE: 0.0929 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137719.531\n",
      "[Epoch 6, Batch 54/100] Loss: 0.0973 | RMSE: 0.0973 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 155868.406\n",
      "[Epoch 6, Batch 55/100] Loss: 0.0727 | RMSE: 0.0727 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 70319.414\n",
      "[Epoch 6, Batch 56/100] Loss: 0.0674 | RMSE: 0.0674 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92147.914\n",
      "[Epoch 6, Batch 57/100] Loss: 0.0587 | RMSE: 0.0587 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 75307.891\n",
      "[Epoch 6, Batch 58/100] Loss: 0.0861 | RMSE: 0.0861 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127224.758\n",
      "[Epoch 6, Batch 59/100] Loss: 0.1017 | RMSE: 0.1017 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 142714.828\n",
      "[Epoch 6, Batch 60/100] Loss: 0.0767 | RMSE: 0.0767 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 132248.672\n",
      "[Epoch 6, Batch 61/100] Loss: 0.0760 | RMSE: 0.0760 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 163241.422\n",
      "[Epoch 6, Batch 62/100] Loss: 0.0855 | RMSE: 0.0855 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128114.305\n",
      "[Epoch 6, Batch 63/100] Loss: 0.0930 | RMSE: 0.0930 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 131017.117\n",
      "[Epoch 6, Batch 64/100] Loss: 0.0799 | RMSE: 0.0799 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103310.938\n",
      "[Epoch 6, Batch 65/100] Loss: 0.0844 | RMSE: 0.0844 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117891.461\n",
      "[Epoch 6, Batch 66/100] Loss: 0.0977 | RMSE: 0.0977 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147611.781\n",
      "[Epoch 6, Batch 67/100] Loss: 0.0686 | RMSE: 0.0686 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 73736.414\n",
      "[Epoch 6, Batch 68/100] Loss: 0.0837 | RMSE: 0.0837 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 89290.406\n",
      "[Epoch 6, Batch 69/100] Loss: 0.0958 | RMSE: 0.0958 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139819.594\n",
      "[Epoch 6, Batch 70/100] Loss: 0.0825 | RMSE: 0.0825 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118502.492\n",
      "[Epoch 6, Batch 71/100] Loss: 0.0722 | RMSE: 0.0722 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134081.578\n",
      "[Epoch 6, Batch 72/100] Loss: 0.0955 | RMSE: 0.0955 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122079.781\n",
      "[Epoch 6, Batch 73/100] Loss: 0.0873 | RMSE: 0.0873 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146237.750\n",
      "[Epoch 6, Batch 74/100] Loss: 0.0751 | RMSE: 0.0751 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109122.062\n",
      "[Epoch 6, Batch 75/100] Loss: 0.0777 | RMSE: 0.0777 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101546.930\n",
      "[Epoch 6, Batch 76/100] Loss: 0.0886 | RMSE: 0.0886 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119077.641\n",
      "[Epoch 6, Batch 77/100] Loss: 0.0696 | RMSE: 0.0696 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 59314.746\n",
      "[Epoch 6, Batch 78/100] Loss: 0.0722 | RMSE: 0.0722 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114783.945\n",
      "[Epoch 6, Batch 79/100] Loss: 0.0914 | RMSE: 0.0914 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147210.062\n",
      "[Epoch 6, Batch 80/100] Loss: 0.0784 | RMSE: 0.0784 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 82342.992\n",
      "[Epoch 6, Batch 81/100] Loss: 0.0652 | RMSE: 0.0652 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 51583.320\n",
      "[Epoch 6, Batch 82/100] Loss: 0.0766 | RMSE: 0.0766 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 63532.941\n",
      "[Epoch 6, Batch 83/100] Loss: 0.0846 | RMSE: 0.0846 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 83915.352\n",
      "[Epoch 6, Batch 84/100] Loss: 0.0675 | RMSE: 0.0675 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113166.148\n",
      "[Epoch 6, Batch 85/100] Loss: 0.0869 | RMSE: 0.0869 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115996.312\n",
      "[Epoch 6, Batch 86/100] Loss: 0.0750 | RMSE: 0.0750 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130973.312\n",
      "[Epoch 6, Batch 87/100] Loss: 0.0854 | RMSE: 0.0854 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114897.742\n",
      "[Epoch 6, Batch 88/100] Loss: 0.0749 | RMSE: 0.0749 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134134.109\n",
      "[Epoch 6, Batch 89/100] Loss: 0.0716 | RMSE: 0.0716 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 59653.844\n",
      "[Epoch 6, Batch 90/100] Loss: 0.0927 | RMSE: 0.0927 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 171148.328\n",
      "[Epoch 6, Batch 91/100] Loss: 0.0891 | RMSE: 0.0891 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 135366.562\n",
      "[Epoch 6, Batch 92/100] Loss: 0.0685 | RMSE: 0.0685 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 86051.203\n",
      "[Epoch 6, Batch 93/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 123987.883\n",
      "[Epoch 6, Batch 94/100] Loss: 0.0856 | RMSE: 0.0856 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124616.859\n",
      "[Epoch 6, Batch 95/100] Loss: 0.0843 | RMSE: 0.0843 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 80043.844\n",
      "[Epoch 6, Batch 96/100] Loss: 0.0749 | RMSE: 0.0749 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108238.398\n",
      "[Epoch 6, Batch 97/100] Loss: 0.0755 | RMSE: 0.0755 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 89929.609\n",
      "[Epoch 6, Batch 98/100] Loss: 0.0619 | RMSE: 0.0619 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 77044.859\n",
      "[Epoch 6, Batch 99/100] Loss: 0.0746 | RMSE: 0.0746 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116404.945\n",
      "[Epoch 6, Batch 100/100] Loss: 0.0879 | RMSE: 0.0879 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118681.586\n",
      "✅ Epoch 6 완료!\n",
      "   📈 평균 Loss: 0.081254\n",
      "   📊 평균 RMSE: 0.081254\n",
      "   ⚙️  학습률: 0.000860\n",
      "   🏆 NEW BEST! RMSE: 0.081254\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 7/80 시작...\n",
      "[Epoch 7, Batch 1/100] Loss: 0.0683 | RMSE: 0.0683 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 78089.914\n",
      "[Epoch 7, Batch 2/100] Loss: 0.0714 | RMSE: 0.0714 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101221.312\n",
      "[Epoch 7, Batch 3/100] Loss: 0.0741 | RMSE: 0.0741 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97612.852\n",
      "[Epoch 7, Batch 4/100] Loss: 0.0581 | RMSE: 0.0581 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 50930.262\n",
      "[Epoch 7, Batch 5/100] Loss: 0.0794 | RMSE: 0.0794 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113085.375\n",
      "[Epoch 7, Batch 6/100] Loss: 0.0860 | RMSE: 0.0860 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 107911.469\n",
      "[Epoch 7, Batch 7/100] Loss: 0.0730 | RMSE: 0.0730 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 56613.086\n",
      "[Epoch 7, Batch 8/100] Loss: 0.0853 | RMSE: 0.0853 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91231.812\n",
      "[Epoch 7, Batch 9/100] Loss: 0.0770 | RMSE: 0.0770 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 82885.992\n",
      "[Epoch 7, Batch 10/100] Loss: 0.0775 | RMSE: 0.0775 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 89228.898\n",
      "[Epoch 7, Batch 11/100] Loss: 0.0734 | RMSE: 0.0734 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101948.680\n",
      "[Epoch 7, Batch 12/100] Loss: 0.0820 | RMSE: 0.0820 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103156.406\n",
      "[Epoch 7, Batch 13/100] Loss: 0.0806 | RMSE: 0.0806 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 73303.320\n",
      "[Epoch 7, Batch 14/100] Loss: 0.0782 | RMSE: 0.0782 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 59940.180\n",
      "[Epoch 7, Batch 15/100] Loss: 0.0877 | RMSE: 0.0877 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 159805.688\n",
      "[Epoch 7, Batch 16/100] Loss: 0.0780 | RMSE: 0.0780 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92590.664\n",
      "[Epoch 7, Batch 17/100] Loss: 0.0743 | RMSE: 0.0743 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101465.250\n",
      "[Epoch 7, Batch 18/100] Loss: 0.0778 | RMSE: 0.0778 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128131.867\n",
      "[Epoch 7, Batch 19/100] Loss: 0.0844 | RMSE: 0.0844 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129030.438\n",
      "[Epoch 7, Batch 20/100] Loss: 0.1015 | RMSE: 0.1015 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158948.344\n",
      "[Epoch 7, Batch 21/100] Loss: 0.0822 | RMSE: 0.0822 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111309.047\n",
      "[Epoch 7, Batch 22/100] Loss: 0.0742 | RMSE: 0.0742 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 80036.312\n",
      "[Epoch 7, Batch 23/100] Loss: 0.0911 | RMSE: 0.0911 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161142.406\n",
      "[Epoch 7, Batch 24/100] Loss: 0.0693 | RMSE: 0.0693 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 76862.359\n",
      "[Epoch 7, Batch 25/100] Loss: 0.0775 | RMSE: 0.0775 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 82459.453\n",
      "[Epoch 7, Batch 26/100] Loss: 0.0899 | RMSE: 0.0899 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101341.367\n",
      "[Epoch 7, Batch 27/100] Loss: 0.0758 | RMSE: 0.0758 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 123568.234\n",
      "[Epoch 7, Batch 28/100] Loss: 0.0877 | RMSE: 0.0877 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121012.008\n",
      "[Epoch 7, Batch 29/100] Loss: 0.0707 | RMSE: 0.0707 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 65390.969\n",
      "[Epoch 7, Batch 30/100] Loss: 0.0734 | RMSE: 0.0734 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114260.945\n",
      "[Epoch 7, Batch 31/100] Loss: 0.0809 | RMSE: 0.0809 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117889.078\n",
      "[Epoch 7, Batch 32/100] Loss: 0.0828 | RMSE: 0.0828 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104452.820\n",
      "[Epoch 7, Batch 33/100] Loss: 0.0835 | RMSE: 0.0835 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116627.188\n",
      "[Epoch 7, Batch 34/100] Loss: 0.0561 | RMSE: 0.0561 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 69729.203\n",
      "[Epoch 7, Batch 35/100] Loss: 0.0711 | RMSE: 0.0711 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94821.922\n",
      "[Epoch 7, Batch 36/100] Loss: 0.0668 | RMSE: 0.0668 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 93132.773\n",
      "[Epoch 7, Batch 37/100] Loss: 0.0670 | RMSE: 0.0670 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 39627.988\n",
      "[Epoch 7, Batch 38/100] Loss: 0.0674 | RMSE: 0.0674 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 64794.234\n",
      "[Epoch 7, Batch 39/100] Loss: 0.0718 | RMSE: 0.0718 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128829.047\n",
      "[Epoch 7, Batch 40/100] Loss: 0.0771 | RMSE: 0.0771 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109979.570\n",
      "[Epoch 7, Batch 41/100] Loss: 0.0668 | RMSE: 0.0668 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 89706.852\n",
      "[Epoch 7, Batch 42/100] Loss: 0.0937 | RMSE: 0.0937 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156731.094\n",
      "[Epoch 7, Batch 43/100] Loss: 0.0840 | RMSE: 0.0840 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126812.930\n",
      "[Epoch 7, Batch 44/100] Loss: 0.0694 | RMSE: 0.0694 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118757.164\n",
      "[Epoch 7, Batch 45/100] Loss: 0.0809 | RMSE: 0.0809 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 78327.273\n",
      "[Epoch 7, Batch 46/100] Loss: 0.0842 | RMSE: 0.0842 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 141280.453\n",
      "[Epoch 7, Batch 47/100] Loss: 0.0830 | RMSE: 0.0830 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105034.820\n",
      "[Epoch 7, Batch 48/100] Loss: 0.0760 | RMSE: 0.0760 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 77223.211\n",
      "[Epoch 7, Batch 49/100] Loss: 0.0681 | RMSE: 0.0681 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 77492.180\n",
      "[Epoch 7, Batch 50/100] Loss: 0.0733 | RMSE: 0.0733 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118313.758\n",
      "[Epoch 7, Batch 51/100] Loss: 0.0707 | RMSE: 0.0707 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95582.539\n",
      "[Epoch 7, Batch 52/100] Loss: 0.0713 | RMSE: 0.0713 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 60814.504\n",
      "[Epoch 7, Batch 53/100] Loss: 0.0682 | RMSE: 0.0682 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87319.203\n",
      "[Epoch 7, Batch 54/100] Loss: 0.0719 | RMSE: 0.0719 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91665.766\n",
      "[Epoch 7, Batch 55/100] Loss: 0.0752 | RMSE: 0.0752 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 46045.750\n",
      "[Epoch 7, Batch 56/100] Loss: 0.0984 | RMSE: 0.0984 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 169464.969\n",
      "[Epoch 7, Batch 57/100] Loss: 0.0922 | RMSE: 0.0922 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 145853.016\n",
      "[Epoch 7, Batch 58/100] Loss: 0.0856 | RMSE: 0.0856 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113894.688\n",
      "[Epoch 7, Batch 59/100] Loss: 0.0755 | RMSE: 0.0755 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 98949.188\n",
      "[Epoch 7, Batch 60/100] Loss: 0.0667 | RMSE: 0.0667 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 59026.992\n",
      "[Epoch 7, Batch 61/100] Loss: 0.1031 | RMSE: 0.1031 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 170781.688\n",
      "[Epoch 7, Batch 62/100] Loss: 0.0952 | RMSE: 0.0952 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 179292.250\n",
      "[Epoch 7, Batch 63/100] Loss: 0.0884 | RMSE: 0.0884 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138440.750\n",
      "[Epoch 7, Batch 64/100] Loss: 0.0776 | RMSE: 0.0776 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115631.656\n",
      "[Epoch 7, Batch 65/100] Loss: 0.0809 | RMSE: 0.0809 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127009.000\n",
      "[Epoch 7, Batch 66/100] Loss: 0.0811 | RMSE: 0.0811 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92698.930\n",
      "[Epoch 7, Batch 67/100] Loss: 0.0744 | RMSE: 0.0744 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 96596.734\n",
      "[Epoch 7, Batch 68/100] Loss: 0.1011 | RMSE: 0.1011 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 175075.703\n",
      "[Epoch 7, Batch 69/100] Loss: 0.0779 | RMSE: 0.0779 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 102914.328\n",
      "[Epoch 7, Batch 70/100] Loss: 0.0939 | RMSE: 0.0939 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 169754.812\n",
      "[Epoch 7, Batch 71/100] Loss: 0.1069 | RMSE: 0.1069 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 202659.594\n",
      "[Epoch 7, Batch 72/100] Loss: 0.1067 | RMSE: 0.1067 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 165005.969\n",
      "[Epoch 7, Batch 73/100] Loss: 0.0836 | RMSE: 0.0836 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118295.672\n",
      "[Epoch 7, Batch 74/100] Loss: 0.0911 | RMSE: 0.0911 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122211.906\n",
      "[Epoch 7, Batch 75/100] Loss: 0.0756 | RMSE: 0.0756 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94735.148\n",
      "[Epoch 7, Batch 76/100] Loss: 0.0825 | RMSE: 0.0825 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97544.648\n",
      "[Epoch 7, Batch 77/100] Loss: 0.0788 | RMSE: 0.0788 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126866.609\n",
      "[Epoch 7, Batch 78/100] Loss: 0.0775 | RMSE: 0.0775 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 86603.289\n",
      "[Epoch 7, Batch 79/100] Loss: 0.0777 | RMSE: 0.0777 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121067.852\n",
      "[Epoch 7, Batch 80/100] Loss: 0.0764 | RMSE: 0.0764 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118277.672\n",
      "[Epoch 7, Batch 81/100] Loss: 0.0714 | RMSE: 0.0714 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79744.078\n",
      "[Epoch 7, Batch 82/100] Loss: 0.0778 | RMSE: 0.0778 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 102190.289\n",
      "[Epoch 7, Batch 83/100] Loss: 0.0772 | RMSE: 0.0772 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154235.594\n",
      "[Epoch 7, Batch 84/100] Loss: 0.0780 | RMSE: 0.0780 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130061.281\n",
      "[Epoch 7, Batch 85/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121863.000\n",
      "[Epoch 7, Batch 86/100] Loss: 0.0760 | RMSE: 0.0760 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 76344.273\n",
      "[Epoch 7, Batch 87/100] Loss: 0.0640 | RMSE: 0.0640 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 76828.750\n",
      "[Epoch 7, Batch 88/100] Loss: 0.0842 | RMSE: 0.0842 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143164.422\n",
      "[Epoch 7, Batch 89/100] Loss: 0.0781 | RMSE: 0.0781 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 110527.258\n",
      "[Epoch 7, Batch 90/100] Loss: 0.0632 | RMSE: 0.0632 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 74680.242\n",
      "[Epoch 7, Batch 91/100] Loss: 0.0743 | RMSE: 0.0743 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 46317.828\n",
      "[Epoch 7, Batch 92/100] Loss: 0.0791 | RMSE: 0.0791 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 112034.109\n",
      "[Epoch 7, Batch 93/100] Loss: 0.0723 | RMSE: 0.0723 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 141295.109\n",
      "[Epoch 7, Batch 94/100] Loss: 0.0672 | RMSE: 0.0672 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85345.500\n",
      "[Epoch 7, Batch 95/100] Loss: 0.0788 | RMSE: 0.0788 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 73801.070\n",
      "[Epoch 7, Batch 96/100] Loss: 0.0753 | RMSE: 0.0753 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120689.516\n",
      "[Epoch 7, Batch 97/100] Loss: 0.0737 | RMSE: 0.0737 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 100419.586\n",
      "[Epoch 7, Batch 98/100] Loss: 0.0703 | RMSE: 0.0703 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 83738.266\n",
      "[Epoch 7, Batch 99/100] Loss: 0.0728 | RMSE: 0.0728 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125231.328\n",
      "[Epoch 7, Batch 100/100] Loss: 0.0667 | RMSE: 0.0667 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 68733.375\n",
      "✅ Epoch 7 완료!\n",
      "   📈 평균 Loss: 0.078506\n",
      "   📊 평균 RMSE: 0.078506\n",
      "   ⚙️  학습률: 0.000964\n",
      "   🏆 NEW BEST! RMSE: 0.078506\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 8/80 시작...\n",
      "[Epoch 8, Batch 1/100] Loss: 0.0757 | RMSE: 0.0757 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 70830.695\n",
      "[Epoch 8, Batch 2/100] Loss: 0.0734 | RMSE: 0.0734 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148988.281\n",
      "[Epoch 8, Batch 3/100] Loss: 0.0863 | RMSE: 0.0863 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 134160.938\n",
      "[Epoch 8, Batch 4/100] Loss: 0.0698 | RMSE: 0.0698 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 68336.008\n",
      "[Epoch 8, Batch 5/100] Loss: 0.0711 | RMSE: 0.0711 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117121.633\n",
      "[Epoch 8, Batch 6/100] Loss: 0.0701 | RMSE: 0.0701 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 78253.148\n",
      "[Epoch 8, Batch 7/100] Loss: 0.0772 | RMSE: 0.0772 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139189.641\n",
      "[Epoch 8, Batch 8/100] Loss: 0.0796 | RMSE: 0.0796 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 110292.398\n",
      "[Epoch 8, Batch 9/100] Loss: 0.0620 | RMSE: 0.0620 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92230.289\n",
      "[Epoch 8, Batch 10/100] Loss: 0.0792 | RMSE: 0.0792 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115229.055\n",
      "[Epoch 8, Batch 11/100] Loss: 0.0685 | RMSE: 0.0685 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115092.242\n",
      "[Epoch 8, Batch 12/100] Loss: 0.0844 | RMSE: 0.0844 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 133883.375\n",
      "[Epoch 8, Batch 13/100] Loss: 0.0976 | RMSE: 0.0976 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156184.344\n",
      "[Epoch 8, Batch 14/100] Loss: 0.0747 | RMSE: 0.0747 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 58983.012\n",
      "[Epoch 8, Batch 15/100] Loss: 0.0906 | RMSE: 0.0906 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 135332.875\n",
      "[Epoch 8, Batch 16/100] Loss: 0.0929 | RMSE: 0.0929 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139454.656\n",
      "[Epoch 8, Batch 17/100] Loss: 0.0628 | RMSE: 0.0628 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 46960.141\n",
      "[Epoch 8, Batch 18/100] Loss: 0.0740 | RMSE: 0.0740 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148060.516\n",
      "[Epoch 8, Batch 19/100] Loss: 0.0803 | RMSE: 0.0803 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124046.023\n",
      "[Epoch 8, Batch 20/100] Loss: 0.0785 | RMSE: 0.0785 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111152.133\n",
      "[Epoch 8, Batch 21/100] Loss: 0.0744 | RMSE: 0.0744 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116886.078\n",
      "[Epoch 8, Batch 22/100] Loss: 0.0736 | RMSE: 0.0736 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118909.539\n",
      "[Epoch 8, Batch 23/100] Loss: 0.0814 | RMSE: 0.0814 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139239.609\n",
      "[Epoch 8, Batch 24/100] Loss: 0.0719 | RMSE: 0.0719 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113005.172\n",
      "[Epoch 8, Batch 25/100] Loss: 0.0699 | RMSE: 0.0699 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97234.812\n",
      "[Epoch 8, Batch 26/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101918.836\n",
      "[Epoch 8, Batch 27/100] Loss: 0.0841 | RMSE: 0.0841 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 102348.203\n",
      "[Epoch 8, Batch 28/100] Loss: 0.0649 | RMSE: 0.0649 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79611.281\n",
      "[Epoch 8, Batch 29/100] Loss: 0.0849 | RMSE: 0.0849 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115273.734\n",
      "[Epoch 8, Batch 30/100] Loss: 0.0724 | RMSE: 0.0724 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126750.094\n",
      "[Epoch 8, Batch 31/100] Loss: 0.0599 | RMSE: 0.0599 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108675.648\n",
      "[Epoch 8, Batch 32/100] Loss: 0.0717 | RMSE: 0.0717 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 98732.859\n",
      "[Epoch 8, Batch 33/100] Loss: 0.0816 | RMSE: 0.0816 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 157737.953\n",
      "[Epoch 8, Batch 34/100] Loss: 0.0829 | RMSE: 0.0829 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 133167.062\n",
      "[Epoch 8, Batch 35/100] Loss: 0.0707 | RMSE: 0.0707 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 107790.875\n",
      "[Epoch 8, Batch 36/100] Loss: 0.0718 | RMSE: 0.0718 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108738.500\n",
      "[Epoch 8, Batch 37/100] Loss: 0.0734 | RMSE: 0.0734 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 59825.234\n",
      "[Epoch 8, Batch 38/100] Loss: 0.0782 | RMSE: 0.0782 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118784.133\n",
      "[Epoch 8, Batch 39/100] Loss: 0.0788 | RMSE: 0.0788 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 132161.531\n",
      "[Epoch 8, Batch 40/100] Loss: 0.0667 | RMSE: 0.0667 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87418.469\n",
      "[Epoch 8, Batch 41/100] Loss: 0.0781 | RMSE: 0.0781 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 135168.438\n",
      "[Epoch 8, Batch 42/100] Loss: 0.0942 | RMSE: 0.0942 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 140042.516\n",
      "[Epoch 8, Batch 43/100] Loss: 0.0812 | RMSE: 0.0812 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130724.125\n",
      "[Epoch 8, Batch 44/100] Loss: 0.0722 | RMSE: 0.0722 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 41886.922\n",
      "[Epoch 8, Batch 45/100] Loss: 0.0841 | RMSE: 0.0841 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 149186.156\n",
      "[Epoch 8, Batch 46/100] Loss: 0.0761 | RMSE: 0.0761 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108424.375\n",
      "[Epoch 8, Batch 47/100] Loss: 0.0818 | RMSE: 0.0818 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108636.969\n",
      "[Epoch 8, Batch 48/100] Loss: 0.0831 | RMSE: 0.0831 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120580.617\n",
      "[Epoch 8, Batch 49/100] Loss: 0.0847 | RMSE: 0.0847 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 112963.117\n",
      "[Epoch 8, Batch 50/100] Loss: 0.0844 | RMSE: 0.0844 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122809.859\n",
      "[Epoch 8, Batch 51/100] Loss: 0.0787 | RMSE: 0.0787 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97181.836\n",
      "[Epoch 8, Batch 52/100] Loss: 0.0639 | RMSE: 0.0639 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87184.898\n",
      "[Epoch 8, Batch 53/100] Loss: 0.0701 | RMSE: 0.0701 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117759.695\n",
      "[Epoch 8, Batch 54/100] Loss: 0.0732 | RMSE: 0.0732 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121840.391\n",
      "[Epoch 8, Batch 55/100] Loss: 0.0702 | RMSE: 0.0702 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91425.055\n",
      "[Epoch 8, Batch 56/100] Loss: 0.0730 | RMSE: 0.0730 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 96308.164\n",
      "[Epoch 8, Batch 57/100] Loss: 0.0766 | RMSE: 0.0766 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 103627.547\n",
      "[Epoch 8, Batch 58/100] Loss: 0.0791 | RMSE: 0.0791 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 86753.547\n",
      "[Epoch 8, Batch 59/100] Loss: 0.0710 | RMSE: 0.0710 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 86977.234\n",
      "[Epoch 8, Batch 60/100] Loss: 0.0757 | RMSE: 0.0757 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122606.555\n",
      "[Epoch 8, Batch 61/100] Loss: 0.0693 | RMSE: 0.0693 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 64165.285\n",
      "[Epoch 8, Batch 62/100] Loss: 0.0754 | RMSE: 0.0754 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119201.664\n",
      "[Epoch 8, Batch 63/100] Loss: 0.0818 | RMSE: 0.0818 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124610.992\n",
      "[Epoch 8, Batch 64/100] Loss: 0.0765 | RMSE: 0.0765 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137395.312\n",
      "[Epoch 8, Batch 65/100] Loss: 0.0632 | RMSE: 0.0632 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85189.938\n",
      "[Epoch 8, Batch 66/100] Loss: 0.0735 | RMSE: 0.0735 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122006.891\n",
      "[Epoch 8, Batch 67/100] Loss: 0.0716 | RMSE: 0.0716 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124381.047\n",
      "[Epoch 8, Batch 68/100] Loss: 0.0639 | RMSE: 0.0639 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 102333.617\n",
      "[Epoch 8, Batch 69/100] Loss: 0.0765 | RMSE: 0.0765 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 166838.359\n",
      "[Epoch 8, Batch 70/100] Loss: 0.0780 | RMSE: 0.0780 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117490.719\n",
      "[Epoch 8, Batch 71/100] Loss: 0.0626 | RMSE: 0.0626 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79973.852\n",
      "[Epoch 8, Batch 72/100] Loss: 0.0624 | RMSE: 0.0624 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92083.969\n",
      "[Epoch 8, Batch 73/100] Loss: 0.0733 | RMSE: 0.0733 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105131.258\n",
      "[Epoch 8, Batch 74/100] Loss: 0.0822 | RMSE: 0.0822 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 106104.625\n",
      "[Epoch 8, Batch 75/100] Loss: 0.0732 | RMSE: 0.0732 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 91023.164\n",
      "[Epoch 8, Batch 76/100] Loss: 0.0666 | RMSE: 0.0666 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 77348.336\n",
      "[Epoch 8, Batch 77/100] Loss: 0.0668 | RMSE: 0.0668 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 106252.883\n",
      "[Epoch 8, Batch 78/100] Loss: 0.0683 | RMSE: 0.0683 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 83137.688\n",
      "[Epoch 8, Batch 79/100] Loss: 0.0781 | RMSE: 0.0781 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 100712.891\n",
      "[Epoch 8, Batch 80/100] Loss: 0.0662 | RMSE: 0.0662 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 112429.148\n",
      "[Epoch 8, Batch 81/100] Loss: 0.0675 | RMSE: 0.0675 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104969.906\n",
      "[Epoch 8, Batch 82/100] Loss: 0.0749 | RMSE: 0.0749 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115625.820\n",
      "[Epoch 8, Batch 83/100] Loss: 0.0620 | RMSE: 0.0620 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 84580.320\n",
      "[Epoch 8, Batch 84/100] Loss: 0.0749 | RMSE: 0.0749 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 67846.719\n",
      "[Epoch 8, Batch 85/100] Loss: 0.0786 | RMSE: 0.0786 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124149.297\n",
      "[Epoch 8, Batch 86/100] Loss: 0.0696 | RMSE: 0.0696 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 96250.664\n",
      "[Epoch 8, Batch 87/100] Loss: 0.0648 | RMSE: 0.0648 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94793.359\n",
      "[Epoch 8, Batch 88/100] Loss: 0.0695 | RMSE: 0.0695 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 124074.469\n",
      "[Epoch 8, Batch 89/100] Loss: 0.0699 | RMSE: 0.0699 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117327.023\n",
      "[Epoch 8, Batch 90/100] Loss: 0.0723 | RMSE: 0.0723 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137926.719\n",
      "[Epoch 8, Batch 91/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 102629.844\n",
      "[Epoch 8, Batch 92/100] Loss: 0.0885 | RMSE: 0.0885 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118288.375\n",
      "[Epoch 8, Batch 93/100] Loss: 0.0868 | RMSE: 0.0868 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 172150.188\n",
      "[Epoch 8, Batch 94/100] Loss: 0.0696 | RMSE: 0.0696 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 57779.797\n",
      "[Epoch 8, Batch 95/100] Loss: 0.0713 | RMSE: 0.0713 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119613.250\n",
      "[Epoch 8, Batch 96/100] Loss: 0.0723 | RMSE: 0.0723 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97660.055\n",
      "[Epoch 8, Batch 97/100] Loss: 0.0706 | RMSE: 0.0706 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 70122.156\n",
      "[Epoch 8, Batch 98/100] Loss: 0.0638 | RMSE: 0.0638 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101264.203\n",
      "[Epoch 8, Batch 99/100] Loss: 0.0785 | RMSE: 0.0785 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 43822.820\n",
      "[Epoch 8, Batch 100/100] Loss: 0.0645 | RMSE: 0.0645 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 50640.484\n",
      "✅ Epoch 8 완료!\n",
      "   📈 평균 Loss: 0.074741\n",
      "   📊 평균 RMSE: 0.074741\n",
      "   ⚙️  학습률: 0.001000\n",
      "   🏆 NEW BEST! RMSE: 0.074741\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 9/80 시작...\n",
      "[Epoch 9, Batch 1/100] Loss: 0.0876 | RMSE: 0.0876 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 157843.344\n",
      "[Epoch 9, Batch 2/100] Loss: 0.0735 | RMSE: 0.0735 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87514.648\n",
      "[Epoch 9, Batch 3/100] Loss: 0.0841 | RMSE: 0.0841 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 102298.531\n",
      "[Epoch 9, Batch 4/100] Loss: 0.0898 | RMSE: 0.0898 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 82039.812\n",
      "[Epoch 9, Batch 5/100] Loss: 0.0758 | RMSE: 0.0758 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 45018.129\n",
      "[Epoch 9, Batch 6/100] Loss: 0.0987 | RMSE: 0.0987 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116959.953\n",
      "[Epoch 9, Batch 7/100] Loss: 0.1048 | RMSE: 0.1048 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 183291.531\n",
      "[Epoch 9, Batch 8/100] Loss: 0.0735 | RMSE: 0.0735 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 55987.582\n",
      "[Epoch 9, Batch 9/100] Loss: 0.0936 | RMSE: 0.0936 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130128.312\n",
      "[Epoch 9, Batch 10/100] Loss: 0.0884 | RMSE: 0.0884 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118814.883\n",
      "[Epoch 9, Batch 11/100] Loss: 0.0801 | RMSE: 0.0801 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 117109.461\n",
      "[Epoch 9, Batch 12/100] Loss: 0.0850 | RMSE: 0.0850 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143674.297\n",
      "[Epoch 9, Batch 13/100] Loss: 0.0758 | RMSE: 0.0758 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128472.922\n",
      "[Epoch 9, Batch 14/100] Loss: 0.0839 | RMSE: 0.0839 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 74345.008\n",
      "[Epoch 9, Batch 15/100] Loss: 0.0744 | RMSE: 0.0744 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 61628.855\n",
      "[Epoch 9, Batch 16/100] Loss: 0.0825 | RMSE: 0.0825 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105632.430\n",
      "[Epoch 9, Batch 17/100] Loss: 0.0775 | RMSE: 0.0775 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114134.148\n",
      "[Epoch 9, Batch 18/100] Loss: 0.0731 | RMSE: 0.0731 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126164.453\n",
      "[Epoch 9, Batch 19/100] Loss: 0.0746 | RMSE: 0.0746 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 98096.430\n",
      "[Epoch 9, Batch 20/100] Loss: 0.0707 | RMSE: 0.0707 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113377.406\n",
      "[Epoch 9, Batch 21/100] Loss: 0.0667 | RMSE: 0.0667 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 38631.273\n",
      "[Epoch 9, Batch 22/100] Loss: 0.0722 | RMSE: 0.0722 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 99091.617\n",
      "[Epoch 9, Batch 23/100] Loss: 0.0802 | RMSE: 0.0802 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108939.102\n",
      "[Epoch 9, Batch 24/100] Loss: 0.0755 | RMSE: 0.0755 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 60835.781\n",
      "[Epoch 9, Batch 25/100] Loss: 0.0706 | RMSE: 0.0706 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94692.781\n",
      "[Epoch 9, Batch 26/100] Loss: 0.0717 | RMSE: 0.0717 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 133545.672\n",
      "[Epoch 9, Batch 27/100] Loss: 0.0798 | RMSE: 0.0798 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121259.734\n",
      "[Epoch 9, Batch 28/100] Loss: 0.0786 | RMSE: 0.0786 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 99508.484\n",
      "[Epoch 9, Batch 29/100] Loss: 0.0706 | RMSE: 0.0706 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113341.859\n",
      "[Epoch 9, Batch 30/100] Loss: 0.0707 | RMSE: 0.0707 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137173.828\n",
      "[Epoch 9, Batch 31/100] Loss: 0.0763 | RMSE: 0.0763 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 136208.578\n",
      "[Epoch 9, Batch 32/100] Loss: 0.0561 | RMSE: 0.0561 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 90330.000\n",
      "[Epoch 9, Batch 33/100] Loss: 0.0727 | RMSE: 0.0727 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111359.773\n",
      "[Epoch 9, Batch 34/100] Loss: 0.0775 | RMSE: 0.0775 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116529.680\n",
      "[Epoch 9, Batch 35/100] Loss: 0.0934 | RMSE: 0.0934 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154143.047\n",
      "[Epoch 9, Batch 36/100] Loss: 0.0667 | RMSE: 0.0667 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 82210.242\n",
      "[Epoch 9, Batch 37/100] Loss: 0.0764 | RMSE: 0.0764 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 136983.047\n",
      "[Epoch 9, Batch 38/100] Loss: 0.0820 | RMSE: 0.0820 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138985.250\n",
      "[Epoch 9, Batch 39/100] Loss: 0.0769 | RMSE: 0.0769 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108213.328\n",
      "[Epoch 9, Batch 40/100] Loss: 0.0711 | RMSE: 0.0711 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119002.961\n",
      "[Epoch 9, Batch 41/100] Loss: 0.0828 | RMSE: 0.0828 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129036.570\n",
      "[Epoch 9, Batch 42/100] Loss: 0.0620 | RMSE: 0.0620 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122383.242\n",
      "[Epoch 9, Batch 43/100] Loss: 0.0662 | RMSE: 0.0662 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138306.812\n",
      "[Epoch 9, Batch 44/100] Loss: 0.0657 | RMSE: 0.0657 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125607.672\n",
      "[Epoch 9, Batch 45/100] Loss: 0.0556 | RMSE: 0.0556 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 51889.984\n",
      "[Epoch 9, Batch 46/100] Loss: 0.0692 | RMSE: 0.0692 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95356.781\n",
      "[Epoch 9, Batch 47/100] Loss: 0.0758 | RMSE: 0.0758 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 75910.383\n",
      "[Epoch 9, Batch 48/100] Loss: 0.0676 | RMSE: 0.0676 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 61234.922\n",
      "[Epoch 9, Batch 49/100] Loss: 0.0739 | RMSE: 0.0739 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 93408.398\n",
      "[Epoch 9, Batch 50/100] Loss: 0.0573 | RMSE: 0.0573 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 70593.688\n",
      "[Epoch 9, Batch 51/100] Loss: 0.0748 | RMSE: 0.0748 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125821.430\n",
      "[Epoch 9, Batch 52/100] Loss: 0.0762 | RMSE: 0.0762 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 101495.602\n",
      "[Epoch 9, Batch 53/100] Loss: 0.0657 | RMSE: 0.0657 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 40352.566\n",
      "[Epoch 9, Batch 54/100] Loss: 0.0655 | RMSE: 0.0655 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 72691.344\n",
      "[Epoch 9, Batch 55/100] Loss: 0.0875 | RMSE: 0.0875 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 164904.453\n",
      "[Epoch 9, Batch 56/100] Loss: 0.0765 | RMSE: 0.0765 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111792.133\n",
      "[Epoch 9, Batch 57/100] Loss: 0.0757 | RMSE: 0.0757 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 119285.039\n",
      "[Epoch 9, Batch 58/100] Loss: 0.0797 | RMSE: 0.0797 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156377.422\n",
      "[Epoch 9, Batch 59/100] Loss: 0.0730 | RMSE: 0.0730 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 68027.086\n",
      "[Epoch 9, Batch 60/100] Loss: 0.0804 | RMSE: 0.0804 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 167444.297\n",
      "[Epoch 9, Batch 61/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 172138.516\n",
      "[Epoch 9, Batch 62/100] Loss: 0.0818 | RMSE: 0.0818 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 140279.281\n",
      "[Epoch 9, Batch 63/100] Loss: 0.0740 | RMSE: 0.0740 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 142441.516\n",
      "[Epoch 9, Batch 64/100] Loss: 0.0564 | RMSE: 0.0564 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 68631.414\n",
      "[Epoch 9, Batch 65/100] Loss: 0.0705 | RMSE: 0.0705 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 55346.367\n",
      "[Epoch 9, Batch 66/100] Loss: 0.0815 | RMSE: 0.0815 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116525.195\n",
      "[Epoch 9, Batch 67/100] Loss: 0.0862 | RMSE: 0.0862 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161056.141\n",
      "[Epoch 9, Batch 68/100] Loss: 0.0630 | RMSE: 0.0630 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 80535.648\n",
      "[Epoch 9, Batch 69/100] Loss: 0.0736 | RMSE: 0.0736 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 110319.609\n",
      "[Epoch 9, Batch 70/100] Loss: 0.0892 | RMSE: 0.0892 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 140617.406\n",
      "[Epoch 9, Batch 71/100] Loss: 0.0579 | RMSE: 0.0579 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 79612.414\n",
      "[Epoch 9, Batch 72/100] Loss: 0.0642 | RMSE: 0.0642 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116626.531\n",
      "[Epoch 9, Batch 73/100] Loss: 0.0703 | RMSE: 0.0703 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97807.484\n",
      "[Epoch 9, Batch 74/100] Loss: 0.0710 | RMSE: 0.0710 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 75514.750\n",
      "[Epoch 9, Batch 75/100] Loss: 0.0692 | RMSE: 0.0692 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87470.398\n",
      "[Epoch 9, Batch 76/100] Loss: 0.0777 | RMSE: 0.0777 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116361.469\n",
      "[Epoch 9, Batch 77/100] Loss: 0.0670 | RMSE: 0.0670 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114750.633\n",
      "[Epoch 9, Batch 78/100] Loss: 0.0736 | RMSE: 0.0736 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146047.516\n",
      "[Epoch 9, Batch 79/100] Loss: 0.0666 | RMSE: 0.0666 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139697.906\n",
      "[Epoch 9, Batch 80/100] Loss: 0.0725 | RMSE: 0.0725 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118248.688\n",
      "[Epoch 9, Batch 81/100] Loss: 0.0705 | RMSE: 0.0705 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 115346.562\n",
      "[Epoch 9, Batch 82/100] Loss: 0.0648 | RMSE: 0.0648 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 123541.891\n",
      "[Epoch 9, Batch 83/100] Loss: 0.0731 | RMSE: 0.0731 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137355.500\n",
      "[Epoch 9, Batch 84/100] Loss: 0.0608 | RMSE: 0.0608 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 87559.125\n",
      "[Epoch 9, Batch 85/100] Loss: 0.0738 | RMSE: 0.0738 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 106831.414\n",
      "[Epoch 9, Batch 86/100] Loss: 0.0673 | RMSE: 0.0673 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95554.258\n",
      "[Epoch 9, Batch 87/100] Loss: 0.0644 | RMSE: 0.0644 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138379.156\n",
      "[Epoch 9, Batch 88/100] Loss: 0.0600 | RMSE: 0.0600 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 86698.828\n",
      "[Epoch 9, Batch 89/100] Loss: 0.0587 | RMSE: 0.0587 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 80472.977\n",
      "[Epoch 9, Batch 90/100] Loss: 0.0646 | RMSE: 0.0646 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85628.258\n",
      "[Epoch 9, Batch 91/100] Loss: 0.0736 | RMSE: 0.0736 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138410.781\n",
      "[Epoch 9, Batch 92/100] Loss: 0.0766 | RMSE: 0.0766 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 146786.828\n",
      "[Epoch 9, Batch 93/100] Loss: 0.0696 | RMSE: 0.0696 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 70750.914\n",
      "[Epoch 9, Batch 94/100] Loss: 0.0823 | RMSE: 0.0823 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 106680.844\n",
      "[Epoch 9, Batch 95/100] Loss: 0.0878 | RMSE: 0.0878 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 185867.078\n",
      "[Epoch 9, Batch 96/100] Loss: 0.0666 | RMSE: 0.0666 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109371.977\n",
      "[Epoch 9, Batch 97/100] Loss: 0.0768 | RMSE: 0.0768 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 144606.859\n",
      "[Epoch 9, Batch 98/100] Loss: 0.0810 | RMSE: 0.0810 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 171035.453\n",
      "[Epoch 9, Batch 99/100] Loss: 0.0740 | RMSE: 0.0740 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 112116.133\n",
      "[Epoch 9, Batch 100/100] Loss: 0.0795 | RMSE: 0.0795 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137812.688\n",
      "✅ Epoch 9 완료!\n",
      "   📈 평균 Loss: 0.074370\n",
      "   📊 평균 RMSE: 0.074370\n",
      "   ⚙️  학습률: 0.001000\n",
      "   🏆 NEW BEST! RMSE: 0.074370\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 10/80 시작...\n",
      "[Epoch 10, Batch 1/100] Loss: 0.0821 | RMSE: 0.0821 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 132514.016\n",
      "[Epoch 10, Batch 2/100] Loss: 0.0792 | RMSE: 0.0792 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 131080.719\n",
      "[Epoch 10, Batch 3/100] Loss: 0.0754 | RMSE: 0.0754 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 97576.062\n",
      "[Epoch 10, Batch 4/100] Loss: 0.0664 | RMSE: 0.0664 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108639.758\n",
      "[Epoch 10, Batch 5/100] Loss: 0.0618 | RMSE: 0.0618 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 59277.207\n",
      "[Epoch 10, Batch 6/100] Loss: 0.0707 | RMSE: 0.0707 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 84201.109\n",
      "[Epoch 10, Batch 7/100] Loss: 0.0568 | RMSE: 0.0568 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 55373.570\n",
      "[Epoch 10, Batch 8/100] Loss: 0.0764 | RMSE: 0.0764 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105632.539\n",
      "[Epoch 10, Batch 9/100] Loss: 0.0766 | RMSE: 0.0766 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137222.922\n",
      "[Epoch 10, Batch 10/100] Loss: 0.0630 | RMSE: 0.0630 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 25014.174\n",
      "[Epoch 10, Batch 11/100] Loss: 0.0807 | RMSE: 0.0807 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 150579.734\n",
      "[Epoch 10, Batch 12/100] Loss: 0.1051 | RMSE: 0.1051 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 200747.594\n",
      "[Epoch 10, Batch 13/100] Loss: 0.0907 | RMSE: 0.0907 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129205.617\n",
      "[Epoch 10, Batch 14/100] Loss: 0.0754 | RMSE: 0.0754 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 64848.039\n",
      "[Epoch 10, Batch 15/100] Loss: 0.0832 | RMSE: 0.0832 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 120915.570\n",
      "[Epoch 10, Batch 16/100] Loss: 0.0805 | RMSE: 0.0805 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94013.422\n",
      "[Epoch 10, Batch 17/100] Loss: 0.0769 | RMSE: 0.0769 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 99442.227\n",
      "[Epoch 10, Batch 18/100] Loss: 0.0745 | RMSE: 0.0745 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 116630.500\n",
      "[Epoch 10, Batch 19/100] Loss: 0.0728 | RMSE: 0.0728 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 54021.621\n",
      "[Epoch 10, Batch 20/100] Loss: 0.0934 | RMSE: 0.0934 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126448.867\n",
      "[Epoch 10, Batch 21/100] Loss: 0.1020 | RMSE: 0.1020 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 168306.000\n",
      "[Epoch 10, Batch 22/100] Loss: 0.0857 | RMSE: 0.0857 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85254.898\n",
      "[Epoch 10, Batch 23/100] Loss: 0.0837 | RMSE: 0.0837 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 95977.945\n",
      "[Epoch 10, Batch 24/100] Loss: 0.0872 | RMSE: 0.0872 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148666.812\n",
      "[Epoch 10, Batch 25/100] Loss: 0.0759 | RMSE: 0.0759 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137286.156\n",
      "[Epoch 10, Batch 26/100] Loss: 0.0609 | RMSE: 0.0609 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113277.422\n",
      "[Epoch 10, Batch 27/100] Loss: 0.0792 | RMSE: 0.0792 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113645.711\n",
      "[Epoch 10, Batch 28/100] Loss: 0.0750 | RMSE: 0.0750 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111997.195\n",
      "[Epoch 10, Batch 29/100] Loss: 0.0624 | RMSE: 0.0624 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 77208.969\n",
      "[Epoch 10, Batch 30/100] Loss: 0.0768 | RMSE: 0.0768 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 148706.406\n",
      "[Epoch 10, Batch 31/100] Loss: 0.0826 | RMSE: 0.0826 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 176003.891\n",
      "[Epoch 10, Batch 32/100] Loss: 0.0865 | RMSE: 0.0865 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126780.016\n",
      "[Epoch 10, Batch 33/100] Loss: 0.0589 | RMSE: 0.0589 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 90408.461\n",
      "[Epoch 10, Batch 34/100] Loss: 0.0953 | RMSE: 0.0953 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 193601.781\n",
      "[Epoch 10, Batch 35/100] Loss: 0.0957 | RMSE: 0.0957 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 182744.344\n",
      "[Epoch 10, Batch 36/100] Loss: 0.0690 | RMSE: 0.0690 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 133121.500\n",
      "[Epoch 10, Batch 37/100] Loss: 0.0781 | RMSE: 0.0781 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 162675.719\n",
      "[Epoch 10, Batch 38/100] Loss: 0.0908 | RMSE: 0.0908 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 160048.297\n",
      "[Epoch 10, Batch 39/100] Loss: 0.0823 | RMSE: 0.0823 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152787.812\n",
      "[Epoch 10, Batch 40/100] Loss: 0.0776 | RMSE: 0.0776 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 105732.398\n",
      "[Epoch 10, Batch 41/100] Loss: 0.0815 | RMSE: 0.0815 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 165764.672\n",
      "[Epoch 10, Batch 42/100] Loss: 0.0783 | RMSE: 0.0783 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126028.609\n",
      "[Epoch 10, Batch 43/100] Loss: 0.0829 | RMSE: 0.0829 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 106743.555\n",
      "[Epoch 10, Batch 44/100] Loss: 0.0617 | RMSE: 0.0617 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 70508.961\n",
      "[Epoch 10, Batch 45/100] Loss: 0.0820 | RMSE: 0.0820 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 141620.656\n",
      "[Epoch 10, Batch 46/100] Loss: 0.0599 | RMSE: 0.0599 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 107839.836\n",
      "[Epoch 10, Batch 47/100] Loss: 0.0653 | RMSE: 0.0653 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 138504.781\n",
      "[Epoch 10, Batch 48/100] Loss: 0.0742 | RMSE: 0.0742 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 133854.953\n",
      "[Epoch 10, Batch 49/100] Loss: 0.0631 | RMSE: 0.0631 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 73206.258\n",
      "[Epoch 10, Batch 50/100] Loss: 0.0656 | RMSE: 0.0656 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 86420.312\n",
      "[Epoch 10, Batch 51/100] Loss: 0.0766 | RMSE: 0.0766 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 143690.703\n",
      "[Epoch 10, Batch 52/100] Loss: 0.0750 | RMSE: 0.0750 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 104260.125\n",
      "[Epoch 10, Batch 53/100] Loss: 0.0732 | RMSE: 0.0732 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 125454.641\n",
      "[Epoch 10, Batch 54/100] Loss: 0.0758 | RMSE: 0.0758 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 173731.172\n",
      "[Epoch 10, Batch 55/100] Loss: 0.0734 | RMSE: 0.0734 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 151379.031\n",
      "[Epoch 10, Batch 56/100] Loss: 0.0803 | RMSE: 0.0803 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 156399.703\n",
      "[Epoch 10, Batch 57/100] Loss: 0.0707 | RMSE: 0.0707 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152304.156\n",
      "[Epoch 10, Batch 58/100] Loss: 0.0663 | RMSE: 0.0663 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129382.516\n",
      "[Epoch 10, Batch 59/100] Loss: 0.0800 | RMSE: 0.0800 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147459.906\n",
      "[Epoch 10, Batch 60/100] Loss: 0.0626 | RMSE: 0.0626 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 126834.742\n",
      "[Epoch 10, Batch 61/100] Loss: 0.0703 | RMSE: 0.0703 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 158825.703\n",
      "[Epoch 10, Batch 62/100] Loss: 0.0682 | RMSE: 0.0682 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 113454.836\n",
      "[Epoch 10, Batch 63/100] Loss: 0.0715 | RMSE: 0.0715 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 88253.891\n",
      "[Epoch 10, Batch 64/100] Loss: 0.0664 | RMSE: 0.0664 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 123938.641\n",
      "[Epoch 10, Batch 65/100] Loss: 0.0704 | RMSE: 0.0704 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 108619.758\n",
      "[Epoch 10, Batch 66/100] Loss: 0.0714 | RMSE: 0.0714 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 80826.734\n",
      "[Epoch 10, Batch 67/100] Loss: 0.0718 | RMSE: 0.0718 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 137123.078\n",
      "[Epoch 10, Batch 68/100] Loss: 0.0735 | RMSE: 0.0735 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 122856.922\n",
      "[Epoch 10, Batch 69/100] Loss: 0.0652 | RMSE: 0.0652 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 135754.109\n",
      "[Epoch 10, Batch 70/100] Loss: 0.0687 | RMSE: 0.0687 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 94628.172\n",
      "[Epoch 10, Batch 71/100] Loss: 0.0637 | RMSE: 0.0637 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 131288.500\n",
      "[Epoch 10, Batch 72/100] Loss: 0.0737 | RMSE: 0.0737 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 127822.250\n",
      "[Epoch 10, Batch 73/100] Loss: 0.0638 | RMSE: 0.0638 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 85237.078\n",
      "[Epoch 10, Batch 74/100] Loss: 0.0899 | RMSE: 0.0899 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 154771.031\n",
      "[Epoch 10, Batch 75/100] Loss: 0.0842 | RMSE: 0.0842 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 90613.945\n",
      "[Epoch 10, Batch 76/100] Loss: 0.0694 | RMSE: 0.0694 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 109556.898\n",
      "[Epoch 10, Batch 77/100] Loss: 0.0684 | RMSE: 0.0684 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 139969.812\n",
      "[Epoch 10, Batch 78/100] Loss: 0.0786 | RMSE: 0.0786 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 128854.125\n",
      "[Epoch 10, Batch 79/100] Loss: 0.0753 | RMSE: 0.0753 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 86501.211\n",
      "[Epoch 10, Batch 80/100] Loss: 0.0656 | RMSE: 0.0656 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 63547.594\n",
      "[Epoch 10, Batch 81/100] Loss: 0.0738 | RMSE: 0.0738 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 114884.383\n",
      "[Epoch 10, Batch 82/100] Loss: 0.0785 | RMSE: 0.0785 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 121418.789\n",
      "[Epoch 10, Batch 83/100] Loss: 0.0706 | RMSE: 0.0706 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 24920.594\n",
      "[Epoch 10, Batch 84/100] Loss: 0.0715 | RMSE: 0.0715 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 34287.160\n",
      "[Epoch 10, Batch 85/100] Loss: 0.0739 | RMSE: 0.0739 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 144675.266\n",
      "[Epoch 10, Batch 86/100] Loss: 0.0820 | RMSE: 0.0820 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 118484.266\n",
      "[Epoch 10, Batch 87/100] Loss: 0.0865 | RMSE: 0.0865 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 169688.609\n",
      "[Epoch 10, Batch 88/100] Loss: 0.0785 | RMSE: 0.0785 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 129631.336\n",
      "[Epoch 10, Batch 89/100] Loss: 0.0757 | RMSE: 0.0757 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 157340.984\n",
      "[Epoch 10, Batch 90/100] Loss: 0.0712 | RMSE: 0.0712 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 130475.102\n",
      "[Epoch 10, Batch 91/100] Loss: 0.0762 | RMSE: 0.0762 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 140236.047\n",
      "[Epoch 10, Batch 92/100] Loss: 0.0770 | RMSE: 0.0770 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 111886.055\n",
      "[Epoch 10, Batch 93/100] Loss: 0.0752 | RMSE: 0.0752 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 145824.359\n",
      "[Epoch 10, Batch 94/100] Loss: 0.0845 | RMSE: 0.0845 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 161100.859\n",
      "[Epoch 10, Batch 95/100] Loss: 0.0651 | RMSE: 0.0651 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 92587.258\n",
      "[Epoch 10, Batch 96/100] Loss: 0.0611 | RMSE: 0.0611 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 142173.078\n",
      "[Epoch 10, Batch 97/100] Loss: 0.0810 | RMSE: 0.0810 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 152829.219\n",
      "[Epoch 10, Batch 98/100] Loss: 0.0795 | RMSE: 0.0795 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 145578.750\n",
      "[Epoch 10, Batch 99/100] Loss: 0.0610 | RMSE: 0.0610 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 67460.094\n",
      "[Epoch 10, Batch 100/100] Loss: 0.0716 | RMSE: 0.0716 | Consistency: 0.0000 | SSIM: 0.0000 | Grad: 147778.578\n",
      "✅ Epoch 10 완료!\n",
      "   📈 평균 Loss: 0.075198\n",
      "   📊 평균 RMSE: 0.075198\n",
      "   ⚙️  학습률: 0.000998\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 11/80 시작...\n",
      "[Epoch 11, Batch 1/100] Loss: 0.0799 | RMSE: 0.0738 | Consistency: 0.0257 | SSIM: 0.0583 | Grad: 122143.812\n",
      "[Epoch 11, Batch 2/100] Loss: 0.0676 | RMSE: 0.0619 | Consistency: 0.0213 | SSIM: 0.0540 | Grad: 134046.844\n",
      "[Epoch 11, Batch 3/100] Loss: 0.0695 | RMSE: 0.0631 | Consistency: 0.0170 | SSIM: 0.0626 | Grad: 128562.891\n",
      "[Epoch 11, Batch 4/100] Loss: 0.0882 | RMSE: 0.0811 | Consistency: 0.0411 | SSIM: 0.0664 | Grad: 166480.656\n",
      "[Epoch 11, Batch 5/100] Loss: 0.0714 | RMSE: 0.0657 | Consistency: 0.0213 | SSIM: 0.0551 | Grad: 94713.312\n",
      "[Epoch 11, Batch 6/100] Loss: 0.0688 | RMSE: 0.0636 | Consistency: 0.0216 | SSIM: 0.0501 | Grad: 64126.059\n",
      "[Epoch 11, Batch 7/100] Loss: 0.0846 | RMSE: 0.0789 | Consistency: 0.0365 | SSIM: 0.0530 | Grad: 108152.258\n",
      "[Epoch 11, Batch 8/100] Loss: 0.0787 | RMSE: 0.0727 | Consistency: 0.0292 | SSIM: 0.0571 | Grad: 131131.516\n",
      "[Epoch 11, Batch 9/100] Loss: 0.0742 | RMSE: 0.0687 | Consistency: 0.0204 | SSIM: 0.0533 | Grad: 82137.219\n",
      "[Epoch 11, Batch 10/100] Loss: 0.0855 | RMSE: 0.0797 | Consistency: 0.0352 | SSIM: 0.0544 | Grad: 139232.562\n",
      "[Epoch 11, Batch 11/100] Loss: 0.0815 | RMSE: 0.0755 | Consistency: 0.0238 | SSIM: 0.0581 | Grad: 151780.062\n",
      "[Epoch 11, Batch 12/100] Loss: 0.0823 | RMSE: 0.0765 | Consistency: 0.0210 | SSIM: 0.0563 | Grad: 163728.094\n",
      "[Epoch 11, Batch 13/100] Loss: 0.0794 | RMSE: 0.0736 | Consistency: 0.0297 | SSIM: 0.0554 | Grad: 147476.672\n",
      "[Epoch 11, Batch 14/100] Loss: 0.0765 | RMSE: 0.0711 | Consistency: 0.0210 | SSIM: 0.0521 | Grad: 127299.211\n",
      "[Epoch 11, Batch 15/100] Loss: 0.0723 | RMSE: 0.0672 | Consistency: 0.0205 | SSIM: 0.0487 | Grad: 121741.742\n",
      "[Epoch 11, Batch 16/100] Loss: 0.0750 | RMSE: 0.0691 | Consistency: 0.0234 | SSIM: 0.0560 | Grad: 60931.078\n",
      "[Epoch 11, Batch 17/100] Loss: 0.0886 | RMSE: 0.0830 | Consistency: 0.0298 | SSIM: 0.0531 | Grad: 132270.250\n",
      "[Epoch 11, Batch 18/100] Loss: 0.0786 | RMSE: 0.0737 | Consistency: 0.0232 | SSIM: 0.0469 | Grad: 123674.227\n",
      "[Epoch 11, Batch 19/100] Loss: 0.0882 | RMSE: 0.0822 | Consistency: 0.0374 | SSIM: 0.0565 | Grad: 164755.438\n",
      "[Epoch 11, Batch 20/100] Loss: 0.0727 | RMSE: 0.0675 | Consistency: 0.0206 | SSIM: 0.0500 | Grad: 79748.617\n",
      "[Epoch 11, Batch 21/100] Loss: 0.0873 | RMSE: 0.0810 | Consistency: 0.0297 | SSIM: 0.0609 | Grad: 84311.320\n",
      "[Epoch 11, Batch 22/100] Loss: 0.0720 | RMSE: 0.0665 | Consistency: 0.0255 | SSIM: 0.0526 | Grad: 121787.430\n",
      "[Epoch 11, Batch 23/100] Loss: 0.0669 | RMSE: 0.0620 | Consistency: 0.0172 | SSIM: 0.0471 | Grad: 56243.008\n",
      "[Epoch 11, Batch 24/100] Loss: 0.0818 | RMSE: 0.0756 | Consistency: 0.0382 | SSIM: 0.0587 | Grad: 154341.234\n",
      "[Epoch 11, Batch 25/100] Loss: 0.0830 | RMSE: 0.0767 | Consistency: 0.0413 | SSIM: 0.0590 | Grad: 173222.688\n",
      "[Epoch 11, Batch 26/100] Loss: 0.0644 | RMSE: 0.0600 | Consistency: 0.0171 | SSIM: 0.0424 | Grad: 101701.906\n",
      "[Epoch 11, Batch 27/100] Loss: 0.0802 | RMSE: 0.0736 | Consistency: 0.0283 | SSIM: 0.0636 | Grad: 116041.086\n",
      "[Epoch 11, Batch 28/100] Loss: 0.0642 | RMSE: 0.0591 | Consistency: 0.0216 | SSIM: 0.0491 | Grad: 101838.773\n",
      "[Epoch 11, Batch 29/100] Loss: 0.0772 | RMSE: 0.0713 | Consistency: 0.0325 | SSIM: 0.0562 | Grad: 94629.555\n",
      "[Epoch 11, Batch 30/100] Loss: 0.0710 | RMSE: 0.0656 | Consistency: 0.0258 | SSIM: 0.0520 | Grad: 107919.844\n",
      "[Epoch 11, Batch 31/100] Loss: 0.0709 | RMSE: 0.0659 | Consistency: 0.0226 | SSIM: 0.0483 | Grad: 78703.250\n",
      "[Epoch 11, Batch 32/100] Loss: 0.0720 | RMSE: 0.0668 | Consistency: 0.0230 | SSIM: 0.0497 | Grad: 134381.266\n",
      "[Epoch 11, Batch 33/100] Loss: 0.0716 | RMSE: 0.0664 | Consistency: 0.0243 | SSIM: 0.0496 | Grad: 126239.648\n",
      "[Epoch 11, Batch 34/100] Loss: 0.0699 | RMSE: 0.0649 | Consistency: 0.0196 | SSIM: 0.0487 | Grad: 117793.336\n",
      "[Epoch 11, Batch 35/100] Loss: 0.0867 | RMSE: 0.0799 | Consistency: 0.0346 | SSIM: 0.0642 | Grad: 91491.766\n",
      "[Epoch 11, Batch 36/100] Loss: 0.0815 | RMSE: 0.0755 | Consistency: 0.0233 | SSIM: 0.0573 | Grad: 139625.250\n",
      "[Epoch 11, Batch 37/100] Loss: 0.0713 | RMSE: 0.0658 | Consistency: 0.0204 | SSIM: 0.0530 | Grad: 81756.867\n",
      "[Epoch 11, Batch 38/100] Loss: 0.0895 | RMSE: 0.0839 | Consistency: 0.0281 | SSIM: 0.0536 | Grad: 199673.812\n",
      "[Epoch 11, Batch 39/100] Loss: 0.0828 | RMSE: 0.0771 | Consistency: 0.0237 | SSIM: 0.0541 | Grad: 204682.297\n",
      "[Epoch 11, Batch 40/100] Loss: 0.0885 | RMSE: 0.0823 | Consistency: 0.0309 | SSIM: 0.0594 | Grad: 178728.938\n",
      "[Epoch 11, Batch 41/100] Loss: 0.0773 | RMSE: 0.0714 | Consistency: 0.0246 | SSIM: 0.0561 | Grad: 129773.680\n",
      "[Epoch 11, Batch 42/100] Loss: 0.0681 | RMSE: 0.0629 | Consistency: 0.0194 | SSIM: 0.0506 | Grad: 114546.875\n",
      "[Epoch 11, Batch 43/100] Loss: 0.0667 | RMSE: 0.0617 | Consistency: 0.0171 | SSIM: 0.0476 | Grad: 125180.703\n",
      "[Epoch 11, Batch 44/100] Loss: 0.0778 | RMSE: 0.0723 | Consistency: 0.0219 | SSIM: 0.0521 | Grad: 135817.562\n",
      "[Epoch 11, Batch 45/100] Loss: 0.0744 | RMSE: 0.0681 | Consistency: 0.0219 | SSIM: 0.0606 | Grad: 110356.516\n",
      "[Epoch 11, Batch 46/100] Loss: 0.0739 | RMSE: 0.0677 | Consistency: 0.0202 | SSIM: 0.0592 | Grad: 121329.719\n",
      "[Epoch 11, Batch 47/100] Loss: 0.0717 | RMSE: 0.0669 | Consistency: 0.0216 | SSIM: 0.0459 | Grad: 128513.570\n",
      "[Epoch 11, Batch 48/100] Loss: 0.0742 | RMSE: 0.0694 | Consistency: 0.0190 | SSIM: 0.0464 | Grad: 129174.891\n",
      "[Epoch 11, Batch 49/100] Loss: 0.0560 | RMSE: 0.0522 | Consistency: 0.0135 | SSIM: 0.0376 | Grad: 102288.164\n",
      "[Epoch 11, Batch 50/100] Loss: 0.0693 | RMSE: 0.0637 | Consistency: 0.0218 | SSIM: 0.0534 | Grad: 127387.961\n",
      "[Epoch 11, Batch 51/100] Loss: 0.0774 | RMSE: 0.0719 | Consistency: 0.0242 | SSIM: 0.0525 | Grad: 154667.641\n",
      "[Epoch 11, Batch 52/100] Loss: 0.0631 | RMSE: 0.0583 | Consistency: 0.0186 | SSIM: 0.0466 | Grad: 77890.945\n",
      "[Epoch 11, Batch 53/100] Loss: 0.0623 | RMSE: 0.0577 | Consistency: 0.0155 | SSIM: 0.0448 | Grad: 96858.094\n",
      "[Epoch 11, Batch 54/100] Loss: 0.0721 | RMSE: 0.0677 | Consistency: 0.0162 | SSIM: 0.0425 | Grad: 109930.148\n",
      "[Epoch 11, Batch 55/100] Loss: 0.0708 | RMSE: 0.0661 | Consistency: 0.0201 | SSIM: 0.0443 | Grad: 91922.156\n",
      "[Epoch 11, Batch 56/100] Loss: 0.0668 | RMSE: 0.0625 | Consistency: 0.0179 | SSIM: 0.0415 | Grad: 23671.574\n",
      "[Epoch 11, Batch 57/100] Loss: 0.0849 | RMSE: 0.0784 | Consistency: 0.0220 | SSIM: 0.0629 | Grad: 156115.922\n",
      "[Epoch 11, Batch 58/100] Loss: 0.0826 | RMSE: 0.0767 | Consistency: 0.0228 | SSIM: 0.0569 | Grad: 144274.547\n",
      "[Epoch 11, Batch 59/100] Loss: 0.0863 | RMSE: 0.0794 | Consistency: 0.0296 | SSIM: 0.0656 | Grad: 98435.008\n",
      "[Epoch 11, Batch 60/100] Loss: 0.0789 | RMSE: 0.0730 | Consistency: 0.0260 | SSIM: 0.0567 | Grad: 90598.438\n",
      "[Epoch 11, Batch 61/100] Loss: 0.0803 | RMSE: 0.0743 | Consistency: 0.0225 | SSIM: 0.0577 | Grad: 114358.734\n",
      "[Epoch 11, Batch 62/100] Loss: 0.0746 | RMSE: 0.0692 | Consistency: 0.0228 | SSIM: 0.0516 | Grad: 55679.449\n",
      "[Epoch 11, Batch 63/100] Loss: 0.0752 | RMSE: 0.0698 | Consistency: 0.0272 | SSIM: 0.0520 | Grad: 113760.227\n",
      "[Epoch 11, Batch 64/100] Loss: 0.0786 | RMSE: 0.0732 | Consistency: 0.0250 | SSIM: 0.0519 | Grad: 170552.797\n",
      "[Epoch 11, Batch 65/100] Loss: 0.0637 | RMSE: 0.0585 | Consistency: 0.0201 | SSIM: 0.0503 | Grad: 63149.871\n",
      "[Epoch 11, Batch 66/100] Loss: 0.0690 | RMSE: 0.0635 | Consistency: 0.0237 | SSIM: 0.0530 | Grad: 107439.555\n",
      "[Epoch 11, Batch 67/100] Loss: 0.0796 | RMSE: 0.0731 | Consistency: 0.0247 | SSIM: 0.0626 | Grad: 52943.730\n",
      "[Epoch 11, Batch 68/100] Loss: 0.0662 | RMSE: 0.0613 | Consistency: 0.0186 | SSIM: 0.0473 | Grad: 58261.848\n",
      "[Epoch 11, Batch 69/100] Loss: 0.0888 | RMSE: 0.0826 | Consistency: 0.0338 | SSIM: 0.0583 | Grad: 165058.453\n",
      "[Epoch 11, Batch 70/100] Loss: 0.0749 | RMSE: 0.0696 | Consistency: 0.0251 | SSIM: 0.0499 | Grad: 120638.898\n",
      "[Epoch 11, Batch 71/100] Loss: 0.0664 | RMSE: 0.0614 | Consistency: 0.0193 | SSIM: 0.0481 | Grad: 127920.680\n",
      "[Epoch 11, Batch 72/100] Loss: 0.0798 | RMSE: 0.0740 | Consistency: 0.0242 | SSIM: 0.0556 | Grad: 131883.453\n",
      "[Epoch 11, Batch 73/100] Loss: 0.0730 | RMSE: 0.0673 | Consistency: 0.0305 | SSIM: 0.0536 | Grad: 135876.188\n",
      "[Epoch 11, Batch 74/100] Loss: 0.0783 | RMSE: 0.0736 | Consistency: 0.0214 | SSIM: 0.0443 | Grad: 101155.922\n",
      "[Epoch 11, Batch 75/100] Loss: 0.0727 | RMSE: 0.0679 | Consistency: 0.0195 | SSIM: 0.0455 | Grad: 117278.609\n",
      "[Epoch 11, Batch 76/100] Loss: 0.0693 | RMSE: 0.0644 | Consistency: 0.0219 | SSIM: 0.0465 | Grad: 128336.773\n",
      "[Epoch 11, Batch 77/100] Loss: 0.0756 | RMSE: 0.0704 | Consistency: 0.0276 | SSIM: 0.0495 | Grad: 91505.391\n",
      "[Epoch 11, Batch 78/100] Loss: 0.0812 | RMSE: 0.0750 | Consistency: 0.0271 | SSIM: 0.0591 | Grad: 118408.602\n",
      "[Epoch 11, Batch 79/100] Loss: 0.0759 | RMSE: 0.0700 | Consistency: 0.0306 | SSIM: 0.0557 | Grad: 126327.031\n",
      "[Epoch 11, Batch 80/100] Loss: 0.0710 | RMSE: 0.0656 | Consistency: 0.0265 | SSIM: 0.0512 | Grad: 122790.617\n",
      "[Epoch 11, Batch 81/100] Loss: 0.0619 | RMSE: 0.0575 | Consistency: 0.0144 | SSIM: 0.0422 | Grad: 36260.441\n",
      "[Epoch 11, Batch 82/100] Loss: 0.0851 | RMSE: 0.0790 | Consistency: 0.0299 | SSIM: 0.0577 | Grad: 147376.203\n",
      "[Epoch 11, Batch 83/100] Loss: 0.0926 | RMSE: 0.0851 | Consistency: 0.0411 | SSIM: 0.0711 | Grad: 149969.953\n",
      "[Epoch 11, Batch 84/100] Loss: 0.0769 | RMSE: 0.0712 | Consistency: 0.0297 | SSIM: 0.0541 | Grad: 100914.961\n",
      "[Epoch 11, Batch 85/100] Loss: 0.0796 | RMSE: 0.0740 | Consistency: 0.0324 | SSIM: 0.0537 | Grad: 160522.812\n",
      "[Epoch 11, Batch 86/100] Loss: 0.0930 | RMSE: 0.0864 | Consistency: 0.0361 | SSIM: 0.0625 | Grad: 204325.641\n",
      "[Epoch 11, Batch 87/100] Loss: 0.0666 | RMSE: 0.0604 | Consistency: 0.0210 | SSIM: 0.0603 | Grad: 64317.590\n",
      "[Epoch 11, Batch 88/100] Loss: 0.0803 | RMSE: 0.0751 | Consistency: 0.0224 | SSIM: 0.0496 | Grad: 141356.406\n",
      "[Epoch 11, Batch 89/100] Loss: 0.0818 | RMSE: 0.0759 | Consistency: 0.0268 | SSIM: 0.0557 | Grad: 171921.484\n",
      "[Epoch 11, Batch 90/100] Loss: 0.0725 | RMSE: 0.0673 | Consistency: 0.0272 | SSIM: 0.0497 | Grad: 131244.703\n",
      "[Epoch 11, Batch 91/100] Loss: 0.0858 | RMSE: 0.0801 | Consistency: 0.0247 | SSIM: 0.0552 | Grad: 185834.359\n",
      "[Epoch 11, Batch 92/100] Loss: 0.1195 | RMSE: 0.1113 | Consistency: 0.0426 | SSIM: 0.0782 | Grad: 229618.922\n",
      "[Epoch 11, Batch 93/100] Loss: 0.0881 | RMSE: 0.0825 | Consistency: 0.0292 | SSIM: 0.0531 | Grad: 173086.719\n",
      "[Epoch 11, Batch 94/100] Loss: 0.0710 | RMSE: 0.0661 | Consistency: 0.0209 | SSIM: 0.0475 | Grad: 102797.438\n",
      "[Epoch 11, Batch 95/100] Loss: 0.0853 | RMSE: 0.0787 | Consistency: 0.0333 | SSIM: 0.0625 | Grad: 177838.125\n",
      "[Epoch 11, Batch 96/100] Loss: 0.0679 | RMSE: 0.0632 | Consistency: 0.0220 | SSIM: 0.0444 | Grad: 94302.977\n",
      "[Epoch 11, Batch 97/100] Loss: 0.0642 | RMSE: 0.0592 | Consistency: 0.0175 | SSIM: 0.0485 | Grad: 48561.090\n",
      "[Epoch 11, Batch 98/100] Loss: 0.0774 | RMSE: 0.0714 | Consistency: 0.0254 | SSIM: 0.0575 | Grad: 103460.500\n",
      "[Epoch 11, Batch 99/100] Loss: 0.0686 | RMSE: 0.0638 | Consistency: 0.0209 | SSIM: 0.0456 | Grad: 99824.047\n",
      "[Epoch 11, Batch 100/100] Loss: 0.0793 | RMSE: 0.0736 | Consistency: 0.0250 | SSIM: 0.0542 | Grad: 123755.664\n",
      "✅ Epoch 11 완료!\n",
      "   📈 평균 Loss: 0.076425\n",
      "   📊 평균 RMSE: 0.070828\n",
      "   ⚙️  학습률: 0.000996\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 12/80 시작...\n",
      "[Epoch 12, Batch 1/100] Loss: 0.0682 | RMSE: 0.0630 | Consistency: 0.0196 | SSIM: 0.0504 | Grad: 52061.176\n",
      "[Epoch 12, Batch 2/100] Loss: 0.0800 | RMSE: 0.0745 | Consistency: 0.0307 | SSIM: 0.0517 | Grad: 140294.109\n",
      "[Epoch 12, Batch 3/100] Loss: 0.0804 | RMSE: 0.0749 | Consistency: 0.0202 | SSIM: 0.0537 | Grad: 148894.391\n",
      "[Epoch 12, Batch 4/100] Loss: 0.0749 | RMSE: 0.0695 | Consistency: 0.0232 | SSIM: 0.0518 | Grad: 114308.469\n",
      "[Epoch 12, Batch 5/100] Loss: 0.0670 | RMSE: 0.0617 | Consistency: 0.0172 | SSIM: 0.0516 | Grad: 106264.648\n",
      "[Epoch 12, Batch 6/100] Loss: 0.0847 | RMSE: 0.0786 | Consistency: 0.0358 | SSIM: 0.0570 | Grad: 81794.773\n",
      "[Epoch 12, Batch 7/100] Loss: 0.0681 | RMSE: 0.0632 | Consistency: 0.0184 | SSIM: 0.0473 | Grad: 74020.695\n",
      "[Epoch 12, Batch 8/100] Loss: 0.0772 | RMSE: 0.0724 | Consistency: 0.0198 | SSIM: 0.0459 | Grad: 147396.938\n",
      "[Epoch 12, Batch 9/100] Loss: 0.0790 | RMSE: 0.0732 | Consistency: 0.0260 | SSIM: 0.0558 | Grad: 157307.344\n",
      "[Epoch 12, Batch 10/100] Loss: 0.0744 | RMSE: 0.0692 | Consistency: 0.0198 | SSIM: 0.0500 | Grad: 151627.109\n",
      "[Epoch 12, Batch 11/100] Loss: 0.0744 | RMSE: 0.0687 | Consistency: 0.0235 | SSIM: 0.0544 | Grad: 125462.430\n",
      "[Epoch 12, Batch 12/100] Loss: 0.0715 | RMSE: 0.0654 | Consistency: 0.0213 | SSIM: 0.0589 | Grad: 86378.258\n",
      "[Epoch 12, Batch 13/100] Loss: 0.0740 | RMSE: 0.0688 | Consistency: 0.0185 | SSIM: 0.0501 | Grad: 130460.469\n",
      "[Epoch 12, Batch 14/100] Loss: 0.0803 | RMSE: 0.0753 | Consistency: 0.0246 | SSIM: 0.0478 | Grad: 119927.609\n",
      "[Epoch 12, Batch 15/100] Loss: 0.0801 | RMSE: 0.0745 | Consistency: 0.0268 | SSIM: 0.0541 | Grad: 123660.367\n",
      "[Epoch 12, Batch 16/100] Loss: 0.0912 | RMSE: 0.0846 | Consistency: 0.0367 | SSIM: 0.0626 | Grad: 149940.453\n",
      "[Epoch 12, Batch 17/100] Loss: 0.0659 | RMSE: 0.0612 | Consistency: 0.0153 | SSIM: 0.0460 | Grad: 24935.623\n",
      "[Epoch 12, Batch 18/100] Loss: 0.0699 | RMSE: 0.0650 | Consistency: 0.0170 | SSIM: 0.0477 | Grad: 88734.828\n",
      "[Epoch 12, Batch 19/100] Loss: 0.0752 | RMSE: 0.0695 | Consistency: 0.0206 | SSIM: 0.0550 | Grad: 81014.000\n",
      "[Epoch 12, Batch 20/100] Loss: 0.0718 | RMSE: 0.0665 | Consistency: 0.0195 | SSIM: 0.0511 | Grad: 91917.984\n",
      "[Epoch 12, Batch 21/100] Loss: 0.0844 | RMSE: 0.0777 | Consistency: 0.0233 | SSIM: 0.0643 | Grad: 132857.656\n",
      "[Epoch 12, Batch 22/100] Loss: 0.0706 | RMSE: 0.0656 | Consistency: 0.0193 | SSIM: 0.0481 | Grad: 68265.109\n",
      "[Epoch 12, Batch 23/100] Loss: 0.0632 | RMSE: 0.0583 | Consistency: 0.0178 | SSIM: 0.0476 | Grad: 57620.121\n",
      "[Epoch 12, Batch 24/100] Loss: 0.0778 | RMSE: 0.0720 | Consistency: 0.0300 | SSIM: 0.0548 | Grad: 168769.000\n",
      "[Epoch 12, Batch 25/100] Loss: 0.1001 | RMSE: 0.0930 | Consistency: 0.0614 | SSIM: 0.0652 | Grad: 200282.156\n",
      "[Epoch 12, Batch 26/100] Loss: 0.0899 | RMSE: 0.0835 | Consistency: 0.0436 | SSIM: 0.0589 | Grad: 165907.656\n",
      "[Epoch 12, Batch 27/100] Loss: 0.0757 | RMSE: 0.0707 | Consistency: 0.0187 | SSIM: 0.0483 | Grad: 116439.117\n",
      "[Epoch 12, Batch 28/100] Loss: 0.0834 | RMSE: 0.0772 | Consistency: 0.0423 | SSIM: 0.0580 | Grad: 137094.578\n",
      "[Epoch 12, Batch 29/100] Loss: 0.0753 | RMSE: 0.0687 | Consistency: 0.0320 | SSIM: 0.0630 | Grad: 134147.844\n",
      "[Epoch 12, Batch 30/100] Loss: 0.0711 | RMSE: 0.0652 | Consistency: 0.0208 | SSIM: 0.0566 | Grad: 97959.625\n",
      "[Epoch 12, Batch 31/100] Loss: 0.0796 | RMSE: 0.0739 | Consistency: 0.0211 | SSIM: 0.0558 | Grad: 84511.195\n",
      "[Epoch 12, Batch 32/100] Loss: 0.0809 | RMSE: 0.0749 | Consistency: 0.0232 | SSIM: 0.0576 | Grad: 101685.828\n",
      "[Epoch 12, Batch 33/100] Loss: 0.0810 | RMSE: 0.0755 | Consistency: 0.0271 | SSIM: 0.0529 | Grad: 164515.531\n",
      "[Epoch 12, Batch 34/100] Loss: 0.0778 | RMSE: 0.0714 | Consistency: 0.0307 | SSIM: 0.0617 | Grad: 130957.281\n",
      "[Epoch 12, Batch 35/100] Loss: 0.0590 | RMSE: 0.0547 | Consistency: 0.0160 | SSIM: 0.0415 | Grad: 92005.945\n",
      "[Epoch 12, Batch 36/100] Loss: 0.0683 | RMSE: 0.0633 | Consistency: 0.0271 | SSIM: 0.0471 | Grad: 133982.969\n",
      "[Epoch 12, Batch 37/100] Loss: 0.0701 | RMSE: 0.0645 | Consistency: 0.0219 | SSIM: 0.0537 | Grad: 86749.664\n",
      "[Epoch 12, Batch 38/100] Loss: 0.0714 | RMSE: 0.0669 | Consistency: 0.0200 | SSIM: 0.0433 | Grad: 117146.789\n",
      "[Epoch 12, Batch 39/100] Loss: 0.0756 | RMSE: 0.0701 | Consistency: 0.0311 | SSIM: 0.0521 | Grad: 146108.312\n",
      "[Epoch 12, Batch 40/100] Loss: 0.0638 | RMSE: 0.0594 | Consistency: 0.0189 | SSIM: 0.0429 | Grad: 30050.275\n",
      "[Epoch 12, Batch 41/100] Loss: 0.0736 | RMSE: 0.0688 | Consistency: 0.0214 | SSIM: 0.0458 | Grad: 106262.758\n",
      "[Epoch 12, Batch 42/100] Loss: 0.0686 | RMSE: 0.0636 | Consistency: 0.0193 | SSIM: 0.0481 | Grad: 91210.375\n",
      "[Epoch 12, Batch 43/100] Loss: 0.0694 | RMSE: 0.0640 | Consistency: 0.0207 | SSIM: 0.0515 | Grad: 101635.133\n",
      "[Epoch 12, Batch 44/100] Loss: 0.0692 | RMSE: 0.0644 | Consistency: 0.0214 | SSIM: 0.0458 | Grad: 121599.219\n",
      "[Epoch 12, Batch 45/100] Loss: 0.0708 | RMSE: 0.0661 | Consistency: 0.0186 | SSIM: 0.0451 | Grad: 98416.469\n",
      "[Epoch 12, Batch 46/100] Loss: 0.0710 | RMSE: 0.0660 | Consistency: 0.0201 | SSIM: 0.0480 | Grad: 100071.195\n",
      "[Epoch 12, Batch 47/100] Loss: 0.0679 | RMSE: 0.0635 | Consistency: 0.0209 | SSIM: 0.0423 | Grad: 140595.609\n",
      "[Epoch 12, Batch 48/100] Loss: 0.0654 | RMSE: 0.0614 | Consistency: 0.0210 | SSIM: 0.0378 | Grad: 102713.211\n",
      "[Epoch 12, Batch 49/100] Loss: 0.0675 | RMSE: 0.0625 | Consistency: 0.0198 | SSIM: 0.0474 | Grad: 87006.805\n",
      "[Epoch 12, Batch 50/100] Loss: 0.0748 | RMSE: 0.0699 | Consistency: 0.0257 | SSIM: 0.0471 | Grad: 160704.500\n",
      "[Epoch 12, Batch 51/100] Loss: 0.0729 | RMSE: 0.0678 | Consistency: 0.0226 | SSIM: 0.0492 | Grad: 122781.781\n",
      "[Epoch 12, Batch 52/100] Loss: 0.0592 | RMSE: 0.0547 | Consistency: 0.0132 | SSIM: 0.0446 | Grad: 54862.141\n",
      "[Epoch 12, Batch 53/100] Loss: 0.0797 | RMSE: 0.0747 | Consistency: 0.0368 | SSIM: 0.0460 | Grad: 170568.172\n",
      "[Epoch 12, Batch 54/100] Loss: 0.0685 | RMSE: 0.0639 | Consistency: 0.0255 | SSIM: 0.0436 | Grad: 108941.312\n",
      "[Epoch 12, Batch 55/100] Loss: 0.0629 | RMSE: 0.0584 | Consistency: 0.0181 | SSIM: 0.0427 | Grad: 50974.953\n",
      "[Epoch 12, Batch 56/100] Loss: 0.0676 | RMSE: 0.0626 | Consistency: 0.0226 | SSIM: 0.0473 | Grad: 42730.449\n",
      "[Epoch 12, Batch 57/100] Loss: 0.0678 | RMSE: 0.0632 | Consistency: 0.0215 | SSIM: 0.0442 | Grad: 92777.055\n",
      "[Epoch 12, Batch 58/100] Loss: 0.0832 | RMSE: 0.0777 | Consistency: 0.0260 | SSIM: 0.0517 | Grad: 140186.422\n",
      "[Epoch 12, Batch 59/100] Loss: 0.0700 | RMSE: 0.0649 | Consistency: 0.0216 | SSIM: 0.0485 | Grad: 148105.562\n",
      "[Epoch 12, Batch 60/100] Loss: 0.0701 | RMSE: 0.0647 | Consistency: 0.0255 | SSIM: 0.0514 | Grad: 74394.891\n",
      "[Epoch 12, Batch 61/100] Loss: 0.0762 | RMSE: 0.0708 | Consistency: 0.0206 | SSIM: 0.0518 | Grad: 163573.000\n",
      "[Epoch 12, Batch 62/100] Loss: 0.0767 | RMSE: 0.0712 | Consistency: 0.0258 | SSIM: 0.0521 | Grad: 85797.328\n",
      "[Epoch 12, Batch 63/100] Loss: 0.0847 | RMSE: 0.0791 | Consistency: 0.0282 | SSIM: 0.0537 | Grad: 45233.492\n",
      "[Epoch 12, Batch 64/100] Loss: 0.0675 | RMSE: 0.0622 | Consistency: 0.0204 | SSIM: 0.0505 | Grad: 97481.211\n",
      "[Epoch 12, Batch 65/100] Loss: 0.0758 | RMSE: 0.0700 | Consistency: 0.0257 | SSIM: 0.0550 | Grad: 143908.938\n",
      "[Epoch 12, Batch 66/100] Loss: 0.0824 | RMSE: 0.0767 | Consistency: 0.0216 | SSIM: 0.0548 | Grad: 144703.422\n",
      "[Epoch 12, Batch 67/100] Loss: 0.0673 | RMSE: 0.0613 | Consistency: 0.0188 | SSIM: 0.0582 | Grad: 96169.727\n",
      "[Epoch 12, Batch 68/100] Loss: 0.0670 | RMSE: 0.0621 | Consistency: 0.0195 | SSIM: 0.0467 | Grad: 102548.828\n",
      "[Epoch 12, Batch 69/100] Loss: 0.0650 | RMSE: 0.0606 | Consistency: 0.0180 | SSIM: 0.0420 | Grad: 136419.938\n",
      "[Epoch 12, Batch 70/100] Loss: 0.0642 | RMSE: 0.0597 | Consistency: 0.0171 | SSIM: 0.0431 | Grad: 88827.352\n",
      "[Epoch 12, Batch 71/100] Loss: 0.0720 | RMSE: 0.0669 | Consistency: 0.0223 | SSIM: 0.0493 | Grad: 93368.047\n",
      "[Epoch 12, Batch 72/100] Loss: 0.0646 | RMSE: 0.0595 | Consistency: 0.0207 | SSIM: 0.0487 | Grad: 109312.422\n",
      "[Epoch 12, Batch 73/100] Loss: 0.0616 | RMSE: 0.0566 | Consistency: 0.0172 | SSIM: 0.0482 | Grad: 69270.039\n",
      "[Epoch 12, Batch 74/100] Loss: 0.0695 | RMSE: 0.0645 | Consistency: 0.0227 | SSIM: 0.0481 | Grad: 144082.781\n",
      "[Epoch 12, Batch 75/100] Loss: 0.0644 | RMSE: 0.0596 | Consistency: 0.0228 | SSIM: 0.0454 | Grad: 111390.586\n",
      "[Epoch 12, Batch 76/100] Loss: 0.0566 | RMSE: 0.0524 | Consistency: 0.0143 | SSIM: 0.0405 | Grad: 72369.594\n",
      "[Epoch 12, Batch 77/100] Loss: 0.0875 | RMSE: 0.0821 | Consistency: 0.0373 | SSIM: 0.0503 | Grad: 200494.578\n",
      "[Epoch 12, Batch 78/100] Loss: 0.0754 | RMSE: 0.0697 | Consistency: 0.0283 | SSIM: 0.0542 | Grad: 173015.719\n",
      "[Epoch 12, Batch 79/100] Loss: 0.0780 | RMSE: 0.0721 | Consistency: 0.0250 | SSIM: 0.0562 | Grad: 85435.328\n",
      "[Epoch 12, Batch 80/100] Loss: 0.0678 | RMSE: 0.0631 | Consistency: 0.0171 | SSIM: 0.0446 | Grad: 78341.945\n",
      "[Epoch 12, Batch 81/100] Loss: 0.0595 | RMSE: 0.0552 | Consistency: 0.0166 | SSIM: 0.0412 | Grad: 94245.219\n",
      "[Epoch 12, Batch 82/100] Loss: 0.0782 | RMSE: 0.0724 | Consistency: 0.0310 | SSIM: 0.0545 | Grad: 140557.500\n",
      "[Epoch 12, Batch 83/100] Loss: 0.0829 | RMSE: 0.0772 | Consistency: 0.0278 | SSIM: 0.0537 | Grad: 104151.109\n",
      "[Epoch 12, Batch 84/100] Loss: 0.0699 | RMSE: 0.0648 | Consistency: 0.0225 | SSIM: 0.0481 | Grad: 101037.016\n",
      "[Epoch 12, Batch 85/100] Loss: 0.0826 | RMSE: 0.0768 | Consistency: 0.0317 | SSIM: 0.0546 | Grad: 152598.422\n",
      "[Epoch 12, Batch 86/100] Loss: 0.0655 | RMSE: 0.0608 | Consistency: 0.0171 | SSIM: 0.0460 | Grad: 81817.078\n",
      "[Epoch 12, Batch 87/100] Loss: 0.0696 | RMSE: 0.0650 | Consistency: 0.0163 | SSIM: 0.0452 | Grad: 103177.680\n",
      "[Epoch 12, Batch 88/100] Loss: 0.0845 | RMSE: 0.0783 | Consistency: 0.0414 | SSIM: 0.0577 | Grad: 189884.859\n",
      "[Epoch 12, Batch 89/100] Loss: 0.0760 | RMSE: 0.0712 | Consistency: 0.0295 | SSIM: 0.0450 | Grad: 110558.594\n",
      "[Epoch 12, Batch 90/100] Loss: 0.0654 | RMSE: 0.0597 | Consistency: 0.0176 | SSIM: 0.0556 | Grad: 68529.477\n",
      "[Epoch 12, Batch 91/100] Loss: 0.0672 | RMSE: 0.0625 | Consistency: 0.0198 | SSIM: 0.0456 | Grad: 69875.852\n",
      "[Epoch 12, Batch 92/100] Loss: 0.0830 | RMSE: 0.0774 | Consistency: 0.0279 | SSIM: 0.0533 | Grad: 102877.703\n",
      "[Epoch 12, Batch 93/100] Loss: 0.0721 | RMSE: 0.0671 | Consistency: 0.0235 | SSIM: 0.0478 | Grad: 114863.961\n",
      "[Epoch 12, Batch 94/100] Loss: 0.0738 | RMSE: 0.0689 | Consistency: 0.0203 | SSIM: 0.0463 | Grad: 101506.242\n",
      "[Epoch 12, Batch 95/100] Loss: 0.0722 | RMSE: 0.0671 | Consistency: 0.0218 | SSIM: 0.0486 | Grad: 98985.500\n",
      "[Epoch 12, Batch 96/100] Loss: 0.0682 | RMSE: 0.0629 | Consistency: 0.0214 | SSIM: 0.0511 | Grad: 176387.047\n",
      "[Epoch 12, Batch 97/100] Loss: 0.0767 | RMSE: 0.0719 | Consistency: 0.0214 | SSIM: 0.0455 | Grad: 174377.812\n",
      "[Epoch 12, Batch 98/100] Loss: 0.0638 | RMSE: 0.0599 | Consistency: 0.0181 | SSIM: 0.0371 | Grad: 138058.781\n",
      "[Epoch 12, Batch 99/100] Loss: 0.0785 | RMSE: 0.0739 | Consistency: 0.0248 | SSIM: 0.0443 | Grad: 147245.953\n",
      "[Epoch 12, Batch 100/100] Loss: 0.0782 | RMSE: 0.0726 | Consistency: 0.0202 | SSIM: 0.0538 | Grad: 177872.922\n",
      "✅ Epoch 12 완료!\n",
      "   📈 평균 Loss: 0.073195\n",
      "   📊 평균 RMSE: 0.067947\n",
      "   ⚙️  학습률: 0.000992\n",
      "   🏆 NEW BEST! RMSE: 0.067947\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 13/80 시작...\n",
      "[Epoch 13, Batch 1/100] Loss: 0.0725 | RMSE: 0.0672 | Consistency: 0.0222 | SSIM: 0.0512 | Grad: 141874.172\n",
      "[Epoch 13, Batch 2/100] Loss: 0.0757 | RMSE: 0.0701 | Consistency: 0.0244 | SSIM: 0.0531 | Grad: 113891.008\n",
      "[Epoch 13, Batch 3/100] Loss: 0.0605 | RMSE: 0.0566 | Consistency: 0.0151 | SSIM: 0.0368 | Grad: 76634.398\n",
      "[Epoch 13, Batch 4/100] Loss: 0.0802 | RMSE: 0.0747 | Consistency: 0.0194 | SSIM: 0.0526 | Grad: 169452.125\n",
      "[Epoch 13, Batch 5/100] Loss: 0.0771 | RMSE: 0.0721 | Consistency: 0.0184 | SSIM: 0.0481 | Grad: 173266.297\n",
      "[Epoch 13, Batch 6/100] Loss: 0.0631 | RMSE: 0.0591 | Consistency: 0.0183 | SSIM: 0.0386 | Grad: 102467.883\n",
      "[Epoch 13, Batch 7/100] Loss: 0.0794 | RMSE: 0.0752 | Consistency: 0.0162 | SSIM: 0.0401 | Grad: 187662.203\n",
      "[Epoch 13, Batch 8/100] Loss: 0.0711 | RMSE: 0.0667 | Consistency: 0.0182 | SSIM: 0.0426 | Grad: 145964.734\n",
      "[Epoch 13, Batch 9/100] Loss: 0.0756 | RMSE: 0.0691 | Consistency: 0.0220 | SSIM: 0.0627 | Grad: 147929.391\n",
      "[Epoch 13, Batch 10/100] Loss: 0.0617 | RMSE: 0.0569 | Consistency: 0.0189 | SSIM: 0.0457 | Grad: 103235.906\n",
      "[Epoch 13, Batch 11/100] Loss: 0.0781 | RMSE: 0.0726 | Consistency: 0.0314 | SSIM: 0.0522 | Grad: 198632.500\n",
      "[Epoch 13, Batch 12/100] Loss: 0.0875 | RMSE: 0.0820 | Consistency: 0.0233 | SSIM: 0.0529 | Grad: 167230.625\n",
      "[Epoch 13, Batch 13/100] Loss: 0.0646 | RMSE: 0.0594 | Consistency: 0.0193 | SSIM: 0.0497 | Grad: 149219.844\n",
      "[Epoch 13, Batch 14/100] Loss: 0.0695 | RMSE: 0.0645 | Consistency: 0.0178 | SSIM: 0.0483 | Grad: 61383.793\n",
      "[Epoch 13, Batch 15/100] Loss: 0.0704 | RMSE: 0.0660 | Consistency: 0.0197 | SSIM: 0.0422 | Grad: 121050.750\n",
      "[Epoch 13, Batch 16/100] Loss: 0.0674 | RMSE: 0.0623 | Consistency: 0.0172 | SSIM: 0.0499 | Grad: 75276.102\n",
      "[Epoch 13, Batch 17/100] Loss: 0.0624 | RMSE: 0.0574 | Consistency: 0.0183 | SSIM: 0.0478 | Grad: 108632.211\n",
      "[Epoch 13, Batch 18/100] Loss: 0.0712 | RMSE: 0.0661 | Consistency: 0.0210 | SSIM: 0.0492 | Grad: 111222.156\n",
      "[Epoch 13, Batch 19/100] Loss: 0.0676 | RMSE: 0.0631 | Consistency: 0.0192 | SSIM: 0.0429 | Grad: 81481.750\n",
      "[Epoch 13, Batch 20/100] Loss: 0.0697 | RMSE: 0.0644 | Consistency: 0.0189 | SSIM: 0.0506 | Grad: 140921.453\n",
      "[Epoch 13, Batch 21/100] Loss: 0.0692 | RMSE: 0.0636 | Consistency: 0.0204 | SSIM: 0.0539 | Grad: 21090.516\n",
      "[Epoch 13, Batch 22/100] Loss: 0.0743 | RMSE: 0.0688 | Consistency: 0.0356 | SSIM: 0.0518 | Grad: 153501.484\n",
      "[Epoch 13, Batch 23/100] Loss: 0.0788 | RMSE: 0.0726 | Consistency: 0.0292 | SSIM: 0.0586 | Grad: 90322.242\n",
      "[Epoch 13, Batch 24/100] Loss: 0.0678 | RMSE: 0.0628 | Consistency: 0.0215 | SSIM: 0.0481 | Grad: 69960.141\n",
      "[Epoch 13, Batch 25/100] Loss: 0.0716 | RMSE: 0.0653 | Consistency: 0.0268 | SSIM: 0.0597 | Grad: 96286.203\n",
      "[Epoch 13, Batch 26/100] Loss: 0.0692 | RMSE: 0.0645 | Consistency: 0.0186 | SSIM: 0.0447 | Grad: 114265.398\n",
      "[Epoch 13, Batch 27/100] Loss: 0.0764 | RMSE: 0.0709 | Consistency: 0.0203 | SSIM: 0.0532 | Grad: 76256.789\n",
      "[Epoch 13, Batch 28/100] Loss: 0.0844 | RMSE: 0.0786 | Consistency: 0.0251 | SSIM: 0.0557 | Grad: 195886.297\n",
      "[Epoch 13, Batch 29/100] Loss: 0.0929 | RMSE: 0.0864 | Consistency: 0.0261 | SSIM: 0.0619 | Grad: 186441.781\n",
      "[Epoch 13, Batch 30/100] Loss: 0.0679 | RMSE: 0.0633 | Consistency: 0.0197 | SSIM: 0.0432 | Grad: 88312.000\n",
      "[Epoch 13, Batch 31/100] Loss: 0.0951 | RMSE: 0.0887 | Consistency: 0.0329 | SSIM: 0.0602 | Grad: 187466.531\n",
      "[Epoch 13, Batch 32/100] Loss: 0.0873 | RMSE: 0.0815 | Consistency: 0.0218 | SSIM: 0.0553 | Grad: 173433.453\n",
      "[Epoch 13, Batch 33/100] Loss: 0.0792 | RMSE: 0.0743 | Consistency: 0.0228 | SSIM: 0.0467 | Grad: 129522.195\n",
      "[Epoch 13, Batch 34/100] Loss: 0.0836 | RMSE: 0.0780 | Consistency: 0.0208 | SSIM: 0.0536 | Grad: 162238.656\n",
      "[Epoch 13, Batch 35/100] Loss: 0.0785 | RMSE: 0.0732 | Consistency: 0.0179 | SSIM: 0.0514 | Grad: 186002.062\n",
      "[Epoch 13, Batch 36/100] Loss: 0.0750 | RMSE: 0.0700 | Consistency: 0.0167 | SSIM: 0.0483 | Grad: 198438.172\n",
      "[Epoch 13, Batch 37/100] Loss: 0.0687 | RMSE: 0.0637 | Consistency: 0.0206 | SSIM: 0.0481 | Grad: 169015.453\n",
      "[Epoch 13, Batch 38/100] Loss: 0.0791 | RMSE: 0.0737 | Consistency: 0.0189 | SSIM: 0.0521 | Grad: 189648.375\n",
      "[Epoch 13, Batch 39/100] Loss: 0.0702 | RMSE: 0.0649 | Consistency: 0.0196 | SSIM: 0.0506 | Grad: 121381.094\n",
      "[Epoch 13, Batch 40/100] Loss: 0.0731 | RMSE: 0.0666 | Consistency: 0.0295 | SSIM: 0.0623 | Grad: 101140.188\n",
      "[Epoch 13, Batch 41/100] Loss: 0.0612 | RMSE: 0.0569 | Consistency: 0.0184 | SSIM: 0.0413 | Grad: 46041.262\n",
      "[Epoch 13, Batch 42/100] Loss: 0.0644 | RMSE: 0.0596 | Consistency: 0.0185 | SSIM: 0.0465 | Grad: 73670.078\n",
      "[Epoch 13, Batch 43/100] Loss: 0.0698 | RMSE: 0.0639 | Consistency: 0.0262 | SSIM: 0.0567 | Grad: 115099.883\n",
      "[Epoch 13, Batch 44/100] Loss: 0.0690 | RMSE: 0.0639 | Consistency: 0.0238 | SSIM: 0.0480 | Grad: 132331.031\n",
      "[Epoch 13, Batch 45/100] Loss: 0.0645 | RMSE: 0.0603 | Consistency: 0.0138 | SSIM: 0.0408 | Grad: 71665.906\n",
      "[Epoch 13, Batch 46/100] Loss: 0.0777 | RMSE: 0.0722 | Consistency: 0.0216 | SSIM: 0.0525 | Grad: 160154.562\n",
      "[Epoch 13, Batch 47/100] Loss: 0.0822 | RMSE: 0.0768 | Consistency: 0.0268 | SSIM: 0.0513 | Grad: 177416.359\n",
      "[Epoch 13, Batch 48/100] Loss: 0.0660 | RMSE: 0.0616 | Consistency: 0.0191 | SSIM: 0.0421 | Grad: 105837.305\n",
      "[Epoch 13, Batch 49/100] Loss: 0.0684 | RMSE: 0.0631 | Consistency: 0.0217 | SSIM: 0.0510 | Grad: 118373.977\n",
      "[Epoch 13, Batch 50/100] Loss: 0.0968 | RMSE: 0.0900 | Consistency: 0.0397 | SSIM: 0.0645 | Grad: 200058.469\n",
      "[Epoch 13, Batch 51/100] Loss: 0.0756 | RMSE: 0.0696 | Consistency: 0.0285 | SSIM: 0.0575 | Grad: 142266.219\n",
      "[Epoch 13, Batch 52/100] Loss: 0.0666 | RMSE: 0.0617 | Consistency: 0.0213 | SSIM: 0.0473 | Grad: 112165.375\n",
      "[Epoch 13, Batch 53/100] Loss: 0.0731 | RMSE: 0.0679 | Consistency: 0.0205 | SSIM: 0.0509 | Grad: 119700.953\n",
      "[Epoch 13, Batch 54/100] Loss: 0.0781 | RMSE: 0.0726 | Consistency: 0.0234 | SSIM: 0.0522 | Grad: 143140.578\n",
      "[Epoch 13, Batch 55/100] Loss: 0.0741 | RMSE: 0.0691 | Consistency: 0.0241 | SSIM: 0.0474 | Grad: 102681.656\n",
      "[Epoch 13, Batch 56/100] Loss: 0.0839 | RMSE: 0.0788 | Consistency: 0.0246 | SSIM: 0.0484 | Grad: 139521.219\n",
      "[Epoch 13, Batch 57/100] Loss: 0.0816 | RMSE: 0.0758 | Consistency: 0.0264 | SSIM: 0.0550 | Grad: 196021.328\n",
      "[Epoch 13, Batch 58/100] Loss: 0.0730 | RMSE: 0.0681 | Consistency: 0.0224 | SSIM: 0.0476 | Grad: 131822.656\n",
      "[Epoch 13, Batch 59/100] Loss: 0.0691 | RMSE: 0.0646 | Consistency: 0.0192 | SSIM: 0.0435 | Grad: 120335.164\n",
      "[Epoch 13, Batch 60/100] Loss: 0.0638 | RMSE: 0.0598 | Consistency: 0.0170 | SSIM: 0.0384 | Grad: 99359.633\n",
      "[Epoch 13, Batch 61/100] Loss: 0.0689 | RMSE: 0.0640 | Consistency: 0.0266 | SSIM: 0.0469 | Grad: 101465.586\n",
      "[Epoch 13, Batch 62/100] Loss: 0.0612 | RMSE: 0.0574 | Consistency: 0.0167 | SSIM: 0.0362 | Grad: 99546.070\n",
      "[Epoch 13, Batch 63/100] Loss: 0.0858 | RMSE: 0.0798 | Consistency: 0.0331 | SSIM: 0.0562 | Grad: 43535.121\n",
      "[Epoch 13, Batch 64/100] Loss: 0.0811 | RMSE: 0.0753 | Consistency: 0.0340 | SSIM: 0.0541 | Grad: 196704.156\n",
      "[Epoch 13, Batch 65/100] Loss: 0.0818 | RMSE: 0.0760 | Consistency: 0.0374 | SSIM: 0.0539 | Grad: 156151.797\n",
      "[Epoch 13, Batch 66/100] Loss: 0.0732 | RMSE: 0.0681 | Consistency: 0.0268 | SSIM: 0.0486 | Grad: 119971.570\n",
      "[Epoch 13, Batch 67/100] Loss: 0.0663 | RMSE: 0.0619 | Consistency: 0.0190 | SSIM: 0.0421 | Grad: 128262.797\n",
      "[Epoch 13, Batch 68/100] Loss: 0.0724 | RMSE: 0.0675 | Consistency: 0.0215 | SSIM: 0.0473 | Grad: 107025.977\n",
      "[Epoch 13, Batch 69/100] Loss: 0.0616 | RMSE: 0.0568 | Consistency: 0.0167 | SSIM: 0.0467 | Grad: 140861.172\n",
      "[Epoch 13, Batch 70/100] Loss: 0.0737 | RMSE: 0.0685 | Consistency: 0.0234 | SSIM: 0.0493 | Grad: 118135.828\n",
      "[Epoch 13, Batch 71/100] Loss: 0.0698 | RMSE: 0.0649 | Consistency: 0.0271 | SSIM: 0.0460 | Grad: 127115.477\n",
      "[Epoch 13, Batch 72/100] Loss: 0.0648 | RMSE: 0.0601 | Consistency: 0.0172 | SSIM: 0.0451 | Grad: 76646.055\n",
      "[Epoch 13, Batch 73/100] Loss: 0.0581 | RMSE: 0.0542 | Consistency: 0.0133 | SSIM: 0.0375 | Grad: 25960.211\n",
      "[Epoch 13, Batch 74/100] Loss: 0.0770 | RMSE: 0.0724 | Consistency: 0.0269 | SSIM: 0.0436 | Grad: 151032.328\n",
      "[Epoch 13, Batch 75/100] Loss: 0.0890 | RMSE: 0.0830 | Consistency: 0.0333 | SSIM: 0.0573 | Grad: 86837.336\n",
      "[Epoch 13, Batch 76/100] Loss: 0.0967 | RMSE: 0.0897 | Consistency: 0.0274 | SSIM: 0.0670 | Grad: 163064.250\n",
      "[Epoch 13, Batch 77/100] Loss: 0.1046 | RMSE: 0.0972 | Consistency: 0.0316 | SSIM: 0.0715 | Grad: 187783.125\n",
      "[Epoch 13, Batch 78/100] Loss: 0.0698 | RMSE: 0.0648 | Consistency: 0.0210 | SSIM: 0.0474 | Grad: 102862.812\n",
      "[Epoch 13, Batch 79/100] Loss: 0.0724 | RMSE: 0.0676 | Consistency: 0.0203 | SSIM: 0.0460 | Grad: 123067.734\n",
      "[Epoch 13, Batch 80/100] Loss: 0.0721 | RMSE: 0.0671 | Consistency: 0.0215 | SSIM: 0.0485 | Grad: 119561.977\n",
      "[Epoch 13, Batch 81/100] Loss: 0.0745 | RMSE: 0.0685 | Consistency: 0.0248 | SSIM: 0.0578 | Grad: 102943.906\n",
      "[Epoch 13, Batch 82/100] Loss: 0.0704 | RMSE: 0.0658 | Consistency: 0.0208 | SSIM: 0.0442 | Grad: 142459.062\n",
      "[Epoch 13, Batch 83/100] Loss: 0.0696 | RMSE: 0.0645 | Consistency: 0.0190 | SSIM: 0.0493 | Grad: 134826.109\n",
      "[Epoch 13, Batch 84/100] Loss: 0.0830 | RMSE: 0.0764 | Consistency: 0.0229 | SSIM: 0.0634 | Grad: 93172.922\n",
      "[Epoch 13, Batch 85/100] Loss: 0.0772 | RMSE: 0.0717 | Consistency: 0.0203 | SSIM: 0.0527 | Grad: 175632.141\n",
      "[Epoch 13, Batch 86/100] Loss: 0.0753 | RMSE: 0.0700 | Consistency: 0.0189 | SSIM: 0.0508 | Grad: 115461.703\n",
      "[Epoch 13, Batch 87/100] Loss: 0.0742 | RMSE: 0.0690 | Consistency: 0.0232 | SSIM: 0.0501 | Grad: 144938.484\n",
      "[Epoch 13, Batch 88/100] Loss: 0.0705 | RMSE: 0.0652 | Consistency: 0.0185 | SSIM: 0.0514 | Grad: 144870.500\n",
      "[Epoch 13, Batch 89/100] Loss: 0.0670 | RMSE: 0.0620 | Consistency: 0.0180 | SSIM: 0.0475 | Grad: 126947.930\n",
      "[Epoch 13, Batch 90/100] Loss: 0.0758 | RMSE: 0.0711 | Consistency: 0.0155 | SSIM: 0.0457 | Grad: 147472.375\n",
      "[Epoch 13, Batch 91/100] Loss: 0.0799 | RMSE: 0.0744 | Consistency: 0.0247 | SSIM: 0.0521 | Grad: 162649.484\n",
      "[Epoch 13, Batch 92/100] Loss: 0.0735 | RMSE: 0.0683 | Consistency: 0.0298 | SSIM: 0.0484 | Grad: 113843.016\n",
      "[Epoch 13, Batch 93/100] Loss: 0.0699 | RMSE: 0.0649 | Consistency: 0.0231 | SSIM: 0.0480 | Grad: 112763.672\n",
      "[Epoch 13, Batch 94/100] Loss: 0.0713 | RMSE: 0.0666 | Consistency: 0.0191 | SSIM: 0.0450 | Grad: 137057.562\n",
      "[Epoch 13, Batch 95/100] Loss: 0.0799 | RMSE: 0.0744 | Consistency: 0.0269 | SSIM: 0.0524 | Grad: 132139.969\n",
      "[Epoch 13, Batch 96/100] Loss: 0.0840 | RMSE: 0.0785 | Consistency: 0.0244 | SSIM: 0.0529 | Grad: 102284.492\n",
      "[Epoch 13, Batch 97/100] Loss: 0.0784 | RMSE: 0.0727 | Consistency: 0.0220 | SSIM: 0.0542 | Grad: 138425.219\n",
      "[Epoch 13, Batch 98/100] Loss: 0.0883 | RMSE: 0.0819 | Consistency: 0.0230 | SSIM: 0.0617 | Grad: 155299.484\n",
      "[Epoch 13, Batch 99/100] Loss: 0.0726 | RMSE: 0.0673 | Consistency: 0.0177 | SSIM: 0.0520 | Grad: 144145.172\n",
      "[Epoch 13, Batch 100/100] Loss: 0.0813 | RMSE: 0.0762 | Consistency: 0.0251 | SSIM: 0.0486 | Grad: 163822.984\n",
      "✅ Epoch 13 완료!\n",
      "   📈 평균 Loss: 0.074435\n",
      "   📊 평균 RMSE: 0.069191\n",
      "   ⚙️  학습률: 0.000988\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 14/80 시작...\n",
      "[Epoch 14, Batch 1/100] Loss: 0.0831 | RMSE: 0.0780 | Consistency: 0.0191 | SSIM: 0.0491 | Grad: 162291.953\n",
      "[Epoch 14, Batch 2/100] Loss: 0.0753 | RMSE: 0.0694 | Consistency: 0.0156 | SSIM: 0.0580 | Grad: 183366.328\n",
      "[Epoch 14, Batch 3/100] Loss: 0.0639 | RMSE: 0.0593 | Consistency: 0.0180 | SSIM: 0.0444 | Grad: 80568.102\n",
      "[Epoch 14, Batch 4/100] Loss: 0.0759 | RMSE: 0.0707 | Consistency: 0.0261 | SSIM: 0.0493 | Grad: 120140.797\n",
      "[Epoch 14, Batch 5/100] Loss: 0.0685 | RMSE: 0.0641 | Consistency: 0.0148 | SSIM: 0.0423 | Grad: 134073.531\n",
      "[Epoch 14, Batch 6/100] Loss: 0.0792 | RMSE: 0.0739 | Consistency: 0.0270 | SSIM: 0.0502 | Grad: 126637.273\n",
      "[Epoch 14, Batch 7/100] Loss: 0.0694 | RMSE: 0.0649 | Consistency: 0.0202 | SSIM: 0.0428 | Grad: 116546.867\n",
      "[Epoch 14, Batch 8/100] Loss: 0.0617 | RMSE: 0.0572 | Consistency: 0.0150 | SSIM: 0.0435 | Grad: 68722.523\n",
      "[Epoch 14, Batch 9/100] Loss: 0.0643 | RMSE: 0.0598 | Consistency: 0.0150 | SSIM: 0.0432 | Grad: 112229.719\n",
      "[Epoch 14, Batch 10/100] Loss: 0.0648 | RMSE: 0.0605 | Consistency: 0.0211 | SSIM: 0.0414 | Grad: 91931.930\n",
      "[Epoch 14, Batch 11/100] Loss: 0.0625 | RMSE: 0.0577 | Consistency: 0.0191 | SSIM: 0.0469 | Grad: 81436.336\n",
      "[Epoch 14, Batch 12/100] Loss: 0.0602 | RMSE: 0.0562 | Consistency: 0.0153 | SSIM: 0.0392 | Grad: 114890.383\n",
      "[Epoch 14, Batch 13/100] Loss: 0.0679 | RMSE: 0.0637 | Consistency: 0.0219 | SSIM: 0.0395 | Grad: 99286.461\n",
      "[Epoch 14, Batch 14/100] Loss: 0.0778 | RMSE: 0.0733 | Consistency: 0.0201 | SSIM: 0.0435 | Grad: 112925.070\n",
      "[Epoch 14, Batch 15/100] Loss: 0.0739 | RMSE: 0.0693 | Consistency: 0.0228 | SSIM: 0.0443 | Grad: 184730.125\n",
      "[Epoch 14, Batch 16/100] Loss: 0.0755 | RMSE: 0.0701 | Consistency: 0.0248 | SSIM: 0.0517 | Grad: 162960.812\n",
      "[Epoch 14, Batch 17/100] Loss: 0.0658 | RMSE: 0.0611 | Consistency: 0.0179 | SSIM: 0.0450 | Grad: 108991.062\n",
      "[Epoch 14, Batch 18/100] Loss: 0.0645 | RMSE: 0.0600 | Consistency: 0.0192 | SSIM: 0.0432 | Grad: 152471.469\n",
      "[Epoch 14, Batch 19/100] Loss: 0.0670 | RMSE: 0.0623 | Consistency: 0.0223 | SSIM: 0.0450 | Grad: 119417.797\n",
      "[Epoch 14, Batch 20/100] Loss: 0.0759 | RMSE: 0.0709 | Consistency: 0.0235 | SSIM: 0.0481 | Grad: 87421.977\n",
      "[Epoch 14, Batch 21/100] Loss: 0.0718 | RMSE: 0.0675 | Consistency: 0.0209 | SSIM: 0.0408 | Grad: 131619.828\n",
      "[Epoch 14, Batch 22/100] Loss: 0.0592 | RMSE: 0.0553 | Consistency: 0.0131 | SSIM: 0.0379 | Grad: 29677.135\n",
      "[Epoch 14, Batch 23/100] Loss: 0.0646 | RMSE: 0.0605 | Consistency: 0.0181 | SSIM: 0.0392 | Grad: 147336.375\n",
      "[Epoch 14, Batch 24/100] Loss: 0.0660 | RMSE: 0.0619 | Consistency: 0.0191 | SSIM: 0.0387 | Grad: 164627.750\n",
      "[Epoch 14, Batch 25/100] Loss: 0.0694 | RMSE: 0.0640 | Consistency: 0.0196 | SSIM: 0.0530 | Grad: 131286.141\n",
      "[Epoch 14, Batch 26/100] Loss: 0.0798 | RMSE: 0.0743 | Consistency: 0.0245 | SSIM: 0.0524 | Grad: 106061.375\n",
      "[Epoch 14, Batch 27/100] Loss: 0.0842 | RMSE: 0.0784 | Consistency: 0.0190 | SSIM: 0.0562 | Grad: 157999.891\n",
      "[Epoch 14, Batch 28/100] Loss: 0.0928 | RMSE: 0.0861 | Consistency: 0.0213 | SSIM: 0.0649 | Grad: 175877.844\n",
      "[Epoch 14, Batch 29/100] Loss: 0.0715 | RMSE: 0.0662 | Consistency: 0.0203 | SSIM: 0.0502 | Grad: 96669.148\n",
      "[Epoch 14, Batch 30/100] Loss: 0.0647 | RMSE: 0.0599 | Consistency: 0.0177 | SSIM: 0.0462 | Grad: 42428.887\n",
      "[Epoch 14, Batch 31/100] Loss: 0.0659 | RMSE: 0.0612 | Consistency: 0.0159 | SSIM: 0.0446 | Grad: 146876.859\n",
      "[Epoch 14, Batch 32/100] Loss: 0.0627 | RMSE: 0.0571 | Consistency: 0.0171 | SSIM: 0.0543 | Grad: 97468.719\n",
      "[Epoch 14, Batch 33/100] Loss: 0.0770 | RMSE: 0.0711 | Consistency: 0.0239 | SSIM: 0.0557 | Grad: 64090.344\n",
      "[Epoch 14, Batch 34/100] Loss: 0.0655 | RMSE: 0.0612 | Consistency: 0.0212 | SSIM: 0.0410 | Grad: 69907.141\n",
      "[Epoch 14, Batch 35/100] Loss: 0.0779 | RMSE: 0.0727 | Consistency: 0.0216 | SSIM: 0.0498 | Grad: 151075.141\n",
      "[Epoch 14, Batch 36/100] Loss: 0.0815 | RMSE: 0.0759 | Consistency: 0.0217 | SSIM: 0.0532 | Grad: 115916.828\n",
      "[Epoch 14, Batch 37/100] Loss: 0.0706 | RMSE: 0.0656 | Consistency: 0.0197 | SSIM: 0.0471 | Grad: 118342.508\n",
      "[Epoch 14, Batch 38/100] Loss: 0.0711 | RMSE: 0.0664 | Consistency: 0.0182 | SSIM: 0.0456 | Grad: 68282.055\n",
      "[Epoch 14, Batch 39/100] Loss: 0.0718 | RMSE: 0.0667 | Consistency: 0.0217 | SSIM: 0.0495 | Grad: 128062.391\n",
      "[Epoch 14, Batch 40/100] Loss: 0.0660 | RMSE: 0.0613 | Consistency: 0.0158 | SSIM: 0.0458 | Grad: 110779.734\n",
      "[Epoch 14, Batch 41/100] Loss: 0.0764 | RMSE: 0.0710 | Consistency: 0.0223 | SSIM: 0.0522 | Grad: 128984.078\n",
      "[Epoch 14, Batch 42/100] Loss: 0.0702 | RMSE: 0.0646 | Consistency: 0.0230 | SSIM: 0.0536 | Grad: 83299.477\n",
      "[Epoch 14, Batch 43/100] Loss: 0.0661 | RMSE: 0.0610 | Consistency: 0.0230 | SSIM: 0.0488 | Grad: 69257.562\n",
      "[Epoch 14, Batch 44/100] Loss: 0.0747 | RMSE: 0.0695 | Consistency: 0.0241 | SSIM: 0.0496 | Grad: 127168.094\n",
      "[Epoch 14, Batch 45/100] Loss: 0.0670 | RMSE: 0.0621 | Consistency: 0.0179 | SSIM: 0.0469 | Grad: 57501.355\n",
      "[Epoch 14, Batch 46/100] Loss: 0.0627 | RMSE: 0.0589 | Consistency: 0.0175 | SSIM: 0.0365 | Grad: 92161.875\n",
      "[Epoch 14, Batch 47/100] Loss: 0.0661 | RMSE: 0.0612 | Consistency: 0.0227 | SSIM: 0.0466 | Grad: 94911.336\n",
      "[Epoch 14, Batch 48/100] Loss: 0.0706 | RMSE: 0.0657 | Consistency: 0.0204 | SSIM: 0.0467 | Grad: 85432.945\n",
      "[Epoch 14, Batch 49/100] Loss: 0.0643 | RMSE: 0.0597 | Consistency: 0.0189 | SSIM: 0.0440 | Grad: 62796.055\n",
      "[Epoch 14, Batch 50/100] Loss: 0.0703 | RMSE: 0.0654 | Consistency: 0.0187 | SSIM: 0.0469 | Grad: 106697.273\n",
      "[Epoch 14, Batch 51/100] Loss: 0.0789 | RMSE: 0.0741 | Consistency: 0.0239 | SSIM: 0.0459 | Grad: 158869.016\n",
      "[Epoch 14, Batch 52/100] Loss: 0.0742 | RMSE: 0.0692 | Consistency: 0.0220 | SSIM: 0.0472 | Grad: 134568.203\n",
      "[Epoch 14, Batch 53/100] Loss: 0.0729 | RMSE: 0.0678 | Consistency: 0.0235 | SSIM: 0.0484 | Grad: 49563.434\n",
      "[Epoch 14, Batch 54/100] Loss: 0.0571 | RMSE: 0.0532 | Consistency: 0.0135 | SSIM: 0.0379 | Grad: 114256.711\n",
      "[Epoch 14, Batch 55/100] Loss: 0.0756 | RMSE: 0.0699 | Consistency: 0.0212 | SSIM: 0.0546 | Grad: 155539.984\n",
      "[Epoch 14, Batch 56/100] Loss: 0.0817 | RMSE: 0.0765 | Consistency: 0.0223 | SSIM: 0.0497 | Grad: 186471.359\n",
      "[Epoch 14, Batch 57/100] Loss: 0.0766 | RMSE: 0.0715 | Consistency: 0.0210 | SSIM: 0.0488 | Grad: 79006.234\n",
      "[Epoch 14, Batch 58/100] Loss: 0.0914 | RMSE: 0.0856 | Consistency: 0.0275 | SSIM: 0.0559 | Grad: 154348.062\n",
      "[Epoch 14, Batch 59/100] Loss: 0.0774 | RMSE: 0.0721 | Consistency: 0.0188 | SSIM: 0.0518 | Grad: 164835.375\n",
      "[Epoch 14, Batch 60/100] Loss: 0.0823 | RMSE: 0.0773 | Consistency: 0.0204 | SSIM: 0.0478 | Grad: 109498.078\n",
      "[Epoch 14, Batch 61/100] Loss: 0.0615 | RMSE: 0.0566 | Consistency: 0.0171 | SSIM: 0.0474 | Grad: 87526.508\n",
      "[Epoch 14, Batch 62/100] Loss: 0.0799 | RMSE: 0.0746 | Consistency: 0.0196 | SSIM: 0.0513 | Grad: 191931.000\n",
      "[Epoch 14, Batch 63/100] Loss: 0.0794 | RMSE: 0.0739 | Consistency: 0.0165 | SSIM: 0.0529 | Grad: 191522.031\n",
      "[Epoch 14, Batch 64/100] Loss: 0.0894 | RMSE: 0.0837 | Consistency: 0.0190 | SSIM: 0.0547 | Grad: 189309.375\n",
      "[Epoch 14, Batch 65/100] Loss: 0.0765 | RMSE: 0.0710 | Consistency: 0.0261 | SSIM: 0.0519 | Grad: 91899.656\n",
      "[Epoch 14, Batch 66/100] Loss: 0.0751 | RMSE: 0.0698 | Consistency: 0.0162 | SSIM: 0.0513 | Grad: 178045.172\n",
      "[Epoch 14, Batch 67/100] Loss: 0.0726 | RMSE: 0.0664 | Consistency: 0.0262 | SSIM: 0.0594 | Grad: 127164.750\n",
      "[Epoch 14, Batch 68/100] Loss: 0.0595 | RMSE: 0.0548 | Consistency: 0.0180 | SSIM: 0.0452 | Grad: 64639.039\n",
      "[Epoch 14, Batch 69/100] Loss: 0.0668 | RMSE: 0.0628 | Consistency: 0.0151 | SSIM: 0.0384 | Grad: 126864.891\n",
      "[Epoch 14, Batch 70/100] Loss: 0.0873 | RMSE: 0.0815 | Consistency: 0.0205 | SSIM: 0.0557 | Grad: 149181.047\n",
      "[Epoch 14, Batch 71/100] Loss: 0.0720 | RMSE: 0.0669 | Consistency: 0.0169 | SSIM: 0.0491 | Grad: 103396.789\n",
      "[Epoch 14, Batch 72/100] Loss: 0.0764 | RMSE: 0.0714 | Consistency: 0.0205 | SSIM: 0.0478 | Grad: 85557.539\n",
      "[Epoch 14, Batch 73/100] Loss: 0.0513 | RMSE: 0.0474 | Consistency: 0.0127 | SSIM: 0.0371 | Grad: 32455.072\n",
      "[Epoch 14, Batch 74/100] Loss: 0.0637 | RMSE: 0.0591 | Consistency: 0.0188 | SSIM: 0.0451 | Grad: 134559.531\n",
      "[Epoch 14, Batch 75/100] Loss: 0.0819 | RMSE: 0.0764 | Consistency: 0.0284 | SSIM: 0.0518 | Grad: 177933.250\n",
      "[Epoch 14, Batch 76/100] Loss: 0.0637 | RMSE: 0.0587 | Consistency: 0.0195 | SSIM: 0.0483 | Grad: 104758.930\n",
      "[Epoch 14, Batch 77/100] Loss: 0.0673 | RMSE: 0.0627 | Consistency: 0.0179 | SSIM: 0.0443 | Grad: 101926.078\n",
      "[Epoch 14, Batch 78/100] Loss: 0.0648 | RMSE: 0.0602 | Consistency: 0.0167 | SSIM: 0.0435 | Grad: 152443.875\n",
      "[Epoch 14, Batch 79/100] Loss: 0.0677 | RMSE: 0.0628 | Consistency: 0.0223 | SSIM: 0.0465 | Grad: 103984.680\n",
      "[Epoch 14, Batch 80/100] Loss: 0.0715 | RMSE: 0.0667 | Consistency: 0.0233 | SSIM: 0.0455 | Grad: 161355.719\n",
      "[Epoch 14, Batch 81/100] Loss: 0.0737 | RMSE: 0.0682 | Consistency: 0.0189 | SSIM: 0.0532 | Grad: 137629.859\n",
      "[Epoch 14, Batch 82/100] Loss: 0.0734 | RMSE: 0.0674 | Consistency: 0.0189 | SSIM: 0.0589 | Grad: 133805.547\n",
      "[Epoch 14, Batch 83/100] Loss: 0.0672 | RMSE: 0.0625 | Consistency: 0.0206 | SSIM: 0.0446 | Grad: 140344.266\n",
      "[Epoch 14, Batch 84/100] Loss: 0.0685 | RMSE: 0.0641 | Consistency: 0.0194 | SSIM: 0.0425 | Grad: 97645.477\n",
      "[Epoch 14, Batch 85/100] Loss: 0.0720 | RMSE: 0.0671 | Consistency: 0.0176 | SSIM: 0.0469 | Grad: 146792.109\n",
      "[Epoch 14, Batch 86/100] Loss: 0.0631 | RMSE: 0.0588 | Consistency: 0.0183 | SSIM: 0.0413 | Grad: 98640.234\n",
      "[Epoch 14, Batch 87/100] Loss: 0.0653 | RMSE: 0.0598 | Consistency: 0.0158 | SSIM: 0.0536 | Grad: 147226.438\n",
      "[Epoch 14, Batch 88/100] Loss: 0.0683 | RMSE: 0.0635 | Consistency: 0.0146 | SSIM: 0.0466 | Grad: 168261.188\n",
      "[Epoch 14, Batch 89/100] Loss: 0.0702 | RMSE: 0.0652 | Consistency: 0.0192 | SSIM: 0.0484 | Grad: 136412.938\n",
      "[Epoch 14, Batch 90/100] Loss: 0.0753 | RMSE: 0.0702 | Consistency: 0.0186 | SSIM: 0.0490 | Grad: 127628.383\n",
      "[Epoch 14, Batch 91/100] Loss: 0.0754 | RMSE: 0.0701 | Consistency: 0.0212 | SSIM: 0.0504 | Grad: 91083.227\n",
      "[Epoch 14, Batch 92/100] Loss: 0.0645 | RMSE: 0.0599 | Consistency: 0.0162 | SSIM: 0.0443 | Grad: 134254.031\n",
      "[Epoch 14, Batch 93/100] Loss: 0.0736 | RMSE: 0.0689 | Consistency: 0.0232 | SSIM: 0.0445 | Grad: 123857.000\n",
      "[Epoch 14, Batch 94/100] Loss: 0.0718 | RMSE: 0.0670 | Consistency: 0.0195 | SSIM: 0.0458 | Grad: 131136.797\n",
      "[Epoch 14, Batch 95/100] Loss: 0.0740 | RMSE: 0.0690 | Consistency: 0.0177 | SSIM: 0.0489 | Grad: 185811.719\n",
      "[Epoch 14, Batch 96/100] Loss: 0.0683 | RMSE: 0.0632 | Consistency: 0.0216 | SSIM: 0.0488 | Grad: 160499.750\n",
      "[Epoch 14, Batch 97/100] Loss: 0.0600 | RMSE: 0.0553 | Consistency: 0.0192 | SSIM: 0.0457 | Grad: 129716.531\n",
      "[Epoch 14, Batch 98/100] Loss: 0.0735 | RMSE: 0.0688 | Consistency: 0.0186 | SSIM: 0.0448 | Grad: 110565.070\n",
      "[Epoch 14, Batch 99/100] Loss: 0.0544 | RMSE: 0.0510 | Consistency: 0.0135 | SSIM: 0.0330 | Grad: 91974.266\n",
      "[Epoch 14, Batch 100/100] Loss: 0.0640 | RMSE: 0.0591 | Consistency: 0.0182 | SSIM: 0.0466 | Grad: 113629.016\n",
      "✅ Epoch 14 완료!\n",
      "   📈 평균 Loss: 0.070925\n",
      "   📊 평균 RMSE: 0.065986\n",
      "   ⚙️  학습률: 0.000983\n",
      "   🏆 NEW BEST! RMSE: 0.065986\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 15/80 시작...\n",
      "[Epoch 15, Batch 1/100] Loss: 0.0671 | RMSE: 0.0624 | Consistency: 0.0205 | SSIM: 0.0452 | Grad: 88605.758\n",
      "[Epoch 15, Batch 2/100] Loss: 0.0636 | RMSE: 0.0593 | Consistency: 0.0191 | SSIM: 0.0407 | Grad: 137399.750\n",
      "[Epoch 15, Batch 3/100] Loss: 0.0580 | RMSE: 0.0541 | Consistency: 0.0163 | SSIM: 0.0374 | Grad: 92031.992\n",
      "[Epoch 15, Batch 4/100] Loss: 0.0644 | RMSE: 0.0590 | Consistency: 0.0171 | SSIM: 0.0529 | Grad: 82964.875\n",
      "[Epoch 15, Batch 5/100] Loss: 0.0579 | RMSE: 0.0539 | Consistency: 0.0157 | SSIM: 0.0385 | Grad: 102586.398\n",
      "[Epoch 15, Batch 6/100] Loss: 0.0620 | RMSE: 0.0581 | Consistency: 0.0125 | SSIM: 0.0374 | Grad: 122914.023\n",
      "[Epoch 15, Batch 7/100] Loss: 0.0549 | RMSE: 0.0511 | Consistency: 0.0121 | SSIM: 0.0372 | Grad: 45654.254\n",
      "[Epoch 15, Batch 8/100] Loss: 0.0773 | RMSE: 0.0717 | Consistency: 0.0279 | SSIM: 0.0526 | Grad: 174908.172\n",
      "[Epoch 15, Batch 9/100] Loss: 0.0684 | RMSE: 0.0638 | Consistency: 0.0175 | SSIM: 0.0443 | Grad: 152209.156\n",
      "[Epoch 15, Batch 10/100] Loss: 0.0610 | RMSE: 0.0568 | Consistency: 0.0156 | SSIM: 0.0411 | Grad: 74828.445\n",
      "[Epoch 15, Batch 11/100] Loss: 0.0615 | RMSE: 0.0578 | Consistency: 0.0128 | SSIM: 0.0355 | Grad: 129382.242\n",
      "[Epoch 15, Batch 12/100] Loss: 0.0858 | RMSE: 0.0799 | Consistency: 0.0300 | SSIM: 0.0557 | Grad: 97107.930\n",
      "[Epoch 15, Batch 13/100] Loss: 0.0658 | RMSE: 0.0611 | Consistency: 0.0175 | SSIM: 0.0455 | Grad: 54471.977\n",
      "[Epoch 15, Batch 14/100] Loss: 0.0792 | RMSE: 0.0735 | Consistency: 0.0227 | SSIM: 0.0556 | Grad: 140634.047\n",
      "[Epoch 15, Batch 15/100] Loss: 0.0740 | RMSE: 0.0690 | Consistency: 0.0212 | SSIM: 0.0487 | Grad: 133851.094\n",
      "[Epoch 15, Batch 16/100] Loss: 0.0770 | RMSE: 0.0716 | Consistency: 0.0245 | SSIM: 0.0515 | Grad: 155957.609\n",
      "[Epoch 15, Batch 17/100] Loss: 0.0748 | RMSE: 0.0694 | Consistency: 0.0254 | SSIM: 0.0513 | Grad: 134204.875\n",
      "[Epoch 15, Batch 18/100] Loss: 0.0731 | RMSE: 0.0688 | Consistency: 0.0207 | SSIM: 0.0408 | Grad: 100586.930\n",
      "[Epoch 15, Batch 19/100] Loss: 0.0717 | RMSE: 0.0665 | Consistency: 0.0186 | SSIM: 0.0499 | Grad: 103601.117\n",
      "[Epoch 15, Batch 20/100] Loss: 0.0692 | RMSE: 0.0648 | Consistency: 0.0167 | SSIM: 0.0424 | Grad: 168827.875\n",
      "[Epoch 15, Batch 21/100] Loss: 0.0815 | RMSE: 0.0758 | Consistency: 0.0321 | SSIM: 0.0534 | Grad: 43905.750\n",
      "[Epoch 15, Batch 22/100] Loss: 0.0672 | RMSE: 0.0618 | Consistency: 0.0254 | SSIM: 0.0510 | Grad: 88156.164\n",
      "[Epoch 15, Batch 23/100] Loss: 0.0877 | RMSE: 0.0826 | Consistency: 0.0361 | SSIM: 0.0474 | Grad: 148566.781\n",
      "[Epoch 15, Batch 24/100] Loss: 0.0690 | RMSE: 0.0634 | Consistency: 0.0194 | SSIM: 0.0539 | Grad: 77245.602\n",
      "[Epoch 15, Batch 25/100] Loss: 0.0592 | RMSE: 0.0551 | Consistency: 0.0163 | SSIM: 0.0391 | Grad: 43023.793\n",
      "[Epoch 15, Batch 26/100] Loss: 0.0614 | RMSE: 0.0572 | Consistency: 0.0161 | SSIM: 0.0402 | Grad: 76419.227\n",
      "[Epoch 15, Batch 27/100] Loss: 0.0599 | RMSE: 0.0557 | Consistency: 0.0162 | SSIM: 0.0410 | Grad: 42788.469\n",
      "[Epoch 15, Batch 28/100] Loss: 0.0662 | RMSE: 0.0618 | Consistency: 0.0176 | SSIM: 0.0427 | Grad: 55676.141\n",
      "[Epoch 15, Batch 29/100] Loss: 0.0608 | RMSE: 0.0560 | Consistency: 0.0185 | SSIM: 0.0468 | Grad: 42419.480\n",
      "[Epoch 15, Batch 30/100] Loss: 0.0751 | RMSE: 0.0699 | Consistency: 0.0268 | SSIM: 0.0493 | Grad: 112854.875\n",
      "[Epoch 15, Batch 31/100] Loss: 0.0741 | RMSE: 0.0680 | Consistency: 0.0208 | SSIM: 0.0585 | Grad: 96770.781\n",
      "[Epoch 15, Batch 32/100] Loss: 0.0790 | RMSE: 0.0738 | Consistency: 0.0256 | SSIM: 0.0498 | Grad: 153586.078\n",
      "[Epoch 15, Batch 33/100] Loss: 0.0706 | RMSE: 0.0655 | Consistency: 0.0203 | SSIM: 0.0496 | Grad: 119762.180\n",
      "[Epoch 15, Batch 34/100] Loss: 0.0707 | RMSE: 0.0656 | Consistency: 0.0245 | SSIM: 0.0485 | Grad: 127870.617\n",
      "[Epoch 15, Batch 35/100] Loss: 0.0691 | RMSE: 0.0642 | Consistency: 0.0172 | SSIM: 0.0473 | Grad: 82956.023\n",
      "[Epoch 15, Batch 36/100] Loss: 0.0610 | RMSE: 0.0565 | Consistency: 0.0166 | SSIM: 0.0438 | Grad: 83165.398\n",
      "[Epoch 15, Batch 37/100] Loss: 0.0691 | RMSE: 0.0643 | Consistency: 0.0186 | SSIM: 0.0463 | Grad: 45113.953\n",
      "[Epoch 15, Batch 38/100] Loss: 0.0519 | RMSE: 0.0483 | Consistency: 0.0141 | SSIM: 0.0354 | Grad: 31357.121\n",
      "[Epoch 15, Batch 39/100] Loss: 0.0776 | RMSE: 0.0722 | Consistency: 0.0182 | SSIM: 0.0513 | Grad: 111460.719\n",
      "[Epoch 15, Batch 40/100] Loss: 0.0639 | RMSE: 0.0586 | Consistency: 0.0174 | SSIM: 0.0514 | Grad: 75163.508\n",
      "[Epoch 15, Batch 41/100] Loss: 0.0609 | RMSE: 0.0563 | Consistency: 0.0164 | SSIM: 0.0442 | Grad: 39305.176\n",
      "[Epoch 15, Batch 42/100] Loss: 0.0702 | RMSE: 0.0653 | Consistency: 0.0182 | SSIM: 0.0475 | Grad: 137414.188\n",
      "[Epoch 15, Batch 43/100] Loss: 0.0689 | RMSE: 0.0642 | Consistency: 0.0195 | SSIM: 0.0457 | Grad: 144420.844\n",
      "[Epoch 15, Batch 44/100] Loss: 0.0682 | RMSE: 0.0631 | Consistency: 0.0198 | SSIM: 0.0494 | Grad: 38570.617\n",
      "[Epoch 15, Batch 45/100] Loss: 0.0847 | RMSE: 0.0789 | Consistency: 0.0298 | SSIM: 0.0550 | Grad: 143174.875\n",
      "[Epoch 15, Batch 46/100] Loss: 0.0687 | RMSE: 0.0637 | Consistency: 0.0224 | SSIM: 0.0477 | Grad: 129696.070\n",
      "[Epoch 15, Batch 47/100] Loss: 0.0709 | RMSE: 0.0651 | Consistency: 0.0244 | SSIM: 0.0559 | Grad: 82994.992\n",
      "[Epoch 15, Batch 48/100] Loss: 0.0709 | RMSE: 0.0659 | Consistency: 0.0195 | SSIM: 0.0479 | Grad: 142807.469\n",
      "[Epoch 15, Batch 49/100] Loss: 0.0690 | RMSE: 0.0642 | Consistency: 0.0245 | SSIM: 0.0461 | Grad: 133567.984\n",
      "[Epoch 15, Batch 50/100] Loss: 0.0621 | RMSE: 0.0576 | Consistency: 0.0212 | SSIM: 0.0422 | Grad: 130958.766\n",
      "[Epoch 15, Batch 51/100] Loss: 0.0775 | RMSE: 0.0721 | Consistency: 0.0246 | SSIM: 0.0510 | Grad: 100306.750\n",
      "[Epoch 15, Batch 52/100] Loss: 0.0692 | RMSE: 0.0636 | Consistency: 0.0218 | SSIM: 0.0537 | Grad: 120514.664\n",
      "[Epoch 15, Batch 53/100] Loss: 0.0618 | RMSE: 0.0576 | Consistency: 0.0212 | SSIM: 0.0395 | Grad: 75948.328\n",
      "[Epoch 15, Batch 54/100] Loss: 0.0723 | RMSE: 0.0676 | Consistency: 0.0219 | SSIM: 0.0453 | Grad: 58980.258\n",
      "[Epoch 15, Batch 55/100] Loss: 0.0602 | RMSE: 0.0559 | Consistency: 0.0152 | SSIM: 0.0414 | Grad: 59374.395\n",
      "[Epoch 15, Batch 56/100] Loss: 0.0701 | RMSE: 0.0652 | Consistency: 0.0256 | SSIM: 0.0464 | Grad: 111635.383\n",
      "[Epoch 15, Batch 57/100] Loss: 0.0680 | RMSE: 0.0637 | Consistency: 0.0208 | SSIM: 0.0412 | Grad: 128105.078\n",
      "[Epoch 15, Batch 58/100] Loss: 0.0649 | RMSE: 0.0598 | Consistency: 0.0209 | SSIM: 0.0489 | Grad: 85324.820\n",
      "[Epoch 15, Batch 59/100] Loss: 0.0692 | RMSE: 0.0647 | Consistency: 0.0181 | SSIM: 0.0434 | Grad: 116812.727\n",
      "[Epoch 15, Batch 60/100] Loss: 0.0640 | RMSE: 0.0597 | Consistency: 0.0153 | SSIM: 0.0423 | Grad: 117291.961\n",
      "[Epoch 15, Batch 61/100] Loss: 0.0639 | RMSE: 0.0596 | Consistency: 0.0173 | SSIM: 0.0414 | Grad: 108381.148\n",
      "[Epoch 15, Batch 62/100] Loss: 0.0608 | RMSE: 0.0565 | Consistency: 0.0150 | SSIM: 0.0414 | Grad: 43749.379\n",
      "[Epoch 15, Batch 63/100] Loss: 0.0665 | RMSE: 0.0617 | Consistency: 0.0187 | SSIM: 0.0460 | Grad: 123313.562\n",
      "[Epoch 15, Batch 64/100] Loss: 0.0731 | RMSE: 0.0680 | Consistency: 0.0199 | SSIM: 0.0486 | Grad: 131931.891\n",
      "[Epoch 15, Batch 65/100] Loss: 0.0631 | RMSE: 0.0589 | Consistency: 0.0162 | SSIM: 0.0402 | Grad: 84628.781\n",
      "[Epoch 15, Batch 66/100] Loss: 0.0751 | RMSE: 0.0701 | Consistency: 0.0235 | SSIM: 0.0476 | Grad: 128359.461\n",
      "[Epoch 15, Batch 67/100] Loss: 0.0652 | RMSE: 0.0611 | Consistency: 0.0218 | SSIM: 0.0382 | Grad: 142068.922\n",
      "[Epoch 15, Batch 68/100] Loss: 0.0640 | RMSE: 0.0597 | Consistency: 0.0182 | SSIM: 0.0409 | Grad: 69605.141\n",
      "[Epoch 15, Batch 69/100] Loss: 0.0662 | RMSE: 0.0615 | Consistency: 0.0228 | SSIM: 0.0448 | Grad: 147993.828\n",
      "[Epoch 15, Batch 70/100] Loss: 0.0657 | RMSE: 0.0605 | Consistency: 0.0195 | SSIM: 0.0504 | Grad: 90097.898\n",
      "[Epoch 15, Batch 71/100] Loss: 0.0624 | RMSE: 0.0580 | Consistency: 0.0161 | SSIM: 0.0420 | Grad: 74985.078\n",
      "[Epoch 15, Batch 72/100] Loss: 0.0628 | RMSE: 0.0589 | Consistency: 0.0173 | SSIM: 0.0375 | Grad: 59981.410\n",
      "[Epoch 15, Batch 73/100] Loss: 0.0805 | RMSE: 0.0757 | Consistency: 0.0290 | SSIM: 0.0449 | Grad: 61863.246\n",
      "[Epoch 15, Batch 74/100] Loss: 0.0770 | RMSE: 0.0725 | Consistency: 0.0183 | SSIM: 0.0425 | Grad: 167000.922\n",
      "[Epoch 15, Batch 75/100] Loss: 0.0756 | RMSE: 0.0707 | Consistency: 0.0211 | SSIM: 0.0469 | Grad: 189316.688\n",
      "[Epoch 15, Batch 76/100] Loss: 0.0682 | RMSE: 0.0640 | Consistency: 0.0166 | SSIM: 0.0396 | Grad: 98009.070\n",
      "[Epoch 15, Batch 77/100] Loss: 0.0640 | RMSE: 0.0592 | Consistency: 0.0180 | SSIM: 0.0464 | Grad: 86301.820\n",
      "[Epoch 15, Batch 78/100] Loss: 0.0653 | RMSE: 0.0604 | Consistency: 0.0141 | SSIM: 0.0471 | Grad: 103321.242\n",
      "[Epoch 15, Batch 79/100] Loss: 0.0657 | RMSE: 0.0617 | Consistency: 0.0199 | SSIM: 0.0384 | Grad: 130966.938\n",
      "[Epoch 15, Batch 80/100] Loss: 0.0684 | RMSE: 0.0636 | Consistency: 0.0177 | SSIM: 0.0459 | Grad: 124405.602\n",
      "[Epoch 15, Batch 81/100] Loss: 0.0638 | RMSE: 0.0597 | Consistency: 0.0202 | SSIM: 0.0394 | Grad: 97723.211\n",
      "[Epoch 15, Batch 82/100] Loss: 0.0647 | RMSE: 0.0597 | Consistency: 0.0184 | SSIM: 0.0479 | Grad: 124496.688\n",
      "[Epoch 15, Batch 83/100] Loss: 0.0651 | RMSE: 0.0604 | Consistency: 0.0189 | SSIM: 0.0456 | Grad: 101656.844\n",
      "[Epoch 15, Batch 84/100] Loss: 0.0554 | RMSE: 0.0515 | Consistency: 0.0142 | SSIM: 0.0377 | Grad: 42407.039\n",
      "[Epoch 15, Batch 85/100] Loss: 0.0792 | RMSE: 0.0743 | Consistency: 0.0178 | SSIM: 0.0471 | Grad: 193791.766\n",
      "[Epoch 15, Batch 86/100] Loss: 0.0772 | RMSE: 0.0720 | Consistency: 0.0200 | SSIM: 0.0498 | Grad: 180860.688\n",
      "[Epoch 15, Batch 87/100] Loss: 0.0725 | RMSE: 0.0666 | Consistency: 0.0218 | SSIM: 0.0574 | Grad: 98042.156\n",
      "[Epoch 15, Batch 88/100] Loss: 0.0766 | RMSE: 0.0713 | Consistency: 0.0219 | SSIM: 0.0512 | Grad: 150657.203\n",
      "[Epoch 15, Batch 89/100] Loss: 0.0812 | RMSE: 0.0764 | Consistency: 0.0213 | SSIM: 0.0464 | Grad: 157117.844\n",
      "[Epoch 15, Batch 90/100] Loss: 0.0654 | RMSE: 0.0603 | Consistency: 0.0137 | SSIM: 0.0494 | Grad: 116440.742\n",
      "[Epoch 15, Batch 91/100] Loss: 0.0640 | RMSE: 0.0589 | Consistency: 0.0158 | SSIM: 0.0496 | Grad: 91633.477\n",
      "[Epoch 15, Batch 92/100] Loss: 0.0536 | RMSE: 0.0495 | Consistency: 0.0129 | SSIM: 0.0394 | Grad: 70699.758\n",
      "[Epoch 15, Batch 93/100] Loss: 0.0597 | RMSE: 0.0555 | Consistency: 0.0156 | SSIM: 0.0410 | Grad: 95862.406\n",
      "[Epoch 15, Batch 94/100] Loss: 0.0697 | RMSE: 0.0653 | Consistency: 0.0178 | SSIM: 0.0417 | Grad: 138620.188\n",
      "[Epoch 15, Batch 95/100] Loss: 0.0682 | RMSE: 0.0638 | Consistency: 0.0170 | SSIM: 0.0429 | Grad: 108729.273\n",
      "[Epoch 15, Batch 96/100] Loss: 0.0605 | RMSE: 0.0558 | Consistency: 0.0176 | SSIM: 0.0451 | Grad: 102047.359\n",
      "[Epoch 15, Batch 97/100] Loss: 0.0614 | RMSE: 0.0565 | Consistency: 0.0164 | SSIM: 0.0471 | Grad: 102557.156\n",
      "[Epoch 15, Batch 98/100] Loss: 0.0620 | RMSE: 0.0576 | Consistency: 0.0173 | SSIM: 0.0419 | Grad: 87024.562\n",
      "[Epoch 15, Batch 99/100] Loss: 0.0600 | RMSE: 0.0563 | Consistency: 0.0158 | SSIM: 0.0354 | Grad: 60087.375\n",
      "[Epoch 15, Batch 100/100] Loss: 0.0674 | RMSE: 0.0629 | Consistency: 0.0205 | SSIM: 0.0428 | Grad: 147456.688\n",
      "✅ Epoch 15 완료!\n",
      "   📈 평균 Loss: 0.067950\n",
      "   📊 평균 RMSE: 0.063199\n",
      "   ⚙️  학습률: 0.000977\n",
      "   🏆 NEW BEST! RMSE: 0.063199\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 16/80 시작...\n",
      "[Epoch 16, Batch 1/100] Loss: 0.0606 | RMSE: 0.0565 | Consistency: 0.0166 | SSIM: 0.0395 | Grad: 117452.945\n",
      "[Epoch 16, Batch 2/100] Loss: 0.0626 | RMSE: 0.0583 | Consistency: 0.0150 | SSIM: 0.0413 | Grad: 99654.102\n",
      "[Epoch 16, Batch 3/100] Loss: 0.0731 | RMSE: 0.0681 | Consistency: 0.0306 | SSIM: 0.0471 | Grad: 173661.000\n",
      "[Epoch 16, Batch 4/100] Loss: 0.0736 | RMSE: 0.0683 | Consistency: 0.0205 | SSIM: 0.0507 | Grad: 171940.812\n",
      "[Epoch 16, Batch 5/100] Loss: 0.0702 | RMSE: 0.0658 | Consistency: 0.0201 | SSIM: 0.0415 | Grad: 124220.102\n",
      "[Epoch 16, Batch 6/100] Loss: 0.0579 | RMSE: 0.0540 | Consistency: 0.0152 | SSIM: 0.0375 | Grad: 94976.305\n",
      "[Epoch 16, Batch 7/100] Loss: 0.0712 | RMSE: 0.0669 | Consistency: 0.0177 | SSIM: 0.0415 | Grad: 128844.930\n",
      "[Epoch 16, Batch 8/100] Loss: 0.0702 | RMSE: 0.0660 | Consistency: 0.0175 | SSIM: 0.0397 | Grad: 65746.312\n",
      "[Epoch 16, Batch 9/100] Loss: 0.0585 | RMSE: 0.0544 | Consistency: 0.0166 | SSIM: 0.0392 | Grad: 36099.840\n",
      "[Epoch 16, Batch 10/100] Loss: 0.0648 | RMSE: 0.0605 | Consistency: 0.0211 | SSIM: 0.0412 | Grad: 123658.891\n",
      "[Epoch 16, Batch 11/100] Loss: 0.0697 | RMSE: 0.0649 | Consistency: 0.0225 | SSIM: 0.0448 | Grad: 38757.258\n",
      "[Epoch 16, Batch 12/100] Loss: 0.0648 | RMSE: 0.0598 | Consistency: 0.0159 | SSIM: 0.0489 | Grad: 162748.062\n",
      "[Epoch 16, Batch 13/100] Loss: 0.0627 | RMSE: 0.0583 | Consistency: 0.0192 | SSIM: 0.0427 | Grad: 114786.703\n",
      "[Epoch 16, Batch 14/100] Loss: 0.0646 | RMSE: 0.0604 | Consistency: 0.0159 | SSIM: 0.0400 | Grad: 115650.328\n",
      "[Epoch 16, Batch 15/100] Loss: 0.0609 | RMSE: 0.0563 | Consistency: 0.0163 | SSIM: 0.0443 | Grad: 112260.578\n",
      "[Epoch 16, Batch 16/100] Loss: 0.0626 | RMSE: 0.0580 | Consistency: 0.0166 | SSIM: 0.0441 | Grad: 70695.328\n",
      "[Epoch 16, Batch 17/100] Loss: 0.0828 | RMSE: 0.0772 | Consistency: 0.0236 | SSIM: 0.0545 | Grad: 153959.359\n",
      "[Epoch 16, Batch 18/100] Loss: 0.0754 | RMSE: 0.0704 | Consistency: 0.0245 | SSIM: 0.0475 | Grad: 160867.828\n",
      "[Epoch 16, Batch 19/100] Loss: 0.0623 | RMSE: 0.0580 | Consistency: 0.0183 | SSIM: 0.0412 | Grad: 146329.891\n",
      "[Epoch 16, Batch 20/100] Loss: 0.0718 | RMSE: 0.0665 | Consistency: 0.0189 | SSIM: 0.0509 | Grad: 107969.633\n",
      "[Epoch 16, Batch 21/100] Loss: 0.0721 | RMSE: 0.0671 | Consistency: 0.0256 | SSIM: 0.0476 | Grad: 145929.312\n",
      "[Epoch 16, Batch 22/100] Loss: 0.0660 | RMSE: 0.0612 | Consistency: 0.0198 | SSIM: 0.0457 | Grad: 119349.898\n",
      "[Epoch 16, Batch 23/100] Loss: 0.0589 | RMSE: 0.0546 | Consistency: 0.0180 | SSIM: 0.0412 | Grad: 115669.633\n",
      "[Epoch 16, Batch 24/100] Loss: 0.0580 | RMSE: 0.0539 | Consistency: 0.0182 | SSIM: 0.0397 | Grad: 124461.078\n",
      "[Epoch 16, Batch 25/100] Loss: 0.0672 | RMSE: 0.0627 | Consistency: 0.0164 | SSIM: 0.0431 | Grad: 79034.641\n",
      "[Epoch 16, Batch 26/100] Loss: 0.0623 | RMSE: 0.0574 | Consistency: 0.0172 | SSIM: 0.0472 | Grad: 36436.965\n",
      "[Epoch 16, Batch 27/100] Loss: 0.0737 | RMSE: 0.0684 | Consistency: 0.0226 | SSIM: 0.0506 | Grad: 126573.586\n",
      "[Epoch 16, Batch 28/100] Loss: 0.0587 | RMSE: 0.0546 | Consistency: 0.0128 | SSIM: 0.0398 | Grad: 129078.602\n",
      "[Epoch 16, Batch 29/100] Loss: 0.0561 | RMSE: 0.0513 | Consistency: 0.0181 | SSIM: 0.0462 | Grad: 82874.016\n",
      "[Epoch 16, Batch 30/100] Loss: 0.0700 | RMSE: 0.0656 | Consistency: 0.0183 | SSIM: 0.0427 | Grad: 92875.711\n",
      "[Epoch 16, Batch 31/100] Loss: 0.0681 | RMSE: 0.0637 | Consistency: 0.0207 | SSIM: 0.0426 | Grad: 119023.664\n",
      "[Epoch 16, Batch 32/100] Loss: 0.0667 | RMSE: 0.0619 | Consistency: 0.0168 | SSIM: 0.0466 | Grad: 102087.461\n",
      "[Epoch 16, Batch 33/100] Loss: 0.0654 | RMSE: 0.0614 | Consistency: 0.0142 | SSIM: 0.0382 | Grad: 141170.109\n",
      "[Epoch 16, Batch 34/100] Loss: 0.0640 | RMSE: 0.0599 | Consistency: 0.0236 | SSIM: 0.0386 | Grad: 100957.977\n",
      "[Epoch 16, Batch 35/100] Loss: 0.0646 | RMSE: 0.0608 | Consistency: 0.0157 | SSIM: 0.0364 | Grad: 106833.172\n",
      "[Epoch 16, Batch 36/100] Loss: 0.0616 | RMSE: 0.0574 | Consistency: 0.0169 | SSIM: 0.0405 | Grad: 92856.055\n",
      "[Epoch 16, Batch 37/100] Loss: 0.0618 | RMSE: 0.0583 | Consistency: 0.0155 | SSIM: 0.0335 | Grad: 89808.211\n",
      "[Epoch 16, Batch 38/100] Loss: 0.0632 | RMSE: 0.0588 | Consistency: 0.0216 | SSIM: 0.0418 | Grad: 113901.188\n",
      "[Epoch 16, Batch 39/100] Loss: 0.0681 | RMSE: 0.0637 | Consistency: 0.0192 | SSIM: 0.0429 | Grad: 144207.188\n",
      "[Epoch 16, Batch 40/100] Loss: 0.0708 | RMSE: 0.0661 | Consistency: 0.0212 | SSIM: 0.0444 | Grad: 70226.047\n",
      "[Epoch 16, Batch 41/100] Loss: 0.0627 | RMSE: 0.0587 | Consistency: 0.0139 | SSIM: 0.0388 | Grad: 91600.203\n",
      "[Epoch 16, Batch 42/100] Loss: 0.0713 | RMSE: 0.0665 | Consistency: 0.0211 | SSIM: 0.0457 | Grad: 150667.547\n",
      "[Epoch 16, Batch 43/100] Loss: 0.0677 | RMSE: 0.0629 | Consistency: 0.0184 | SSIM: 0.0463 | Grad: 115443.469\n",
      "[Epoch 16, Batch 44/100] Loss: 0.0613 | RMSE: 0.0571 | Consistency: 0.0148 | SSIM: 0.0398 | Grad: 117555.438\n",
      "[Epoch 16, Batch 45/100] Loss: 0.0573 | RMSE: 0.0524 | Consistency: 0.0158 | SSIM: 0.0468 | Grad: 67787.984\n",
      "[Epoch 16, Batch 46/100] Loss: 0.0576 | RMSE: 0.0538 | Consistency: 0.0133 | SSIM: 0.0371 | Grad: 72832.242\n",
      "[Epoch 16, Batch 47/100] Loss: 0.0566 | RMSE: 0.0528 | Consistency: 0.0143 | SSIM: 0.0374 | Grad: 93091.656\n",
      "[Epoch 16, Batch 48/100] Loss: 0.0588 | RMSE: 0.0551 | Consistency: 0.0153 | SSIM: 0.0352 | Grad: 98188.148\n",
      "[Epoch 16, Batch 49/100] Loss: 0.0635 | RMSE: 0.0590 | Consistency: 0.0158 | SSIM: 0.0434 | Grad: 114335.945\n",
      "[Epoch 16, Batch 50/100] Loss: 0.0683 | RMSE: 0.0637 | Consistency: 0.0225 | SSIM: 0.0434 | Grad: 107960.930\n",
      "[Epoch 16, Batch 51/100] Loss: 0.0568 | RMSE: 0.0528 | Consistency: 0.0158 | SSIM: 0.0388 | Grad: 106987.289\n",
      "[Epoch 16, Batch 52/100] Loss: 0.0579 | RMSE: 0.0543 | Consistency: 0.0132 | SSIM: 0.0351 | Grad: 125132.797\n",
      "[Epoch 16, Batch 53/100] Loss: 0.0537 | RMSE: 0.0501 | Consistency: 0.0127 | SSIM: 0.0351 | Grad: 59162.992\n",
      "[Epoch 16, Batch 54/100] Loss: 0.0687 | RMSE: 0.0647 | Consistency: 0.0129 | SSIM: 0.0392 | Grad: 47218.164\n",
      "[Epoch 16, Batch 55/100] Loss: 0.0653 | RMSE: 0.0609 | Consistency: 0.0175 | SSIM: 0.0425 | Grad: 95033.602\n",
      "[Epoch 16, Batch 56/100] Loss: 0.0539 | RMSE: 0.0496 | Consistency: 0.0124 | SSIM: 0.0413 | Grad: 105464.555\n",
      "[Epoch 16, Batch 57/100] Loss: 0.0838 | RMSE: 0.0784 | Consistency: 0.0334 | SSIM: 0.0507 | Grad: 63945.910\n",
      "[Epoch 16, Batch 58/100] Loss: 0.0568 | RMSE: 0.0534 | Consistency: 0.0115 | SSIM: 0.0333 | Grad: 46981.723\n",
      "[Epoch 16, Batch 59/100] Loss: 0.0612 | RMSE: 0.0561 | Consistency: 0.0140 | SSIM: 0.0499 | Grad: 76525.695\n",
      "[Epoch 16, Batch 60/100] Loss: 0.0603 | RMSE: 0.0560 | Consistency: 0.0167 | SSIM: 0.0411 | Grad: 75441.422\n",
      "[Epoch 16, Batch 61/100] Loss: 0.0760 | RMSE: 0.0707 | Consistency: 0.0206 | SSIM: 0.0508 | Grad: 120252.945\n",
      "[Epoch 16, Batch 62/100] Loss: 0.0559 | RMSE: 0.0525 | Consistency: 0.0140 | SSIM: 0.0332 | Grad: 138877.438\n",
      "[Epoch 16, Batch 63/100] Loss: 0.0617 | RMSE: 0.0582 | Consistency: 0.0141 | SSIM: 0.0333 | Grad: 79282.773\n",
      "[Epoch 16, Batch 64/100] Loss: 0.0596 | RMSE: 0.0554 | Consistency: 0.0132 | SSIM: 0.0408 | Grad: 92285.828\n",
      "[Epoch 16, Batch 65/100] Loss: 0.0724 | RMSE: 0.0679 | Consistency: 0.0216 | SSIM: 0.0435 | Grad: 114862.359\n",
      "[Epoch 16, Batch 66/100] Loss: 0.0530 | RMSE: 0.0490 | Consistency: 0.0143 | SSIM: 0.0386 | Grad: 39302.285\n",
      "[Epoch 16, Batch 67/100] Loss: 0.0731 | RMSE: 0.0688 | Consistency: 0.0207 | SSIM: 0.0414 | Grad: 169097.141\n",
      "[Epoch 16, Batch 68/100] Loss: 0.0826 | RMSE: 0.0772 | Consistency: 0.0281 | SSIM: 0.0519 | Grad: 152921.938\n",
      "[Epoch 16, Batch 69/100] Loss: 0.0642 | RMSE: 0.0595 | Consistency: 0.0188 | SSIM: 0.0445 | Grad: 71612.969\n",
      "[Epoch 16, Batch 70/100] Loss: 0.0748 | RMSE: 0.0697 | Consistency: 0.0255 | SSIM: 0.0479 | Grad: 152237.500\n",
      "[Epoch 16, Batch 71/100] Loss: 0.0835 | RMSE: 0.0771 | Consistency: 0.0349 | SSIM: 0.0608 | Grad: 141747.203\n",
      "[Epoch 16, Batch 72/100] Loss: 0.0719 | RMSE: 0.0668 | Consistency: 0.0220 | SSIM: 0.0494 | Grad: 94405.180\n",
      "[Epoch 16, Batch 73/100] Loss: 0.0737 | RMSE: 0.0692 | Consistency: 0.0237 | SSIM: 0.0433 | Grad: 108548.078\n",
      "[Epoch 16, Batch 74/100] Loss: 0.0689 | RMSE: 0.0644 | Consistency: 0.0204 | SSIM: 0.0429 | Grad: 144011.016\n",
      "[Epoch 16, Batch 75/100] Loss: 0.0659 | RMSE: 0.0612 | Consistency: 0.0171 | SSIM: 0.0448 | Grad: 108034.500\n",
      "[Epoch 16, Batch 76/100] Loss: 0.0754 | RMSE: 0.0703 | Consistency: 0.0192 | SSIM: 0.0489 | Grad: 126321.242\n",
      "[Epoch 16, Batch 77/100] Loss: 0.0840 | RMSE: 0.0786 | Consistency: 0.0330 | SSIM: 0.0505 | Grad: 88276.805\n",
      "[Epoch 16, Batch 78/100] Loss: 0.0595 | RMSE: 0.0554 | Consistency: 0.0145 | SSIM: 0.0393 | Grad: 91441.820\n",
      "[Epoch 16, Batch 79/100] Loss: 0.0561 | RMSE: 0.0520 | Consistency: 0.0160 | SSIM: 0.0396 | Grad: 83137.047\n",
      "[Epoch 16, Batch 80/100] Loss: 0.0598 | RMSE: 0.0555 | Consistency: 0.0192 | SSIM: 0.0405 | Grad: 81521.117\n",
      "[Epoch 16, Batch 81/100] Loss: 0.0654 | RMSE: 0.0606 | Consistency: 0.0193 | SSIM: 0.0460 | Grad: 103274.820\n",
      "[Epoch 16, Batch 82/100] Loss: 0.0604 | RMSE: 0.0553 | Consistency: 0.0157 | SSIM: 0.0495 | Grad: 85857.562\n",
      "[Epoch 16, Batch 83/100] Loss: 0.0740 | RMSE: 0.0694 | Consistency: 0.0191 | SSIM: 0.0445 | Grad: 111485.680\n",
      "[Epoch 16, Batch 84/100] Loss: 0.0576 | RMSE: 0.0536 | Consistency: 0.0172 | SSIM: 0.0382 | Grad: 90618.234\n",
      "[Epoch 16, Batch 85/100] Loss: 0.0655 | RMSE: 0.0605 | Consistency: 0.0166 | SSIM: 0.0483 | Grad: 85697.930\n",
      "[Epoch 16, Batch 86/100] Loss: 0.0626 | RMSE: 0.0585 | Consistency: 0.0179 | SSIM: 0.0396 | Grad: 110849.766\n",
      "[Epoch 16, Batch 87/100] Loss: 0.0589 | RMSE: 0.0552 | Consistency: 0.0136 | SSIM: 0.0362 | Grad: 44134.777\n",
      "[Epoch 16, Batch 88/100] Loss: 0.0703 | RMSE: 0.0656 | Consistency: 0.0152 | SSIM: 0.0453 | Grad: 155920.078\n",
      "[Epoch 16, Batch 89/100] Loss: 0.0659 | RMSE: 0.0612 | Consistency: 0.0151 | SSIM: 0.0456 | Grad: 132450.359\n",
      "[Epoch 16, Batch 90/100] Loss: 0.0600 | RMSE: 0.0561 | Consistency: 0.0197 | SSIM: 0.0376 | Grad: 134887.500\n",
      "[Epoch 16, Batch 91/100] Loss: 0.0678 | RMSE: 0.0634 | Consistency: 0.0156 | SSIM: 0.0425 | Grad: 123245.648\n",
      "[Epoch 16, Batch 92/100] Loss: 0.0714 | RMSE: 0.0669 | Consistency: 0.0229 | SSIM: 0.0427 | Grad: 151583.938\n",
      "[Epoch 16, Batch 93/100] Loss: 0.0669 | RMSE: 0.0620 | Consistency: 0.0185 | SSIM: 0.0470 | Grad: 119145.727\n",
      "[Epoch 16, Batch 94/100] Loss: 0.0633 | RMSE: 0.0588 | Consistency: 0.0171 | SSIM: 0.0431 | Grad: 103661.406\n",
      "[Epoch 16, Batch 95/100] Loss: 0.0666 | RMSE: 0.0623 | Consistency: 0.0226 | SSIM: 0.0403 | Grad: 117054.008\n",
      "[Epoch 16, Batch 96/100] Loss: 0.0559 | RMSE: 0.0525 | Consistency: 0.0126 | SSIM: 0.0330 | Grad: 100101.609\n",
      "[Epoch 16, Batch 97/100] Loss: 0.0659 | RMSE: 0.0613 | Consistency: 0.0154 | SSIM: 0.0450 | Grad: 112659.195\n",
      "[Epoch 16, Batch 98/100] Loss: 0.0556 | RMSE: 0.0513 | Consistency: 0.0142 | SSIM: 0.0416 | Grad: 111585.906\n",
      "[Epoch 16, Batch 99/100] Loss: 0.0625 | RMSE: 0.0581 | Consistency: 0.0190 | SSIM: 0.0422 | Grad: 72201.094\n",
      "[Epoch 16, Batch 100/100] Loss: 0.0530 | RMSE: 0.0493 | Consistency: 0.0129 | SSIM: 0.0351 | Grad: 47891.699\n",
      "✅ Epoch 16 완료!\n",
      "   📈 평균 Loss: 0.065226\n",
      "   📊 평균 RMSE: 0.060765\n",
      "   ⚙️  학습률: 0.000970\n",
      "   🏆 NEW BEST! RMSE: 0.060765\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 17/80 시작...\n",
      "[Epoch 17, Batch 1/100] Loss: 0.0536 | RMSE: 0.0498 | Consistency: 0.0119 | SSIM: 0.0364 | Grad: 53125.422\n",
      "[Epoch 17, Batch 2/100] Loss: 0.0728 | RMSE: 0.0683 | Consistency: 0.0209 | SSIM: 0.0426 | Grad: 164039.922\n",
      "[Epoch 17, Batch 3/100] Loss: 0.0707 | RMSE: 0.0656 | Consistency: 0.0176 | SSIM: 0.0499 | Grad: 188338.172\n",
      "[Epoch 17, Batch 4/100] Loss: 0.0578 | RMSE: 0.0533 | Consistency: 0.0166 | SSIM: 0.0438 | Grad: 87539.883\n",
      "[Epoch 17, Batch 5/100] Loss: 0.0649 | RMSE: 0.0605 | Consistency: 0.0150 | SSIM: 0.0422 | Grad: 93847.289\n",
      "[Epoch 17, Batch 6/100] Loss: 0.0599 | RMSE: 0.0560 | Consistency: 0.0137 | SSIM: 0.0378 | Grad: 126059.672\n",
      "[Epoch 17, Batch 7/100] Loss: 0.0712 | RMSE: 0.0658 | Consistency: 0.0230 | SSIM: 0.0510 | Grad: 73038.961\n",
      "[Epoch 17, Batch 8/100] Loss: 0.0633 | RMSE: 0.0587 | Consistency: 0.0168 | SSIM: 0.0440 | Grad: 120795.742\n",
      "[Epoch 17, Batch 9/100] Loss: 0.0764 | RMSE: 0.0718 | Consistency: 0.0198 | SSIM: 0.0444 | Grad: 166800.188\n",
      "[Epoch 17, Batch 10/100] Loss: 0.0550 | RMSE: 0.0510 | Consistency: 0.0145 | SSIM: 0.0390 | Grad: 64625.504\n",
      "[Epoch 17, Batch 11/100] Loss: 0.0642 | RMSE: 0.0596 | Consistency: 0.0170 | SSIM: 0.0445 | Grad: 139968.641\n",
      "[Epoch 17, Batch 12/100] Loss: 0.0632 | RMSE: 0.0587 | Consistency: 0.0159 | SSIM: 0.0433 | Grad: 63063.551\n",
      "[Epoch 17, Batch 13/100] Loss: 0.0579 | RMSE: 0.0537 | Consistency: 0.0139 | SSIM: 0.0411 | Grad: 67509.836\n",
      "[Epoch 17, Batch 14/100] Loss: 0.0648 | RMSE: 0.0606 | Consistency: 0.0132 | SSIM: 0.0401 | Grad: 117942.781\n",
      "[Epoch 17, Batch 15/100] Loss: 0.0572 | RMSE: 0.0529 | Consistency: 0.0147 | SSIM: 0.0419 | Grad: 63423.367\n",
      "[Epoch 17, Batch 16/100] Loss: 0.0662 | RMSE: 0.0610 | Consistency: 0.0185 | SSIM: 0.0497 | Grad: 122130.391\n",
      "[Epoch 17, Batch 17/100] Loss: 0.0628 | RMSE: 0.0585 | Consistency: 0.0164 | SSIM: 0.0422 | Grad: 118671.555\n",
      "[Epoch 17, Batch 18/100] Loss: 0.0685 | RMSE: 0.0642 | Consistency: 0.0145 | SSIM: 0.0414 | Grad: 180163.000\n",
      "[Epoch 17, Batch 19/100] Loss: 0.0517 | RMSE: 0.0479 | Consistency: 0.0138 | SSIM: 0.0363 | Grad: 55383.520\n",
      "[Epoch 17, Batch 20/100] Loss: 0.0694 | RMSE: 0.0642 | Consistency: 0.0183 | SSIM: 0.0506 | Grad: 151357.734\n",
      "[Epoch 17, Batch 21/100] Loss: 0.0781 | RMSE: 0.0730 | Consistency: 0.0266 | SSIM: 0.0478 | Grad: 171754.734\n",
      "[Epoch 17, Batch 22/100] Loss: 0.0659 | RMSE: 0.0612 | Consistency: 0.0166 | SSIM: 0.0452 | Grad: 56412.941\n",
      "[Epoch 17, Batch 23/100] Loss: 0.0508 | RMSE: 0.0469 | Consistency: 0.0113 | SSIM: 0.0382 | Grad: 33917.176\n",
      "[Epoch 17, Batch 24/100] Loss: 0.0753 | RMSE: 0.0701 | Consistency: 0.0255 | SSIM: 0.0496 | Grad: 126134.883\n",
      "[Epoch 17, Batch 25/100] Loss: 0.0658 | RMSE: 0.0609 | Consistency: 0.0205 | SSIM: 0.0471 | Grad: 61839.004\n",
      "[Epoch 17, Batch 26/100] Loss: 0.0595 | RMSE: 0.0548 | Consistency: 0.0161 | SSIM: 0.0458 | Grad: 88379.438\n",
      "[Epoch 17, Batch 27/100] Loss: 0.0695 | RMSE: 0.0646 | Consistency: 0.0235 | SSIM: 0.0466 | Grad: 111845.781\n",
      "[Epoch 17, Batch 28/100] Loss: 0.0638 | RMSE: 0.0589 | Consistency: 0.0161 | SSIM: 0.0474 | Grad: 118579.492\n",
      "[Epoch 17, Batch 29/100] Loss: 0.0667 | RMSE: 0.0616 | Consistency: 0.0206 | SSIM: 0.0495 | Grad: 55831.504\n",
      "[Epoch 17, Batch 30/100] Loss: 0.0685 | RMSE: 0.0638 | Consistency: 0.0167 | SSIM: 0.0452 | Grad: 143883.156\n",
      "[Epoch 17, Batch 31/100] Loss: 0.0650 | RMSE: 0.0602 | Consistency: 0.0191 | SSIM: 0.0467 | Grad: 79343.508\n",
      "[Epoch 17, Batch 32/100] Loss: 0.0763 | RMSE: 0.0705 | Consistency: 0.0251 | SSIM: 0.0555 | Grad: 121427.203\n",
      "[Epoch 17, Batch 33/100] Loss: 0.0638 | RMSE: 0.0598 | Consistency: 0.0147 | SSIM: 0.0392 | Grad: 165428.438\n",
      "[Epoch 17, Batch 34/100] Loss: 0.0649 | RMSE: 0.0594 | Consistency: 0.0232 | SSIM: 0.0526 | Grad: 106866.852\n",
      "[Epoch 17, Batch 35/100] Loss: 0.0681 | RMSE: 0.0629 | Consistency: 0.0193 | SSIM: 0.0499 | Grad: 113293.141\n",
      "[Epoch 17, Batch 36/100] Loss: 0.0601 | RMSE: 0.0557 | Consistency: 0.0174 | SSIM: 0.0420 | Grad: 108008.070\n",
      "[Epoch 17, Batch 37/100] Loss: 0.0619 | RMSE: 0.0582 | Consistency: 0.0137 | SSIM: 0.0360 | Grad: 67740.398\n",
      "[Epoch 17, Batch 38/100] Loss: 0.0674 | RMSE: 0.0630 | Consistency: 0.0206 | SSIM: 0.0419 | Grad: 159252.875\n",
      "[Epoch 17, Batch 39/100] Loss: 0.0776 | RMSE: 0.0729 | Consistency: 0.0268 | SSIM: 0.0449 | Grad: 157728.281\n",
      "[Epoch 17, Batch 40/100] Loss: 0.0591 | RMSE: 0.0546 | Consistency: 0.0178 | SSIM: 0.0431 | Grad: 72982.188\n",
      "[Epoch 17, Batch 41/100] Loss: 0.0650 | RMSE: 0.0602 | Consistency: 0.0176 | SSIM: 0.0466 | Grad: 83981.273\n",
      "[Epoch 17, Batch 42/100] Loss: 0.0586 | RMSE: 0.0548 | Consistency: 0.0182 | SSIM: 0.0359 | Grad: 111507.859\n",
      "[Epoch 17, Batch 43/100] Loss: 0.0580 | RMSE: 0.0539 | Consistency: 0.0160 | SSIM: 0.0394 | Grad: 91211.734\n",
      "[Epoch 17, Batch 44/100] Loss: 0.0640 | RMSE: 0.0598 | Consistency: 0.0160 | SSIM: 0.0412 | Grad: 154530.297\n",
      "[Epoch 17, Batch 45/100] Loss: 0.0641 | RMSE: 0.0599 | Consistency: 0.0258 | SSIM: 0.0392 | Grad: 127413.750\n",
      "[Epoch 17, Batch 46/100] Loss: 0.0604 | RMSE: 0.0565 | Consistency: 0.0177 | SSIM: 0.0374 | Grad: 143423.531\n",
      "[Epoch 17, Batch 47/100] Loss: 0.0630 | RMSE: 0.0583 | Consistency: 0.0152 | SSIM: 0.0451 | Grad: 117585.789\n",
      "[Epoch 17, Batch 48/100] Loss: 0.0629 | RMSE: 0.0588 | Consistency: 0.0203 | SSIM: 0.0394 | Grad: 146566.125\n",
      "[Epoch 17, Batch 49/100] Loss: 0.0688 | RMSE: 0.0642 | Consistency: 0.0226 | SSIM: 0.0435 | Grad: 75667.891\n",
      "[Epoch 17, Batch 50/100] Loss: 0.0511 | RMSE: 0.0472 | Consistency: 0.0124 | SSIM: 0.0381 | Grad: 87910.562\n",
      "[Epoch 17, Batch 51/100] Loss: 0.0571 | RMSE: 0.0532 | Consistency: 0.0148 | SSIM: 0.0371 | Grad: 54332.746\n",
      "[Epoch 17, Batch 52/100] Loss: 0.0667 | RMSE: 0.0623 | Consistency: 0.0205 | SSIM: 0.0417 | Grad: 88091.508\n",
      "[Epoch 17, Batch 53/100] Loss: 0.0590 | RMSE: 0.0551 | Consistency: 0.0136 | SSIM: 0.0368 | Grad: 98633.711\n",
      "[Epoch 17, Batch 54/100] Loss: 0.0513 | RMSE: 0.0476 | Consistency: 0.0110 | SSIM: 0.0353 | Grad: 57323.133\n",
      "[Epoch 17, Batch 55/100] Loss: 0.0497 | RMSE: 0.0460 | Consistency: 0.0116 | SSIM: 0.0353 | Grad: 78636.781\n",
      "[Epoch 17, Batch 56/100] Loss: 0.0486 | RMSE: 0.0454 | Consistency: 0.0111 | SSIM: 0.0309 | Grad: 80565.695\n",
      "[Epoch 17, Batch 57/100] Loss: 0.0604 | RMSE: 0.0563 | Consistency: 0.0165 | SSIM: 0.0395 | Grad: 100369.984\n",
      "[Epoch 17, Batch 58/100] Loss: 0.0547 | RMSE: 0.0505 | Consistency: 0.0111 | SSIM: 0.0412 | Grad: 88289.891\n",
      "[Epoch 17, Batch 59/100] Loss: 0.0565 | RMSE: 0.0528 | Consistency: 0.0156 | SSIM: 0.0354 | Grad: 75209.586\n",
      "[Epoch 17, Batch 60/100] Loss: 0.0633 | RMSE: 0.0592 | Consistency: 0.0176 | SSIM: 0.0392 | Grad: 45407.738\n",
      "[Epoch 17, Batch 61/100] Loss: 0.0522 | RMSE: 0.0482 | Consistency: 0.0135 | SSIM: 0.0381 | Grad: 26291.367\n",
      "[Epoch 17, Batch 62/100] Loss: 0.0629 | RMSE: 0.0579 | Consistency: 0.0155 | SSIM: 0.0488 | Grad: 100427.492\n",
      "[Epoch 17, Batch 63/100] Loss: 0.0682 | RMSE: 0.0632 | Consistency: 0.0197 | SSIM: 0.0473 | Grad: 160170.641\n",
      "[Epoch 17, Batch 64/100] Loss: 0.0650 | RMSE: 0.0608 | Consistency: 0.0166 | SSIM: 0.0403 | Grad: 98023.789\n",
      "[Epoch 17, Batch 65/100] Loss: 0.0773 | RMSE: 0.0724 | Consistency: 0.0219 | SSIM: 0.0477 | Grad: 146921.250\n",
      "[Epoch 17, Batch 66/100] Loss: 0.0713 | RMSE: 0.0666 | Consistency: 0.0195 | SSIM: 0.0455 | Grad: 138026.047\n",
      "[Epoch 17, Batch 67/100] Loss: 0.0608 | RMSE: 0.0564 | Consistency: 0.0137 | SSIM: 0.0425 | Grad: 70007.555\n",
      "[Epoch 17, Batch 68/100] Loss: 0.0658 | RMSE: 0.0620 | Consistency: 0.0188 | SSIM: 0.0356 | Grad: 126462.961\n",
      "[Epoch 17, Batch 69/100] Loss: 0.0658 | RMSE: 0.0617 | Consistency: 0.0200 | SSIM: 0.0386 | Grad: 139294.719\n",
      "[Epoch 17, Batch 70/100] Loss: 0.0707 | RMSE: 0.0660 | Consistency: 0.0152 | SSIM: 0.0447 | Grad: 169316.422\n",
      "[Epoch 17, Batch 71/100] Loss: 0.0595 | RMSE: 0.0554 | Consistency: 0.0163 | SSIM: 0.0391 | Grad: 95771.391\n",
      "[Epoch 17, Batch 72/100] Loss: 0.0650 | RMSE: 0.0610 | Consistency: 0.0141 | SSIM: 0.0386 | Grad: 90115.453\n",
      "[Epoch 17, Batch 73/100] Loss: 0.0566 | RMSE: 0.0529 | Consistency: 0.0156 | SSIM: 0.0360 | Grad: 78029.695\n",
      "[Epoch 17, Batch 74/100] Loss: 0.0616 | RMSE: 0.0572 | Consistency: 0.0150 | SSIM: 0.0429 | Grad: 48951.504\n",
      "[Epoch 17, Batch 75/100] Loss: 0.0712 | RMSE: 0.0669 | Consistency: 0.0241 | SSIM: 0.0409 | Grad: 183642.266\n",
      "[Epoch 17, Batch 76/100] Loss: 0.0571 | RMSE: 0.0534 | Consistency: 0.0143 | SSIM: 0.0354 | Grad: 106750.281\n",
      "[Epoch 17, Batch 77/100] Loss: 0.0581 | RMSE: 0.0537 | Consistency: 0.0146 | SSIM: 0.0417 | Grad: 35714.250\n",
      "[Epoch 17, Batch 78/100] Loss: 0.0836 | RMSE: 0.0787 | Consistency: 0.0245 | SSIM: 0.0466 | Grad: 150735.844\n",
      "[Epoch 17, Batch 79/100] Loss: 0.0904 | RMSE: 0.0847 | Consistency: 0.0141 | SSIM: 0.0552 | Grad: 206385.391\n",
      "[Epoch 17, Batch 80/100] Loss: 0.0762 | RMSE: 0.0705 | Consistency: 0.0195 | SSIM: 0.0554 | Grad: 133434.000\n",
      "[Epoch 17, Batch 81/100] Loss: 0.0631 | RMSE: 0.0584 | Consistency: 0.0180 | SSIM: 0.0453 | Grad: 101562.852\n",
      "[Epoch 17, Batch 82/100] Loss: 0.0755 | RMSE: 0.0697 | Consistency: 0.0154 | SSIM: 0.0565 | Grad: 166781.750\n",
      "[Epoch 17, Batch 83/100] Loss: 0.0633 | RMSE: 0.0589 | Consistency: 0.0141 | SSIM: 0.0426 | Grad: 154726.500\n",
      "[Epoch 17, Batch 84/100] Loss: 0.0596 | RMSE: 0.0550 | Consistency: 0.0153 | SSIM: 0.0444 | Grad: 113068.586\n",
      "[Epoch 17, Batch 85/100] Loss: 0.0709 | RMSE: 0.0666 | Consistency: 0.0149 | SSIM: 0.0407 | Grad: 118872.938\n",
      "[Epoch 17, Batch 86/100] Loss: 0.0719 | RMSE: 0.0671 | Consistency: 0.0194 | SSIM: 0.0462 | Grad: 73880.672\n",
      "[Epoch 17, Batch 87/100] Loss: 0.0591 | RMSE: 0.0552 | Consistency: 0.0145 | SSIM: 0.0375 | Grad: 54719.543\n",
      "[Epoch 17, Batch 88/100] Loss: 0.0568 | RMSE: 0.0529 | Consistency: 0.0168 | SSIM: 0.0377 | Grad: 47316.781\n",
      "[Epoch 17, Batch 89/100] Loss: 0.0661 | RMSE: 0.0619 | Consistency: 0.0182 | SSIM: 0.0407 | Grad: 147073.125\n",
      "[Epoch 17, Batch 90/100] Loss: 0.0666 | RMSE: 0.0622 | Consistency: 0.0178 | SSIM: 0.0419 | Grad: 125143.266\n",
      "[Epoch 17, Batch 91/100] Loss: 0.0627 | RMSE: 0.0582 | Consistency: 0.0180 | SSIM: 0.0436 | Grad: 62990.758\n",
      "[Epoch 17, Batch 92/100] Loss: 0.0707 | RMSE: 0.0660 | Consistency: 0.0189 | SSIM: 0.0446 | Grad: 204431.531\n",
      "[Epoch 17, Batch 93/100] Loss: 0.0731 | RMSE: 0.0690 | Consistency: 0.0162 | SSIM: 0.0394 | Grad: 167464.859\n",
      "[Epoch 17, Batch 94/100] Loss: 0.0657 | RMSE: 0.0613 | Consistency: 0.0193 | SSIM: 0.0419 | Grad: 94442.500\n",
      "[Epoch 17, Batch 95/100] Loss: 0.0682 | RMSE: 0.0640 | Consistency: 0.0201 | SSIM: 0.0396 | Grad: 143050.422\n",
      "[Epoch 17, Batch 96/100] Loss: 0.0765 | RMSE: 0.0715 | Consistency: 0.0205 | SSIM: 0.0487 | Grad: 172202.844\n",
      "[Epoch 17, Batch 97/100] Loss: 0.0780 | RMSE: 0.0734 | Consistency: 0.0221 | SSIM: 0.0445 | Grad: 138383.156\n",
      "[Epoch 17, Batch 98/100] Loss: 0.0710 | RMSE: 0.0656 | Consistency: 0.0247 | SSIM: 0.0518 | Grad: 99194.500\n",
      "[Epoch 17, Batch 99/100] Loss: 0.0623 | RMSE: 0.0581 | Consistency: 0.0150 | SSIM: 0.0402 | Grad: 117712.500\n",
      "[Epoch 17, Batch 100/100] Loss: 0.0637 | RMSE: 0.0595 | Consistency: 0.0178 | SSIM: 0.0406 | Grad: 68910.500\n",
      "✅ Epoch 17 완료!\n",
      "   📈 평균 Loss: 0.064665\n",
      "   📊 평균 RMSE: 0.060207\n",
      "   ⚙️  학습률: 0.000962\n",
      "   🏆 NEW BEST! RMSE: 0.060207\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 18/80 시작...\n",
      "[Epoch 18, Batch 1/100] Loss: 0.0632 | RMSE: 0.0588 | Consistency: 0.0161 | SSIM: 0.0424 | Grad: 75414.648\n",
      "[Epoch 18, Batch 2/100] Loss: 0.0643 | RMSE: 0.0595 | Consistency: 0.0172 | SSIM: 0.0462 | Grad: 68916.781\n",
      "[Epoch 18, Batch 3/100] Loss: 0.0682 | RMSE: 0.0631 | Consistency: 0.0222 | SSIM: 0.0497 | Grad: 90011.141\n",
      "[Epoch 18, Batch 4/100] Loss: 0.0644 | RMSE: 0.0594 | Consistency: 0.0164 | SSIM: 0.0484 | Grad: 70590.820\n",
      "[Epoch 18, Batch 5/100] Loss: 0.0454 | RMSE: 0.0418 | Consistency: 0.0110 | SSIM: 0.0349 | Grad: 78395.750\n",
      "[Epoch 18, Batch 6/100] Loss: 0.0592 | RMSE: 0.0553 | Consistency: 0.0160 | SSIM: 0.0367 | Grad: 85299.219\n",
      "[Epoch 18, Batch 7/100] Loss: 0.0555 | RMSE: 0.0519 | Consistency: 0.0133 | SSIM: 0.0351 | Grad: 130214.953\n",
      "[Epoch 18, Batch 8/100] Loss: 0.0589 | RMSE: 0.0546 | Consistency: 0.0163 | SSIM: 0.0412 | Grad: 85789.766\n",
      "[Epoch 18, Batch 9/100] Loss: 0.0657 | RMSE: 0.0614 | Consistency: 0.0167 | SSIM: 0.0412 | Grad: 48913.211\n",
      "[Epoch 18, Batch 10/100] Loss: 0.0666 | RMSE: 0.0617 | Consistency: 0.0157 | SSIM: 0.0465 | Grad: 80625.141\n",
      "[Epoch 18, Batch 11/100] Loss: 0.0643 | RMSE: 0.0600 | Consistency: 0.0215 | SSIM: 0.0414 | Grad: 123823.500\n",
      "[Epoch 18, Batch 12/100] Loss: 0.0756 | RMSE: 0.0704 | Consistency: 0.0210 | SSIM: 0.0501 | Grad: 176530.094\n",
      "[Epoch 18, Batch 13/100] Loss: 0.0521 | RMSE: 0.0481 | Consistency: 0.0129 | SSIM: 0.0388 | Grad: 80702.055\n",
      "[Epoch 18, Batch 14/100] Loss: 0.0623 | RMSE: 0.0577 | Consistency: 0.0155 | SSIM: 0.0449 | Grad: 123670.641\n",
      "[Epoch 18, Batch 15/100] Loss: 0.0647 | RMSE: 0.0605 | Consistency: 0.0147 | SSIM: 0.0407 | Grad: 94330.391\n",
      "[Epoch 18, Batch 16/100] Loss: 0.0624 | RMSE: 0.0581 | Consistency: 0.0128 | SSIM: 0.0419 | Grad: 67014.219\n",
      "[Epoch 18, Batch 17/100] Loss: 0.0518 | RMSE: 0.0480 | Consistency: 0.0108 | SSIM: 0.0371 | Grad: 65559.688\n",
      "[Epoch 18, Batch 18/100] Loss: 0.0749 | RMSE: 0.0703 | Consistency: 0.0197 | SSIM: 0.0437 | Grad: 118864.844\n",
      "[Epoch 18, Batch 19/100] Loss: 0.0708 | RMSE: 0.0661 | Consistency: 0.0193 | SSIM: 0.0446 | Grad: 101440.688\n",
      "[Epoch 18, Batch 20/100] Loss: 0.0587 | RMSE: 0.0543 | Consistency: 0.0174 | SSIM: 0.0421 | Grad: 103440.898\n",
      "[Epoch 18, Batch 21/100] Loss: 0.0626 | RMSE: 0.0585 | Consistency: 0.0189 | SSIM: 0.0391 | Grad: 169266.484\n",
      "[Epoch 18, Batch 22/100] Loss: 0.0607 | RMSE: 0.0564 | Consistency: 0.0138 | SSIM: 0.0424 | Grad: 129158.672\n",
      "[Epoch 18, Batch 23/100] Loss: 0.0587 | RMSE: 0.0545 | Consistency: 0.0143 | SSIM: 0.0410 | Grad: 61784.684\n",
      "[Epoch 18, Batch 24/100] Loss: 0.0675 | RMSE: 0.0627 | Consistency: 0.0165 | SSIM: 0.0463 | Grad: 120833.719\n",
      "[Epoch 18, Batch 25/100] Loss: 0.0602 | RMSE: 0.0560 | Consistency: 0.0155 | SSIM: 0.0410 | Grad: 101979.047\n",
      "[Epoch 18, Batch 26/100] Loss: 0.0683 | RMSE: 0.0633 | Consistency: 0.0175 | SSIM: 0.0482 | Grad: 76284.812\n",
      "[Epoch 18, Batch 27/100] Loss: 0.0646 | RMSE: 0.0608 | Consistency: 0.0188 | SSIM: 0.0357 | Grad: 131268.203\n",
      "[Epoch 18, Batch 28/100] Loss: 0.0701 | RMSE: 0.0654 | Consistency: 0.0231 | SSIM: 0.0441 | Grad: 138260.250\n",
      "[Epoch 18, Batch 29/100] Loss: 0.0566 | RMSE: 0.0520 | Consistency: 0.0132 | SSIM: 0.0448 | Grad: 57393.656\n",
      "[Epoch 18, Batch 30/100] Loss: 0.0657 | RMSE: 0.0616 | Consistency: 0.0186 | SSIM: 0.0387 | Grad: 161167.891\n",
      "[Epoch 18, Batch 31/100] Loss: 0.0709 | RMSE: 0.0663 | Consistency: 0.0177 | SSIM: 0.0438 | Grad: 143833.891\n",
      "[Epoch 18, Batch 32/100] Loss: 0.0617 | RMSE: 0.0572 | Consistency: 0.0179 | SSIM: 0.0432 | Grad: 89231.000\n",
      "[Epoch 18, Batch 33/100] Loss: 0.0618 | RMSE: 0.0570 | Consistency: 0.0150 | SSIM: 0.0457 | Grad: 116426.922\n",
      "[Epoch 18, Batch 34/100] Loss: 0.0674 | RMSE: 0.0631 | Consistency: 0.0149 | SSIM: 0.0418 | Grad: 74487.578\n",
      "[Epoch 18, Batch 35/100] Loss: 0.0709 | RMSE: 0.0660 | Consistency: 0.0228 | SSIM: 0.0467 | Grad: 68477.430\n",
      "[Epoch 18, Batch 36/100] Loss: 0.0594 | RMSE: 0.0554 | Consistency: 0.0142 | SSIM: 0.0394 | Grad: 114995.422\n",
      "[Epoch 18, Batch 37/100] Loss: 0.0588 | RMSE: 0.0546 | Consistency: 0.0142 | SSIM: 0.0407 | Grad: 131333.141\n",
      "[Epoch 18, Batch 38/100] Loss: 0.0750 | RMSE: 0.0696 | Consistency: 0.0207 | SSIM: 0.0516 | Grad: 117497.469\n",
      "[Epoch 18, Batch 39/100] Loss: 0.0544 | RMSE: 0.0506 | Consistency: 0.0136 | SSIM: 0.0357 | Grad: 46172.891\n",
      "[Epoch 18, Batch 40/100] Loss: 0.0591 | RMSE: 0.0552 | Consistency: 0.0138 | SSIM: 0.0377 | Grad: 62224.469\n",
      "[Epoch 18, Batch 41/100] Loss: 0.0609 | RMSE: 0.0570 | Consistency: 0.0172 | SSIM: 0.0367 | Grad: 79248.969\n",
      "[Epoch 18, Batch 42/100] Loss: 0.0680 | RMSE: 0.0629 | Consistency: 0.0211 | SSIM: 0.0492 | Grad: 82692.734\n",
      "[Epoch 18, Batch 43/100] Loss: 0.0700 | RMSE: 0.0649 | Consistency: 0.0209 | SSIM: 0.0480 | Grad: 120836.750\n",
      "[Epoch 18, Batch 44/100] Loss: 0.0583 | RMSE: 0.0545 | Consistency: 0.0152 | SSIM: 0.0371 | Grad: 106198.492\n",
      "[Epoch 18, Batch 45/100] Loss: 0.0550 | RMSE: 0.0508 | Consistency: 0.0122 | SSIM: 0.0408 | Grad: 54258.543\n",
      "[Epoch 18, Batch 46/100] Loss: 0.0642 | RMSE: 0.0603 | Consistency: 0.0137 | SSIM: 0.0370 | Grad: 133268.203\n",
      "[Epoch 18, Batch 47/100] Loss: 0.0626 | RMSE: 0.0588 | Consistency: 0.0214 | SSIM: 0.0358 | Grad: 150767.422\n",
      "[Epoch 18, Batch 48/100] Loss: 0.0633 | RMSE: 0.0594 | Consistency: 0.0154 | SSIM: 0.0372 | Grad: 97534.805\n",
      "[Epoch 18, Batch 49/100] Loss: 0.0775 | RMSE: 0.0717 | Consistency: 0.0239 | SSIM: 0.0549 | Grad: 124110.688\n",
      "[Epoch 18, Batch 50/100] Loss: 0.0635 | RMSE: 0.0589 | Consistency: 0.0197 | SSIM: 0.0435 | Grad: 147467.188\n",
      "[Epoch 18, Batch 51/100] Loss: 0.0575 | RMSE: 0.0533 | Consistency: 0.0169 | SSIM: 0.0403 | Grad: 107229.344\n",
      "[Epoch 18, Batch 52/100] Loss: 0.0703 | RMSE: 0.0654 | Consistency: 0.0182 | SSIM: 0.0476 | Grad: 146500.938\n",
      "[Epoch 18, Batch 53/100] Loss: 0.0700 | RMSE: 0.0654 | Consistency: 0.0212 | SSIM: 0.0443 | Grad: 154352.156\n",
      "[Epoch 18, Batch 54/100] Loss: 0.0566 | RMSE: 0.0530 | Consistency: 0.0172 | SSIM: 0.0342 | Grad: 134965.359\n",
      "[Epoch 18, Batch 55/100] Loss: 0.0557 | RMSE: 0.0520 | Consistency: 0.0119 | SSIM: 0.0351 | Grad: 99448.281\n",
      "[Epoch 18, Batch 56/100] Loss: 0.0720 | RMSE: 0.0664 | Consistency: 0.0308 | SSIM: 0.0522 | Grad: 114776.617\n",
      "[Epoch 18, Batch 57/100] Loss: 0.0738 | RMSE: 0.0687 | Consistency: 0.0237 | SSIM: 0.0490 | Grad: 73906.125\n",
      "[Epoch 18, Batch 58/100] Loss: 0.0611 | RMSE: 0.0566 | Consistency: 0.0155 | SSIM: 0.0436 | Grad: 100529.984\n",
      "[Epoch 18, Batch 59/100] Loss: 0.0553 | RMSE: 0.0516 | Consistency: 0.0132 | SSIM: 0.0357 | Grad: 79010.742\n",
      "[Epoch 18, Batch 60/100] Loss: 0.0612 | RMSE: 0.0569 | Consistency: 0.0162 | SSIM: 0.0414 | Grad: 62039.922\n",
      "[Epoch 18, Batch 61/100] Loss: 0.0854 | RMSE: 0.0804 | Consistency: 0.0281 | SSIM: 0.0467 | Grad: 109919.766\n",
      "[Epoch 18, Batch 62/100] Loss: 0.0664 | RMSE: 0.0619 | Consistency: 0.0247 | SSIM: 0.0433 | Grad: 151677.766\n",
      "[Epoch 18, Batch 63/100] Loss: 0.0648 | RMSE: 0.0600 | Consistency: 0.0191 | SSIM: 0.0456 | Grad: 116339.297\n",
      "[Epoch 18, Batch 64/100] Loss: 0.0662 | RMSE: 0.0616 | Consistency: 0.0159 | SSIM: 0.0443 | Grad: 122567.797\n",
      "[Epoch 18, Batch 65/100] Loss: 0.0638 | RMSE: 0.0598 | Consistency: 0.0175 | SSIM: 0.0388 | Grad: 80339.727\n",
      "[Epoch 18, Batch 66/100] Loss: 0.0594 | RMSE: 0.0553 | Consistency: 0.0162 | SSIM: 0.0384 | Grad: 121010.391\n",
      "[Epoch 18, Batch 67/100] Loss: 0.0635 | RMSE: 0.0588 | Consistency: 0.0153 | SSIM: 0.0456 | Grad: 145630.484\n",
      "[Epoch 18, Batch 68/100] Loss: 0.0568 | RMSE: 0.0530 | Consistency: 0.0134 | SSIM: 0.0367 | Grad: 62238.934\n",
      "[Epoch 18, Batch 69/100] Loss: 0.0672 | RMSE: 0.0630 | Consistency: 0.0122 | SSIM: 0.0409 | Grad: 168184.156\n",
      "[Epoch 18, Batch 70/100] Loss: 0.0563 | RMSE: 0.0521 | Consistency: 0.0105 | SSIM: 0.0407 | Grad: 142470.297\n",
      "[Epoch 18, Batch 71/100] Loss: 0.0599 | RMSE: 0.0560 | Consistency: 0.0164 | SSIM: 0.0371 | Grad: 141520.656\n",
      "[Epoch 18, Batch 72/100] Loss: 0.0618 | RMSE: 0.0577 | Consistency: 0.0144 | SSIM: 0.0394 | Grad: 128853.445\n",
      "[Epoch 18, Batch 73/100] Loss: 0.0522 | RMSE: 0.0479 | Consistency: 0.0131 | SSIM: 0.0415 | Grad: 68469.547\n",
      "[Epoch 18, Batch 74/100] Loss: 0.0636 | RMSE: 0.0595 | Consistency: 0.0162 | SSIM: 0.0393 | Grad: 156280.359\n",
      "[Epoch 18, Batch 75/100] Loss: 0.0698 | RMSE: 0.0652 | Consistency: 0.0154 | SSIM: 0.0439 | Grad: 147962.094\n",
      "[Epoch 18, Batch 76/100] Loss: 0.0698 | RMSE: 0.0657 | Consistency: 0.0196 | SSIM: 0.0395 | Grad: 125314.414\n",
      "[Epoch 18, Batch 77/100] Loss: 0.0684 | RMSE: 0.0636 | Consistency: 0.0198 | SSIM: 0.0458 | Grad: 105604.703\n",
      "[Epoch 18, Batch 78/100] Loss: 0.0612 | RMSE: 0.0574 | Consistency: 0.0151 | SSIM: 0.0361 | Grad: 130667.352\n",
      "[Epoch 18, Batch 79/100] Loss: 0.0579 | RMSE: 0.0547 | Consistency: 0.0124 | SSIM: 0.0315 | Grad: 150095.266\n",
      "[Epoch 18, Batch 80/100] Loss: 0.0587 | RMSE: 0.0542 | Consistency: 0.0144 | SSIM: 0.0430 | Grad: 95695.438\n",
      "[Epoch 18, Batch 81/100] Loss: 0.0638 | RMSE: 0.0597 | Consistency: 0.0163 | SSIM: 0.0400 | Grad: 124758.430\n",
      "[Epoch 18, Batch 82/100] Loss: 0.0655 | RMSE: 0.0615 | Consistency: 0.0126 | SSIM: 0.0388 | Grad: 139650.000\n",
      "[Epoch 18, Batch 83/100] Loss: 0.0652 | RMSE: 0.0606 | Consistency: 0.0188 | SSIM: 0.0442 | Grad: 159102.578\n",
      "[Epoch 18, Batch 84/100] Loss: 0.0706 | RMSE: 0.0650 | Consistency: 0.0252 | SSIM: 0.0531 | Grad: 171392.141\n",
      "[Epoch 18, Batch 85/100] Loss: 0.0549 | RMSE: 0.0507 | Consistency: 0.0110 | SSIM: 0.0413 | Grad: 108064.773\n",
      "[Epoch 18, Batch 86/100] Loss: 0.0592 | RMSE: 0.0549 | Consistency: 0.0180 | SSIM: 0.0413 | Grad: 133637.781\n",
      "[Epoch 18, Batch 87/100] Loss: 0.0643 | RMSE: 0.0599 | Consistency: 0.0207 | SSIM: 0.0416 | Grad: 143534.547\n",
      "[Epoch 18, Batch 88/100] Loss: 0.0611 | RMSE: 0.0572 | Consistency: 0.0189 | SSIM: 0.0365 | Grad: 105728.898\n",
      "[Epoch 18, Batch 89/100] Loss: 0.0629 | RMSE: 0.0585 | Consistency: 0.0181 | SSIM: 0.0426 | Grad: 160754.953\n",
      "[Epoch 18, Batch 90/100] Loss: 0.0556 | RMSE: 0.0519 | Consistency: 0.0136 | SSIM: 0.0356 | Grad: 115234.586\n",
      "[Epoch 18, Batch 91/100] Loss: 0.0520 | RMSE: 0.0481 | Consistency: 0.0132 | SSIM: 0.0377 | Grad: 29979.900\n",
      "[Epoch 18, Batch 92/100] Loss: 0.0547 | RMSE: 0.0512 | Consistency: 0.0114 | SSIM: 0.0337 | Grad: 101788.047\n",
      "[Epoch 18, Batch 93/100] Loss: 0.0650 | RMSE: 0.0609 | Consistency: 0.0150 | SSIM: 0.0398 | Grad: 51426.211\n",
      "[Epoch 18, Batch 94/100] Loss: 0.0658 | RMSE: 0.0615 | Consistency: 0.0155 | SSIM: 0.0420 | Grad: 129626.438\n",
      "[Epoch 18, Batch 95/100] Loss: 0.0654 | RMSE: 0.0616 | Consistency: 0.0151 | SSIM: 0.0370 | Grad: 138655.625\n",
      "[Epoch 18, Batch 96/100] Loss: 0.0726 | RMSE: 0.0671 | Consistency: 0.0148 | SSIM: 0.0535 | Grad: 154188.547\n",
      "[Epoch 18, Batch 97/100] Loss: 0.0675 | RMSE: 0.0627 | Consistency: 0.0148 | SSIM: 0.0470 | Grad: 53894.348\n",
      "[Epoch 18, Batch 98/100] Loss: 0.0745 | RMSE: 0.0700 | Consistency: 0.0184 | SSIM: 0.0425 | Grad: 166278.312\n",
      "[Epoch 18, Batch 99/100] Loss: 0.0822 | RMSE: 0.0759 | Consistency: 0.0305 | SSIM: 0.0591 | Grad: 126737.617\n",
      "[Epoch 18, Batch 100/100] Loss: 0.0782 | RMSE: 0.0728 | Consistency: 0.0314 | SSIM: 0.0506 | Grad: 123512.844\n",
      "✅ Epoch 18 완료!\n",
      "   📈 평균 Loss: 0.063742\n",
      "   📊 평균 RMSE: 0.059356\n",
      "   ⚙️  학습률: 0.000953\n",
      "   🏆 NEW BEST! RMSE: 0.059356\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 19/80 시작...\n",
      "[Epoch 19, Batch 1/100] Loss: 0.0774 | RMSE: 0.0717 | Consistency: 0.0265 | SSIM: 0.0546 | Grad: 105189.156\n",
      "[Epoch 19, Batch 2/100] Loss: 0.0651 | RMSE: 0.0606 | Consistency: 0.0206 | SSIM: 0.0426 | Grad: 142666.234\n",
      "[Epoch 19, Batch 3/100] Loss: 0.0681 | RMSE: 0.0634 | Consistency: 0.0193 | SSIM: 0.0443 | Grad: 111354.266\n",
      "[Epoch 19, Batch 4/100] Loss: 0.0823 | RMSE: 0.0763 | Consistency: 0.0268 | SSIM: 0.0581 | Grad: 186309.625\n",
      "[Epoch 19, Batch 5/100] Loss: 0.0705 | RMSE: 0.0663 | Consistency: 0.0160 | SSIM: 0.0406 | Grad: 192266.312\n",
      "[Epoch 19, Batch 6/100] Loss: 0.0687 | RMSE: 0.0639 | Consistency: 0.0188 | SSIM: 0.0465 | Grad: 105099.023\n",
      "[Epoch 19, Batch 7/100] Loss: 0.0725 | RMSE: 0.0675 | Consistency: 0.0290 | SSIM: 0.0472 | Grad: 120537.211\n",
      "[Epoch 19, Batch 8/100] Loss: 0.0653 | RMSE: 0.0608 | Consistency: 0.0161 | SSIM: 0.0427 | Grad: 170194.609\n",
      "[Epoch 19, Batch 9/100] Loss: 0.0661 | RMSE: 0.0607 | Consistency: 0.0162 | SSIM: 0.0523 | Grad: 149206.203\n",
      "[Epoch 19, Batch 10/100] Loss: 0.0607 | RMSE: 0.0567 | Consistency: 0.0192 | SSIM: 0.0383 | Grad: 98647.914\n",
      "[Epoch 19, Batch 11/100] Loss: 0.0543 | RMSE: 0.0507 | Consistency: 0.0112 | SSIM: 0.0349 | Grad: 43533.039\n",
      "[Epoch 19, Batch 12/100] Loss: 0.0693 | RMSE: 0.0647 | Consistency: 0.0248 | SSIM: 0.0431 | Grad: 176876.500\n",
      "[Epoch 19, Batch 13/100] Loss: 0.0793 | RMSE: 0.0739 | Consistency: 0.0323 | SSIM: 0.0502 | Grad: 186198.234\n",
      "[Epoch 19, Batch 14/100] Loss: 0.0828 | RMSE: 0.0768 | Consistency: 0.0300 | SSIM: 0.0579 | Grad: 85258.820\n",
      "[Epoch 19, Batch 15/100] Loss: 0.0668 | RMSE: 0.0618 | Consistency: 0.0182 | SSIM: 0.0484 | Grad: 71003.570\n",
      "[Epoch 19, Batch 16/100] Loss: 0.0645 | RMSE: 0.0601 | Consistency: 0.0181 | SSIM: 0.0420 | Grad: 122224.641\n",
      "[Epoch 19, Batch 17/100] Loss: 0.0669 | RMSE: 0.0626 | Consistency: 0.0166 | SSIM: 0.0411 | Grad: 103224.422\n",
      "[Epoch 19, Batch 18/100] Loss: 0.0587 | RMSE: 0.0544 | Consistency: 0.0145 | SSIM: 0.0412 | Grad: 60867.449\n",
      "[Epoch 19, Batch 19/100] Loss: 0.0567 | RMSE: 0.0527 | Consistency: 0.0148 | SSIM: 0.0386 | Grad: 117981.406\n",
      "[Epoch 19, Batch 20/100] Loss: 0.0627 | RMSE: 0.0584 | Consistency: 0.0166 | SSIM: 0.0409 | Grad: 119982.367\n",
      "[Epoch 19, Batch 21/100] Loss: 0.0683 | RMSE: 0.0637 | Consistency: 0.0142 | SSIM: 0.0443 | Grad: 171538.062\n",
      "[Epoch 19, Batch 22/100] Loss: 0.0623 | RMSE: 0.0584 | Consistency: 0.0141 | SSIM: 0.0375 | Grad: 105940.188\n",
      "[Epoch 19, Batch 23/100] Loss: 0.0566 | RMSE: 0.0522 | Consistency: 0.0155 | SSIM: 0.0421 | Grad: 107523.055\n",
      "[Epoch 19, Batch 24/100] Loss: 0.0572 | RMSE: 0.0537 | Consistency: 0.0146 | SSIM: 0.0340 | Grad: 130719.875\n",
      "[Epoch 19, Batch 25/100] Loss: 0.0619 | RMSE: 0.0573 | Consistency: 0.0164 | SSIM: 0.0438 | Grad: 122505.094\n",
      "[Epoch 19, Batch 26/100] Loss: 0.0630 | RMSE: 0.0588 | Consistency: 0.0159 | SSIM: 0.0413 | Grad: 60739.324\n",
      "[Epoch 19, Batch 27/100] Loss: 0.0537 | RMSE: 0.0498 | Consistency: 0.0130 | SSIM: 0.0376 | Grad: 34648.453\n",
      "[Epoch 19, Batch 28/100] Loss: 0.0728 | RMSE: 0.0683 | Consistency: 0.0187 | SSIM: 0.0434 | Grad: 191960.141\n",
      "[Epoch 19, Batch 29/100] Loss: 0.0826 | RMSE: 0.0774 | Consistency: 0.0280 | SSIM: 0.0496 | Grad: 213178.672\n",
      "[Epoch 19, Batch 30/100] Loss: 0.0610 | RMSE: 0.0567 | Consistency: 0.0168 | SSIM: 0.0416 | Grad: 127789.328\n",
      "[Epoch 19, Batch 31/100] Loss: 0.0653 | RMSE: 0.0603 | Consistency: 0.0186 | SSIM: 0.0479 | Grad: 60758.832\n",
      "[Epoch 19, Batch 32/100] Loss: 0.0572 | RMSE: 0.0531 | Consistency: 0.0145 | SSIM: 0.0391 | Grad: 36365.688\n",
      "[Epoch 19, Batch 33/100] Loss: 0.0627 | RMSE: 0.0582 | Consistency: 0.0155 | SSIM: 0.0438 | Grad: 131621.234\n",
      "[Epoch 19, Batch 34/100] Loss: 0.0668 | RMSE: 0.0621 | Consistency: 0.0220 | SSIM: 0.0455 | Grad: 114451.078\n",
      "[Epoch 19, Batch 35/100] Loss: 0.0615 | RMSE: 0.0566 | Consistency: 0.0182 | SSIM: 0.0474 | Grad: 51579.094\n",
      "[Epoch 19, Batch 36/100] Loss: 0.0634 | RMSE: 0.0584 | Consistency: 0.0179 | SSIM: 0.0485 | Grad: 37938.645\n",
      "[Epoch 19, Batch 37/100] Loss: 0.0631 | RMSE: 0.0584 | Consistency: 0.0193 | SSIM: 0.0452 | Grad: 45801.387\n",
      "[Epoch 19, Batch 38/100] Loss: 0.0621 | RMSE: 0.0579 | Consistency: 0.0164 | SSIM: 0.0409 | Grad: 87075.914\n",
      "[Epoch 19, Batch 39/100] Loss: 0.0633 | RMSE: 0.0584 | Consistency: 0.0168 | SSIM: 0.0470 | Grad: 97514.633\n",
      "[Epoch 19, Batch 40/100] Loss: 0.0632 | RMSE: 0.0585 | Consistency: 0.0168 | SSIM: 0.0453 | Grad: 84801.477\n",
      "[Epoch 19, Batch 41/100] Loss: 0.0627 | RMSE: 0.0583 | Consistency: 0.0185 | SSIM: 0.0426 | Grad: 115060.031\n",
      "[Epoch 19, Batch 42/100] Loss: 0.0704 | RMSE: 0.0647 | Consistency: 0.0209 | SSIM: 0.0549 | Grad: 134155.719\n",
      "[Epoch 19, Batch 43/100] Loss: 0.0642 | RMSE: 0.0597 | Consistency: 0.0177 | SSIM: 0.0432 | Grad: 109654.656\n",
      "[Epoch 19, Batch 44/100] Loss: 0.0601 | RMSE: 0.0557 | Consistency: 0.0152 | SSIM: 0.0428 | Grad: 101693.938\n",
      "[Epoch 19, Batch 45/100] Loss: 0.0620 | RMSE: 0.0571 | Consistency: 0.0173 | SSIM: 0.0473 | Grad: 78652.227\n",
      "[Epoch 19, Batch 46/100] Loss: 0.0660 | RMSE: 0.0606 | Consistency: 0.0138 | SSIM: 0.0523 | Grad: 112540.883\n",
      "[Epoch 19, Batch 47/100] Loss: 0.0702 | RMSE: 0.0652 | Consistency: 0.0181 | SSIM: 0.0482 | Grad: 121105.266\n",
      "[Epoch 19, Batch 48/100] Loss: 0.0599 | RMSE: 0.0556 | Consistency: 0.0139 | SSIM: 0.0412 | Grad: 150574.688\n",
      "[Epoch 19, Batch 49/100] Loss: 0.0550 | RMSE: 0.0504 | Consistency: 0.0137 | SSIM: 0.0439 | Grad: 106193.797\n",
      "[Epoch 19, Batch 50/100] Loss: 0.0577 | RMSE: 0.0536 | Consistency: 0.0145 | SSIM: 0.0397 | Grad: 106945.430\n",
      "[Epoch 19, Batch 51/100] Loss: 0.0621 | RMSE: 0.0575 | Consistency: 0.0150 | SSIM: 0.0443 | Grad: 104732.797\n",
      "[Epoch 19, Batch 52/100] Loss: 0.0553 | RMSE: 0.0507 | Consistency: 0.0147 | SSIM: 0.0451 | Grad: 75965.914\n",
      "[Epoch 19, Batch 53/100] Loss: 0.0623 | RMSE: 0.0576 | Consistency: 0.0166 | SSIM: 0.0449 | Grad: 78157.516\n",
      "[Epoch 19, Batch 54/100] Loss: 0.0686 | RMSE: 0.0642 | Consistency: 0.0192 | SSIM: 0.0425 | Grad: 151720.156\n",
      "[Epoch 19, Batch 55/100] Loss: 0.0615 | RMSE: 0.0570 | Consistency: 0.0176 | SSIM: 0.0431 | Grad: 37132.527\n",
      "[Epoch 19, Batch 56/100] Loss: 0.0615 | RMSE: 0.0569 | Consistency: 0.0187 | SSIM: 0.0441 | Grad: 133809.953\n",
      "[Epoch 19, Batch 57/100] Loss: 0.0598 | RMSE: 0.0564 | Consistency: 0.0188 | SSIM: 0.0320 | Grad: 90654.484\n",
      "[Epoch 19, Batch 58/100] Loss: 0.0576 | RMSE: 0.0546 | Consistency: 0.0114 | SSIM: 0.0295 | Grad: 128805.156\n",
      "[Epoch 19, Batch 59/100] Loss: 0.0682 | RMSE: 0.0628 | Consistency: 0.0192 | SSIM: 0.0521 | Grad: 60613.805\n",
      "[Epoch 19, Batch 60/100] Loss: 0.0659 | RMSE: 0.0613 | Consistency: 0.0224 | SSIM: 0.0433 | Grad: 118323.484\n",
      "[Epoch 19, Batch 61/100] Loss: 0.0562 | RMSE: 0.0519 | Consistency: 0.0155 | SSIM: 0.0414 | Grad: 85644.430\n",
      "[Epoch 19, Batch 62/100] Loss: 0.0682 | RMSE: 0.0635 | Consistency: 0.0189 | SSIM: 0.0447 | Grad: 67278.219\n",
      "[Epoch 19, Batch 63/100] Loss: 0.0616 | RMSE: 0.0573 | Consistency: 0.0226 | SSIM: 0.0415 | Grad: 113101.727\n",
      "[Epoch 19, Batch 64/100] Loss: 0.0628 | RMSE: 0.0582 | Consistency: 0.0177 | SSIM: 0.0440 | Grad: 61239.219\n",
      "[Epoch 19, Batch 65/100] Loss: 0.0666 | RMSE: 0.0624 | Consistency: 0.0209 | SSIM: 0.0399 | Grad: 115128.336\n",
      "[Epoch 19, Batch 66/100] Loss: 0.0658 | RMSE: 0.0608 | Consistency: 0.0222 | SSIM: 0.0470 | Grad: 122031.070\n",
      "[Epoch 19, Batch 67/100] Loss: 0.0641 | RMSE: 0.0597 | Consistency: 0.0200 | SSIM: 0.0418 | Grad: 143241.094\n",
      "[Epoch 19, Batch 68/100] Loss: 0.0568 | RMSE: 0.0530 | Consistency: 0.0125 | SSIM: 0.0367 | Grad: 52016.430\n",
      "[Epoch 19, Batch 69/100] Loss: 0.0647 | RMSE: 0.0604 | Consistency: 0.0223 | SSIM: 0.0410 | Grad: 106160.500\n",
      "[Epoch 19, Batch 70/100] Loss: 0.0797 | RMSE: 0.0744 | Consistency: 0.0445 | SSIM: 0.0486 | Grad: 222379.203\n",
      "[Epoch 19, Batch 71/100] Loss: 0.0653 | RMSE: 0.0610 | Consistency: 0.0209 | SSIM: 0.0404 | Grad: 173337.328\n",
      "[Epoch 19, Batch 72/100] Loss: 0.0616 | RMSE: 0.0578 | Consistency: 0.0147 | SSIM: 0.0368 | Grad: 100733.211\n",
      "[Epoch 19, Batch 73/100] Loss: 0.0637 | RMSE: 0.0594 | Consistency: 0.0153 | SSIM: 0.0411 | Grad: 84917.727\n",
      "[Epoch 19, Batch 74/100] Loss: 0.0859 | RMSE: 0.0795 | Consistency: 0.0278 | SSIM: 0.0620 | Grad: 144940.641\n",
      "[Epoch 19, Batch 75/100] Loss: 0.0676 | RMSE: 0.0624 | Consistency: 0.0134 | SSIM: 0.0499 | Grad: 161750.797\n",
      "[Epoch 19, Batch 76/100] Loss: 0.0626 | RMSE: 0.0583 | Consistency: 0.0150 | SSIM: 0.0414 | Grad: 69217.031\n",
      "[Epoch 19, Batch 77/100] Loss: 0.0652 | RMSE: 0.0606 | Consistency: 0.0144 | SSIM: 0.0444 | Grad: 137718.469\n",
      "[Epoch 19, Batch 78/100] Loss: 0.0672 | RMSE: 0.0630 | Consistency: 0.0176 | SSIM: 0.0405 | Grad: 106623.461\n",
      "[Epoch 19, Batch 79/100] Loss: 0.0531 | RMSE: 0.0495 | Consistency: 0.0125 | SSIM: 0.0342 | Grad: 99924.805\n",
      "[Epoch 19, Batch 80/100] Loss: 0.0672 | RMSE: 0.0631 | Consistency: 0.0212 | SSIM: 0.0384 | Grad: 143234.391\n",
      "[Epoch 19, Batch 81/100] Loss: 0.0653 | RMSE: 0.0607 | Consistency: 0.0189 | SSIM: 0.0436 | Grad: 120163.312\n",
      "[Epoch 19, Batch 82/100] Loss: 0.0630 | RMSE: 0.0589 | Consistency: 0.0161 | SSIM: 0.0394 | Grad: 124490.391\n",
      "[Epoch 19, Batch 83/100] Loss: 0.0693 | RMSE: 0.0650 | Consistency: 0.0172 | SSIM: 0.0418 | Grad: 158262.000\n",
      "[Epoch 19, Batch 84/100] Loss: 0.0584 | RMSE: 0.0542 | Consistency: 0.0126 | SSIM: 0.0400 | Grad: 135984.234\n",
      "[Epoch 19, Batch 85/100] Loss: 0.0563 | RMSE: 0.0526 | Consistency: 0.0142 | SSIM: 0.0353 | Grad: 60063.449\n",
      "[Epoch 19, Batch 86/100] Loss: 0.0644 | RMSE: 0.0602 | Consistency: 0.0149 | SSIM: 0.0411 | Grad: 87294.680\n",
      "[Epoch 19, Batch 87/100] Loss: 0.0545 | RMSE: 0.0502 | Consistency: 0.0152 | SSIM: 0.0415 | Grad: 76221.273\n",
      "[Epoch 19, Batch 88/100] Loss: 0.0624 | RMSE: 0.0583 | Consistency: 0.0137 | SSIM: 0.0395 | Grad: 122819.195\n",
      "[Epoch 19, Batch 89/100] Loss: 0.0676 | RMSE: 0.0629 | Consistency: 0.0184 | SSIM: 0.0452 | Grad: 29034.721\n",
      "[Epoch 19, Batch 90/100] Loss: 0.0513 | RMSE: 0.0483 | Consistency: 0.0116 | SSIM: 0.0290 | Grad: 68864.359\n",
      "[Epoch 19, Batch 91/100] Loss: 0.0589 | RMSE: 0.0548 | Consistency: 0.0172 | SSIM: 0.0386 | Grad: 114464.102\n",
      "[Epoch 19, Batch 92/100] Loss: 0.0738 | RMSE: 0.0696 | Consistency: 0.0253 | SSIM: 0.0388 | Grad: 100505.141\n",
      "[Epoch 19, Batch 93/100] Loss: 0.0613 | RMSE: 0.0572 | Consistency: 0.0206 | SSIM: 0.0390 | Grad: 51326.297\n",
      "[Epoch 19, Batch 94/100] Loss: 0.0611 | RMSE: 0.0569 | Consistency: 0.0183 | SSIM: 0.0402 | Grad: 156992.781\n",
      "[Epoch 19, Batch 95/100] Loss: 0.0708 | RMSE: 0.0653 | Consistency: 0.0239 | SSIM: 0.0534 | Grad: 163494.719\n",
      "[Epoch 19, Batch 96/100] Loss: 0.0675 | RMSE: 0.0624 | Consistency: 0.0244 | SSIM: 0.0482 | Grad: 123635.977\n",
      "[Epoch 19, Batch 97/100] Loss: 0.0561 | RMSE: 0.0514 | Consistency: 0.0139 | SSIM: 0.0458 | Grad: 58741.195\n",
      "[Epoch 19, Batch 98/100] Loss: 0.0663 | RMSE: 0.0615 | Consistency: 0.0201 | SSIM: 0.0465 | Grad: 129960.656\n",
      "[Epoch 19, Batch 99/100] Loss: 0.0670 | RMSE: 0.0625 | Consistency: 0.0194 | SSIM: 0.0427 | Grad: 104056.109\n",
      "[Epoch 19, Batch 100/100] Loss: 0.0652 | RMSE: 0.0613 | Consistency: 0.0150 | SSIM: 0.0376 | Grad: 122299.492\n",
      "✅ Epoch 19 완료!\n",
      "   📈 평균 Loss: 0.064441\n",
      "   📊 평균 RMSE: 0.059927\n",
      "   ⚙️  학습률: 0.000943\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 20/80 시작...\n",
      "[Epoch 20, Batch 1/100] Loss: 0.0507 | RMSE: 0.0466 | Consistency: 0.0109 | SSIM: 0.0398 | Grad: 103957.906\n",
      "[Epoch 20, Batch 2/100] Loss: 0.0611 | RMSE: 0.0572 | Consistency: 0.0176 | SSIM: 0.0380 | Grad: 127799.484\n",
      "[Epoch 20, Batch 3/100] Loss: 0.0635 | RMSE: 0.0591 | Consistency: 0.0170 | SSIM: 0.0422 | Grad: 26558.381\n",
      "[Epoch 20, Batch 4/100] Loss: 0.0688 | RMSE: 0.0644 | Consistency: 0.0257 | SSIM: 0.0415 | Grad: 133615.078\n",
      "[Epoch 20, Batch 5/100] Loss: 0.0704 | RMSE: 0.0655 | Consistency: 0.0262 | SSIM: 0.0463 | Grad: 124960.297\n",
      "[Epoch 20, Batch 6/100] Loss: 0.0672 | RMSE: 0.0630 | Consistency: 0.0183 | SSIM: 0.0407 | Grad: 69555.117\n",
      "[Epoch 20, Batch 7/100] Loss: 0.0712 | RMSE: 0.0660 | Consistency: 0.0215 | SSIM: 0.0495 | Grad: 117918.914\n",
      "[Epoch 20, Batch 8/100] Loss: 0.0728 | RMSE: 0.0676 | Consistency: 0.0222 | SSIM: 0.0496 | Grad: 142776.406\n",
      "[Epoch 20, Batch 9/100] Loss: 0.0691 | RMSE: 0.0639 | Consistency: 0.0214 | SSIM: 0.0499 | Grad: 126261.758\n",
      "[Epoch 20, Batch 10/100] Loss: 0.0660 | RMSE: 0.0620 | Consistency: 0.0184 | SSIM: 0.0384 | Grad: 67244.023\n",
      "[Epoch 20, Batch 11/100] Loss: 0.0817 | RMSE: 0.0755 | Consistency: 0.0385 | SSIM: 0.0578 | Grad: 194173.453\n",
      "[Epoch 20, Batch 12/100] Loss: 0.0939 | RMSE: 0.0870 | Consistency: 0.0577 | SSIM: 0.0630 | Grad: 196844.562\n",
      "[Epoch 20, Batch 13/100] Loss: 0.0686 | RMSE: 0.0640 | Consistency: 0.0245 | SSIM: 0.0433 | Grad: 120282.195\n",
      "[Epoch 20, Batch 14/100] Loss: 0.0651 | RMSE: 0.0607 | Consistency: 0.0168 | SSIM: 0.0427 | Grad: 72488.805\n",
      "[Epoch 20, Batch 15/100] Loss: 0.0632 | RMSE: 0.0592 | Consistency: 0.0136 | SSIM: 0.0381 | Grad: 82122.023\n",
      "[Epoch 20, Batch 16/100] Loss: 0.0696 | RMSE: 0.0652 | Consistency: 0.0199 | SSIM: 0.0423 | Grad: 122729.305\n",
      "[Epoch 20, Batch 17/100] Loss: 0.0577 | RMSE: 0.0536 | Consistency: 0.0122 | SSIM: 0.0403 | Grad: 106889.891\n",
      "[Epoch 20, Batch 18/100] Loss: 0.0560 | RMSE: 0.0514 | Consistency: 0.0147 | SSIM: 0.0445 | Grad: 136986.109\n",
      "[Epoch 20, Batch 19/100] Loss: 0.0774 | RMSE: 0.0721 | Consistency: 0.0171 | SSIM: 0.0507 | Grad: 161794.594\n",
      "[Epoch 20, Batch 20/100] Loss: 0.0679 | RMSE: 0.0635 | Consistency: 0.0142 | SSIM: 0.0422 | Grad: 136279.656\n",
      "[Epoch 20, Batch 21/100] Loss: 0.0616 | RMSE: 0.0571 | Consistency: 0.0167 | SSIM: 0.0436 | Grad: 92460.086\n",
      "[Epoch 20, Batch 22/100] Loss: 0.0592 | RMSE: 0.0552 | Consistency: 0.0145 | SSIM: 0.0391 | Grad: 139970.828\n",
      "[Epoch 20, Batch 23/100] Loss: 0.0597 | RMSE: 0.0559 | Consistency: 0.0143 | SSIM: 0.0366 | Grad: 108561.023\n",
      "[Epoch 20, Batch 24/100] Loss: 0.0678 | RMSE: 0.0625 | Consistency: 0.0254 | SSIM: 0.0501 | Grad: 70184.586\n",
      "[Epoch 20, Batch 25/100] Loss: 0.0511 | RMSE: 0.0469 | Consistency: 0.0137 | SSIM: 0.0400 | Grad: 71397.836\n",
      "[Epoch 20, Batch 26/100] Loss: 0.0639 | RMSE: 0.0600 | Consistency: 0.0209 | SSIM: 0.0366 | Grad: 116055.031\n",
      "[Epoch 20, Batch 27/100] Loss: 0.0555 | RMSE: 0.0524 | Consistency: 0.0149 | SSIM: 0.0301 | Grad: 108959.133\n",
      "[Epoch 20, Batch 28/100] Loss: 0.0579 | RMSE: 0.0547 | Consistency: 0.0139 | SSIM: 0.0305 | Grad: 111500.789\n",
      "[Epoch 20, Batch 29/100] Loss: 0.0619 | RMSE: 0.0583 | Consistency: 0.0129 | SSIM: 0.0342 | Grad: 56496.273\n",
      "[Epoch 20, Batch 30/100] Loss: 0.0717 | RMSE: 0.0671 | Consistency: 0.0258 | SSIM: 0.0438 | Grad: 96453.008\n",
      "[Epoch 20, Batch 31/100] Loss: 0.0598 | RMSE: 0.0557 | Consistency: 0.0124 | SSIM: 0.0395 | Grad: 66757.188\n",
      "[Epoch 20, Batch 32/100] Loss: 0.0479 | RMSE: 0.0448 | Consistency: 0.0103 | SSIM: 0.0298 | Grad: 60524.586\n",
      "[Epoch 20, Batch 33/100] Loss: 0.0532 | RMSE: 0.0496 | Consistency: 0.0110 | SSIM: 0.0353 | Grad: 84215.422\n",
      "[Epoch 20, Batch 34/100] Loss: 0.0576 | RMSE: 0.0539 | Consistency: 0.0166 | SSIM: 0.0348 | Grad: 98743.656\n",
      "[Epoch 20, Batch 35/100] Loss: 0.0463 | RMSE: 0.0433 | Consistency: 0.0104 | SSIM: 0.0293 | Grad: 50255.957\n",
      "[Epoch 20, Batch 36/100] Loss: 0.0582 | RMSE: 0.0542 | Consistency: 0.0149 | SSIM: 0.0383 | Grad: 121176.914\n",
      "[Epoch 20, Batch 37/100] Loss: 0.0646 | RMSE: 0.0609 | Consistency: 0.0214 | SSIM: 0.0350 | Grad: 81565.305\n",
      "[Epoch 20, Batch 38/100] Loss: 0.0620 | RMSE: 0.0581 | Consistency: 0.0157 | SSIM: 0.0381 | Grad: 78089.922\n",
      "[Epoch 20, Batch 39/100] Loss: 0.0644 | RMSE: 0.0601 | Consistency: 0.0177 | SSIM: 0.0413 | Grad: 133581.578\n",
      "[Epoch 20, Batch 40/100] Loss: 0.0725 | RMSE: 0.0674 | Consistency: 0.0205 | SSIM: 0.0493 | Grad: 113707.625\n",
      "[Epoch 20, Batch 41/100] Loss: 0.0543 | RMSE: 0.0507 | Consistency: 0.0128 | SSIM: 0.0350 | Grad: 96520.219\n",
      "[Epoch 20, Batch 42/100] Loss: 0.0718 | RMSE: 0.0675 | Consistency: 0.0248 | SSIM: 0.0401 | Grad: 77810.273\n",
      "[Epoch 20, Batch 43/100] Loss: 0.0679 | RMSE: 0.0633 | Consistency: 0.0176 | SSIM: 0.0441 | Grad: 114057.406\n",
      "[Epoch 20, Batch 44/100] Loss: 0.0595 | RMSE: 0.0556 | Consistency: 0.0159 | SSIM: 0.0379 | Grad: 64415.805\n",
      "[Epoch 20, Batch 45/100] Loss: 0.0568 | RMSE: 0.0533 | Consistency: 0.0129 | SSIM: 0.0337 | Grad: 113125.773\n",
      "[Epoch 20, Batch 46/100] Loss: 0.0676 | RMSE: 0.0639 | Consistency: 0.0129 | SSIM: 0.0364 | Grad: 166227.656\n",
      "[Epoch 20, Batch 47/100] Loss: 0.0576 | RMSE: 0.0535 | Consistency: 0.0136 | SSIM: 0.0401 | Grad: 61495.652\n",
      "[Epoch 20, Batch 48/100] Loss: 0.0529 | RMSE: 0.0489 | Consistency: 0.0114 | SSIM: 0.0390 | Grad: 82773.492\n",
      "[Epoch 20, Batch 49/100] Loss: 0.0672 | RMSE: 0.0628 | Consistency: 0.0159 | SSIM: 0.0424 | Grad: 148328.594\n",
      "[Epoch 20, Batch 50/100] Loss: 0.0535 | RMSE: 0.0502 | Consistency: 0.0153 | SSIM: 0.0312 | Grad: 68776.305\n",
      "[Epoch 20, Batch 51/100] Loss: 0.0521 | RMSE: 0.0485 | Consistency: 0.0121 | SSIM: 0.0343 | Grad: 45531.766\n",
      "[Epoch 20, Batch 52/100] Loss: 0.0567 | RMSE: 0.0525 | Consistency: 0.0153 | SSIM: 0.0398 | Grad: 111351.898\n",
      "[Epoch 20, Batch 53/100] Loss: 0.0576 | RMSE: 0.0536 | Consistency: 0.0172 | SSIM: 0.0381 | Grad: 90402.102\n",
      "[Epoch 20, Batch 54/100] Loss: 0.0588 | RMSE: 0.0549 | Consistency: 0.0181 | SSIM: 0.0368 | Grad: 58698.746\n",
      "[Epoch 20, Batch 55/100] Loss: 0.0586 | RMSE: 0.0549 | Consistency: 0.0128 | SSIM: 0.0352 | Grad: 62000.453\n",
      "[Epoch 20, Batch 56/100] Loss: 0.0596 | RMSE: 0.0551 | Consistency: 0.0150 | SSIM: 0.0438 | Grad: 128953.617\n",
      "[Epoch 20, Batch 57/100] Loss: 0.0785 | RMSE: 0.0729 | Consistency: 0.0212 | SSIM: 0.0533 | Grad: 164420.719\n",
      "[Epoch 20, Batch 58/100] Loss: 0.0658 | RMSE: 0.0608 | Consistency: 0.0166 | SSIM: 0.0481 | Grad: 141522.969\n",
      "[Epoch 20, Batch 59/100] Loss: 0.0553 | RMSE: 0.0514 | Consistency: 0.0123 | SSIM: 0.0373 | Grad: 71975.406\n",
      "[Epoch 20, Batch 60/100] Loss: 0.0545 | RMSE: 0.0504 | Consistency: 0.0141 | SSIM: 0.0400 | Grad: 104338.875\n",
      "[Epoch 20, Batch 61/100] Loss: 0.0665 | RMSE: 0.0615 | Consistency: 0.0195 | SSIM: 0.0489 | Grad: 89199.453\n",
      "[Epoch 20, Batch 62/100] Loss: 0.0542 | RMSE: 0.0501 | Consistency: 0.0141 | SSIM: 0.0397 | Grad: 55750.598\n",
      "[Epoch 20, Batch 63/100] Loss: 0.0637 | RMSE: 0.0584 | Consistency: 0.0152 | SSIM: 0.0507 | Grad: 84165.984\n",
      "[Epoch 20, Batch 64/100] Loss: 0.0637 | RMSE: 0.0591 | Consistency: 0.0208 | SSIM: 0.0443 | Grad: 111484.922\n",
      "[Epoch 20, Batch 65/100] Loss: 0.0522 | RMSE: 0.0480 | Consistency: 0.0098 | SSIM: 0.0417 | Grad: 51261.137\n",
      "[Epoch 20, Batch 66/100] Loss: 0.0606 | RMSE: 0.0563 | Consistency: 0.0162 | SSIM: 0.0409 | Grad: 124508.383\n",
      "[Epoch 20, Batch 67/100] Loss: 0.0688 | RMSE: 0.0642 | Consistency: 0.0207 | SSIM: 0.0442 | Grad: 137639.250\n",
      "[Epoch 20, Batch 68/100] Loss: 0.0653 | RMSE: 0.0614 | Consistency: 0.0239 | SSIM: 0.0373 | Grad: 171854.484\n",
      "[Epoch 20, Batch 69/100] Loss: 0.0597 | RMSE: 0.0554 | Consistency: 0.0155 | SSIM: 0.0417 | Grad: 112813.898\n",
      "[Epoch 20, Batch 70/100] Loss: 0.0705 | RMSE: 0.0650 | Consistency: 0.0242 | SSIM: 0.0518 | Grad: 85157.516\n",
      "[Epoch 20, Batch 71/100] Loss: 0.0670 | RMSE: 0.0627 | Consistency: 0.0200 | SSIM: 0.0414 | Grad: 105272.844\n",
      "[Epoch 20, Batch 72/100] Loss: 0.0732 | RMSE: 0.0687 | Consistency: 0.0224 | SSIM: 0.0429 | Grad: 146155.375\n",
      "[Epoch 20, Batch 73/100] Loss: 0.0719 | RMSE: 0.0671 | Consistency: 0.0163 | SSIM: 0.0464 | Grad: 137925.906\n",
      "[Epoch 20, Batch 74/100] Loss: 0.0589 | RMSE: 0.0543 | Consistency: 0.0150 | SSIM: 0.0445 | Grad: 127256.836\n",
      "[Epoch 20, Batch 75/100] Loss: 0.0561 | RMSE: 0.0526 | Consistency: 0.0143 | SSIM: 0.0330 | Grad: 119262.297\n",
      "[Epoch 20, Batch 76/100] Loss: 0.0620 | RMSE: 0.0577 | Consistency: 0.0165 | SSIM: 0.0412 | Grad: 122833.414\n",
      "[Epoch 20, Batch 77/100] Loss: 0.0569 | RMSE: 0.0532 | Consistency: 0.0126 | SSIM: 0.0359 | Grad: 105780.758\n",
      "[Epoch 20, Batch 78/100] Loss: 0.0690 | RMSE: 0.0649 | Consistency: 0.0161 | SSIM: 0.0391 | Grad: 139921.578\n",
      "[Epoch 20, Batch 79/100] Loss: 0.0638 | RMSE: 0.0601 | Consistency: 0.0144 | SSIM: 0.0358 | Grad: 133954.672\n",
      "[Epoch 20, Batch 80/100] Loss: 0.0591 | RMSE: 0.0553 | Consistency: 0.0151 | SSIM: 0.0373 | Grad: 121046.844\n",
      "[Epoch 20, Batch 81/100] Loss: 0.0536 | RMSE: 0.0497 | Consistency: 0.0106 | SSIM: 0.0373 | Grad: 136049.000\n",
      "[Epoch 20, Batch 82/100] Loss: 0.0618 | RMSE: 0.0574 | Consistency: 0.0149 | SSIM: 0.0429 | Grad: 136244.484\n",
      "[Epoch 20, Batch 83/100] Loss: 0.0675 | RMSE: 0.0634 | Consistency: 0.0186 | SSIM: 0.0387 | Grad: 147732.750\n",
      "[Epoch 20, Batch 84/100] Loss: 0.0643 | RMSE: 0.0602 | Consistency: 0.0145 | SSIM: 0.0397 | Grad: 151611.641\n",
      "[Epoch 20, Batch 85/100] Loss: 0.0673 | RMSE: 0.0630 | Consistency: 0.0138 | SSIM: 0.0421 | Grad: 168547.188\n",
      "[Epoch 20, Batch 86/100] Loss: 0.0702 | RMSE: 0.0658 | Consistency: 0.0190 | SSIM: 0.0418 | Grad: 165591.500\n",
      "[Epoch 20, Batch 87/100] Loss: 0.0573 | RMSE: 0.0528 | Consistency: 0.0143 | SSIM: 0.0431 | Grad: 130935.359\n",
      "[Epoch 20, Batch 88/100] Loss: 0.0490 | RMSE: 0.0456 | Consistency: 0.0104 | SSIM: 0.0333 | Grad: 57290.328\n",
      "[Epoch 20, Batch 89/100] Loss: 0.0597 | RMSE: 0.0561 | Consistency: 0.0168 | SSIM: 0.0346 | Grad: 166778.469\n",
      "[Epoch 20, Batch 90/100] Loss: 0.0699 | RMSE: 0.0660 | Consistency: 0.0188 | SSIM: 0.0379 | Grad: 192043.938\n",
      "[Epoch 20, Batch 91/100] Loss: 0.0649 | RMSE: 0.0605 | Consistency: 0.0163 | SSIM: 0.0428 | Grad: 152998.719\n",
      "[Epoch 20, Batch 92/100] Loss: 0.0615 | RMSE: 0.0575 | Consistency: 0.0138 | SSIM: 0.0385 | Grad: 54117.172\n",
      "[Epoch 20, Batch 93/100] Loss: 0.0550 | RMSE: 0.0509 | Consistency: 0.0141 | SSIM: 0.0390 | Grad: 150173.984\n",
      "[Epoch 20, Batch 94/100] Loss: 0.0558 | RMSE: 0.0519 | Consistency: 0.0123 | SSIM: 0.0372 | Grad: 91603.109\n",
      "[Epoch 20, Batch 95/100] Loss: 0.0549 | RMSE: 0.0512 | Consistency: 0.0126 | SSIM: 0.0364 | Grad: 49191.051\n",
      "[Epoch 20, Batch 96/100] Loss: 0.0625 | RMSE: 0.0583 | Consistency: 0.0182 | SSIM: 0.0408 | Grad: 90532.820\n",
      "[Epoch 20, Batch 97/100] Loss: 0.0549 | RMSE: 0.0517 | Consistency: 0.0124 | SSIM: 0.0312 | Grad: 106394.008\n",
      "[Epoch 20, Batch 98/100] Loss: 0.0530 | RMSE: 0.0492 | Consistency: 0.0120 | SSIM: 0.0366 | Grad: 114001.242\n",
      "[Epoch 20, Batch 99/100] Loss: 0.0500 | RMSE: 0.0463 | Consistency: 0.0114 | SSIM: 0.0360 | Grad: 109920.711\n",
      "[Epoch 20, Batch 100/100] Loss: 0.0601 | RMSE: 0.0560 | Consistency: 0.0131 | SSIM: 0.0400 | Grad: 139548.188\n",
      "✅ Epoch 20 완료!\n",
      "   📈 평균 Loss: 0.062215\n",
      "   📊 평균 RMSE: 0.057995\n",
      "   ⚙️  학습률: 0.000933\n",
      "   🏆 NEW BEST! RMSE: 0.057995\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 21/80 시작...\n",
      "[Epoch 21, Batch 1/100] Loss: 0.0629 | RMSE: 0.0589 | Consistency: 0.0129 | SSIM: 0.0391 | Grad: 111668.445\n",
      "[Epoch 21, Batch 2/100] Loss: 0.0621 | RMSE: 0.0582 | Consistency: 0.0113 | SSIM: 0.0382 | Grad: 38499.164\n",
      "[Epoch 21, Batch 3/100] Loss: 0.0516 | RMSE: 0.0478 | Consistency: 0.0140 | SSIM: 0.0363 | Grad: 90054.141\n",
      "[Epoch 21, Batch 4/100] Loss: 0.0706 | RMSE: 0.0658 | Consistency: 0.0247 | SSIM: 0.0457 | Grad: 159446.750\n",
      "[Epoch 21, Batch 5/100] Loss: 0.0667 | RMSE: 0.0621 | Consistency: 0.0185 | SSIM: 0.0443 | Grad: 71617.758\n",
      "[Epoch 21, Batch 6/100] Loss: 0.0669 | RMSE: 0.0629 | Consistency: 0.0184 | SSIM: 0.0388 | Grad: 72612.320\n",
      "[Epoch 21, Batch 7/100] Loss: 0.0871 | RMSE: 0.0812 | Consistency: 0.0439 | SSIM: 0.0545 | Grad: 138298.688\n",
      "[Epoch 21, Batch 8/100] Loss: 0.0818 | RMSE: 0.0767 | Consistency: 0.0391 | SSIM: 0.0472 | Grad: 192521.750\n",
      "[Epoch 21, Batch 9/100] Loss: 0.0596 | RMSE: 0.0558 | Consistency: 0.0191 | SSIM: 0.0365 | Grad: 127781.492\n",
      "[Epoch 21, Batch 10/100] Loss: 0.0515 | RMSE: 0.0476 | Consistency: 0.0137 | SSIM: 0.0368 | Grad: 44445.398\n",
      "[Epoch 21, Batch 11/100] Loss: 0.0694 | RMSE: 0.0650 | Consistency: 0.0225 | SSIM: 0.0419 | Grad: 144840.172\n",
      "[Epoch 21, Batch 12/100] Loss: 0.0755 | RMSE: 0.0709 | Consistency: 0.0256 | SSIM: 0.0433 | Grad: 151330.953\n",
      "[Epoch 21, Batch 13/100] Loss: 0.0581 | RMSE: 0.0542 | Consistency: 0.0145 | SSIM: 0.0373 | Grad: 49430.137\n",
      "[Epoch 21, Batch 14/100] Loss: 0.0645 | RMSE: 0.0604 | Consistency: 0.0162 | SSIM: 0.0387 | Grad: 146581.922\n",
      "[Epoch 21, Batch 15/100] Loss: 0.0659 | RMSE: 0.0609 | Consistency: 0.0166 | SSIM: 0.0481 | Grad: 107915.562\n",
      "[Epoch 21, Batch 16/100] Loss: 0.0653 | RMSE: 0.0600 | Consistency: 0.0211 | SSIM: 0.0515 | Grad: 66289.016\n",
      "[Epoch 21, Batch 17/100] Loss: 0.0632 | RMSE: 0.0589 | Consistency: 0.0140 | SSIM: 0.0418 | Grad: 146191.906\n",
      "[Epoch 21, Batch 18/100] Loss: 0.0652 | RMSE: 0.0608 | Consistency: 0.0169 | SSIM: 0.0418 | Grad: 148800.453\n",
      "[Epoch 21, Batch 19/100] Loss: 0.0649 | RMSE: 0.0601 | Consistency: 0.0219 | SSIM: 0.0461 | Grad: 127036.031\n",
      "[Epoch 21, Batch 20/100] Loss: 0.0621 | RMSE: 0.0577 | Consistency: 0.0155 | SSIM: 0.0428 | Grad: 106553.695\n",
      "[Epoch 21, Batch 21/100] Loss: 0.0658 | RMSE: 0.0614 | Consistency: 0.0175 | SSIM: 0.0423 | Grad: 128067.953\n",
      "[Epoch 21, Batch 22/100] Loss: 0.0627 | RMSE: 0.0582 | Consistency: 0.0158 | SSIM: 0.0430 | Grad: 131201.359\n",
      "[Epoch 21, Batch 23/100] Loss: 0.0570 | RMSE: 0.0531 | Consistency: 0.0166 | SSIM: 0.0367 | Grad: 99986.234\n",
      "[Epoch 21, Batch 24/100] Loss: 0.0512 | RMSE: 0.0469 | Consistency: 0.0116 | SSIM: 0.0422 | Grad: 112833.648\n",
      "[Epoch 21, Batch 25/100] Loss: 0.0672 | RMSE: 0.0629 | Consistency: 0.0249 | SSIM: 0.0413 | Grad: 131378.359\n",
      "[Epoch 21, Batch 26/100] Loss: 0.0581 | RMSE: 0.0543 | Consistency: 0.0141 | SSIM: 0.0372 | Grad: 93602.453\n",
      "[Epoch 21, Batch 27/100] Loss: 0.0647 | RMSE: 0.0610 | Consistency: 0.0173 | SSIM: 0.0347 | Grad: 122425.609\n",
      "[Epoch 21, Batch 28/100] Loss: 0.0539 | RMSE: 0.0500 | Consistency: 0.0130 | SSIM: 0.0373 | Grad: 78164.352\n",
      "[Epoch 21, Batch 29/100] Loss: 0.0691 | RMSE: 0.0646 | Consistency: 0.0191 | SSIM: 0.0430 | Grad: 180889.578\n",
      "[Epoch 21, Batch 30/100] Loss: 0.0607 | RMSE: 0.0564 | Consistency: 0.0154 | SSIM: 0.0420 | Grad: 146307.156\n",
      "[Epoch 21, Batch 31/100] Loss: 0.0567 | RMSE: 0.0527 | Consistency: 0.0134 | SSIM: 0.0387 | Grad: 144393.188\n",
      "[Epoch 21, Batch 32/100] Loss: 0.0544 | RMSE: 0.0502 | Consistency: 0.0149 | SSIM: 0.0397 | Grad: 87496.352\n",
      "[Epoch 21, Batch 33/100] Loss: 0.0514 | RMSE: 0.0480 | Consistency: 0.0118 | SSIM: 0.0331 | Grad: 71554.641\n",
      "[Epoch 21, Batch 34/100] Loss: 0.0558 | RMSE: 0.0517 | Consistency: 0.0151 | SSIM: 0.0396 | Grad: 117962.297\n",
      "[Epoch 21, Batch 35/100] Loss: 0.0574 | RMSE: 0.0536 | Consistency: 0.0135 | SSIM: 0.0375 | Grad: 72800.812\n",
      "[Epoch 21, Batch 36/100] Loss: 0.0603 | RMSE: 0.0559 | Consistency: 0.0145 | SSIM: 0.0428 | Grad: 100608.211\n",
      "[Epoch 21, Batch 37/100] Loss: 0.0645 | RMSE: 0.0598 | Consistency: 0.0171 | SSIM: 0.0450 | Grad: 73827.289\n",
      "[Epoch 21, Batch 38/100] Loss: 0.0589 | RMSE: 0.0550 | Consistency: 0.0165 | SSIM: 0.0369 | Grad: 54934.973\n",
      "[Epoch 21, Batch 39/100] Loss: 0.0571 | RMSE: 0.0535 | Consistency: 0.0130 | SSIM: 0.0346 | Grad: 127381.336\n",
      "[Epoch 21, Batch 40/100] Loss: 0.0650 | RMSE: 0.0607 | Consistency: 0.0223 | SSIM: 0.0412 | Grad: 102408.797\n",
      "[Epoch 21, Batch 41/100] Loss: 0.0595 | RMSE: 0.0559 | Consistency: 0.0129 | SSIM: 0.0338 | Grad: 112064.930\n",
      "[Epoch 21, Batch 42/100] Loss: 0.0580 | RMSE: 0.0543 | Consistency: 0.0147 | SSIM: 0.0357 | Grad: 75568.703\n",
      "[Epoch 21, Batch 43/100] Loss: 0.0616 | RMSE: 0.0571 | Consistency: 0.0155 | SSIM: 0.0428 | Grad: 105387.188\n",
      "[Epoch 21, Batch 44/100] Loss: 0.0691 | RMSE: 0.0646 | Consistency: 0.0226 | SSIM: 0.0427 | Grad: 129062.219\n",
      "[Epoch 21, Batch 45/100] Loss: 0.0616 | RMSE: 0.0567 | Consistency: 0.0181 | SSIM: 0.0479 | Grad: 89970.914\n",
      "[Epoch 21, Batch 46/100] Loss: 0.0469 | RMSE: 0.0437 | Consistency: 0.0104 | SSIM: 0.0307 | Grad: 52672.371\n",
      "[Epoch 21, Batch 47/100] Loss: 0.0573 | RMSE: 0.0536 | Consistency: 0.0152 | SSIM: 0.0359 | Grad: 121717.156\n",
      "[Epoch 21, Batch 48/100] Loss: 0.0595 | RMSE: 0.0556 | Consistency: 0.0168 | SSIM: 0.0372 | Grad: 134820.359\n",
      "[Epoch 21, Batch 49/100] Loss: 0.0587 | RMSE: 0.0547 | Consistency: 0.0163 | SSIM: 0.0383 | Grad: 81536.984\n",
      "[Epoch 21, Batch 50/100] Loss: 0.0507 | RMSE: 0.0468 | Consistency: 0.0132 | SSIM: 0.0378 | Grad: 77004.797\n",
      "[Epoch 21, Batch 51/100] Loss: 0.0584 | RMSE: 0.0547 | Consistency: 0.0151 | SSIM: 0.0349 | Grad: 82611.805\n",
      "[Epoch 21, Batch 52/100] Loss: 0.0641 | RMSE: 0.0599 | Consistency: 0.0155 | SSIM: 0.0395 | Grad: 145528.328\n",
      "[Epoch 21, Batch 53/100] Loss: 0.0573 | RMSE: 0.0541 | Consistency: 0.0176 | SSIM: 0.0306 | Grad: 95029.539\n",
      "[Epoch 21, Batch 54/100] Loss: 0.0498 | RMSE: 0.0457 | Consistency: 0.0119 | SSIM: 0.0405 | Grad: 112988.273\n",
      "[Epoch 21, Batch 55/100] Loss: 0.0519 | RMSE: 0.0482 | Consistency: 0.0130 | SSIM: 0.0349 | Grad: 113406.969\n",
      "[Epoch 21, Batch 56/100] Loss: 0.0810 | RMSE: 0.0754 | Consistency: 0.0206 | SSIM: 0.0536 | Grad: 163851.828\n",
      "[Epoch 21, Batch 57/100] Loss: 0.0622 | RMSE: 0.0579 | Consistency: 0.0217 | SSIM: 0.0403 | Grad: 59754.176\n",
      "[Epoch 21, Batch 58/100] Loss: 0.0495 | RMSE: 0.0458 | Consistency: 0.0108 | SSIM: 0.0365 | Grad: 80912.008\n",
      "[Epoch 21, Batch 59/100] Loss: 0.0545 | RMSE: 0.0510 | Consistency: 0.0145 | SSIM: 0.0337 | Grad: 107957.625\n",
      "[Epoch 21, Batch 60/100] Loss: 0.0446 | RMSE: 0.0417 | Consistency: 0.0085 | SSIM: 0.0280 | Grad: 55941.070\n",
      "[Epoch 21, Batch 61/100] Loss: 0.0617 | RMSE: 0.0575 | Consistency: 0.0138 | SSIM: 0.0404 | Grad: 134589.109\n",
      "[Epoch 21, Batch 62/100] Loss: 0.0678 | RMSE: 0.0632 | Consistency: 0.0195 | SSIM: 0.0439 | Grad: 147546.547\n",
      "[Epoch 21, Batch 63/100] Loss: 0.0623 | RMSE: 0.0579 | Consistency: 0.0145 | SSIM: 0.0432 | Grad: 104453.492\n",
      "[Epoch 21, Batch 64/100] Loss: 0.0595 | RMSE: 0.0549 | Consistency: 0.0151 | SSIM: 0.0446 | Grad: 38625.094\n",
      "[Epoch 21, Batch 65/100] Loss: 0.0546 | RMSE: 0.0512 | Consistency: 0.0172 | SSIM: 0.0325 | Grad: 113581.656\n",
      "[Epoch 21, Batch 66/100] Loss: 0.0590 | RMSE: 0.0548 | Consistency: 0.0155 | SSIM: 0.0411 | Grad: 62136.840\n",
      "[Epoch 21, Batch 67/100] Loss: 0.0517 | RMSE: 0.0478 | Consistency: 0.0121 | SSIM: 0.0372 | Grad: 64495.676\n",
      "[Epoch 21, Batch 68/100] Loss: 0.0575 | RMSE: 0.0531 | Consistency: 0.0144 | SSIM: 0.0430 | Grad: 88804.391\n",
      "[Epoch 21, Batch 69/100] Loss: 0.0587 | RMSE: 0.0551 | Consistency: 0.0153 | SSIM: 0.0348 | Grad: 132032.484\n",
      "[Epoch 21, Batch 70/100] Loss: 0.0598 | RMSE: 0.0558 | Consistency: 0.0167 | SSIM: 0.0383 | Grad: 99740.672\n",
      "[Epoch 21, Batch 71/100] Loss: 0.0511 | RMSE: 0.0476 | Consistency: 0.0119 | SSIM: 0.0336 | Grad: 90735.352\n",
      "[Epoch 21, Batch 72/100] Loss: 0.0504 | RMSE: 0.0473 | Consistency: 0.0089 | SSIM: 0.0299 | Grad: 125608.180\n",
      "[Epoch 21, Batch 73/100] Loss: 0.0477 | RMSE: 0.0433 | Consistency: 0.0105 | SSIM: 0.0426 | Grad: 49706.539\n",
      "[Epoch 21, Batch 74/100] Loss: 0.0557 | RMSE: 0.0522 | Consistency: 0.0153 | SSIM: 0.0337 | Grad: 98592.070\n",
      "[Epoch 21, Batch 75/100] Loss: 0.0513 | RMSE: 0.0476 | Consistency: 0.0122 | SSIM: 0.0358 | Grad: 21314.100\n",
      "[Epoch 21, Batch 76/100] Loss: 0.0577 | RMSE: 0.0544 | Consistency: 0.0157 | SSIM: 0.0319 | Grad: 91996.836\n",
      "[Epoch 21, Batch 77/100] Loss: 0.0643 | RMSE: 0.0593 | Consistency: 0.0157 | SSIM: 0.0478 | Grad: 56257.660\n",
      "[Epoch 21, Batch 78/100] Loss: 0.0602 | RMSE: 0.0563 | Consistency: 0.0185 | SSIM: 0.0377 | Grad: 70147.758\n",
      "[Epoch 21, Batch 79/100] Loss: 0.0643 | RMSE: 0.0602 | Consistency: 0.0211 | SSIM: 0.0390 | Grad: 110950.414\n",
      "[Epoch 21, Batch 80/100] Loss: 0.0660 | RMSE: 0.0614 | Consistency: 0.0201 | SSIM: 0.0439 | Grad: 103259.984\n",
      "[Epoch 21, Batch 81/100] Loss: 0.0547 | RMSE: 0.0507 | Consistency: 0.0137 | SSIM: 0.0382 | Grad: 37588.555\n",
      "[Epoch 21, Batch 82/100] Loss: 0.0618 | RMSE: 0.0578 | Consistency: 0.0161 | SSIM: 0.0383 | Grad: 145331.984\n",
      "[Epoch 21, Batch 83/100] Loss: 0.0668 | RMSE: 0.0621 | Consistency: 0.0197 | SSIM: 0.0454 | Grad: 144237.531\n",
      "[Epoch 21, Batch 84/100] Loss: 0.0635 | RMSE: 0.0594 | Consistency: 0.0145 | SSIM: 0.0388 | Grad: 106423.820\n",
      "[Epoch 21, Batch 85/100] Loss: 0.0584 | RMSE: 0.0538 | Consistency: 0.0153 | SSIM: 0.0440 | Grad: 60828.641\n",
      "[Epoch 21, Batch 86/100] Loss: 0.0535 | RMSE: 0.0503 | Consistency: 0.0121 | SSIM: 0.0307 | Grad: 68829.938\n",
      "[Epoch 21, Batch 87/100] Loss: 0.0585 | RMSE: 0.0543 | Consistency: 0.0208 | SSIM: 0.0404 | Grad: 136194.453\n",
      "[Epoch 21, Batch 88/100] Loss: 0.0675 | RMSE: 0.0628 | Consistency: 0.0205 | SSIM: 0.0453 | Grad: 109740.273\n",
      "[Epoch 21, Batch 89/100] Loss: 0.0569 | RMSE: 0.0530 | Consistency: 0.0143 | SSIM: 0.0380 | Grad: 74707.125\n",
      "[Epoch 21, Batch 90/100] Loss: 0.0515 | RMSE: 0.0472 | Consistency: 0.0132 | SSIM: 0.0414 | Grad: 31199.828\n",
      "[Epoch 21, Batch 91/100] Loss: 0.0640 | RMSE: 0.0606 | Consistency: 0.0136 | SSIM: 0.0324 | Grad: 94190.180\n",
      "[Epoch 21, Batch 92/100] Loss: 0.0564 | RMSE: 0.0526 | Consistency: 0.0134 | SSIM: 0.0367 | Grad: 75378.492\n",
      "[Epoch 21, Batch 93/100] Loss: 0.0559 | RMSE: 0.0515 | Consistency: 0.0123 | SSIM: 0.0429 | Grad: 76512.344\n",
      "[Epoch 21, Batch 94/100] Loss: 0.0547 | RMSE: 0.0502 | Consistency: 0.0121 | SSIM: 0.0445 | Grad: 63387.031\n",
      "[Epoch 21, Batch 95/100] Loss: 0.0574 | RMSE: 0.0533 | Consistency: 0.0147 | SSIM: 0.0392 | Grad: 56985.988\n",
      "[Epoch 21, Batch 96/100] Loss: 0.0562 | RMSE: 0.0527 | Consistency: 0.0123 | SSIM: 0.0337 | Grad: 146496.750\n",
      "[Epoch 21, Batch 97/100] Loss: 0.0774 | RMSE: 0.0719 | Consistency: 0.0182 | SSIM: 0.0529 | Grad: 145237.484\n",
      "[Epoch 21, Batch 98/100] Loss: 0.0603 | RMSE: 0.0566 | Consistency: 0.0131 | SSIM: 0.0359 | Grad: 81812.258\n",
      "[Epoch 21, Batch 99/100] Loss: 0.0696 | RMSE: 0.0644 | Consistency: 0.0165 | SSIM: 0.0509 | Grad: 145004.188\n",
      "[Epoch 21, Batch 100/100] Loss: 0.0765 | RMSE: 0.0710 | Consistency: 0.0218 | SSIM: 0.0527 | Grad: 127512.469\n",
      "✅ Epoch 21 완료!\n",
      "   📈 평균 Loss: 0.060459\n",
      "   📊 평균 RMSE: 0.056304\n",
      "   ⚙️  학습률: 0.000922\n",
      "   🏆 NEW BEST! RMSE: 0.056304\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 22/80 시작...\n",
      "[Epoch 22, Batch 1/100] Loss: 0.0585 | RMSE: 0.0538 | Consistency: 0.0155 | SSIM: 0.0454 | Grad: 75823.664\n",
      "[Epoch 22, Batch 2/100] Loss: 0.0566 | RMSE: 0.0528 | Consistency: 0.0159 | SSIM: 0.0365 | Grad: 145511.266\n",
      "[Epoch 22, Batch 3/100] Loss: 0.0654 | RMSE: 0.0609 | Consistency: 0.0146 | SSIM: 0.0436 | Grad: 179178.703\n",
      "[Epoch 22, Batch 4/100] Loss: 0.0626 | RMSE: 0.0583 | Consistency: 0.0169 | SSIM: 0.0407 | Grad: 130934.742\n",
      "[Epoch 22, Batch 5/100] Loss: 0.0669 | RMSE: 0.0621 | Consistency: 0.0186 | SSIM: 0.0457 | Grad: 118073.867\n",
      "[Epoch 22, Batch 6/100] Loss: 0.0641 | RMSE: 0.0596 | Consistency: 0.0199 | SSIM: 0.0432 | Grad: 159678.188\n",
      "[Epoch 22, Batch 7/100] Loss: 0.0637 | RMSE: 0.0588 | Consistency: 0.0161 | SSIM: 0.0476 | Grad: 158751.188\n",
      "[Epoch 22, Batch 8/100] Loss: 0.0547 | RMSE: 0.0509 | Consistency: 0.0132 | SSIM: 0.0370 | Grad: 75616.836\n",
      "[Epoch 22, Batch 9/100] Loss: 0.0605 | RMSE: 0.0565 | Consistency: 0.0139 | SSIM: 0.0392 | Grad: 152744.891\n",
      "[Epoch 22, Batch 10/100] Loss: 0.0699 | RMSE: 0.0654 | Consistency: 0.0146 | SSIM: 0.0430 | Grad: 176175.719\n",
      "[Epoch 22, Batch 11/100] Loss: 0.0501 | RMSE: 0.0470 | Consistency: 0.0098 | SSIM: 0.0299 | Grad: 86526.141\n",
      "[Epoch 22, Batch 12/100] Loss: 0.0539 | RMSE: 0.0505 | Consistency: 0.0111 | SSIM: 0.0327 | Grad: 98337.914\n",
      "[Epoch 22, Batch 13/100] Loss: 0.0573 | RMSE: 0.0533 | Consistency: 0.0153 | SSIM: 0.0391 | Grad: 88742.891\n",
      "[Epoch 22, Batch 14/100] Loss: 0.0528 | RMSE: 0.0494 | Consistency: 0.0118 | SSIM: 0.0326 | Grad: 112570.461\n",
      "[Epoch 22, Batch 15/100] Loss: 0.0552 | RMSE: 0.0515 | Consistency: 0.0163 | SSIM: 0.0361 | Grad: 84671.539\n",
      "[Epoch 22, Batch 16/100] Loss: 0.0519 | RMSE: 0.0481 | Consistency: 0.0126 | SSIM: 0.0371 | Grad: 66370.773\n",
      "[Epoch 22, Batch 17/100] Loss: 0.0683 | RMSE: 0.0642 | Consistency: 0.0177 | SSIM: 0.0392 | Grad: 47962.875\n",
      "[Epoch 22, Batch 18/100] Loss: 0.0553 | RMSE: 0.0517 | Consistency: 0.0149 | SSIM: 0.0343 | Grad: 89104.367\n",
      "[Epoch 22, Batch 19/100] Loss: 0.0627 | RMSE: 0.0587 | Consistency: 0.0163 | SSIM: 0.0378 | Grad: 142183.531\n",
      "[Epoch 22, Batch 20/100] Loss: 0.0643 | RMSE: 0.0604 | Consistency: 0.0149 | SSIM: 0.0370 | Grad: 115862.891\n",
      "[Epoch 22, Batch 21/100] Loss: 0.0602 | RMSE: 0.0566 | Consistency: 0.0167 | SSIM: 0.0345 | Grad: 41921.926\n",
      "[Epoch 22, Batch 22/100] Loss: 0.0588 | RMSE: 0.0550 | Consistency: 0.0156 | SSIM: 0.0372 | Grad: 129626.219\n",
      "[Epoch 22, Batch 23/100] Loss: 0.0645 | RMSE: 0.0605 | Consistency: 0.0148 | SSIM: 0.0391 | Grad: 170919.984\n",
      "[Epoch 22, Batch 24/100] Loss: 0.0566 | RMSE: 0.0529 | Consistency: 0.0135 | SSIM: 0.0351 | Grad: 92699.711\n",
      "[Epoch 22, Batch 25/100] Loss: 0.0545 | RMSE: 0.0503 | Consistency: 0.0131 | SSIM: 0.0408 | Grad: 82602.102\n",
      "[Epoch 22, Batch 26/100] Loss: 0.0624 | RMSE: 0.0588 | Consistency: 0.0125 | SSIM: 0.0344 | Grad: 151124.625\n",
      "[Epoch 22, Batch 27/100] Loss: 0.0541 | RMSE: 0.0511 | Consistency: 0.0109 | SSIM: 0.0286 | Grad: 130865.984\n",
      "[Epoch 22, Batch 28/100] Loss: 0.0463 | RMSE: 0.0434 | Consistency: 0.0102 | SSIM: 0.0284 | Grad: 96888.578\n",
      "[Epoch 22, Batch 29/100] Loss: 0.0591 | RMSE: 0.0554 | Consistency: 0.0140 | SSIM: 0.0357 | Grad: 66462.789\n",
      "[Epoch 22, Batch 30/100] Loss: 0.0674 | RMSE: 0.0638 | Consistency: 0.0182 | SSIM: 0.0348 | Grad: 147790.703\n",
      "[Epoch 22, Batch 31/100] Loss: 0.0566 | RMSE: 0.0529 | Consistency: 0.0134 | SSIM: 0.0351 | Grad: 115441.781\n",
      "[Epoch 22, Batch 32/100] Loss: 0.0562 | RMSE: 0.0527 | Consistency: 0.0137 | SSIM: 0.0344 | Grad: 66609.273\n",
      "[Epoch 22, Batch 33/100] Loss: 0.0672 | RMSE: 0.0627 | Consistency: 0.0229 | SSIM: 0.0425 | Grad: 38354.180\n",
      "[Epoch 22, Batch 34/100] Loss: 0.0657 | RMSE: 0.0618 | Consistency: 0.0146 | SSIM: 0.0369 | Grad: 151981.688\n",
      "[Epoch 22, Batch 35/100] Loss: 0.0661 | RMSE: 0.0624 | Consistency: 0.0139 | SSIM: 0.0352 | Grad: 138045.391\n",
      "[Epoch 22, Batch 36/100] Loss: 0.0657 | RMSE: 0.0614 | Consistency: 0.0165 | SSIM: 0.0416 | Grad: 98456.633\n",
      "[Epoch 22, Batch 37/100] Loss: 0.0611 | RMSE: 0.0574 | Consistency: 0.0144 | SSIM: 0.0355 | Grad: 116229.422\n",
      "[Epoch 22, Batch 38/100] Loss: 0.0643 | RMSE: 0.0599 | Consistency: 0.0178 | SSIM: 0.0423 | Grad: 111207.391\n",
      "[Epoch 22, Batch 39/100] Loss: 0.0624 | RMSE: 0.0578 | Consistency: 0.0140 | SSIM: 0.0446 | Grad: 136316.172\n",
      "[Epoch 22, Batch 40/100] Loss: 0.0510 | RMSE: 0.0467 | Consistency: 0.0121 | SSIM: 0.0419 | Grad: 69476.750\n",
      "[Epoch 22, Batch 41/100] Loss: 0.0821 | RMSE: 0.0769 | Consistency: 0.0291 | SSIM: 0.0498 | Grad: 120079.242\n",
      "[Epoch 22, Batch 42/100] Loss: 0.0518 | RMSE: 0.0479 | Consistency: 0.0130 | SSIM: 0.0380 | Grad: 86976.875\n",
      "[Epoch 22, Batch 43/100] Loss: 0.0528 | RMSE: 0.0495 | Consistency: 0.0120 | SSIM: 0.0322 | Grad: 56263.426\n",
      "[Epoch 22, Batch 44/100] Loss: 0.0521 | RMSE: 0.0487 | Consistency: 0.0110 | SSIM: 0.0329 | Grad: 117479.781\n",
      "[Epoch 22, Batch 45/100] Loss: 0.0538 | RMSE: 0.0506 | Consistency: 0.0124 | SSIM: 0.0303 | Grad: 76107.672\n",
      "[Epoch 22, Batch 46/100] Loss: 0.0773 | RMSE: 0.0720 | Consistency: 0.0287 | SSIM: 0.0506 | Grad: 140367.094\n",
      "[Epoch 22, Batch 47/100] Loss: 0.0574 | RMSE: 0.0536 | Consistency: 0.0135 | SSIM: 0.0359 | Grad: 130867.742\n",
      "[Epoch 22, Batch 48/100] Loss: 0.0582 | RMSE: 0.0543 | Consistency: 0.0154 | SSIM: 0.0375 | Grad: 74042.352\n",
      "[Epoch 22, Batch 49/100] Loss: 0.0610 | RMSE: 0.0575 | Consistency: 0.0189 | SSIM: 0.0324 | Grad: 160399.219\n",
      "[Epoch 22, Batch 50/100] Loss: 0.0618 | RMSE: 0.0578 | Consistency: 0.0181 | SSIM: 0.0385 | Grad: 118784.891\n",
      "[Epoch 22, Batch 51/100] Loss: 0.0587 | RMSE: 0.0545 | Consistency: 0.0149 | SSIM: 0.0402 | Grad: 80365.984\n",
      "[Epoch 22, Batch 52/100] Loss: 0.0651 | RMSE: 0.0607 | Consistency: 0.0206 | SSIM: 0.0423 | Grad: 100389.969\n",
      "[Epoch 22, Batch 53/100] Loss: 0.0565 | RMSE: 0.0522 | Consistency: 0.0143 | SSIM: 0.0417 | Grad: 111130.617\n",
      "[Epoch 22, Batch 54/100] Loss: 0.0575 | RMSE: 0.0535 | Consistency: 0.0140 | SSIM: 0.0383 | Grad: 92411.891\n",
      "[Epoch 22, Batch 55/100] Loss: 0.0502 | RMSE: 0.0464 | Consistency: 0.0120 | SSIM: 0.0368 | Grad: 93296.656\n",
      "[Epoch 22, Batch 56/100] Loss: 0.0596 | RMSE: 0.0555 | Consistency: 0.0141 | SSIM: 0.0395 | Grad: 114702.828\n",
      "[Epoch 22, Batch 57/100] Loss: 0.0625 | RMSE: 0.0588 | Consistency: 0.0157 | SSIM: 0.0355 | Grad: 106340.992\n",
      "[Epoch 22, Batch 58/100] Loss: 0.0575 | RMSE: 0.0539 | Consistency: 0.0161 | SSIM: 0.0346 | Grad: 116058.969\n",
      "[Epoch 22, Batch 59/100] Loss: 0.0628 | RMSE: 0.0585 | Consistency: 0.0165 | SSIM: 0.0414 | Grad: 126163.836\n",
      "[Epoch 22, Batch 60/100] Loss: 0.0700 | RMSE: 0.0654 | Consistency: 0.0224 | SSIM: 0.0441 | Grad: 97740.578\n",
      "[Epoch 22, Batch 61/100] Loss: 0.0605 | RMSE: 0.0565 | Consistency: 0.0170 | SSIM: 0.0385 | Grad: 111926.766\n",
      "[Epoch 22, Batch 62/100] Loss: 0.0487 | RMSE: 0.0446 | Consistency: 0.0106 | SSIM: 0.0397 | Grad: 79815.852\n",
      "[Epoch 22, Batch 63/100] Loss: 0.0641 | RMSE: 0.0599 | Consistency: 0.0159 | SSIM: 0.0404 | Grad: 70078.242\n",
      "[Epoch 22, Batch 64/100] Loss: 0.0659 | RMSE: 0.0617 | Consistency: 0.0128 | SSIM: 0.0407 | Grad: 89675.336\n",
      "[Epoch 22, Batch 65/100] Loss: 0.0570 | RMSE: 0.0532 | Consistency: 0.0142 | SSIM: 0.0361 | Grad: 95956.961\n",
      "[Epoch 22, Batch 66/100] Loss: 0.0670 | RMSE: 0.0622 | Consistency: 0.0165 | SSIM: 0.0468 | Grad: 164343.656\n",
      "[Epoch 22, Batch 67/100] Loss: 0.0600 | RMSE: 0.0562 | Consistency: 0.0144 | SSIM: 0.0368 | Grad: 133391.156\n",
      "[Epoch 22, Batch 68/100] Loss: 0.0544 | RMSE: 0.0505 | Consistency: 0.0120 | SSIM: 0.0378 | Grad: 102692.195\n",
      "[Epoch 22, Batch 69/100] Loss: 0.0621 | RMSE: 0.0579 | Consistency: 0.0163 | SSIM: 0.0400 | Grad: 169560.547\n",
      "[Epoch 22, Batch 70/100] Loss: 0.0774 | RMSE: 0.0722 | Consistency: 0.0212 | SSIM: 0.0499 | Grad: 176846.812\n",
      "[Epoch 22, Batch 71/100] Loss: 0.0596 | RMSE: 0.0553 | Consistency: 0.0126 | SSIM: 0.0413 | Grad: 157017.984\n",
      "[Epoch 22, Batch 72/100] Loss: 0.0631 | RMSE: 0.0587 | Consistency: 0.0218 | SSIM: 0.0424 | Grad: 119332.148\n",
      "[Epoch 22, Batch 73/100] Loss: 0.0643 | RMSE: 0.0606 | Consistency: 0.0147 | SSIM: 0.0359 | Grad: 170713.906\n",
      "[Epoch 22, Batch 74/100] Loss: 0.0587 | RMSE: 0.0550 | Consistency: 0.0122 | SSIM: 0.0366 | Grad: 125929.883\n",
      "[Epoch 22, Batch 75/100] Loss: 0.0663 | RMSE: 0.0611 | Consistency: 0.0191 | SSIM: 0.0499 | Grad: 99889.281\n",
      "[Epoch 22, Batch 76/100] Loss: 0.0651 | RMSE: 0.0609 | Consistency: 0.0160 | SSIM: 0.0405 | Grad: 136275.234\n",
      "[Epoch 22, Batch 77/100] Loss: 0.0539 | RMSE: 0.0501 | Consistency: 0.0128 | SSIM: 0.0370 | Grad: 53091.832\n",
      "[Epoch 22, Batch 78/100] Loss: 0.0581 | RMSE: 0.0543 | Consistency: 0.0152 | SSIM: 0.0362 | Grad: 97493.531\n",
      "[Epoch 22, Batch 79/100] Loss: 0.0624 | RMSE: 0.0583 | Consistency: 0.0162 | SSIM: 0.0392 | Grad: 145458.766\n",
      "[Epoch 22, Batch 80/100] Loss: 0.0674 | RMSE: 0.0625 | Consistency: 0.0217 | SSIM: 0.0472 | Grad: 126919.203\n",
      "[Epoch 22, Batch 81/100] Loss: 0.0485 | RMSE: 0.0449 | Consistency: 0.0110 | SSIM: 0.0343 | Grad: 95538.977\n",
      "[Epoch 22, Batch 82/100] Loss: 0.0687 | RMSE: 0.0629 | Consistency: 0.0222 | SSIM: 0.0551 | Grad: 133489.094\n",
      "[Epoch 22, Batch 83/100] Loss: 0.0815 | RMSE: 0.0768 | Consistency: 0.0275 | SSIM: 0.0447 | Grad: 170608.359\n",
      "[Epoch 22, Batch 84/100] Loss: 0.0558 | RMSE: 0.0519 | Consistency: 0.0133 | SSIM: 0.0378 | Grad: 46237.629\n",
      "[Epoch 22, Batch 85/100] Loss: 0.0509 | RMSE: 0.0470 | Consistency: 0.0146 | SSIM: 0.0374 | Grad: 102141.781\n",
      "[Epoch 22, Batch 86/100] Loss: 0.0551 | RMSE: 0.0512 | Consistency: 0.0139 | SSIM: 0.0378 | Grad: 93148.070\n",
      "[Epoch 22, Batch 87/100] Loss: 0.0602 | RMSE: 0.0562 | Consistency: 0.0180 | SSIM: 0.0386 | Grad: 120735.477\n",
      "[Epoch 22, Batch 88/100] Loss: 0.0635 | RMSE: 0.0587 | Consistency: 0.0167 | SSIM: 0.0462 | Grad: 109958.602\n",
      "[Epoch 22, Batch 89/100] Loss: 0.0524 | RMSE: 0.0490 | Consistency: 0.0122 | SSIM: 0.0337 | Grad: 69197.695\n",
      "[Epoch 22, Batch 90/100] Loss: 0.0607 | RMSE: 0.0565 | Consistency: 0.0142 | SSIM: 0.0406 | Grad: 93863.406\n",
      "[Epoch 22, Batch 91/100] Loss: 0.0512 | RMSE: 0.0475 | Consistency: 0.0115 | SSIM: 0.0353 | Grad: 105024.695\n",
      "[Epoch 22, Batch 92/100] Loss: 0.0607 | RMSE: 0.0567 | Consistency: 0.0168 | SSIM: 0.0387 | Grad: 58407.406\n",
      "[Epoch 22, Batch 93/100] Loss: 0.0647 | RMSE: 0.0609 | Consistency: 0.0121 | SSIM: 0.0371 | Grad: 182858.141\n",
      "[Epoch 22, Batch 94/100] Loss: 0.0764 | RMSE: 0.0715 | Consistency: 0.0173 | SSIM: 0.0473 | Grad: 190614.062\n",
      "[Epoch 22, Batch 95/100] Loss: 0.0657 | RMSE: 0.0613 | Consistency: 0.0153 | SSIM: 0.0421 | Grad: 178138.047\n",
      "[Epoch 22, Batch 96/100] Loss: 0.0607 | RMSE: 0.0566 | Consistency: 0.0160 | SSIM: 0.0390 | Grad: 56209.254\n",
      "[Epoch 22, Batch 97/100] Loss: 0.0610 | RMSE: 0.0568 | Consistency: 0.0137 | SSIM: 0.0405 | Grad: 134560.312\n",
      "[Epoch 22, Batch 98/100] Loss: 0.0650 | RMSE: 0.0608 | Consistency: 0.0182 | SSIM: 0.0397 | Grad: 128580.734\n",
      "[Epoch 22, Batch 99/100] Loss: 0.0675 | RMSE: 0.0630 | Consistency: 0.0180 | SSIM: 0.0435 | Grad: 143092.266\n",
      "[Epoch 22, Batch 100/100] Loss: 0.0608 | RMSE: 0.0569 | Consistency: 0.0127 | SSIM: 0.0372 | Grad: 81285.680\n",
      "✅ Epoch 22 완료!\n",
      "   📈 평균 Loss: 0.060709\n",
      "   📊 평균 RMSE: 0.056646\n",
      "   ⚙️  학습률: 0.000909\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 23/80 시작...\n",
      "[Epoch 23, Batch 1/100] Loss: 0.0627 | RMSE: 0.0589 | Consistency: 0.0156 | SSIM: 0.0364 | Grad: 129447.305\n",
      "[Epoch 23, Batch 2/100] Loss: 0.0580 | RMSE: 0.0538 | Consistency: 0.0140 | SSIM: 0.0412 | Grad: 93012.094\n",
      "[Epoch 23, Batch 3/100] Loss: 0.0442 | RMSE: 0.0413 | Consistency: 0.0095 | SSIM: 0.0285 | Grad: 48880.605\n",
      "[Epoch 23, Batch 4/100] Loss: 0.0673 | RMSE: 0.0633 | Consistency: 0.0222 | SSIM: 0.0379 | Grad: 76017.141\n",
      "[Epoch 23, Batch 5/100] Loss: 0.0540 | RMSE: 0.0507 | Consistency: 0.0115 | SSIM: 0.0325 | Grad: 147838.219\n",
      "[Epoch 23, Batch 6/100] Loss: 0.0608 | RMSE: 0.0575 | Consistency: 0.0148 | SSIM: 0.0313 | Grad: 175888.797\n",
      "[Epoch 23, Batch 7/100] Loss: 0.0568 | RMSE: 0.0530 | Consistency: 0.0123 | SSIM: 0.0359 | Grad: 91479.711\n",
      "[Epoch 23, Batch 8/100] Loss: 0.0577 | RMSE: 0.0533 | Consistency: 0.0133 | SSIM: 0.0432 | Grad: 69606.586\n",
      "[Epoch 23, Batch 9/100] Loss: 0.0519 | RMSE: 0.0483 | Consistency: 0.0122 | SSIM: 0.0344 | Grad: 88711.266\n",
      "[Epoch 23, Batch 10/100] Loss: 0.0573 | RMSE: 0.0540 | Consistency: 0.0145 | SSIM: 0.0310 | Grad: 123089.117\n",
      "[Epoch 23, Batch 11/100] Loss: 0.0522 | RMSE: 0.0484 | Consistency: 0.0114 | SSIM: 0.0370 | Grad: 58249.863\n",
      "[Epoch 23, Batch 12/100] Loss: 0.0636 | RMSE: 0.0590 | Consistency: 0.0190 | SSIM: 0.0438 | Grad: 110662.906\n",
      "[Epoch 23, Batch 13/100] Loss: 0.0607 | RMSE: 0.0569 | Consistency: 0.0180 | SSIM: 0.0360 | Grad: 126739.586\n",
      "[Epoch 23, Batch 14/100] Loss: 0.0641 | RMSE: 0.0590 | Consistency: 0.0162 | SSIM: 0.0485 | Grad: 131349.984\n",
      "[Epoch 23, Batch 15/100] Loss: 0.0521 | RMSE: 0.0483 | Consistency: 0.0117 | SSIM: 0.0364 | Grad: 67730.797\n",
      "[Epoch 23, Batch 16/100] Loss: 0.0493 | RMSE: 0.0458 | Consistency: 0.0106 | SSIM: 0.0338 | Grad: 142547.125\n",
      "[Epoch 23, Batch 17/100] Loss: 0.0611 | RMSE: 0.0569 | Consistency: 0.0163 | SSIM: 0.0401 | Grad: 119359.695\n",
      "[Epoch 23, Batch 18/100] Loss: 0.0606 | RMSE: 0.0566 | Consistency: 0.0156 | SSIM: 0.0390 | Grad: 147187.812\n",
      "[Epoch 23, Batch 19/100] Loss: 0.0624 | RMSE: 0.0581 | Consistency: 0.0164 | SSIM: 0.0414 | Grad: 88325.938\n",
      "[Epoch 23, Batch 20/100] Loss: 0.0517 | RMSE: 0.0475 | Consistency: 0.0116 | SSIM: 0.0406 | Grad: 61518.387\n",
      "[Epoch 23, Batch 21/100] Loss: 0.0560 | RMSE: 0.0523 | Consistency: 0.0116 | SSIM: 0.0360 | Grad: 100005.523\n",
      "[Epoch 23, Batch 22/100] Loss: 0.0533 | RMSE: 0.0488 | Consistency: 0.0128 | SSIM: 0.0440 | Grad: 119124.117\n",
      "[Epoch 23, Batch 23/100] Loss: 0.0544 | RMSE: 0.0505 | Consistency: 0.0127 | SSIM: 0.0381 | Grad: 86135.414\n",
      "[Epoch 23, Batch 24/100] Loss: 0.0561 | RMSE: 0.0525 | Consistency: 0.0130 | SSIM: 0.0354 | Grad: 107540.633\n",
      "[Epoch 23, Batch 25/100] Loss: 0.0521 | RMSE: 0.0485 | Consistency: 0.0121 | SSIM: 0.0347 | Grad: 107887.703\n",
      "[Epoch 23, Batch 26/100] Loss: 0.0550 | RMSE: 0.0512 | Consistency: 0.0142 | SSIM: 0.0359 | Grad: 60336.262\n",
      "[Epoch 23, Batch 27/100] Loss: 0.0509 | RMSE: 0.0474 | Consistency: 0.0115 | SSIM: 0.0340 | Grad: 73281.227\n",
      "[Epoch 23, Batch 28/100] Loss: 0.0535 | RMSE: 0.0505 | Consistency: 0.0122 | SSIM: 0.0286 | Grad: 69925.555\n",
      "[Epoch 23, Batch 29/100] Loss: 0.0685 | RMSE: 0.0642 | Consistency: 0.0139 | SSIM: 0.0418 | Grad: 157180.203\n",
      "[Epoch 23, Batch 30/100] Loss: 0.0638 | RMSE: 0.0597 | Consistency: 0.0114 | SSIM: 0.0398 | Grad: 150312.188\n",
      "[Epoch 23, Batch 31/100] Loss: 0.0553 | RMSE: 0.0514 | Consistency: 0.0148 | SSIM: 0.0372 | Grad: 58460.512\n",
      "[Epoch 23, Batch 32/100] Loss: 0.0564 | RMSE: 0.0527 | Consistency: 0.0111 | SSIM: 0.0362 | Grad: 170316.406\n",
      "[Epoch 23, Batch 33/100] Loss: 0.0570 | RMSE: 0.0525 | Consistency: 0.0140 | SSIM: 0.0432 | Grad: 80515.258\n",
      "[Epoch 23, Batch 34/100] Loss: 0.0564 | RMSE: 0.0517 | Consistency: 0.0130 | SSIM: 0.0459 | Grad: 66751.359\n",
      "[Epoch 23, Batch 35/100] Loss: 0.0604 | RMSE: 0.0569 | Consistency: 0.0156 | SSIM: 0.0332 | Grad: 127035.242\n",
      "[Epoch 23, Batch 36/100] Loss: 0.0851 | RMSE: 0.0800 | Consistency: 0.0323 | SSIM: 0.0486 | Grad: 152047.156\n",
      "[Epoch 23, Batch 37/100] Loss: 0.0617 | RMSE: 0.0581 | Consistency: 0.0127 | SSIM: 0.0353 | Grad: 109020.359\n",
      "[Epoch 23, Batch 38/100] Loss: 0.0591 | RMSE: 0.0554 | Consistency: 0.0151 | SSIM: 0.0353 | Grad: 97018.742\n",
      "[Epoch 23, Batch 39/100] Loss: 0.0488 | RMSE: 0.0452 | Consistency: 0.0111 | SSIM: 0.0354 | Grad: 96827.680\n",
      "[Epoch 23, Batch 40/100] Loss: 0.0546 | RMSE: 0.0516 | Consistency: 0.0123 | SSIM: 0.0292 | Grad: 92268.258\n",
      "[Epoch 23, Batch 41/100] Loss: 0.0472 | RMSE: 0.0439 | Consistency: 0.0099 | SSIM: 0.0319 | Grad: 94796.305\n",
      "[Epoch 23, Batch 42/100] Loss: 0.0540 | RMSE: 0.0501 | Consistency: 0.0127 | SSIM: 0.0387 | Grad: 103667.266\n",
      "[Epoch 23, Batch 43/100] Loss: 0.0506 | RMSE: 0.0472 | Consistency: 0.0112 | SSIM: 0.0329 | Grad: 59550.105\n",
      "[Epoch 23, Batch 44/100] Loss: 0.0539 | RMSE: 0.0504 | Consistency: 0.0129 | SSIM: 0.0332 | Grad: 128629.203\n",
      "[Epoch 23, Batch 45/100] Loss: 0.0631 | RMSE: 0.0597 | Consistency: 0.0114 | SSIM: 0.0333 | Grad: 188160.000\n",
      "[Epoch 23, Batch 46/100] Loss: 0.0578 | RMSE: 0.0545 | Consistency: 0.0125 | SSIM: 0.0319 | Grad: 155841.656\n",
      "[Epoch 23, Batch 47/100] Loss: 0.0616 | RMSE: 0.0578 | Consistency: 0.0199 | SSIM: 0.0353 | Grad: 131304.797\n",
      "[Epoch 23, Batch 48/100] Loss: 0.0719 | RMSE: 0.0676 | Consistency: 0.0161 | SSIM: 0.0418 | Grad: 147503.078\n",
      "[Epoch 23, Batch 49/100] Loss: 0.0586 | RMSE: 0.0546 | Consistency: 0.0170 | SSIM: 0.0376 | Grad: 101394.805\n",
      "[Epoch 23, Batch 50/100] Loss: 0.0650 | RMSE: 0.0607 | Consistency: 0.0173 | SSIM: 0.0410 | Grad: 118394.875\n",
      "[Epoch 23, Batch 51/100] Loss: 0.0606 | RMSE: 0.0566 | Consistency: 0.0119 | SSIM: 0.0389 | Grad: 151196.484\n",
      "[Epoch 23, Batch 52/100] Loss: 0.0574 | RMSE: 0.0535 | Consistency: 0.0183 | SSIM: 0.0379 | Grad: 151025.547\n",
      "[Epoch 23, Batch 53/100] Loss: 0.0603 | RMSE: 0.0565 | Consistency: 0.0168 | SSIM: 0.0356 | Grad: 122726.789\n",
      "[Epoch 23, Batch 54/100] Loss: 0.0623 | RMSE: 0.0584 | Consistency: 0.0130 | SSIM: 0.0380 | Grad: 128049.922\n",
      "[Epoch 23, Batch 55/100] Loss: 0.0530 | RMSE: 0.0491 | Consistency: 0.0132 | SSIM: 0.0374 | Grad: 35862.141\n",
      "[Epoch 23, Batch 56/100] Loss: 0.0607 | RMSE: 0.0565 | Consistency: 0.0179 | SSIM: 0.0407 | Grad: 155663.250\n",
      "[Epoch 23, Batch 57/100] Loss: 0.0604 | RMSE: 0.0571 | Consistency: 0.0177 | SSIM: 0.0319 | Grad: 134591.594\n",
      "[Epoch 23, Batch 58/100] Loss: 0.0545 | RMSE: 0.0511 | Consistency: 0.0124 | SSIM: 0.0327 | Grad: 56273.723\n",
      "[Epoch 23, Batch 59/100] Loss: 0.0581 | RMSE: 0.0541 | Consistency: 0.0181 | SSIM: 0.0375 | Grad: 161611.656\n",
      "[Epoch 23, Batch 60/100] Loss: 0.0639 | RMSE: 0.0597 | Consistency: 0.0201 | SSIM: 0.0396 | Grad: 189102.500\n",
      "[Epoch 23, Batch 61/100] Loss: 0.0548 | RMSE: 0.0515 | Consistency: 0.0124 | SSIM: 0.0323 | Grad: 121364.344\n",
      "[Epoch 23, Batch 62/100] Loss: 0.0646 | RMSE: 0.0599 | Consistency: 0.0162 | SSIM: 0.0463 | Grad: 102063.484\n",
      "[Epoch 23, Batch 63/100] Loss: 0.0576 | RMSE: 0.0541 | Consistency: 0.0188 | SSIM: 0.0336 | Grad: 153995.719\n",
      "[Epoch 23, Batch 64/100] Loss: 0.0643 | RMSE: 0.0601 | Consistency: 0.0210 | SSIM: 0.0398 | Grad: 161355.266\n",
      "[Epoch 23, Batch 65/100] Loss: 0.0599 | RMSE: 0.0556 | Consistency: 0.0174 | SSIM: 0.0417 | Grad: 85678.445\n",
      "[Epoch 23, Batch 66/100] Loss: 0.0569 | RMSE: 0.0532 | Consistency: 0.0136 | SSIM: 0.0357 | Grad: 81757.805\n",
      "[Epoch 23, Batch 67/100] Loss: 0.0614 | RMSE: 0.0575 | Consistency: 0.0206 | SSIM: 0.0361 | Grad: 116433.016\n",
      "[Epoch 23, Batch 68/100] Loss: 0.0648 | RMSE: 0.0605 | Consistency: 0.0195 | SSIM: 0.0410 | Grad: 99024.812\n",
      "[Epoch 23, Batch 69/100] Loss: 0.0678 | RMSE: 0.0637 | Consistency: 0.0235 | SSIM: 0.0378 | Grad: 103056.320\n",
      "[Epoch 23, Batch 70/100] Loss: 0.0625 | RMSE: 0.0583 | Consistency: 0.0253 | SSIM: 0.0400 | Grad: 151496.641\n",
      "[Epoch 23, Batch 71/100] Loss: 0.0643 | RMSE: 0.0600 | Consistency: 0.0223 | SSIM: 0.0406 | Grad: 136096.234\n",
      "[Epoch 23, Batch 72/100] Loss: 0.0518 | RMSE: 0.0481 | Consistency: 0.0123 | SSIM: 0.0353 | Grad: 66018.977\n",
      "[Epoch 23, Batch 73/100] Loss: 0.0613 | RMSE: 0.0572 | Consistency: 0.0218 | SSIM: 0.0386 | Grad: 121938.039\n",
      "[Epoch 23, Batch 74/100] Loss: 0.0638 | RMSE: 0.0598 | Consistency: 0.0247 | SSIM: 0.0379 | Grad: 161484.906\n",
      "[Epoch 23, Batch 75/100] Loss: 0.0607 | RMSE: 0.0558 | Consistency: 0.0127 | SSIM: 0.0468 | Grad: 165351.219\n",
      "[Epoch 23, Batch 76/100] Loss: 0.0552 | RMSE: 0.0515 | Consistency: 0.0127 | SSIM: 0.0357 | Grad: 112784.133\n",
      "[Epoch 23, Batch 77/100] Loss: 0.0565 | RMSE: 0.0525 | Consistency: 0.0133 | SSIM: 0.0388 | Grad: 60552.953\n",
      "[Epoch 23, Batch 78/100] Loss: 0.0600 | RMSE: 0.0563 | Consistency: 0.0120 | SSIM: 0.0351 | Grad: 115086.617\n",
      "[Epoch 23, Batch 79/100] Loss: 0.0774 | RMSE: 0.0721 | Consistency: 0.0234 | SSIM: 0.0515 | Grad: 161713.312\n",
      "[Epoch 23, Batch 80/100] Loss: 0.0666 | RMSE: 0.0624 | Consistency: 0.0181 | SSIM: 0.0394 | Grad: 129902.820\n",
      "[Epoch 23, Batch 81/100] Loss: 0.0592 | RMSE: 0.0547 | Consistency: 0.0144 | SSIM: 0.0433 | Grad: 119469.156\n",
      "[Epoch 23, Batch 82/100] Loss: 0.0636 | RMSE: 0.0593 | Consistency: 0.0149 | SSIM: 0.0412 | Grad: 137326.406\n",
      "[Epoch 23, Batch 83/100] Loss: 0.0552 | RMSE: 0.0518 | Consistency: 0.0121 | SSIM: 0.0334 | Grad: 124201.062\n",
      "[Epoch 23, Batch 84/100] Loss: 0.0630 | RMSE: 0.0591 | Consistency: 0.0168 | SSIM: 0.0372 | Grad: 146571.281\n",
      "[Epoch 23, Batch 85/100] Loss: 0.0595 | RMSE: 0.0553 | Consistency: 0.0143 | SSIM: 0.0403 | Grad: 146602.172\n",
      "[Epoch 23, Batch 86/100] Loss: 0.0468 | RMSE: 0.0436 | Consistency: 0.0097 | SSIM: 0.0313 | Grad: 61539.012\n",
      "[Epoch 23, Batch 87/100] Loss: 0.0533 | RMSE: 0.0499 | Consistency: 0.0137 | SSIM: 0.0326 | Grad: 108559.273\n",
      "[Epoch 23, Batch 88/100] Loss: 0.0458 | RMSE: 0.0432 | Consistency: 0.0099 | SSIM: 0.0251 | Grad: 94840.828\n",
      "[Epoch 23, Batch 89/100] Loss: 0.0534 | RMSE: 0.0500 | Consistency: 0.0132 | SSIM: 0.0328 | Grad: 87290.914\n",
      "[Epoch 23, Batch 90/100] Loss: 0.0550 | RMSE: 0.0516 | Consistency: 0.0136 | SSIM: 0.0331 | Grad: 75794.133\n",
      "[Epoch 23, Batch 91/100] Loss: 0.0646 | RMSE: 0.0608 | Consistency: 0.0128 | SSIM: 0.0374 | Grad: 131500.719\n",
      "[Epoch 23, Batch 92/100] Loss: 0.0537 | RMSE: 0.0500 | Consistency: 0.0120 | SSIM: 0.0362 | Grad: 141427.000\n",
      "[Epoch 23, Batch 93/100] Loss: 0.0523 | RMSE: 0.0488 | Consistency: 0.0134 | SSIM: 0.0335 | Grad: 49139.547\n",
      "[Epoch 23, Batch 94/100] Loss: 0.0593 | RMSE: 0.0552 | Consistency: 0.0142 | SSIM: 0.0389 | Grad: 133335.906\n",
      "[Epoch 23, Batch 95/100] Loss: 0.0571 | RMSE: 0.0532 | Consistency: 0.0131 | SSIM: 0.0385 | Grad: 122802.781\n",
      "[Epoch 23, Batch 96/100] Loss: 0.0575 | RMSE: 0.0533 | Consistency: 0.0173 | SSIM: 0.0406 | Grad: 113445.422\n",
      "[Epoch 23, Batch 97/100] Loss: 0.0585 | RMSE: 0.0544 | Consistency: 0.0154 | SSIM: 0.0392 | Grad: 80341.664\n",
      "[Epoch 23, Batch 98/100] Loss: 0.0501 | RMSE: 0.0469 | Consistency: 0.0123 | SSIM: 0.0308 | Grad: 102017.461\n",
      "[Epoch 23, Batch 99/100] Loss: 0.0544 | RMSE: 0.0504 | Consistency: 0.0147 | SSIM: 0.0380 | Grad: 96822.531\n",
      "[Epoch 23, Batch 100/100] Loss: 0.0486 | RMSE: 0.0449 | Consistency: 0.0121 | SSIM: 0.0363 | Grad: 68648.305\n",
      "✅ Epoch 23 완료!\n",
      "   📈 평균 Loss: 0.058251\n",
      "   📊 평균 RMSE: 0.054373\n",
      "   ⚙️  학습률: 0.000897\n",
      "   🏆 NEW BEST! RMSE: 0.054373\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 24/80 시작...\n",
      "[Epoch 24, Batch 1/100] Loss: 0.0541 | RMSE: 0.0509 | Consistency: 0.0119 | SSIM: 0.0310 | Grad: 136529.562\n",
      "[Epoch 24, Batch 2/100] Loss: 0.0529 | RMSE: 0.0493 | Consistency: 0.0117 | SSIM: 0.0344 | Grad: 130669.102\n",
      "[Epoch 24, Batch 3/100] Loss: 0.0569 | RMSE: 0.0536 | Consistency: 0.0129 | SSIM: 0.0318 | Grad: 125880.688\n",
      "[Epoch 24, Batch 4/100] Loss: 0.0562 | RMSE: 0.0518 | Consistency: 0.0165 | SSIM: 0.0424 | Grad: 97429.844\n",
      "[Epoch 24, Batch 5/100] Loss: 0.0506 | RMSE: 0.0476 | Consistency: 0.0099 | SSIM: 0.0289 | Grad: 115201.102\n",
      "[Epoch 24, Batch 6/100] Loss: 0.0586 | RMSE: 0.0551 | Consistency: 0.0130 | SSIM: 0.0344 | Grad: 141311.797\n",
      "[Epoch 24, Batch 7/100] Loss: 0.0627 | RMSE: 0.0589 | Consistency: 0.0162 | SSIM: 0.0367 | Grad: 100874.023\n",
      "[Epoch 24, Batch 8/100] Loss: 0.0634 | RMSE: 0.0596 | Consistency: 0.0154 | SSIM: 0.0365 | Grad: 139554.375\n",
      "[Epoch 24, Batch 9/100] Loss: 0.0596 | RMSE: 0.0559 | Consistency: 0.0147 | SSIM: 0.0356 | Grad: 127397.508\n",
      "[Epoch 24, Batch 10/100] Loss: 0.0549 | RMSE: 0.0508 | Consistency: 0.0179 | SSIM: 0.0395 | Grad: 109725.391\n",
      "[Epoch 24, Batch 11/100] Loss: 0.0682 | RMSE: 0.0643 | Consistency: 0.0236 | SSIM: 0.0369 | Grad: 61809.641\n",
      "[Epoch 24, Batch 12/100] Loss: 0.0555 | RMSE: 0.0517 | Consistency: 0.0175 | SSIM: 0.0357 | Grad: 130424.711\n",
      "[Epoch 24, Batch 13/100] Loss: 0.0581 | RMSE: 0.0543 | Consistency: 0.0156 | SSIM: 0.0366 | Grad: 105095.453\n",
      "[Epoch 24, Batch 14/100] Loss: 0.0670 | RMSE: 0.0629 | Consistency: 0.0239 | SSIM: 0.0394 | Grad: 52218.457\n",
      "[Epoch 24, Batch 15/100] Loss: 0.0566 | RMSE: 0.0526 | Consistency: 0.0172 | SSIM: 0.0384 | Grad: 104906.344\n",
      "[Epoch 24, Batch 16/100] Loss: 0.0509 | RMSE: 0.0477 | Consistency: 0.0129 | SSIM: 0.0308 | Grad: 20227.395\n",
      "[Epoch 24, Batch 17/100] Loss: 0.0505 | RMSE: 0.0472 | Consistency: 0.0103 | SSIM: 0.0325 | Grad: 73446.320\n",
      "[Epoch 24, Batch 18/100] Loss: 0.0564 | RMSE: 0.0525 | Consistency: 0.0134 | SSIM: 0.0375 | Grad: 82788.602\n",
      "[Epoch 24, Batch 19/100] Loss: 0.0559 | RMSE: 0.0521 | Consistency: 0.0121 | SSIM: 0.0366 | Grad: 108411.242\n",
      "[Epoch 24, Batch 20/100] Loss: 0.0653 | RMSE: 0.0609 | Consistency: 0.0155 | SSIM: 0.0428 | Grad: 99855.484\n",
      "[Epoch 24, Batch 21/100] Loss: 0.0558 | RMSE: 0.0514 | Consistency: 0.0144 | SSIM: 0.0431 | Grad: 49499.406\n",
      "[Epoch 24, Batch 22/100] Loss: 0.0572 | RMSE: 0.0530 | Consistency: 0.0119 | SSIM: 0.0413 | Grad: 106885.258\n",
      "[Epoch 24, Batch 23/100] Loss: 0.0582 | RMSE: 0.0546 | Consistency: 0.0120 | SSIM: 0.0352 | Grad: 86904.398\n",
      "[Epoch 24, Batch 24/100] Loss: 0.0581 | RMSE: 0.0542 | Consistency: 0.0169 | SSIM: 0.0371 | Grad: 94099.891\n",
      "[Epoch 24, Batch 25/100] Loss: 0.0575 | RMSE: 0.0537 | Consistency: 0.0122 | SSIM: 0.0363 | Grad: 128292.109\n",
      "[Epoch 24, Batch 26/100] Loss: 0.0584 | RMSE: 0.0546 | Consistency: 0.0163 | SSIM: 0.0362 | Grad: 130305.781\n",
      "[Epoch 24, Batch 27/100] Loss: 0.0505 | RMSE: 0.0475 | Consistency: 0.0092 | SSIM: 0.0289 | Grad: 119608.203\n",
      "[Epoch 24, Batch 28/100] Loss: 0.0642 | RMSE: 0.0604 | Consistency: 0.0147 | SSIM: 0.0359 | Grad: 82921.883\n",
      "[Epoch 24, Batch 29/100] Loss: 0.0632 | RMSE: 0.0592 | Consistency: 0.0153 | SSIM: 0.0379 | Grad: 119442.820\n",
      "[Epoch 24, Batch 30/100] Loss: 0.0499 | RMSE: 0.0465 | Consistency: 0.0114 | SSIM: 0.0337 | Grad: 109955.961\n",
      "[Epoch 24, Batch 31/100] Loss: 0.0510 | RMSE: 0.0478 | Consistency: 0.0105 | SSIM: 0.0309 | Grad: 57309.828\n",
      "[Epoch 24, Batch 32/100] Loss: 0.0472 | RMSE: 0.0437 | Consistency: 0.0094 | SSIM: 0.0342 | Grad: 97967.484\n",
      "[Epoch 24, Batch 33/100] Loss: 0.0552 | RMSE: 0.0515 | Consistency: 0.0157 | SSIM: 0.0352 | Grad: 113311.500\n",
      "[Epoch 24, Batch 34/100] Loss: 0.0638 | RMSE: 0.0598 | Consistency: 0.0211 | SSIM: 0.0377 | Grad: 78688.539\n",
      "[Epoch 24, Batch 35/100] Loss: 0.0599 | RMSE: 0.0556 | Consistency: 0.0147 | SSIM: 0.0421 | Grad: 110227.945\n",
      "[Epoch 24, Batch 36/100] Loss: 0.0621 | RMSE: 0.0575 | Consistency: 0.0213 | SSIM: 0.0439 | Grad: 130180.578\n",
      "[Epoch 24, Batch 37/100] Loss: 0.0612 | RMSE: 0.0562 | Consistency: 0.0207 | SSIM: 0.0477 | Grad: 118129.594\n",
      "[Epoch 24, Batch 38/100] Loss: 0.0603 | RMSE: 0.0568 | Consistency: 0.0144 | SSIM: 0.0337 | Grad: 69646.445\n",
      "[Epoch 24, Batch 39/100] Loss: 0.0635 | RMSE: 0.0595 | Consistency: 0.0157 | SSIM: 0.0393 | Grad: 113655.922\n",
      "[Epoch 24, Batch 40/100] Loss: 0.0582 | RMSE: 0.0540 | Consistency: 0.0170 | SSIM: 0.0406 | Grad: 90349.742\n",
      "[Epoch 24, Batch 41/100] Loss: 0.0541 | RMSE: 0.0507 | Consistency: 0.0141 | SSIM: 0.0322 | Grad: 32937.457\n",
      "[Epoch 24, Batch 42/100] Loss: 0.0587 | RMSE: 0.0545 | Consistency: 0.0188 | SSIM: 0.0405 | Grad: 116246.719\n",
      "[Epoch 24, Batch 43/100] Loss: 0.0549 | RMSE: 0.0506 | Consistency: 0.0116 | SSIM: 0.0420 | Grad: 128390.398\n",
      "[Epoch 24, Batch 44/100] Loss: 0.0558 | RMSE: 0.0523 | Consistency: 0.0123 | SSIM: 0.0341 | Grad: 127380.117\n",
      "[Epoch 24, Batch 45/100] Loss: 0.0523 | RMSE: 0.0481 | Consistency: 0.0112 | SSIM: 0.0412 | Grad: 43689.480\n",
      "[Epoch 24, Batch 46/100] Loss: 0.0553 | RMSE: 0.0519 | Consistency: 0.0159 | SSIM: 0.0323 | Grad: 130775.102\n",
      "[Epoch 24, Batch 47/100] Loss: 0.0528 | RMSE: 0.0494 | Consistency: 0.0110 | SSIM: 0.0328 | Grad: 132794.844\n",
      "[Epoch 24, Batch 48/100] Loss: 0.0670 | RMSE: 0.0621 | Consistency: 0.0224 | SSIM: 0.0470 | Grad: 100302.062\n",
      "[Epoch 24, Batch 49/100] Loss: 0.0541 | RMSE: 0.0507 | Consistency: 0.0124 | SSIM: 0.0328 | Grad: 88446.141\n",
      "[Epoch 24, Batch 50/100] Loss: 0.0534 | RMSE: 0.0499 | Consistency: 0.0125 | SSIM: 0.0339 | Grad: 62707.750\n",
      "[Epoch 24, Batch 51/100] Loss: 0.0535 | RMSE: 0.0498 | Consistency: 0.0135 | SSIM: 0.0357 | Grad: 122166.875\n",
      "[Epoch 24, Batch 52/100] Loss: 0.0536 | RMSE: 0.0502 | Consistency: 0.0122 | SSIM: 0.0334 | Grad: 107938.469\n",
      "[Epoch 24, Batch 53/100] Loss: 0.0497 | RMSE: 0.0461 | Consistency: 0.0105 | SSIM: 0.0355 | Grad: 67141.312\n",
      "[Epoch 24, Batch 54/100] Loss: 0.0555 | RMSE: 0.0513 | Consistency: 0.0153 | SSIM: 0.0406 | Grad: 71837.578\n",
      "[Epoch 24, Batch 55/100] Loss: 0.0518 | RMSE: 0.0483 | Consistency: 0.0115 | SSIM: 0.0336 | Grad: 57654.336\n",
      "[Epoch 24, Batch 56/100] Loss: 0.0559 | RMSE: 0.0519 | Consistency: 0.0133 | SSIM: 0.0391 | Grad: 74502.328\n",
      "[Epoch 24, Batch 57/100] Loss: 0.0524 | RMSE: 0.0480 | Consistency: 0.0115 | SSIM: 0.0429 | Grad: 77638.562\n",
      "[Epoch 24, Batch 58/100] Loss: 0.0559 | RMSE: 0.0518 | Consistency: 0.0162 | SSIM: 0.0391 | Grad: 82820.859\n",
      "[Epoch 24, Batch 59/100] Loss: 0.0535 | RMSE: 0.0496 | Consistency: 0.0127 | SSIM: 0.0371 | Grad: 69315.836\n",
      "[Epoch 24, Batch 60/100] Loss: 0.0569 | RMSE: 0.0535 | Consistency: 0.0176 | SSIM: 0.0324 | Grad: 57933.102\n",
      "[Epoch 24, Batch 61/100] Loss: 0.0512 | RMSE: 0.0481 | Consistency: 0.0147 | SSIM: 0.0295 | Grad: 125957.016\n",
      "[Epoch 24, Batch 62/100] Loss: 0.0508 | RMSE: 0.0477 | Consistency: 0.0097 | SSIM: 0.0305 | Grad: 144849.109\n",
      "[Epoch 24, Batch 63/100] Loss: 0.0479 | RMSE: 0.0446 | Consistency: 0.0109 | SSIM: 0.0320 | Grad: 90944.703\n",
      "[Epoch 24, Batch 64/100] Loss: 0.0591 | RMSE: 0.0550 | Consistency: 0.0178 | SSIM: 0.0391 | Grad: 93304.797\n",
      "[Epoch 24, Batch 65/100] Loss: 0.0598 | RMSE: 0.0550 | Consistency: 0.0158 | SSIM: 0.0471 | Grad: 133248.891\n",
      "[Epoch 24, Batch 66/100] Loss: 0.0541 | RMSE: 0.0499 | Consistency: 0.0146 | SSIM: 0.0404 | Grad: 55596.188\n",
      "[Epoch 24, Batch 67/100] Loss: 0.0529 | RMSE: 0.0499 | Consistency: 0.0114 | SSIM: 0.0282 | Grad: 79580.328\n",
      "[Epoch 24, Batch 68/100] Loss: 0.0564 | RMSE: 0.0521 | Consistency: 0.0153 | SSIM: 0.0414 | Grad: 125097.531\n",
      "[Epoch 24, Batch 69/100] Loss: 0.0465 | RMSE: 0.0434 | Consistency: 0.0098 | SSIM: 0.0309 | Grad: 50536.855\n",
      "[Epoch 24, Batch 70/100] Loss: 0.0484 | RMSE: 0.0454 | Consistency: 0.0099 | SSIM: 0.0286 | Grad: 48578.809\n",
      "[Epoch 24, Batch 71/100] Loss: 0.0564 | RMSE: 0.0527 | Consistency: 0.0151 | SSIM: 0.0353 | Grad: 148197.781\n",
      "[Epoch 24, Batch 72/100] Loss: 0.0547 | RMSE: 0.0507 | Consistency: 0.0119 | SSIM: 0.0384 | Grad: 104280.398\n",
      "[Epoch 24, Batch 73/100] Loss: 0.0576 | RMSE: 0.0536 | Consistency: 0.0154 | SSIM: 0.0391 | Grad: 78229.539\n",
      "[Epoch 24, Batch 74/100] Loss: 0.0462 | RMSE: 0.0431 | Consistency: 0.0105 | SSIM: 0.0297 | Grad: 68582.602\n",
      "[Epoch 24, Batch 75/100] Loss: 0.0476 | RMSE: 0.0442 | Consistency: 0.0107 | SSIM: 0.0326 | Grad: 107350.836\n",
      "[Epoch 24, Batch 76/100] Loss: 0.0520 | RMSE: 0.0484 | Consistency: 0.0110 | SSIM: 0.0352 | Grad: 24775.057\n",
      "[Epoch 24, Batch 77/100] Loss: 0.0640 | RMSE: 0.0599 | Consistency: 0.0177 | SSIM: 0.0399 | Grad: 159146.641\n",
      "[Epoch 24, Batch 78/100] Loss: 0.0520 | RMSE: 0.0483 | Consistency: 0.0152 | SSIM: 0.0351 | Grad: 87039.039\n",
      "[Epoch 24, Batch 79/100] Loss: 0.0573 | RMSE: 0.0538 | Consistency: 0.0147 | SSIM: 0.0340 | Grad: 103087.812\n",
      "[Epoch 24, Batch 80/100] Loss: 0.0539 | RMSE: 0.0503 | Consistency: 0.0169 | SSIM: 0.0346 | Grad: 142076.656\n",
      "[Epoch 24, Batch 81/100] Loss: 0.0468 | RMSE: 0.0436 | Consistency: 0.0121 | SSIM: 0.0304 | Grad: 45215.859\n",
      "[Epoch 24, Batch 82/100] Loss: 0.0618 | RMSE: 0.0580 | Consistency: 0.0174 | SSIM: 0.0363 | Grad: 98892.984\n",
      "[Epoch 24, Batch 83/100] Loss: 0.0583 | RMSE: 0.0539 | Consistency: 0.0178 | SSIM: 0.0420 | Grad: 119352.562\n",
      "[Epoch 24, Batch 84/100] Loss: 0.0547 | RMSE: 0.0504 | Consistency: 0.0134 | SSIM: 0.0412 | Grad: 47719.203\n",
      "[Epoch 24, Batch 85/100] Loss: 0.0616 | RMSE: 0.0580 | Consistency: 0.0159 | SSIM: 0.0345 | Grad: 122585.344\n",
      "[Epoch 24, Batch 86/100] Loss: 0.0664 | RMSE: 0.0613 | Consistency: 0.0180 | SSIM: 0.0495 | Grad: 114603.555\n",
      "[Epoch 24, Batch 87/100] Loss: 0.0614 | RMSE: 0.0573 | Consistency: 0.0171 | SSIM: 0.0391 | Grad: 153608.078\n",
      "[Epoch 24, Batch 88/100] Loss: 0.0643 | RMSE: 0.0595 | Consistency: 0.0177 | SSIM: 0.0456 | Grad: 79329.250\n",
      "[Epoch 24, Batch 89/100] Loss: 0.0584 | RMSE: 0.0547 | Consistency: 0.0146 | SSIM: 0.0352 | Grad: 73076.953\n",
      "[Epoch 24, Batch 90/100] Loss: 0.0694 | RMSE: 0.0654 | Consistency: 0.0184 | SSIM: 0.0378 | Grad: 187817.750\n",
      "[Epoch 24, Batch 91/100] Loss: 0.0656 | RMSE: 0.0613 | Consistency: 0.0131 | SSIM: 0.0414 | Grad: 175138.984\n",
      "[Epoch 24, Batch 92/100] Loss: 0.0608 | RMSE: 0.0567 | Consistency: 0.0176 | SSIM: 0.0396 | Grad: 70915.180\n",
      "[Epoch 24, Batch 93/100] Loss: 0.0576 | RMSE: 0.0533 | Consistency: 0.0159 | SSIM: 0.0415 | Grad: 93395.992\n",
      "[Epoch 24, Batch 94/100] Loss: 0.0603 | RMSE: 0.0569 | Consistency: 0.0123 | SSIM: 0.0325 | Grad: 129488.883\n",
      "[Epoch 24, Batch 95/100] Loss: 0.0571 | RMSE: 0.0533 | Consistency: 0.0132 | SSIM: 0.0372 | Grad: 105843.117\n",
      "[Epoch 24, Batch 96/100] Loss: 0.0779 | RMSE: 0.0728 | Consistency: 0.0281 | SSIM: 0.0486 | Grad: 91674.602\n",
      "[Epoch 24, Batch 97/100] Loss: 0.0590 | RMSE: 0.0548 | Consistency: 0.0147 | SSIM: 0.0397 | Grad: 57013.039\n",
      "[Epoch 24, Batch 98/100] Loss: 0.0537 | RMSE: 0.0496 | Consistency: 0.0149 | SSIM: 0.0404 | Grad: 96698.398\n",
      "[Epoch 24, Batch 99/100] Loss: 0.0633 | RMSE: 0.0588 | Consistency: 0.0186 | SSIM: 0.0434 | Grad: 131502.141\n",
      "[Epoch 24, Batch 100/100] Loss: 0.0645 | RMSE: 0.0596 | Consistency: 0.0170 | SSIM: 0.0474 | Grad: 68459.102\n",
      "✅ Epoch 24 완료!\n",
      "   📈 평균 Loss: 0.056987\n",
      "   📊 평균 RMSE: 0.053129\n",
      "   ⚙️  학습률: 0.000883\n",
      "   🏆 NEW BEST! RMSE: 0.053129\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 25/80 시작...\n",
      "[Epoch 25, Batch 1/100] Loss: 0.0653 | RMSE: 0.0610 | Consistency: 0.0211 | SSIM: 0.0413 | Grad: 127154.664\n",
      "[Epoch 25, Batch 2/100] Loss: 0.0552 | RMSE: 0.0516 | Consistency: 0.0141 | SSIM: 0.0350 | Grad: 114721.508\n",
      "[Epoch 25, Batch 3/100] Loss: 0.0550 | RMSE: 0.0511 | Consistency: 0.0137 | SSIM: 0.0378 | Grad: 95065.008\n",
      "[Epoch 25, Batch 4/100] Loss: 0.0581 | RMSE: 0.0539 | Consistency: 0.0183 | SSIM: 0.0396 | Grad: 119833.836\n",
      "[Epoch 25, Batch 5/100] Loss: 0.0532 | RMSE: 0.0491 | Consistency: 0.0125 | SSIM: 0.0392 | Grad: 98378.984\n",
      "[Epoch 25, Batch 6/100] Loss: 0.0518 | RMSE: 0.0484 | Consistency: 0.0129 | SSIM: 0.0325 | Grad: 76146.805\n",
      "[Epoch 25, Batch 7/100] Loss: 0.0572 | RMSE: 0.0533 | Consistency: 0.0134 | SSIM: 0.0380 | Grad: 141202.344\n",
      "[Epoch 25, Batch 8/100] Loss: 0.0663 | RMSE: 0.0610 | Consistency: 0.0202 | SSIM: 0.0510 | Grad: 110654.180\n",
      "[Epoch 25, Batch 9/100] Loss: 0.0549 | RMSE: 0.0508 | Consistency: 0.0165 | SSIM: 0.0389 | Grad: 101706.016\n",
      "[Epoch 25, Batch 10/100] Loss: 0.0700 | RMSE: 0.0646 | Consistency: 0.0274 | SSIM: 0.0516 | Grad: 111715.578\n",
      "[Epoch 25, Batch 11/100] Loss: 0.0577 | RMSE: 0.0533 | Consistency: 0.0159 | SSIM: 0.0423 | Grad: 109833.914\n",
      "[Epoch 25, Batch 12/100] Loss: 0.0567 | RMSE: 0.0524 | Consistency: 0.0165 | SSIM: 0.0417 | Grad: 131071.484\n",
      "[Epoch 25, Batch 13/100] Loss: 0.0584 | RMSE: 0.0545 | Consistency: 0.0150 | SSIM: 0.0374 | Grad: 105436.289\n",
      "[Epoch 25, Batch 14/100] Loss: 0.0472 | RMSE: 0.0445 | Consistency: 0.0103 | SSIM: 0.0257 | Grad: 120639.641\n",
      "[Epoch 25, Batch 15/100] Loss: 0.0702 | RMSE: 0.0653 | Consistency: 0.0254 | SSIM: 0.0467 | Grad: 89694.430\n",
      "[Epoch 25, Batch 16/100] Loss: 0.0513 | RMSE: 0.0478 | Consistency: 0.0123 | SSIM: 0.0341 | Grad: 49423.945\n",
      "[Epoch 25, Batch 17/100] Loss: 0.0601 | RMSE: 0.0564 | Consistency: 0.0119 | SSIM: 0.0358 | Grad: 106921.094\n",
      "[Epoch 25, Batch 18/100] Loss: 0.0535 | RMSE: 0.0508 | Consistency: 0.0125 | SSIM: 0.0261 | Grad: 94915.898\n",
      "[Epoch 25, Batch 19/100] Loss: 0.0524 | RMSE: 0.0486 | Consistency: 0.0156 | SSIM: 0.0366 | Grad: 99132.750\n",
      "[Epoch 25, Batch 20/100] Loss: 0.0491 | RMSE: 0.0458 | Consistency: 0.0106 | SSIM: 0.0317 | Grad: 78148.367\n",
      "[Epoch 25, Batch 21/100] Loss: 0.0487 | RMSE: 0.0455 | Consistency: 0.0117 | SSIM: 0.0310 | Grad: 88472.219\n",
      "[Epoch 25, Batch 22/100] Loss: 0.0493 | RMSE: 0.0459 | Consistency: 0.0104 | SSIM: 0.0322 | Grad: 122131.023\n",
      "[Epoch 25, Batch 23/100] Loss: 0.0592 | RMSE: 0.0559 | Consistency: 0.0155 | SSIM: 0.0310 | Grad: 92797.914\n",
      "[Epoch 25, Batch 24/100] Loss: 0.0457 | RMSE: 0.0428 | Consistency: 0.0085 | SSIM: 0.0278 | Grad: 79725.250\n",
      "[Epoch 25, Batch 25/100] Loss: 0.0539 | RMSE: 0.0498 | Consistency: 0.0135 | SSIM: 0.0393 | Grad: 54034.156\n",
      "[Epoch 25, Batch 26/100] Loss: 0.0668 | RMSE: 0.0623 | Consistency: 0.0190 | SSIM: 0.0433 | Grad: 150663.172\n",
      "[Epoch 25, Batch 27/100] Loss: 0.0619 | RMSE: 0.0575 | Consistency: 0.0196 | SSIM: 0.0425 | Grad: 123851.695\n",
      "[Epoch 25, Batch 28/100] Loss: 0.0608 | RMSE: 0.0572 | Consistency: 0.0158 | SSIM: 0.0338 | Grad: 108533.852\n",
      "[Epoch 25, Batch 29/100] Loss: 0.0612 | RMSE: 0.0569 | Consistency: 0.0129 | SSIM: 0.0422 | Grad: 128079.758\n",
      "[Epoch 25, Batch 30/100] Loss: 0.0589 | RMSE: 0.0556 | Consistency: 0.0147 | SSIM: 0.0314 | Grad: 132887.266\n",
      "[Epoch 25, Batch 31/100] Loss: 0.0565 | RMSE: 0.0530 | Consistency: 0.0150 | SSIM: 0.0334 | Grad: 75722.031\n",
      "[Epoch 25, Batch 32/100] Loss: 0.0529 | RMSE: 0.0490 | Consistency: 0.0142 | SSIM: 0.0368 | Grad: 48043.949\n",
      "[Epoch 25, Batch 33/100] Loss: 0.0554 | RMSE: 0.0518 | Consistency: 0.0151 | SSIM: 0.0348 | Grad: 111754.328\n",
      "[Epoch 25, Batch 34/100] Loss: 0.0662 | RMSE: 0.0624 | Consistency: 0.0212 | SSIM: 0.0361 | Grad: 174514.312\n",
      "[Epoch 25, Batch 35/100] Loss: 0.0664 | RMSE: 0.0619 | Consistency: 0.0165 | SSIM: 0.0439 | Grad: 130732.664\n",
      "[Epoch 25, Batch 36/100] Loss: 0.0472 | RMSE: 0.0441 | Consistency: 0.0117 | SSIM: 0.0295 | Grad: 56969.102\n",
      "[Epoch 25, Batch 37/100] Loss: 0.0506 | RMSE: 0.0474 | Consistency: 0.0109 | SSIM: 0.0305 | Grad: 104359.836\n",
      "[Epoch 25, Batch 38/100] Loss: 0.0678 | RMSE: 0.0626 | Consistency: 0.0191 | SSIM: 0.0502 | Grad: 107399.984\n",
      "[Epoch 25, Batch 39/100] Loss: 0.0513 | RMSE: 0.0475 | Consistency: 0.0123 | SSIM: 0.0361 | Grad: 80632.594\n",
      "[Epoch 25, Batch 40/100] Loss: 0.0556 | RMSE: 0.0521 | Consistency: 0.0131 | SSIM: 0.0331 | Grad: 103811.805\n",
      "[Epoch 25, Batch 41/100] Loss: 0.0482 | RMSE: 0.0448 | Consistency: 0.0111 | SSIM: 0.0321 | Grad: 93209.766\n",
      "[Epoch 25, Batch 42/100] Loss: 0.0498 | RMSE: 0.0459 | Consistency: 0.0114 | SSIM: 0.0371 | Grad: 55367.227\n",
      "[Epoch 25, Batch 43/100] Loss: 0.0621 | RMSE: 0.0582 | Consistency: 0.0173 | SSIM: 0.0374 | Grad: 112113.742\n",
      "[Epoch 25, Batch 44/100] Loss: 0.0510 | RMSE: 0.0474 | Consistency: 0.0120 | SSIM: 0.0345 | Grad: 81207.703\n",
      "[Epoch 25, Batch 45/100] Loss: 0.0487 | RMSE: 0.0453 | Consistency: 0.0109 | SSIM: 0.0329 | Grad: 35129.852\n",
      "[Epoch 25, Batch 46/100] Loss: 0.0538 | RMSE: 0.0499 | Consistency: 0.0108 | SSIM: 0.0379 | Grad: 94319.898\n",
      "[Epoch 25, Batch 47/100] Loss: 0.0591 | RMSE: 0.0549 | Consistency: 0.0134 | SSIM: 0.0403 | Grad: 139850.484\n",
      "[Epoch 25, Batch 48/100] Loss: 0.0533 | RMSE: 0.0494 | Consistency: 0.0124 | SSIM: 0.0378 | Grad: 58419.000\n",
      "[Epoch 25, Batch 49/100] Loss: 0.0498 | RMSE: 0.0469 | Consistency: 0.0099 | SSIM: 0.0284 | Grad: 123458.297\n",
      "[Epoch 25, Batch 50/100] Loss: 0.0634 | RMSE: 0.0593 | Consistency: 0.0196 | SSIM: 0.0394 | Grad: 143211.969\n",
      "[Epoch 25, Batch 51/100] Loss: 0.0568 | RMSE: 0.0535 | Consistency: 0.0142 | SSIM: 0.0322 | Grad: 99624.055\n",
      "[Epoch 25, Batch 52/100] Loss: 0.0490 | RMSE: 0.0454 | Consistency: 0.0102 | SSIM: 0.0354 | Grad: 84374.125\n",
      "[Epoch 25, Batch 53/100] Loss: 0.0525 | RMSE: 0.0494 | Consistency: 0.0131 | SSIM: 0.0303 | Grad: 90368.961\n",
      "[Epoch 25, Batch 54/100] Loss: 0.0594 | RMSE: 0.0556 | Consistency: 0.0132 | SSIM: 0.0367 | Grad: 107868.617\n",
      "[Epoch 25, Batch 55/100] Loss: 0.0568 | RMSE: 0.0530 | Consistency: 0.0114 | SSIM: 0.0365 | Grad: 143911.781\n",
      "[Epoch 25, Batch 56/100] Loss: 0.0560 | RMSE: 0.0527 | Consistency: 0.0159 | SSIM: 0.0313 | Grad: 138608.312\n",
      "[Epoch 25, Batch 57/100] Loss: 0.0522 | RMSE: 0.0485 | Consistency: 0.0121 | SSIM: 0.0353 | Grad: 99692.586\n",
      "[Epoch 25, Batch 58/100] Loss: 0.0465 | RMSE: 0.0438 | Consistency: 0.0092 | SSIM: 0.0262 | Grad: 133961.609\n",
      "[Epoch 25, Batch 59/100] Loss: 0.0527 | RMSE: 0.0492 | Consistency: 0.0138 | SSIM: 0.0333 | Grad: 85972.812\n",
      "[Epoch 25, Batch 60/100] Loss: 0.0521 | RMSE: 0.0487 | Consistency: 0.0127 | SSIM: 0.0334 | Grad: 50487.375\n",
      "[Epoch 25, Batch 61/100] Loss: 0.0525 | RMSE: 0.0487 | Consistency: 0.0117 | SSIM: 0.0364 | Grad: 136726.938\n",
      "[Epoch 25, Batch 62/100] Loss: 0.0552 | RMSE: 0.0516 | Consistency: 0.0138 | SSIM: 0.0349 | Grad: 132790.172\n",
      "[Epoch 25, Batch 63/100] Loss: 0.0539 | RMSE: 0.0502 | Consistency: 0.0148 | SSIM: 0.0355 | Grad: 113892.781\n",
      "[Epoch 25, Batch 64/100] Loss: 0.0595 | RMSE: 0.0557 | Consistency: 0.0138 | SSIM: 0.0365 | Grad: 84952.812\n",
      "[Epoch 25, Batch 65/100] Loss: 0.0628 | RMSE: 0.0588 | Consistency: 0.0174 | SSIM: 0.0387 | Grad: 52276.707\n",
      "[Epoch 25, Batch 66/100] Loss: 0.0662 | RMSE: 0.0623 | Consistency: 0.0209 | SSIM: 0.0366 | Grad: 160068.391\n",
      "[Epoch 25, Batch 67/100] Loss: 0.0612 | RMSE: 0.0574 | Consistency: 0.0174 | SSIM: 0.0362 | Grad: 153238.312\n",
      "[Epoch 25, Batch 68/100] Loss: 0.0584 | RMSE: 0.0544 | Consistency: 0.0147 | SSIM: 0.0386 | Grad: 75925.148\n",
      "[Epoch 25, Batch 69/100] Loss: 0.0597 | RMSE: 0.0562 | Consistency: 0.0161 | SSIM: 0.0342 | Grad: 127613.375\n",
      "[Epoch 25, Batch 70/100] Loss: 0.0605 | RMSE: 0.0567 | Consistency: 0.0155 | SSIM: 0.0367 | Grad: 145303.953\n",
      "[Epoch 25, Batch 71/100] Loss: 0.0564 | RMSE: 0.0527 | Consistency: 0.0136 | SSIM: 0.0364 | Grad: 90397.062\n",
      "[Epoch 25, Batch 72/100] Loss: 0.0513 | RMSE: 0.0481 | Consistency: 0.0103 | SSIM: 0.0313 | Grad: 74212.414\n",
      "[Epoch 25, Batch 73/100] Loss: 0.0540 | RMSE: 0.0504 | Consistency: 0.0133 | SSIM: 0.0341 | Grad: 137584.359\n",
      "[Epoch 25, Batch 74/100] Loss: 0.0506 | RMSE: 0.0472 | Consistency: 0.0120 | SSIM: 0.0330 | Grad: 69212.461\n",
      "[Epoch 25, Batch 75/100] Loss: 0.0500 | RMSE: 0.0463 | Consistency: 0.0111 | SSIM: 0.0355 | Grad: 85786.195\n",
      "[Epoch 25, Batch 76/100] Loss: 0.0508 | RMSE: 0.0473 | Consistency: 0.0126 | SSIM: 0.0330 | Grad: 44857.578\n",
      "[Epoch 25, Batch 77/100] Loss: 0.0516 | RMSE: 0.0480 | Consistency: 0.0113 | SSIM: 0.0344 | Grad: 80861.477\n",
      "[Epoch 25, Batch 78/100] Loss: 0.0489 | RMSE: 0.0454 | Consistency: 0.0119 | SSIM: 0.0331 | Grad: 45332.340\n",
      "[Epoch 25, Batch 79/100] Loss: 0.0491 | RMSE: 0.0458 | Consistency: 0.0116 | SSIM: 0.0317 | Grad: 39369.070\n",
      "[Epoch 25, Batch 80/100] Loss: 0.0483 | RMSE: 0.0454 | Consistency: 0.0085 | SSIM: 0.0276 | Grad: 104904.672\n",
      "[Epoch 25, Batch 81/100] Loss: 0.0579 | RMSE: 0.0541 | Consistency: 0.0095 | SSIM: 0.0368 | Grad: 140899.219\n",
      "[Epoch 25, Batch 82/100] Loss: 0.0500 | RMSE: 0.0468 | Consistency: 0.0097 | SSIM: 0.0308 | Grad: 122192.211\n",
      "[Epoch 25, Batch 83/100] Loss: 0.0525 | RMSE: 0.0489 | Consistency: 0.0100 | SSIM: 0.0349 | Grad: 81226.086\n",
      "[Epoch 25, Batch 84/100] Loss: 0.0453 | RMSE: 0.0417 | Consistency: 0.0083 | SSIM: 0.0349 | Grad: 81003.883\n",
      "[Epoch 25, Batch 85/100] Loss: 0.0542 | RMSE: 0.0507 | Consistency: 0.0123 | SSIM: 0.0340 | Grad: 73018.789\n",
      "[Epoch 25, Batch 86/100] Loss: 0.0548 | RMSE: 0.0512 | Consistency: 0.0120 | SSIM: 0.0357 | Grad: 117395.812\n",
      "[Epoch 25, Batch 87/100] Loss: 0.0527 | RMSE: 0.0493 | Consistency: 0.0128 | SSIM: 0.0328 | Grad: 91165.297\n",
      "[Epoch 25, Batch 88/100] Loss: 0.0589 | RMSE: 0.0548 | Consistency: 0.0140 | SSIM: 0.0394 | Grad: 146898.578\n",
      "[Epoch 25, Batch 89/100] Loss: 0.0553 | RMSE: 0.0522 | Consistency: 0.0091 | SSIM: 0.0307 | Grad: 157319.672\n",
      "[Epoch 25, Batch 90/100] Loss: 0.0468 | RMSE: 0.0433 | Consistency: 0.0103 | SSIM: 0.0346 | Grad: 120340.758\n",
      "[Epoch 25, Batch 91/100] Loss: 0.0551 | RMSE: 0.0513 | Consistency: 0.0132 | SSIM: 0.0367 | Grad: 70726.602\n",
      "[Epoch 25, Batch 92/100] Loss: 0.0551 | RMSE: 0.0514 | Consistency: 0.0094 | SSIM: 0.0359 | Grad: 133084.328\n",
      "[Epoch 25, Batch 93/100] Loss: 0.0528 | RMSE: 0.0497 | Consistency: 0.0114 | SSIM: 0.0293 | Grad: 88808.273\n",
      "[Epoch 25, Batch 94/100] Loss: 0.0488 | RMSE: 0.0452 | Consistency: 0.0086 | SSIM: 0.0343 | Grad: 49667.805\n",
      "[Epoch 25, Batch 95/100] Loss: 0.0524 | RMSE: 0.0484 | Consistency: 0.0145 | SSIM: 0.0380 | Grad: 122227.477\n",
      "[Epoch 25, Batch 96/100] Loss: 0.0578 | RMSE: 0.0537 | Consistency: 0.0156 | SSIM: 0.0391 | Grad: 108995.422\n",
      "[Epoch 25, Batch 97/100] Loss: 0.0542 | RMSE: 0.0498 | Consistency: 0.0103 | SSIM: 0.0428 | Grad: 88091.109\n",
      "[Epoch 25, Batch 98/100] Loss: 0.0501 | RMSE: 0.0468 | Consistency: 0.0124 | SSIM: 0.0320 | Grad: 83813.383\n",
      "[Epoch 25, Batch 99/100] Loss: 0.0581 | RMSE: 0.0531 | Consistency: 0.0148 | SSIM: 0.0489 | Grad: 60390.805\n",
      "[Epoch 25, Batch 100/100] Loss: 0.0453 | RMSE: 0.0420 | Consistency: 0.0097 | SSIM: 0.0323 | Grad: 100099.305\n",
      "✅ Epoch 25 완료!\n",
      "   📈 평균 Loss: 0.055118\n",
      "   📊 평균 RMSE: 0.051403\n",
      "   ⚙️  학습률: 0.000868\n",
      "   🏆 NEW BEST! RMSE: 0.051403\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 26/80 시작...\n",
      "[Epoch 26, Batch 1/100] Loss: 0.0610 | RMSE: 0.0561 | Consistency: 0.0166 | SSIM: 0.0469 | Grad: 112514.445\n",
      "[Epoch 26, Batch 2/100] Loss: 0.0493 | RMSE: 0.0461 | Consistency: 0.0109 | SSIM: 0.0302 | Grad: 60613.762\n",
      "[Epoch 26, Batch 3/100] Loss: 0.0560 | RMSE: 0.0525 | Consistency: 0.0141 | SSIM: 0.0334 | Grad: 130778.539\n",
      "[Epoch 26, Batch 4/100] Loss: 0.0657 | RMSE: 0.0610 | Consistency: 0.0193 | SSIM: 0.0458 | Grad: 152191.812\n",
      "[Epoch 26, Batch 5/100] Loss: 0.0621 | RMSE: 0.0578 | Consistency: 0.0167 | SSIM: 0.0411 | Grad: 99610.836\n",
      "[Epoch 26, Batch 6/100] Loss: 0.0487 | RMSE: 0.0457 | Consistency: 0.0114 | SSIM: 0.0283 | Grad: 33845.949\n",
      "[Epoch 26, Batch 7/100] Loss: 0.0645 | RMSE: 0.0601 | Consistency: 0.0200 | SSIM: 0.0426 | Grad: 91498.133\n",
      "[Epoch 26, Batch 8/100] Loss: 0.0543 | RMSE: 0.0506 | Consistency: 0.0140 | SSIM: 0.0351 | Grad: 66353.438\n",
      "[Epoch 26, Batch 9/100] Loss: 0.0502 | RMSE: 0.0464 | Consistency: 0.0109 | SSIM: 0.0375 | Grad: 68784.078\n",
      "[Epoch 26, Batch 10/100] Loss: 0.0548 | RMSE: 0.0508 | Consistency: 0.0121 | SSIM: 0.0383 | Grad: 101757.242\n",
      "[Epoch 26, Batch 11/100] Loss: 0.0589 | RMSE: 0.0556 | Consistency: 0.0136 | SSIM: 0.0312 | Grad: 79014.750\n",
      "[Epoch 26, Batch 12/100] Loss: 0.0516 | RMSE: 0.0484 | Consistency: 0.0108 | SSIM: 0.0309 | Grad: 73257.586\n",
      "[Epoch 26, Batch 13/100] Loss: 0.0478 | RMSE: 0.0443 | Consistency: 0.0096 | SSIM: 0.0345 | Grad: 103888.008\n",
      "[Epoch 26, Batch 14/100] Loss: 0.0536 | RMSE: 0.0492 | Consistency: 0.0150 | SSIM: 0.0426 | Grad: 84633.414\n",
      "[Epoch 26, Batch 15/100] Loss: 0.0511 | RMSE: 0.0473 | Consistency: 0.0142 | SSIM: 0.0367 | Grad: 106746.164\n",
      "[Epoch 26, Batch 16/100] Loss: 0.0633 | RMSE: 0.0587 | Consistency: 0.0165 | SSIM: 0.0444 | Grad: 87193.727\n",
      "[Epoch 26, Batch 17/100] Loss: 0.0498 | RMSE: 0.0464 | Consistency: 0.0122 | SSIM: 0.0327 | Grad: 35890.223\n",
      "[Epoch 26, Batch 18/100] Loss: 0.0517 | RMSE: 0.0484 | Consistency: 0.0125 | SSIM: 0.0324 | Grad: 110397.789\n",
      "[Epoch 26, Batch 19/100] Loss: 0.0548 | RMSE: 0.0513 | Consistency: 0.0166 | SSIM: 0.0339 | Grad: 145586.969\n",
      "[Epoch 26, Batch 20/100] Loss: 0.0555 | RMSE: 0.0521 | Consistency: 0.0137 | SSIM: 0.0326 | Grad: 132668.938\n",
      "[Epoch 26, Batch 21/100] Loss: 0.0507 | RMSE: 0.0465 | Consistency: 0.0118 | SSIM: 0.0400 | Grad: 60868.898\n",
      "[Epoch 26, Batch 22/100] Loss: 0.0499 | RMSE: 0.0460 | Consistency: 0.0106 | SSIM: 0.0377 | Grad: 97603.125\n",
      "[Epoch 26, Batch 23/100] Loss: 0.0637 | RMSE: 0.0593 | Consistency: 0.0219 | SSIM: 0.0423 | Grad: 153208.734\n",
      "[Epoch 26, Batch 24/100] Loss: 0.0598 | RMSE: 0.0560 | Consistency: 0.0144 | SSIM: 0.0363 | Grad: 101738.023\n",
      "[Epoch 26, Batch 25/100] Loss: 0.0501 | RMSE: 0.0459 | Consistency: 0.0131 | SSIM: 0.0412 | Grad: 81184.000\n",
      "[Epoch 26, Batch 26/100] Loss: 0.0509 | RMSE: 0.0471 | Consistency: 0.0111 | SSIM: 0.0363 | Grad: 69068.078\n",
      "[Epoch 26, Batch 27/100] Loss: 0.0458 | RMSE: 0.0427 | Consistency: 0.0114 | SSIM: 0.0303 | Grad: 66366.984\n",
      "[Epoch 26, Batch 28/100] Loss: 0.0590 | RMSE: 0.0548 | Consistency: 0.0130 | SSIM: 0.0411 | Grad: 105273.883\n",
      "[Epoch 26, Batch 29/100] Loss: 0.0580 | RMSE: 0.0543 | Consistency: 0.0142 | SSIM: 0.0354 | Grad: 44677.480\n",
      "[Epoch 26, Batch 30/100] Loss: 0.0585 | RMSE: 0.0551 | Consistency: 0.0127 | SSIM: 0.0326 | Grad: 144670.984\n",
      "[Epoch 26, Batch 31/100] Loss: 0.0540 | RMSE: 0.0505 | Consistency: 0.0111 | SSIM: 0.0334 | Grad: 116039.641\n",
      "[Epoch 26, Batch 32/100] Loss: 0.0467 | RMSE: 0.0435 | Consistency: 0.0107 | SSIM: 0.0312 | Grad: 36181.305\n",
      "[Epoch 26, Batch 33/100] Loss: 0.0496 | RMSE: 0.0458 | Consistency: 0.0115 | SSIM: 0.0370 | Grad: 113961.195\n",
      "[Epoch 26, Batch 34/100] Loss: 0.0560 | RMSE: 0.0523 | Consistency: 0.0136 | SSIM: 0.0365 | Grad: 87893.664\n",
      "[Epoch 26, Batch 35/100] Loss: 0.0508 | RMSE: 0.0477 | Consistency: 0.0108 | SSIM: 0.0298 | Grad: 74683.500\n",
      "[Epoch 26, Batch 36/100] Loss: 0.0535 | RMSE: 0.0497 | Consistency: 0.0151 | SSIM: 0.0367 | Grad: 48719.430\n",
      "[Epoch 26, Batch 37/100] Loss: 0.0639 | RMSE: 0.0601 | Consistency: 0.0221 | SSIM: 0.0360 | Grad: 53268.449\n",
      "[Epoch 26, Batch 38/100] Loss: 0.0547 | RMSE: 0.0514 | Consistency: 0.0140 | SSIM: 0.0319 | Grad: 141479.516\n",
      "[Epoch 26, Batch 39/100] Loss: 0.0464 | RMSE: 0.0431 | Consistency: 0.0099 | SSIM: 0.0320 | Grad: 36834.273\n",
      "[Epoch 26, Batch 40/100] Loss: 0.0532 | RMSE: 0.0496 | Consistency: 0.0121 | SSIM: 0.0349 | Grad: 83368.844\n",
      "[Epoch 26, Batch 41/100] Loss: 0.0602 | RMSE: 0.0564 | Consistency: 0.0191 | SSIM: 0.0362 | Grad: 131820.984\n",
      "[Epoch 26, Batch 42/100] Loss: 0.0531 | RMSE: 0.0495 | Consistency: 0.0135 | SSIM: 0.0349 | Grad: 55072.383\n",
      "[Epoch 26, Batch 43/100] Loss: 0.0510 | RMSE: 0.0473 | Consistency: 0.0113 | SSIM: 0.0356 | Grad: 99069.867\n",
      "[Epoch 26, Batch 44/100] Loss: 0.0643 | RMSE: 0.0602 | Consistency: 0.0163 | SSIM: 0.0401 | Grad: 108051.414\n",
      "[Epoch 26, Batch 45/100] Loss: 0.0543 | RMSE: 0.0510 | Consistency: 0.0108 | SSIM: 0.0320 | Grad: 37616.934\n",
      "[Epoch 26, Batch 46/100] Loss: 0.0575 | RMSE: 0.0530 | Consistency: 0.0136 | SSIM: 0.0440 | Grad: 133574.391\n",
      "[Epoch 26, Batch 47/100] Loss: 0.0650 | RMSE: 0.0604 | Consistency: 0.0245 | SSIM: 0.0435 | Grad: 77010.328\n",
      "[Epoch 26, Batch 48/100] Loss: 0.0536 | RMSE: 0.0502 | Consistency: 0.0115 | SSIM: 0.0331 | Grad: 107921.125\n",
      "[Epoch 26, Batch 49/100] Loss: 0.0525 | RMSE: 0.0490 | Consistency: 0.0138 | SSIM: 0.0340 | Grad: 45950.141\n",
      "[Epoch 26, Batch 50/100] Loss: 0.0534 | RMSE: 0.0499 | Consistency: 0.0117 | SSIM: 0.0335 | Grad: 123191.125\n",
      "[Epoch 26, Batch 51/100] Loss: 0.0610 | RMSE: 0.0567 | Consistency: 0.0169 | SSIM: 0.0408 | Grad: 122535.164\n",
      "[Epoch 26, Batch 52/100] Loss: 0.0646 | RMSE: 0.0604 | Consistency: 0.0186 | SSIM: 0.0399 | Grad: 120609.867\n",
      "[Epoch 26, Batch 53/100] Loss: 0.0590 | RMSE: 0.0555 | Consistency: 0.0144 | SSIM: 0.0340 | Grad: 90046.570\n",
      "[Epoch 26, Batch 54/100] Loss: 0.0619 | RMSE: 0.0582 | Consistency: 0.0130 | SSIM: 0.0359 | Grad: 131042.273\n",
      "[Epoch 26, Batch 55/100] Loss: 0.0544 | RMSE: 0.0505 | Consistency: 0.0136 | SSIM: 0.0378 | Grad: 76474.906\n",
      "[Epoch 26, Batch 56/100] Loss: 0.0718 | RMSE: 0.0670 | Consistency: 0.0170 | SSIM: 0.0462 | Grad: 133906.406\n",
      "[Epoch 26, Batch 57/100] Loss: 0.0566 | RMSE: 0.0526 | Consistency: 0.0158 | SSIM: 0.0389 | Grad: 60735.762\n",
      "[Epoch 26, Batch 58/100] Loss: 0.0516 | RMSE: 0.0484 | Consistency: 0.0154 | SSIM: 0.0301 | Grad: 131471.562\n",
      "[Epoch 26, Batch 59/100] Loss: 0.0569 | RMSE: 0.0528 | Consistency: 0.0152 | SSIM: 0.0391 | Grad: 84417.875\n",
      "[Epoch 26, Batch 60/100] Loss: 0.0478 | RMSE: 0.0447 | Consistency: 0.0120 | SSIM: 0.0294 | Grad: 58209.660\n",
      "[Epoch 26, Batch 61/100] Loss: 0.0492 | RMSE: 0.0465 | Consistency: 0.0122 | SSIM: 0.0261 | Grad: 77761.359\n",
      "[Epoch 26, Batch 62/100] Loss: 0.0548 | RMSE: 0.0513 | Consistency: 0.0137 | SSIM: 0.0338 | Grad: 124432.023\n",
      "[Epoch 26, Batch 63/100] Loss: 0.0603 | RMSE: 0.0563 | Consistency: 0.0126 | SSIM: 0.0386 | Grad: 60236.855\n",
      "[Epoch 26, Batch 64/100] Loss: 0.0515 | RMSE: 0.0473 | Consistency: 0.0112 | SSIM: 0.0413 | Grad: 98243.312\n",
      "[Epoch 26, Batch 65/100] Loss: 0.0514 | RMSE: 0.0476 | Consistency: 0.0100 | SSIM: 0.0372 | Grad: 115072.805\n",
      "[Epoch 26, Batch 66/100] Loss: 0.0585 | RMSE: 0.0549 | Consistency: 0.0125 | SSIM: 0.0351 | Grad: 114959.391\n",
      "[Epoch 26, Batch 67/100] Loss: 0.0493 | RMSE: 0.0457 | Consistency: 0.0121 | SSIM: 0.0344 | Grad: 32482.018\n",
      "[Epoch 26, Batch 68/100] Loss: 0.0627 | RMSE: 0.0585 | Consistency: 0.0158 | SSIM: 0.0408 | Grad: 119593.484\n",
      "[Epoch 26, Batch 69/100] Loss: 0.0617 | RMSE: 0.0580 | Consistency: 0.0207 | SSIM: 0.0350 | Grad: 106070.828\n",
      "[Epoch 26, Batch 70/100] Loss: 0.0623 | RMSE: 0.0586 | Consistency: 0.0186 | SSIM: 0.0350 | Grad: 88410.711\n",
      "[Epoch 26, Batch 71/100] Loss: 0.0560 | RMSE: 0.0521 | Consistency: 0.0126 | SSIM: 0.0379 | Grad: 91337.914\n",
      "[Epoch 26, Batch 72/100] Loss: 0.0649 | RMSE: 0.0605 | Consistency: 0.0182 | SSIM: 0.0417 | Grad: 101629.820\n",
      "[Epoch 26, Batch 73/100] Loss: 0.0564 | RMSE: 0.0525 | Consistency: 0.0153 | SSIM: 0.0370 | Grad: 87094.398\n",
      "[Epoch 26, Batch 74/100] Loss: 0.0485 | RMSE: 0.0454 | Consistency: 0.0112 | SSIM: 0.0290 | Grad: 34031.418\n",
      "[Epoch 26, Batch 75/100] Loss: 0.0539 | RMSE: 0.0505 | Consistency: 0.0137 | SSIM: 0.0318 | Grad: 67837.695\n",
      "[Epoch 26, Batch 76/100] Loss: 0.0532 | RMSE: 0.0501 | Consistency: 0.0134 | SSIM: 0.0305 | Grad: 100363.836\n",
      "[Epoch 26, Batch 77/100] Loss: 0.0608 | RMSE: 0.0567 | Consistency: 0.0148 | SSIM: 0.0391 | Grad: 69942.523\n",
      "[Epoch 26, Batch 78/100] Loss: 0.0578 | RMSE: 0.0535 | Consistency: 0.0159 | SSIM: 0.0407 | Grad: 112446.414\n",
      "[Epoch 26, Batch 79/100] Loss: 0.0578 | RMSE: 0.0538 | Consistency: 0.0183 | SSIM: 0.0383 | Grad: 121322.359\n",
      "[Epoch 26, Batch 80/100] Loss: 0.0575 | RMSE: 0.0538 | Consistency: 0.0141 | SSIM: 0.0357 | Grad: 76970.219\n",
      "[Epoch 26, Batch 81/100] Loss: 0.0539 | RMSE: 0.0503 | Consistency: 0.0131 | SSIM: 0.0346 | Grad: 89847.078\n",
      "[Epoch 26, Batch 82/100] Loss: 0.0506 | RMSE: 0.0468 | Consistency: 0.0121 | SSIM: 0.0366 | Grad: 78019.914\n",
      "[Epoch 26, Batch 83/100] Loss: 0.0562 | RMSE: 0.0530 | Consistency: 0.0130 | SSIM: 0.0310 | Grad: 150306.047\n",
      "[Epoch 26, Batch 84/100] Loss: 0.0575 | RMSE: 0.0533 | Consistency: 0.0145 | SSIM: 0.0409 | Grad: 37713.215\n",
      "[Epoch 26, Batch 85/100] Loss: 0.0541 | RMSE: 0.0510 | Consistency: 0.0122 | SSIM: 0.0295 | Grad: 113884.141\n",
      "[Epoch 26, Batch 86/100] Loss: 0.0589 | RMSE: 0.0557 | Consistency: 0.0126 | SSIM: 0.0311 | Grad: 134154.062\n",
      "[Epoch 26, Batch 87/100] Loss: 0.0576 | RMSE: 0.0534 | Consistency: 0.0170 | SSIM: 0.0403 | Grad: 77086.781\n",
      "[Epoch 26, Batch 88/100] Loss: 0.0628 | RMSE: 0.0589 | Consistency: 0.0136 | SSIM: 0.0380 | Grad: 149177.094\n",
      "[Epoch 26, Batch 89/100] Loss: 0.0496 | RMSE: 0.0466 | Consistency: 0.0110 | SSIM: 0.0284 | Grad: 64345.273\n",
      "[Epoch 26, Batch 90/100] Loss: 0.0508 | RMSE: 0.0470 | Consistency: 0.0136 | SSIM: 0.0366 | Grad: 64316.633\n",
      "[Epoch 26, Batch 91/100] Loss: 0.0510 | RMSE: 0.0478 | Consistency: 0.0122 | SSIM: 0.0305 | Grad: 66505.602\n",
      "[Epoch 26, Batch 92/100] Loss: 0.0462 | RMSE: 0.0424 | Consistency: 0.0102 | SSIM: 0.0372 | Grad: 90982.016\n",
      "[Epoch 26, Batch 93/100] Loss: 0.0517 | RMSE: 0.0481 | Consistency: 0.0107 | SSIM: 0.0349 | Grad: 93675.008\n",
      "[Epoch 26, Batch 94/100] Loss: 0.0546 | RMSE: 0.0511 | Consistency: 0.0114 | SSIM: 0.0330 | Grad: 141795.578\n",
      "[Epoch 26, Batch 95/100] Loss: 0.0544 | RMSE: 0.0510 | Consistency: 0.0107 | SSIM: 0.0327 | Grad: 137224.406\n",
      "[Epoch 26, Batch 96/100] Loss: 0.0479 | RMSE: 0.0442 | Consistency: 0.0105 | SSIM: 0.0360 | Grad: 27761.121\n",
      "[Epoch 26, Batch 97/100] Loss: 0.0446 | RMSE: 0.0417 | Consistency: 0.0103 | SSIM: 0.0281 | Grad: 38060.664\n",
      "[Epoch 26, Batch 98/100] Loss: 0.0521 | RMSE: 0.0485 | Consistency: 0.0124 | SSIM: 0.0348 | Grad: 62452.578\n",
      "[Epoch 26, Batch 99/100] Loss: 0.0535 | RMSE: 0.0497 | Consistency: 0.0119 | SSIM: 0.0371 | Grad: 82764.742\n",
      "[Epoch 26, Batch 100/100] Loss: 0.0492 | RMSE: 0.0461 | Consistency: 0.0111 | SSIM: 0.0299 | Grad: 77980.945\n",
      "✅ Epoch 26 완료!\n",
      "   📈 평균 Loss: 0.055162\n",
      "   📊 평균 RMSE: 0.051441\n",
      "   ⚙️  학습률: 0.000853\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 27/80 시작...\n",
      "[Epoch 27, Batch 1/100] Loss: 0.0461 | RMSE: 0.0431 | Consistency: 0.0098 | SSIM: 0.0287 | Grad: 67352.125\n",
      "[Epoch 27, Batch 2/100] Loss: 0.0530 | RMSE: 0.0497 | Consistency: 0.0132 | SSIM: 0.0319 | Grad: 118571.312\n",
      "[Epoch 27, Batch 3/100] Loss: 0.0470 | RMSE: 0.0438 | Consistency: 0.0088 | SSIM: 0.0305 | Grad: 123115.383\n",
      "[Epoch 27, Batch 4/100] Loss: 0.0501 | RMSE: 0.0465 | Consistency: 0.0115 | SSIM: 0.0349 | Grad: 45998.504\n",
      "[Epoch 27, Batch 5/100] Loss: 0.0506 | RMSE: 0.0469 | Consistency: 0.0129 | SSIM: 0.0350 | Grad: 72189.047\n",
      "[Epoch 27, Batch 6/100] Loss: 0.0567 | RMSE: 0.0531 | Consistency: 0.0138 | SSIM: 0.0351 | Grad: 134419.609\n",
      "[Epoch 27, Batch 7/100] Loss: 0.0671 | RMSE: 0.0620 | Consistency: 0.0252 | SSIM: 0.0478 | Grad: 126435.844\n",
      "[Epoch 27, Batch 8/100] Loss: 0.0491 | RMSE: 0.0456 | Consistency: 0.0122 | SSIM: 0.0334 | Grad: 69098.961\n",
      "[Epoch 27, Batch 9/100] Loss: 0.0605 | RMSE: 0.0562 | Consistency: 0.0160 | SSIM: 0.0410 | Grad: 78497.969\n",
      "[Epoch 27, Batch 10/100] Loss: 0.0646 | RMSE: 0.0599 | Consistency: 0.0241 | SSIM: 0.0450 | Grad: 109460.656\n",
      "[Epoch 27, Batch 11/100] Loss: 0.0663 | RMSE: 0.0617 | Consistency: 0.0221 | SSIM: 0.0436 | Grad: 96696.570\n",
      "[Epoch 27, Batch 12/100] Loss: 0.0542 | RMSE: 0.0507 | Consistency: 0.0110 | SSIM: 0.0342 | Grad: 128230.711\n",
      "[Epoch 27, Batch 13/100] Loss: 0.0608 | RMSE: 0.0563 | Consistency: 0.0183 | SSIM: 0.0431 | Grad: 91893.664\n",
      "[Epoch 27, Batch 14/100] Loss: 0.0627 | RMSE: 0.0582 | Consistency: 0.0157 | SSIM: 0.0434 | Grad: 109665.906\n",
      "[Epoch 27, Batch 15/100] Loss: 0.0545 | RMSE: 0.0507 | Consistency: 0.0128 | SSIM: 0.0367 | Grad: 97496.633\n",
      "[Epoch 27, Batch 16/100] Loss: 0.0512 | RMSE: 0.0479 | Consistency: 0.0123 | SSIM: 0.0315 | Grad: 56155.500\n",
      "[Epoch 27, Batch 17/100] Loss: 0.0505 | RMSE: 0.0475 | Consistency: 0.0129 | SSIM: 0.0287 | Grad: 170340.609\n",
      "[Epoch 27, Batch 18/100] Loss: 0.0636 | RMSE: 0.0596 | Consistency: 0.0167 | SSIM: 0.0391 | Grad: 140528.062\n",
      "[Epoch 27, Batch 19/100] Loss: 0.0520 | RMSE: 0.0488 | Consistency: 0.0104 | SSIM: 0.0307 | Grad: 103732.695\n",
      "[Epoch 27, Batch 20/100] Loss: 0.0551 | RMSE: 0.0516 | Consistency: 0.0169 | SSIM: 0.0337 | Grad: 108733.164\n",
      "[Epoch 27, Batch 21/100] Loss: 0.0540 | RMSE: 0.0501 | Consistency: 0.0121 | SSIM: 0.0372 | Grad: 119348.938\n",
      "[Epoch 27, Batch 22/100] Loss: 0.0503 | RMSE: 0.0472 | Consistency: 0.0094 | SSIM: 0.0307 | Grad: 152415.750\n",
      "[Epoch 27, Batch 23/100] Loss: 0.0489 | RMSE: 0.0453 | Consistency: 0.0109 | SSIM: 0.0347 | Grad: 31459.697\n",
      "[Epoch 27, Batch 24/100] Loss: 0.0556 | RMSE: 0.0517 | Consistency: 0.0113 | SSIM: 0.0374 | Grad: 147087.875\n",
      "[Epoch 27, Batch 25/100] Loss: 0.0615 | RMSE: 0.0571 | Consistency: 0.0137 | SSIM: 0.0432 | Grad: 85870.688\n",
      "[Epoch 27, Batch 26/100] Loss: 0.0587 | RMSE: 0.0542 | Consistency: 0.0156 | SSIM: 0.0434 | Grad: 67604.023\n",
      "[Epoch 27, Batch 27/100] Loss: 0.0521 | RMSE: 0.0482 | Consistency: 0.0124 | SSIM: 0.0384 | Grad: 66821.188\n",
      "[Epoch 27, Batch 28/100] Loss: 0.0487 | RMSE: 0.0456 | Consistency: 0.0104 | SSIM: 0.0295 | Grad: 81595.570\n",
      "[Epoch 27, Batch 29/100] Loss: 0.0557 | RMSE: 0.0518 | Consistency: 0.0138 | SSIM: 0.0381 | Grad: 93884.883\n",
      "[Epoch 27, Batch 30/100] Loss: 0.0511 | RMSE: 0.0475 | Consistency: 0.0100 | SSIM: 0.0357 | Grad: 114404.375\n",
      "[Epoch 27, Batch 31/100] Loss: 0.0491 | RMSE: 0.0457 | Consistency: 0.0096 | SSIM: 0.0327 | Grad: 68974.953\n",
      "[Epoch 27, Batch 32/100] Loss: 0.0546 | RMSE: 0.0511 | Consistency: 0.0121 | SSIM: 0.0343 | Grad: 109374.922\n",
      "[Epoch 27, Batch 33/100] Loss: 0.0540 | RMSE: 0.0498 | Consistency: 0.0102 | SSIM: 0.0413 | Grad: 104139.016\n",
      "[Epoch 27, Batch 34/100] Loss: 0.0720 | RMSE: 0.0671 | Consistency: 0.0272 | SSIM: 0.0461 | Grad: 55420.078\n",
      "[Epoch 27, Batch 35/100] Loss: 0.0677 | RMSE: 0.0627 | Consistency: 0.0162 | SSIM: 0.0478 | Grad: 176260.406\n",
      "[Epoch 27, Batch 36/100] Loss: 0.0674 | RMSE: 0.0636 | Consistency: 0.0182 | SSIM: 0.0360 | Grad: 185349.984\n",
      "[Epoch 27, Batch 37/100] Loss: 0.0685 | RMSE: 0.0641 | Consistency: 0.0107 | SSIM: 0.0436 | Grad: 189439.422\n",
      "[Epoch 27, Batch 38/100] Loss: 0.0622 | RMSE: 0.0576 | Consistency: 0.0150 | SSIM: 0.0442 | Grad: 96578.578\n",
      "[Epoch 27, Batch 39/100] Loss: 0.0479 | RMSE: 0.0440 | Consistency: 0.0095 | SSIM: 0.0386 | Grad: 20240.189\n",
      "[Epoch 27, Batch 40/100] Loss: 0.0693 | RMSE: 0.0649 | Consistency: 0.0151 | SSIM: 0.0429 | Grad: 146919.328\n",
      "[Epoch 27, Batch 41/100] Loss: 0.0722 | RMSE: 0.0675 | Consistency: 0.0205 | SSIM: 0.0453 | Grad: 139970.938\n",
      "[Epoch 27, Batch 42/100] Loss: 0.0611 | RMSE: 0.0567 | Consistency: 0.0181 | SSIM: 0.0416 | Grad: 89208.375\n",
      "[Epoch 27, Batch 43/100] Loss: 0.0587 | RMSE: 0.0547 | Consistency: 0.0143 | SSIM: 0.0388 | Grad: 126778.797\n",
      "[Epoch 27, Batch 44/100] Loss: 0.0582 | RMSE: 0.0542 | Consistency: 0.0125 | SSIM: 0.0389 | Grad: 112606.023\n",
      "[Epoch 27, Batch 45/100] Loss: 0.0902 | RMSE: 0.0838 | Consistency: 0.0426 | SSIM: 0.0597 | Grad: 137293.859\n",
      "[Epoch 27, Batch 46/100] Loss: 0.0567 | RMSE: 0.0519 | Consistency: 0.0133 | SSIM: 0.0465 | Grad: 84689.078\n",
      "[Epoch 27, Batch 47/100] Loss: 0.0545 | RMSE: 0.0505 | Consistency: 0.0136 | SSIM: 0.0383 | Grad: 77051.203\n",
      "[Epoch 27, Batch 48/100] Loss: 0.0539 | RMSE: 0.0502 | Consistency: 0.0134 | SSIM: 0.0351 | Grad: 102403.812\n",
      "[Epoch 27, Batch 49/100] Loss: 0.0652 | RMSE: 0.0605 | Consistency: 0.0165 | SSIM: 0.0450 | Grad: 104386.320\n",
      "[Epoch 27, Batch 50/100] Loss: 0.0574 | RMSE: 0.0534 | Consistency: 0.0161 | SSIM: 0.0383 | Grad: 72090.969\n",
      "[Epoch 27, Batch 51/100] Loss: 0.0449 | RMSE: 0.0417 | Consistency: 0.0095 | SSIM: 0.0309 | Grad: 43873.688\n",
      "[Epoch 27, Batch 52/100] Loss: 0.0629 | RMSE: 0.0587 | Consistency: 0.0178 | SSIM: 0.0399 | Grad: 113245.055\n",
      "[Epoch 27, Batch 53/100] Loss: 0.0564 | RMSE: 0.0530 | Consistency: 0.0144 | SSIM: 0.0320 | Grad: 137652.375\n",
      "[Epoch 27, Batch 54/100] Loss: 0.0579 | RMSE: 0.0535 | Consistency: 0.0147 | SSIM: 0.0419 | Grad: 109179.188\n",
      "[Epoch 27, Batch 55/100] Loss: 0.0554 | RMSE: 0.0514 | Consistency: 0.0134 | SSIM: 0.0380 | Grad: 49223.496\n",
      "[Epoch 27, Batch 56/100] Loss: 0.0665 | RMSE: 0.0623 | Consistency: 0.0242 | SSIM: 0.0400 | Grad: 131754.797\n",
      "[Epoch 27, Batch 57/100] Loss: 0.0642 | RMSE: 0.0602 | Consistency: 0.0251 | SSIM: 0.0374 | Grad: 107693.688\n",
      "[Epoch 27, Batch 58/100] Loss: 0.0554 | RMSE: 0.0519 | Consistency: 0.0137 | SSIM: 0.0334 | Grad: 108079.516\n",
      "[Epoch 27, Batch 59/100] Loss: 0.0534 | RMSE: 0.0497 | Consistency: 0.0134 | SSIM: 0.0361 | Grad: 114688.078\n",
      "[Epoch 27, Batch 60/100] Loss: 0.0555 | RMSE: 0.0518 | Consistency: 0.0152 | SSIM: 0.0354 | Grad: 129780.984\n",
      "[Epoch 27, Batch 61/100] Loss: 0.0626 | RMSE: 0.0586 | Consistency: 0.0158 | SSIM: 0.0378 | Grad: 141745.047\n",
      "[Epoch 27, Batch 62/100] Loss: 0.0499 | RMSE: 0.0471 | Consistency: 0.0105 | SSIM: 0.0264 | Grad: 63651.379\n",
      "[Epoch 27, Batch 63/100] Loss: 0.0603 | RMSE: 0.0562 | Consistency: 0.0146 | SSIM: 0.0397 | Grad: 136571.906\n",
      "[Epoch 27, Batch 64/100] Loss: 0.0597 | RMSE: 0.0563 | Consistency: 0.0136 | SSIM: 0.0320 | Grad: 173865.969\n",
      "[Epoch 27, Batch 65/100] Loss: 0.0455 | RMSE: 0.0420 | Consistency: 0.0086 | SSIM: 0.0334 | Grad: 93102.484\n",
      "[Epoch 27, Batch 66/100] Loss: 0.0523 | RMSE: 0.0489 | Consistency: 0.0127 | SSIM: 0.0326 | Grad: 80386.461\n",
      "[Epoch 27, Batch 67/100] Loss: 0.0611 | RMSE: 0.0568 | Consistency: 0.0177 | SSIM: 0.0411 | Grad: 115552.430\n",
      "[Epoch 27, Batch 68/100] Loss: 0.0509 | RMSE: 0.0474 | Consistency: 0.0110 | SSIM: 0.0337 | Grad: 99934.734\n",
      "[Epoch 27, Batch 69/100] Loss: 0.0504 | RMSE: 0.0474 | Consistency: 0.0108 | SSIM: 0.0284 | Grad: 84096.148\n",
      "[Epoch 27, Batch 70/100] Loss: 0.0497 | RMSE: 0.0455 | Consistency: 0.0104 | SSIM: 0.0410 | Grad: 28324.193\n",
      "[Epoch 27, Batch 71/100] Loss: 0.0413 | RMSE: 0.0386 | Consistency: 0.0091 | SSIM: 0.0255 | Grad: 55069.062\n",
      "[Epoch 27, Batch 72/100] Loss: 0.0535 | RMSE: 0.0499 | Consistency: 0.0141 | SSIM: 0.0344 | Grad: 97566.211\n",
      "[Epoch 27, Batch 73/100] Loss: 0.0486 | RMSE: 0.0452 | Consistency: 0.0114 | SSIM: 0.0327 | Grad: 47117.660\n",
      "[Epoch 27, Batch 74/100] Loss: 0.0587 | RMSE: 0.0556 | Consistency: 0.0135 | SSIM: 0.0291 | Grad: 98229.992\n",
      "[Epoch 27, Batch 75/100] Loss: 0.0524 | RMSE: 0.0490 | Consistency: 0.0144 | SSIM: 0.0326 | Grad: 56835.578\n",
      "[Epoch 27, Batch 76/100] Loss: 0.0539 | RMSE: 0.0506 | Consistency: 0.0125 | SSIM: 0.0321 | Grad: 92759.625\n",
      "[Epoch 27, Batch 77/100] Loss: 0.0499 | RMSE: 0.0468 | Consistency: 0.0128 | SSIM: 0.0288 | Grad: 145031.141\n",
      "[Epoch 27, Batch 78/100] Loss: 0.0507 | RMSE: 0.0469 | Consistency: 0.0094 | SSIM: 0.0373 | Grad: 134449.688\n",
      "[Epoch 27, Batch 79/100] Loss: 0.0461 | RMSE: 0.0435 | Consistency: 0.0098 | SSIM: 0.0251 | Grad: 94891.250\n",
      "[Epoch 27, Batch 80/100] Loss: 0.0491 | RMSE: 0.0461 | Consistency: 0.0112 | SSIM: 0.0289 | Grad: 107400.633\n",
      "[Epoch 27, Batch 81/100] Loss: 0.0537 | RMSE: 0.0498 | Consistency: 0.0131 | SSIM: 0.0376 | Grad: 100491.109\n",
      "[Epoch 27, Batch 82/100] Loss: 0.0512 | RMSE: 0.0479 | Consistency: 0.0117 | SSIM: 0.0313 | Grad: 52338.344\n",
      "[Epoch 27, Batch 83/100] Loss: 0.0610 | RMSE: 0.0571 | Consistency: 0.0167 | SSIM: 0.0376 | Grad: 30613.734\n",
      "[Epoch 27, Batch 84/100] Loss: 0.0565 | RMSE: 0.0527 | Consistency: 0.0158 | SSIM: 0.0360 | Grad: 57906.320\n",
      "[Epoch 27, Batch 85/100] Loss: 0.0513 | RMSE: 0.0479 | Consistency: 0.0114 | SSIM: 0.0323 | Grad: 101190.703\n",
      "[Epoch 27, Batch 86/100] Loss: 0.0522 | RMSE: 0.0487 | Consistency: 0.0140 | SSIM: 0.0330 | Grad: 89386.945\n",
      "[Epoch 27, Batch 87/100] Loss: 0.0454 | RMSE: 0.0421 | Consistency: 0.0095 | SSIM: 0.0316 | Grad: 47957.117\n",
      "[Epoch 27, Batch 88/100] Loss: 0.0599 | RMSE: 0.0565 | Consistency: 0.0143 | SSIM: 0.0330 | Grad: 72044.781\n",
      "[Epoch 27, Batch 89/100] Loss: 0.0500 | RMSE: 0.0464 | Consistency: 0.0115 | SSIM: 0.0345 | Grad: 65917.188\n",
      "[Epoch 27, Batch 90/100] Loss: 0.0590 | RMSE: 0.0553 | Consistency: 0.0137 | SSIM: 0.0357 | Grad: 162793.281\n",
      "[Epoch 27, Batch 91/100] Loss: 0.0543 | RMSE: 0.0505 | Consistency: 0.0111 | SSIM: 0.0362 | Grad: 105638.570\n",
      "[Epoch 27, Batch 92/100] Loss: 0.0569 | RMSE: 0.0528 | Consistency: 0.0154 | SSIM: 0.0395 | Grad: 95251.727\n",
      "[Epoch 27, Batch 93/100] Loss: 0.0512 | RMSE: 0.0480 | Consistency: 0.0107 | SSIM: 0.0311 | Grad: 111253.836\n",
      "[Epoch 27, Batch 94/100] Loss: 0.0593 | RMSE: 0.0554 | Consistency: 0.0137 | SSIM: 0.0381 | Grad: 119887.086\n",
      "[Epoch 27, Batch 95/100] Loss: 0.0544 | RMSE: 0.0508 | Consistency: 0.0151 | SSIM: 0.0345 | Grad: 109322.633\n",
      "[Epoch 27, Batch 96/100] Loss: 0.0564 | RMSE: 0.0528 | Consistency: 0.0134 | SSIM: 0.0345 | Grad: 87756.383\n",
      "[Epoch 27, Batch 97/100] Loss: 0.0551 | RMSE: 0.0507 | Consistency: 0.0114 | SSIM: 0.0431 | Grad: 145089.250\n",
      "[Epoch 27, Batch 98/100] Loss: 0.0511 | RMSE: 0.0475 | Consistency: 0.0125 | SSIM: 0.0353 | Grad: 106302.711\n",
      "[Epoch 27, Batch 99/100] Loss: 0.0570 | RMSE: 0.0535 | Consistency: 0.0176 | SSIM: 0.0336 | Grad: 130313.758\n",
      "[Epoch 27, Batch 100/100] Loss: 0.0527 | RMSE: 0.0489 | Consistency: 0.0111 | SSIM: 0.0371 | Grad: 72350.805\n",
      "✅ Epoch 27 완료!\n",
      "   📈 평균 Loss: 0.056002\n",
      "   📊 평균 RMSE: 0.052207\n",
      "   ⚙️  학습률: 0.000838\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 28/80 시작...\n",
      "[Epoch 28, Batch 1/100] Loss: 0.0509 | RMSE: 0.0475 | Consistency: 0.0115 | SSIM: 0.0331 | Grad: 96424.312\n",
      "[Epoch 28, Batch 2/100] Loss: 0.0569 | RMSE: 0.0537 | Consistency: 0.0143 | SSIM: 0.0304 | Grad: 136954.141\n",
      "[Epoch 28, Batch 3/100] Loss: 0.0507 | RMSE: 0.0474 | Consistency: 0.0107 | SSIM: 0.0327 | Grad: 81307.992\n",
      "[Epoch 28, Batch 4/100] Loss: 0.0581 | RMSE: 0.0541 | Consistency: 0.0173 | SSIM: 0.0380 | Grad: 168964.297\n",
      "[Epoch 28, Batch 5/100] Loss: 0.0607 | RMSE: 0.0567 | Consistency: 0.0176 | SSIM: 0.0384 | Grad: 164057.297\n",
      "[Epoch 28, Batch 6/100] Loss: 0.0544 | RMSE: 0.0514 | Consistency: 0.0146 | SSIM: 0.0279 | Grad: 176937.203\n",
      "[Epoch 28, Batch 7/100] Loss: 0.0501 | RMSE: 0.0471 | Consistency: 0.0102 | SSIM: 0.0290 | Grad: 121754.672\n",
      "[Epoch 28, Batch 8/100] Loss: 0.0570 | RMSE: 0.0533 | Consistency: 0.0122 | SSIM: 0.0355 | Grad: 107471.867\n",
      "[Epoch 28, Batch 9/100] Loss: 0.0507 | RMSE: 0.0468 | Consistency: 0.0105 | SSIM: 0.0389 | Grad: 142482.562\n",
      "[Epoch 28, Batch 10/100] Loss: 0.0495 | RMSE: 0.0461 | Consistency: 0.0110 | SSIM: 0.0330 | Grad: 43420.184\n",
      "[Epoch 28, Batch 11/100] Loss: 0.0528 | RMSE: 0.0493 | Consistency: 0.0104 | SSIM: 0.0341 | Grad: 97682.320\n",
      "[Epoch 28, Batch 12/100] Loss: 0.0565 | RMSE: 0.0529 | Consistency: 0.0161 | SSIM: 0.0343 | Grad: 76323.891\n",
      "[Epoch 28, Batch 13/100] Loss: 0.0504 | RMSE: 0.0473 | Consistency: 0.0100 | SSIM: 0.0305 | Grad: 73258.867\n",
      "[Epoch 28, Batch 14/100] Loss: 0.0518 | RMSE: 0.0485 | Consistency: 0.0109 | SSIM: 0.0314 | Grad: 41127.727\n",
      "[Epoch 28, Batch 15/100] Loss: 0.0522 | RMSE: 0.0493 | Consistency: 0.0112 | SSIM: 0.0281 | Grad: 91205.172\n",
      "[Epoch 28, Batch 16/100] Loss: 0.0502 | RMSE: 0.0468 | Consistency: 0.0113 | SSIM: 0.0323 | Grad: 49339.191\n",
      "[Epoch 28, Batch 17/100] Loss: 0.0514 | RMSE: 0.0479 | Consistency: 0.0124 | SSIM: 0.0338 | Grad: 39147.148\n",
      "[Epoch 28, Batch 18/100] Loss: 0.0483 | RMSE: 0.0453 | Consistency: 0.0085 | SSIM: 0.0293 | Grad: 70694.711\n",
      "[Epoch 28, Batch 19/100] Loss: 0.0468 | RMSE: 0.0436 | Consistency: 0.0090 | SSIM: 0.0315 | Grad: 102372.805\n",
      "[Epoch 28, Batch 20/100] Loss: 0.0488 | RMSE: 0.0457 | Consistency: 0.0099 | SSIM: 0.0305 | Grad: 86980.188\n",
      "[Epoch 28, Batch 21/100] Loss: 0.0502 | RMSE: 0.0468 | Consistency: 0.0085 | SSIM: 0.0332 | Grad: 145133.719\n",
      "[Epoch 28, Batch 22/100] Loss: 0.0554 | RMSE: 0.0523 | Consistency: 0.0127 | SSIM: 0.0298 | Grad: 153675.672\n",
      "[Epoch 28, Batch 23/100] Loss: 0.0655 | RMSE: 0.0612 | Consistency: 0.0228 | SSIM: 0.0406 | Grad: 56603.781\n",
      "[Epoch 28, Batch 24/100] Loss: 0.0448 | RMSE: 0.0413 | Consistency: 0.0093 | SSIM: 0.0341 | Grad: 59819.184\n",
      "[Epoch 28, Batch 25/100] Loss: 0.0490 | RMSE: 0.0456 | Consistency: 0.0130 | SSIM: 0.0323 | Grad: 71733.492\n",
      "[Epoch 28, Batch 26/100] Loss: 0.0575 | RMSE: 0.0533 | Consistency: 0.0150 | SSIM: 0.0407 | Grad: 86613.617\n",
      "[Epoch 28, Batch 27/100] Loss: 0.0535 | RMSE: 0.0491 | Consistency: 0.0115 | SSIM: 0.0428 | Grad: 109107.695\n",
      "[Epoch 28, Batch 28/100] Loss: 0.0492 | RMSE: 0.0455 | Consistency: 0.0120 | SSIM: 0.0349 | Grad: 79115.242\n",
      "[Epoch 28, Batch 29/100] Loss: 0.0525 | RMSE: 0.0486 | Consistency: 0.0121 | SSIM: 0.0376 | Grad: 82574.969\n",
      "[Epoch 28, Batch 30/100] Loss: 0.0599 | RMSE: 0.0567 | Consistency: 0.0140 | SSIM: 0.0309 | Grad: 117981.445\n",
      "[Epoch 28, Batch 31/100] Loss: 0.0590 | RMSE: 0.0552 | Consistency: 0.0140 | SSIM: 0.0367 | Grad: 89611.719\n",
      "[Epoch 28, Batch 32/100] Loss: 0.0430 | RMSE: 0.0404 | Consistency: 0.0083 | SSIM: 0.0244 | Grad: 90529.602\n",
      "[Epoch 28, Batch 33/100] Loss: 0.0498 | RMSE: 0.0463 | Consistency: 0.0114 | SSIM: 0.0343 | Grad: 123033.523\n",
      "[Epoch 28, Batch 34/100] Loss: 0.0535 | RMSE: 0.0502 | Consistency: 0.0102 | SSIM: 0.0324 | Grad: 108863.031\n",
      "[Epoch 28, Batch 35/100] Loss: 0.0517 | RMSE: 0.0487 | Consistency: 0.0104 | SSIM: 0.0284 | Grad: 55884.484\n",
      "[Epoch 28, Batch 36/100] Loss: 0.0403 | RMSE: 0.0375 | Consistency: 0.0075 | SSIM: 0.0273 | Grad: 31075.529\n",
      "[Epoch 28, Batch 37/100] Loss: 0.0463 | RMSE: 0.0432 | Consistency: 0.0094 | SSIM: 0.0301 | Grad: 55112.828\n",
      "[Epoch 28, Batch 38/100] Loss: 0.0543 | RMSE: 0.0511 | Consistency: 0.0144 | SSIM: 0.0311 | Grad: 80548.453\n",
      "[Epoch 28, Batch 39/100] Loss: 0.0459 | RMSE: 0.0426 | Consistency: 0.0100 | SSIM: 0.0317 | Grad: 23001.807\n",
      "[Epoch 28, Batch 40/100] Loss: 0.0573 | RMSE: 0.0537 | Consistency: 0.0138 | SSIM: 0.0349 | Grad: 91521.828\n",
      "[Epoch 28, Batch 41/100] Loss: 0.0590 | RMSE: 0.0549 | Consistency: 0.0178 | SSIM: 0.0395 | Grad: 126903.406\n",
      "[Epoch 28, Batch 42/100] Loss: 0.0660 | RMSE: 0.0616 | Consistency: 0.0158 | SSIM: 0.0419 | Grad: 107058.500\n",
      "[Epoch 28, Batch 43/100] Loss: 0.0547 | RMSE: 0.0513 | Consistency: 0.0136 | SSIM: 0.0330 | Grad: 98453.859\n",
      "[Epoch 28, Batch 44/100] Loss: 0.0535 | RMSE: 0.0498 | Consistency: 0.0143 | SSIM: 0.0354 | Grad: 90670.078\n",
      "[Epoch 28, Batch 45/100] Loss: 0.0580 | RMSE: 0.0540 | Consistency: 0.0183 | SSIM: 0.0374 | Grad: 78717.164\n",
      "[Epoch 28, Batch 46/100] Loss: 0.0493 | RMSE: 0.0462 | Consistency: 0.0101 | SSIM: 0.0300 | Grad: 58165.691\n",
      "[Epoch 28, Batch 47/100] Loss: 0.0626 | RMSE: 0.0579 | Consistency: 0.0157 | SSIM: 0.0452 | Grad: 120715.773\n",
      "[Epoch 28, Batch 48/100] Loss: 0.0608 | RMSE: 0.0573 | Consistency: 0.0174 | SSIM: 0.0335 | Grad: 154773.984\n",
      "[Epoch 28, Batch 49/100] Loss: 0.0580 | RMSE: 0.0538 | Consistency: 0.0154 | SSIM: 0.0406 | Grad: 45801.906\n",
      "[Epoch 28, Batch 50/100] Loss: 0.0521 | RMSE: 0.0485 | Consistency: 0.0114 | SSIM: 0.0356 | Grad: 94813.844\n",
      "[Epoch 28, Batch 51/100] Loss: 0.0623 | RMSE: 0.0579 | Consistency: 0.0163 | SSIM: 0.0422 | Grad: 96881.859\n",
      "[Epoch 28, Batch 52/100] Loss: 0.0584 | RMSE: 0.0541 | Consistency: 0.0126 | SSIM: 0.0415 | Grad: 77849.039\n",
      "[Epoch 28, Batch 53/100] Loss: 0.0541 | RMSE: 0.0506 | Consistency: 0.0121 | SSIM: 0.0335 | Grad: 60916.168\n",
      "[Epoch 28, Batch 54/100] Loss: 0.0487 | RMSE: 0.0455 | Consistency: 0.0105 | SSIM: 0.0310 | Grad: 73495.055\n",
      "[Epoch 28, Batch 55/100] Loss: 0.0669 | RMSE: 0.0624 | Consistency: 0.0243 | SSIM: 0.0428 | Grad: 80705.703\n",
      "[Epoch 28, Batch 56/100] Loss: 0.0586 | RMSE: 0.0544 | Consistency: 0.0133 | SSIM: 0.0407 | Grad: 68160.258\n",
      "[Epoch 28, Batch 57/100] Loss: 0.0558 | RMSE: 0.0527 | Consistency: 0.0121 | SSIM: 0.0297 | Grad: 122534.844\n",
      "[Epoch 28, Batch 58/100] Loss: 0.0542 | RMSE: 0.0502 | Consistency: 0.0136 | SSIM: 0.0381 | Grad: 100036.453\n",
      "[Epoch 28, Batch 59/100] Loss: 0.0474 | RMSE: 0.0439 | Consistency: 0.0104 | SSIM: 0.0334 | Grad: 66291.078\n",
      "[Epoch 28, Batch 60/100] Loss: 0.0513 | RMSE: 0.0467 | Consistency: 0.0143 | SSIM: 0.0445 | Grad: 77495.812\n",
      "[Epoch 28, Batch 61/100] Loss: 0.0519 | RMSE: 0.0488 | Consistency: 0.0099 | SSIM: 0.0303 | Grad: 88381.555\n",
      "[Epoch 28, Batch 62/100] Loss: 0.0547 | RMSE: 0.0516 | Consistency: 0.0140 | SSIM: 0.0299 | Grad: 128700.516\n",
      "[Epoch 28, Batch 63/100] Loss: 0.0525 | RMSE: 0.0490 | Consistency: 0.0131 | SSIM: 0.0340 | Grad: 52652.477\n",
      "[Epoch 28, Batch 64/100] Loss: 0.0452 | RMSE: 0.0425 | Consistency: 0.0102 | SSIM: 0.0260 | Grad: 75402.945\n",
      "[Epoch 28, Batch 65/100] Loss: 0.0538 | RMSE: 0.0499 | Consistency: 0.0137 | SSIM: 0.0373 | Grad: 102903.078\n",
      "[Epoch 28, Batch 66/100] Loss: 0.0528 | RMSE: 0.0494 | Consistency: 0.0147 | SSIM: 0.0323 | Grad: 121735.234\n",
      "[Epoch 28, Batch 67/100] Loss: 0.0487 | RMSE: 0.0455 | Consistency: 0.0109 | SSIM: 0.0312 | Grad: 79800.555\n",
      "[Epoch 28, Batch 68/100] Loss: 0.0612 | RMSE: 0.0570 | Consistency: 0.0119 | SSIM: 0.0402 | Grad: 84652.125\n",
      "[Epoch 28, Batch 69/100] Loss: 0.0639 | RMSE: 0.0596 | Consistency: 0.0220 | SSIM: 0.0406 | Grad: 139434.953\n",
      "[Epoch 28, Batch 70/100] Loss: 0.0604 | RMSE: 0.0563 | Consistency: 0.0210 | SSIM: 0.0381 | Grad: 148893.953\n",
      "[Epoch 28, Batch 71/100] Loss: 0.0580 | RMSE: 0.0538 | Consistency: 0.0169 | SSIM: 0.0403 | Grad: 75626.648\n",
      "[Epoch 28, Batch 72/100] Loss: 0.0585 | RMSE: 0.0543 | Consistency: 0.0130 | SSIM: 0.0399 | Grad: 124107.422\n",
      "[Epoch 28, Batch 73/100] Loss: 0.0696 | RMSE: 0.0656 | Consistency: 0.0225 | SSIM: 0.0378 | Grad: 149381.297\n",
      "[Epoch 28, Batch 74/100] Loss: 0.0717 | RMSE: 0.0674 | Consistency: 0.0252 | SSIM: 0.0409 | Grad: 115078.898\n",
      "[Epoch 28, Batch 75/100] Loss: 0.0479 | RMSE: 0.0451 | Consistency: 0.0110 | SSIM: 0.0263 | Grad: 105729.750\n",
      "[Epoch 28, Batch 76/100] Loss: 0.0568 | RMSE: 0.0529 | Consistency: 0.0144 | SSIM: 0.0382 | Grad: 72074.477\n",
      "[Epoch 28, Batch 77/100] Loss: 0.0603 | RMSE: 0.0560 | Consistency: 0.0197 | SSIM: 0.0406 | Grad: 126582.203\n",
      "[Epoch 28, Batch 78/100] Loss: 0.0636 | RMSE: 0.0597 | Consistency: 0.0229 | SSIM: 0.0367 | Grad: 145835.422\n",
      "[Epoch 28, Batch 79/100] Loss: 0.0591 | RMSE: 0.0554 | Consistency: 0.0170 | SSIM: 0.0353 | Grad: 123178.797\n",
      "[Epoch 28, Batch 80/100] Loss: 0.0545 | RMSE: 0.0508 | Consistency: 0.0146 | SSIM: 0.0348 | Grad: 90810.391\n",
      "[Epoch 28, Batch 81/100] Loss: 0.0549 | RMSE: 0.0510 | Consistency: 0.0160 | SSIM: 0.0366 | Grad: 123835.422\n",
      "[Epoch 28, Batch 82/100] Loss: 0.0524 | RMSE: 0.0491 | Consistency: 0.0135 | SSIM: 0.0313 | Grad: 95096.266\n",
      "[Epoch 28, Batch 83/100] Loss: 0.0717 | RMSE: 0.0680 | Consistency: 0.0183 | SSIM: 0.0352 | Grad: 139002.781\n",
      "[Epoch 28, Batch 84/100] Loss: 0.0503 | RMSE: 0.0470 | Consistency: 0.0144 | SSIM: 0.0318 | Grad: 142052.312\n",
      "[Epoch 28, Batch 85/100] Loss: 0.0561 | RMSE: 0.0529 | Consistency: 0.0192 | SSIM: 0.0309 | Grad: 157102.625\n",
      "[Epoch 28, Batch 86/100] Loss: 0.0574 | RMSE: 0.0534 | Consistency: 0.0152 | SSIM: 0.0385 | Grad: 181273.312\n",
      "[Epoch 28, Batch 87/100] Loss: 0.0613 | RMSE: 0.0571 | Consistency: 0.0126 | SSIM: 0.0408 | Grad: 163318.141\n",
      "[Epoch 28, Batch 88/100] Loss: 0.0650 | RMSE: 0.0614 | Consistency: 0.0191 | SSIM: 0.0339 | Grad: 121768.797\n",
      "[Epoch 28, Batch 89/100] Loss: 0.0581 | RMSE: 0.0539 | Consistency: 0.0185 | SSIM: 0.0398 | Grad: 167795.219\n",
      "[Epoch 28, Batch 90/100] Loss: 0.0597 | RMSE: 0.0561 | Consistency: 0.0163 | SSIM: 0.0344 | Grad: 139367.344\n",
      "[Epoch 28, Batch 91/100] Loss: 0.0632 | RMSE: 0.0592 | Consistency: 0.0146 | SSIM: 0.0387 | Grad: 150473.734\n",
      "[Epoch 28, Batch 92/100] Loss: 0.0432 | RMSE: 0.0407 | Consistency: 0.0090 | SSIM: 0.0247 | Grad: 93973.336\n",
      "[Epoch 28, Batch 93/100] Loss: 0.0557 | RMSE: 0.0524 | Consistency: 0.0113 | SSIM: 0.0327 | Grad: 135296.188\n",
      "[Epoch 28, Batch 94/100] Loss: 0.0511 | RMSE: 0.0481 | Consistency: 0.0113 | SSIM: 0.0287 | Grad: 85361.930\n",
      "[Epoch 28, Batch 95/100] Loss: 0.0560 | RMSE: 0.0519 | Consistency: 0.0150 | SSIM: 0.0395 | Grad: 88295.953\n",
      "[Epoch 28, Batch 96/100] Loss: 0.0465 | RMSE: 0.0435 | Consistency: 0.0097 | SSIM: 0.0289 | Grad: 115526.969\n",
      "[Epoch 28, Batch 97/100] Loss: 0.0489 | RMSE: 0.0452 | Consistency: 0.0106 | SSIM: 0.0359 | Grad: 75418.539\n",
      "[Epoch 28, Batch 98/100] Loss: 0.0523 | RMSE: 0.0485 | Consistency: 0.0125 | SSIM: 0.0376 | Grad: 55225.035\n",
      "[Epoch 28, Batch 99/100] Loss: 0.0446 | RMSE: 0.0418 | Consistency: 0.0089 | SSIM: 0.0271 | Grad: 58307.633\n",
      "[Epoch 28, Batch 100/100] Loss: 0.0494 | RMSE: 0.0458 | Consistency: 0.0094 | SSIM: 0.0352 | Grad: 113093.234\n",
      "✅ Epoch 28 완료!\n",
      "   📈 평균 Loss: 0.054612\n",
      "   📊 평균 RMSE: 0.051012\n",
      "   ⚙️  학습률: 0.000821\n",
      "   🏆 NEW BEST! RMSE: 0.051012\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 29/80 시작...\n",
      "[Epoch 29, Batch 1/100] Loss: 0.0487 | RMSE: 0.0452 | Consistency: 0.0110 | SSIM: 0.0344 | Grad: 57886.238\n",
      "[Epoch 29, Batch 2/100] Loss: 0.0435 | RMSE: 0.0406 | Consistency: 0.0084 | SSIM: 0.0285 | Grad: 39668.797\n",
      "[Epoch 29, Batch 3/100] Loss: 0.0484 | RMSE: 0.0456 | Consistency: 0.0116 | SSIM: 0.0274 | Grad: 49284.918\n",
      "[Epoch 29, Batch 4/100] Loss: 0.0553 | RMSE: 0.0519 | Consistency: 0.0118 | SSIM: 0.0332 | Grad: 111586.062\n",
      "[Epoch 29, Batch 5/100] Loss: 0.0518 | RMSE: 0.0479 | Consistency: 0.0123 | SSIM: 0.0380 | Grad: 44676.430\n",
      "[Epoch 29, Batch 6/100] Loss: 0.0515 | RMSE: 0.0484 | Consistency: 0.0106 | SSIM: 0.0294 | Grad: 103966.453\n",
      "[Epoch 29, Batch 7/100] Loss: 0.0637 | RMSE: 0.0593 | Consistency: 0.0211 | SSIM: 0.0413 | Grad: 76637.992\n",
      "[Epoch 29, Batch 8/100] Loss: 0.0471 | RMSE: 0.0440 | Consistency: 0.0109 | SSIM: 0.0295 | Grad: 35231.848\n",
      "[Epoch 29, Batch 9/100] Loss: 0.0583 | RMSE: 0.0540 | Consistency: 0.0152 | SSIM: 0.0415 | Grad: 159379.891\n",
      "[Epoch 29, Batch 10/100] Loss: 0.0631 | RMSE: 0.0597 | Consistency: 0.0163 | SSIM: 0.0319 | Grad: 136029.547\n",
      "[Epoch 29, Batch 11/100] Loss: 0.0574 | RMSE: 0.0529 | Consistency: 0.0141 | SSIM: 0.0436 | Grad: 78486.789\n",
      "[Epoch 29, Batch 12/100] Loss: 0.0558 | RMSE: 0.0521 | Consistency: 0.0140 | SSIM: 0.0356 | Grad: 65231.145\n",
      "[Epoch 29, Batch 13/100] Loss: 0.0560 | RMSE: 0.0518 | Consistency: 0.0122 | SSIM: 0.0406 | Grad: 115594.508\n",
      "[Epoch 29, Batch 14/100] Loss: 0.0553 | RMSE: 0.0520 | Consistency: 0.0120 | SSIM: 0.0318 | Grad: 134954.266\n",
      "[Epoch 29, Batch 15/100] Loss: 0.0581 | RMSE: 0.0537 | Consistency: 0.0170 | SSIM: 0.0427 | Grad: 118084.258\n",
      "[Epoch 29, Batch 16/100] Loss: 0.0573 | RMSE: 0.0534 | Consistency: 0.0142 | SSIM: 0.0374 | Grad: 124660.484\n",
      "[Epoch 29, Batch 17/100] Loss: 0.0555 | RMSE: 0.0515 | Consistency: 0.0148 | SSIM: 0.0385 | Grad: 126334.008\n",
      "[Epoch 29, Batch 18/100] Loss: 0.0462 | RMSE: 0.0429 | Consistency: 0.0097 | SSIM: 0.0326 | Grad: 25398.691\n",
      "[Epoch 29, Batch 19/100] Loss: 0.0426 | RMSE: 0.0396 | Consistency: 0.0071 | SSIM: 0.0291 | Grad: 44353.129\n",
      "[Epoch 29, Batch 20/100] Loss: 0.0591 | RMSE: 0.0538 | Consistency: 0.0149 | SSIM: 0.0512 | Grad: 114935.945\n",
      "[Epoch 29, Batch 21/100] Loss: 0.0484 | RMSE: 0.0447 | Consistency: 0.0115 | SSIM: 0.0352 | Grad: 44100.719\n",
      "[Epoch 29, Batch 22/100] Loss: 0.0485 | RMSE: 0.0453 | Consistency: 0.0109 | SSIM: 0.0304 | Grad: 17560.109\n",
      "[Epoch 29, Batch 23/100] Loss: 0.0590 | RMSE: 0.0555 | Consistency: 0.0147 | SSIM: 0.0335 | Grad: 71723.758\n",
      "[Epoch 29, Batch 24/100] Loss: 0.0489 | RMSE: 0.0455 | Consistency: 0.0102 | SSIM: 0.0337 | Grad: 26209.375\n",
      "[Epoch 29, Batch 25/100] Loss: 0.0503 | RMSE: 0.0470 | Consistency: 0.0107 | SSIM: 0.0327 | Grad: 60446.148\n",
      "[Epoch 29, Batch 26/100] Loss: 0.0611 | RMSE: 0.0568 | Consistency: 0.0176 | SSIM: 0.0416 | Grad: 56834.316\n",
      "[Epoch 29, Batch 27/100] Loss: 0.0549 | RMSE: 0.0508 | Consistency: 0.0135 | SSIM: 0.0394 | Grad: 96734.742\n",
      "[Epoch 29, Batch 28/100] Loss: 0.0684 | RMSE: 0.0631 | Consistency: 0.0220 | SSIM: 0.0510 | Grad: 145127.484\n",
      "[Epoch 29, Batch 29/100] Loss: 0.0570 | RMSE: 0.0537 | Consistency: 0.0162 | SSIM: 0.0308 | Grad: 122733.078\n",
      "[Epoch 29, Batch 30/100] Loss: 0.0567 | RMSE: 0.0529 | Consistency: 0.0138 | SSIM: 0.0360 | Grad: 64996.883\n",
      "[Epoch 29, Batch 31/100] Loss: 0.0603 | RMSE: 0.0552 | Consistency: 0.0184 | SSIM: 0.0491 | Grad: 90799.086\n",
      "[Epoch 29, Batch 32/100] Loss: 0.0639 | RMSE: 0.0599 | Consistency: 0.0169 | SSIM: 0.0382 | Grad: 132551.531\n",
      "[Epoch 29, Batch 33/100] Loss: 0.0578 | RMSE: 0.0537 | Consistency: 0.0153 | SSIM: 0.0400 | Grad: 71523.094\n",
      "[Epoch 29, Batch 34/100] Loss: 0.0535 | RMSE: 0.0500 | Consistency: 0.0148 | SSIM: 0.0339 | Grad: 31926.680\n",
      "[Epoch 29, Batch 35/100] Loss: 0.0575 | RMSE: 0.0539 | Consistency: 0.0177 | SSIM: 0.0345 | Grad: 112275.938\n",
      "[Epoch 29, Batch 36/100] Loss: 0.0496 | RMSE: 0.0466 | Consistency: 0.0118 | SSIM: 0.0288 | Grad: 69577.641\n",
      "[Epoch 29, Batch 37/100] Loss: 0.0503 | RMSE: 0.0467 | Consistency: 0.0092 | SSIM: 0.0346 | Grad: 98315.719\n",
      "[Epoch 29, Batch 38/100] Loss: 0.0494 | RMSE: 0.0461 | Consistency: 0.0129 | SSIM: 0.0322 | Grad: 63702.832\n",
      "[Epoch 29, Batch 39/100] Loss: 0.0468 | RMSE: 0.0435 | Consistency: 0.0090 | SSIM: 0.0325 | Grad: 78992.656\n",
      "[Epoch 29, Batch 40/100] Loss: 0.0543 | RMSE: 0.0511 | Consistency: 0.0131 | SSIM: 0.0306 | Grad: 89358.719\n",
      "[Epoch 29, Batch 41/100] Loss: 0.0483 | RMSE: 0.0444 | Consistency: 0.0112 | SSIM: 0.0383 | Grad: 70547.328\n",
      "[Epoch 29, Batch 42/100] Loss: 0.0519 | RMSE: 0.0482 | Consistency: 0.0119 | SSIM: 0.0353 | Grad: 81915.602\n",
      "[Epoch 29, Batch 43/100] Loss: 0.0529 | RMSE: 0.0495 | Consistency: 0.0141 | SSIM: 0.0330 | Grad: 89602.281\n",
      "[Epoch 29, Batch 44/100] Loss: 0.0505 | RMSE: 0.0472 | Consistency: 0.0103 | SSIM: 0.0322 | Grad: 108156.219\n",
      "[Epoch 29, Batch 45/100] Loss: 0.0465 | RMSE: 0.0432 | Consistency: 0.0110 | SSIM: 0.0324 | Grad: 33778.055\n",
      "[Epoch 29, Batch 46/100] Loss: 0.0506 | RMSE: 0.0469 | Consistency: 0.0106 | SSIM: 0.0362 | Grad: 110521.719\n",
      "[Epoch 29, Batch 47/100] Loss: 0.0618 | RMSE: 0.0581 | Consistency: 0.0126 | SSIM: 0.0364 | Grad: 180630.469\n",
      "[Epoch 29, Batch 48/100] Loss: 0.0545 | RMSE: 0.0509 | Consistency: 0.0130 | SSIM: 0.0353 | Grad: 124118.906\n",
      "[Epoch 29, Batch 49/100] Loss: 0.0503 | RMSE: 0.0470 | Consistency: 0.0132 | SSIM: 0.0318 | Grad: 43488.945\n",
      "[Epoch 29, Batch 50/100] Loss: 0.0574 | RMSE: 0.0537 | Consistency: 0.0143 | SSIM: 0.0355 | Grad: 139990.047\n",
      "[Epoch 29, Batch 51/100] Loss: 0.0588 | RMSE: 0.0544 | Consistency: 0.0154 | SSIM: 0.0421 | Grad: 124808.266\n",
      "[Epoch 29, Batch 52/100] Loss: 0.0559 | RMSE: 0.0521 | Consistency: 0.0136 | SSIM: 0.0363 | Grad: 139687.625\n",
      "[Epoch 29, Batch 53/100] Loss: 0.0523 | RMSE: 0.0490 | Consistency: 0.0124 | SSIM: 0.0316 | Grad: 64048.395\n",
      "[Epoch 29, Batch 54/100] Loss: 0.0522 | RMSE: 0.0485 | Consistency: 0.0116 | SSIM: 0.0355 | Grad: 132126.141\n",
      "[Epoch 29, Batch 55/100] Loss: 0.0497 | RMSE: 0.0458 | Consistency: 0.0102 | SSIM: 0.0380 | Grad: 79908.898\n",
      "[Epoch 29, Batch 56/100] Loss: 0.0562 | RMSE: 0.0524 | Consistency: 0.0135 | SSIM: 0.0369 | Grad: 87493.422\n",
      "[Epoch 29, Batch 57/100] Loss: 0.0487 | RMSE: 0.0457 | Consistency: 0.0109 | SSIM: 0.0283 | Grad: 127462.500\n",
      "[Epoch 29, Batch 58/100] Loss: 0.0556 | RMSE: 0.0516 | Consistency: 0.0143 | SSIM: 0.0386 | Grad: 121505.453\n",
      "[Epoch 29, Batch 59/100] Loss: 0.0475 | RMSE: 0.0445 | Consistency: 0.0088 | SSIM: 0.0287 | Grad: 76733.000\n",
      "[Epoch 29, Batch 60/100] Loss: 0.0557 | RMSE: 0.0522 | Consistency: 0.0142 | SSIM: 0.0337 | Grad: 107195.750\n",
      "[Epoch 29, Batch 61/100] Loss: 0.0556 | RMSE: 0.0516 | Consistency: 0.0146 | SSIM: 0.0382 | Grad: 95678.211\n",
      "[Epoch 29, Batch 62/100] Loss: 0.0470 | RMSE: 0.0442 | Consistency: 0.0125 | SSIM: 0.0273 | Grad: 103936.102\n",
      "[Epoch 29, Batch 63/100] Loss: 0.0486 | RMSE: 0.0448 | Consistency: 0.0084 | SSIM: 0.0371 | Grad: 55966.754\n",
      "[Epoch 29, Batch 64/100] Loss: 0.0478 | RMSE: 0.0445 | Consistency: 0.0137 | SSIM: 0.0314 | Grad: 62132.984\n",
      "[Epoch 29, Batch 65/100] Loss: 0.0610 | RMSE: 0.0564 | Consistency: 0.0161 | SSIM: 0.0448 | Grad: 47831.828\n",
      "[Epoch 29, Batch 66/100] Loss: 0.0426 | RMSE: 0.0398 | Consistency: 0.0087 | SSIM: 0.0274 | Grad: 101790.023\n",
      "[Epoch 29, Batch 67/100] Loss: 0.0427 | RMSE: 0.0400 | Consistency: 0.0087 | SSIM: 0.0266 | Grad: 60124.855\n",
      "[Epoch 29, Batch 68/100] Loss: 0.0626 | RMSE: 0.0590 | Consistency: 0.0117 | SSIM: 0.0356 | Grad: 152304.141\n",
      "[Epoch 29, Batch 69/100] Loss: 0.0599 | RMSE: 0.0562 | Consistency: 0.0163 | SSIM: 0.0348 | Grad: 139130.672\n",
      "[Epoch 29, Batch 70/100] Loss: 0.0611 | RMSE: 0.0574 | Consistency: 0.0194 | SSIM: 0.0350 | Grad: 157039.594\n",
      "[Epoch 29, Batch 71/100] Loss: 0.0534 | RMSE: 0.0494 | Consistency: 0.0145 | SSIM: 0.0390 | Grad: 78204.969\n",
      "[Epoch 29, Batch 72/100] Loss: 0.0501 | RMSE: 0.0471 | Consistency: 0.0103 | SSIM: 0.0294 | Grad: 76193.430\n",
      "[Epoch 29, Batch 73/100] Loss: 0.0462 | RMSE: 0.0425 | Consistency: 0.0111 | SSIM: 0.0353 | Grad: 81493.039\n",
      "[Epoch 29, Batch 74/100] Loss: 0.0571 | RMSE: 0.0530 | Consistency: 0.0167 | SSIM: 0.0390 | Grad: 95730.523\n",
      "[Epoch 29, Batch 75/100] Loss: 0.0521 | RMSE: 0.0489 | Consistency: 0.0127 | SSIM: 0.0310 | Grad: 86165.836\n",
      "[Epoch 29, Batch 76/100] Loss: 0.0504 | RMSE: 0.0470 | Consistency: 0.0113 | SSIM: 0.0324 | Grad: 75485.141\n",
      "[Epoch 29, Batch 77/100] Loss: 0.0561 | RMSE: 0.0528 | Consistency: 0.0144 | SSIM: 0.0313 | Grad: 86876.289\n",
      "[Epoch 29, Batch 78/100] Loss: 0.0479 | RMSE: 0.0445 | Consistency: 0.0115 | SSIM: 0.0325 | Grad: 85850.445\n",
      "[Epoch 29, Batch 79/100] Loss: 0.0509 | RMSE: 0.0471 | Consistency: 0.0109 | SSIM: 0.0364 | Grad: 98085.688\n",
      "[Epoch 29, Batch 80/100] Loss: 0.0532 | RMSE: 0.0501 | Consistency: 0.0114 | SSIM: 0.0304 | Grad: 125549.234\n",
      "[Epoch 29, Batch 81/100] Loss: 0.0582 | RMSE: 0.0546 | Consistency: 0.0172 | SSIM: 0.0346 | Grad: 113867.609\n",
      "[Epoch 29, Batch 82/100] Loss: 0.0550 | RMSE: 0.0513 | Consistency: 0.0118 | SSIM: 0.0359 | Grad: 80433.539\n",
      "[Epoch 29, Batch 83/100] Loss: 0.0517 | RMSE: 0.0481 | Consistency: 0.0136 | SSIM: 0.0347 | Grad: 115536.680\n",
      "[Epoch 29, Batch 84/100] Loss: 0.0432 | RMSE: 0.0401 | Consistency: 0.0072 | SSIM: 0.0304 | Grad: 99125.578\n",
      "[Epoch 29, Batch 85/100] Loss: 0.0437 | RMSE: 0.0409 | Consistency: 0.0090 | SSIM: 0.0278 | Grad: 60914.348\n",
      "[Epoch 29, Batch 86/100] Loss: 0.0511 | RMSE: 0.0473 | Consistency: 0.0118 | SSIM: 0.0366 | Grad: 74619.109\n",
      "[Epoch 29, Batch 87/100] Loss: 0.0463 | RMSE: 0.0434 | Consistency: 0.0094 | SSIM: 0.0280 | Grad: 79719.945\n",
      "[Epoch 29, Batch 88/100] Loss: 0.0597 | RMSE: 0.0556 | Consistency: 0.0136 | SSIM: 0.0396 | Grad: 107019.352\n",
      "[Epoch 29, Batch 89/100] Loss: 0.0533 | RMSE: 0.0500 | Consistency: 0.0116 | SSIM: 0.0323 | Grad: 123343.695\n",
      "[Epoch 29, Batch 90/100] Loss: 0.0502 | RMSE: 0.0467 | Consistency: 0.0108 | SSIM: 0.0341 | Grad: 98382.961\n",
      "[Epoch 29, Batch 91/100] Loss: 0.0526 | RMSE: 0.0491 | Consistency: 0.0142 | SSIM: 0.0331 | Grad: 103303.242\n",
      "[Epoch 29, Batch 92/100] Loss: 0.0481 | RMSE: 0.0445 | Consistency: 0.0090 | SSIM: 0.0355 | Grad: 108229.508\n",
      "[Epoch 29, Batch 93/100] Loss: 0.0604 | RMSE: 0.0563 | Consistency: 0.0143 | SSIM: 0.0402 | Grad: 156080.531\n",
      "[Epoch 29, Batch 94/100] Loss: 0.0521 | RMSE: 0.0491 | Consistency: 0.0119 | SSIM: 0.0294 | Grad: 146834.328\n",
      "[Epoch 29, Batch 95/100] Loss: 0.0494 | RMSE: 0.0465 | Consistency: 0.0091 | SSIM: 0.0288 | Grad: 116100.273\n",
      "[Epoch 29, Batch 96/100] Loss: 0.0717 | RMSE: 0.0675 | Consistency: 0.0212 | SSIM: 0.0402 | Grad: 125317.031\n",
      "[Epoch 29, Batch 97/100] Loss: 0.0539 | RMSE: 0.0505 | Consistency: 0.0127 | SSIM: 0.0328 | Grad: 99922.844\n",
      "[Epoch 29, Batch 98/100] Loss: 0.0574 | RMSE: 0.0536 | Consistency: 0.0155 | SSIM: 0.0366 | Grad: 55788.363\n",
      "[Epoch 29, Batch 99/100] Loss: 0.0636 | RMSE: 0.0590 | Consistency: 0.0161 | SSIM: 0.0445 | Grad: 121770.586\n",
      "[Epoch 29, Batch 100/100] Loss: 0.0529 | RMSE: 0.0500 | Consistency: 0.0108 | SSIM: 0.0283 | Grad: 124029.812\n",
      "✅ Epoch 29 완료!\n",
      "   📈 평균 Loss: 0.053500\n",
      "   📊 평균 RMSE: 0.049879\n",
      "   ⚙️  학습률: 0.000804\n",
      "   🏆 NEW BEST! RMSE: 0.049879\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 30/80 시작...\n",
      "[Epoch 30, Batch 1/100] Loss: 0.0507 | RMSE: 0.0476 | Consistency: 0.0104 | SSIM: 0.0297 | Grad: 90986.117\n",
      "[Epoch 30, Batch 2/100] Loss: 0.0551 | RMSE: 0.0518 | Consistency: 0.0110 | SSIM: 0.0317 | Grad: 85761.070\n",
      "[Epoch 30, Batch 3/100] Loss: 0.0647 | RMSE: 0.0611 | Consistency: 0.0167 | SSIM: 0.0346 | Grad: 108456.766\n",
      "[Epoch 30, Batch 4/100] Loss: 0.0482 | RMSE: 0.0453 | Consistency: 0.0095 | SSIM: 0.0278 | Grad: 85049.914\n",
      "[Epoch 30, Batch 5/100] Loss: 0.0435 | RMSE: 0.0407 | Consistency: 0.0084 | SSIM: 0.0276 | Grad: 50325.855\n",
      "[Epoch 30, Batch 6/100] Loss: 0.0519 | RMSE: 0.0484 | Consistency: 0.0132 | SSIM: 0.0334 | Grad: 91177.953\n",
      "[Epoch 30, Batch 7/100] Loss: 0.0528 | RMSE: 0.0489 | Consistency: 0.0124 | SSIM: 0.0385 | Grad: 67654.875\n",
      "[Epoch 30, Batch 8/100] Loss: 0.0526 | RMSE: 0.0492 | Consistency: 0.0129 | SSIM: 0.0327 | Grad: 81259.555\n",
      "[Epoch 30, Batch 9/100] Loss: 0.0415 | RMSE: 0.0384 | Consistency: 0.0074 | SSIM: 0.0302 | Grad: 51266.004\n",
      "[Epoch 30, Batch 10/100] Loss: 0.0475 | RMSE: 0.0442 | Consistency: 0.0109 | SSIM: 0.0313 | Grad: 89313.234\n",
      "[Epoch 30, Batch 11/100] Loss: 0.0501 | RMSE: 0.0467 | Consistency: 0.0104 | SSIM: 0.0332 | Grad: 108800.453\n",
      "[Epoch 30, Batch 12/100] Loss: 0.0666 | RMSE: 0.0627 | Consistency: 0.0202 | SSIM: 0.0374 | Grad: 106649.664\n",
      "[Epoch 30, Batch 13/100] Loss: 0.0563 | RMSE: 0.0527 | Consistency: 0.0198 | SSIM: 0.0334 | Grad: 160340.484\n",
      "[Epoch 30, Batch 14/100] Loss: 0.0634 | RMSE: 0.0592 | Consistency: 0.0205 | SSIM: 0.0408 | Grad: 157511.844\n",
      "[Epoch 30, Batch 15/100] Loss: 0.0504 | RMSE: 0.0467 | Consistency: 0.0108 | SSIM: 0.0360 | Grad: 90823.789\n",
      "[Epoch 30, Batch 16/100] Loss: 0.0499 | RMSE: 0.0466 | Consistency: 0.0116 | SSIM: 0.0315 | Grad: 56772.512\n",
      "[Epoch 30, Batch 17/100] Loss: 0.0591 | RMSE: 0.0553 | Consistency: 0.0143 | SSIM: 0.0364 | Grad: 79170.336\n",
      "[Epoch 30, Batch 18/100] Loss: 0.0403 | RMSE: 0.0373 | Consistency: 0.0068 | SSIM: 0.0289 | Grad: 100543.305\n",
      "[Epoch 30, Batch 19/100] Loss: 0.0479 | RMSE: 0.0451 | Consistency: 0.0108 | SSIM: 0.0269 | Grad: 56797.453\n",
      "[Epoch 30, Batch 20/100] Loss: 0.0458 | RMSE: 0.0432 | Consistency: 0.0097 | SSIM: 0.0249 | Grad: 100542.586\n",
      "[Epoch 30, Batch 21/100] Loss: 0.0534 | RMSE: 0.0503 | Consistency: 0.0110 | SSIM: 0.0304 | Grad: 79920.133\n",
      "[Epoch 30, Batch 22/100] Loss: 0.0633 | RMSE: 0.0594 | Consistency: 0.0191 | SSIM: 0.0375 | Grad: 131100.625\n",
      "[Epoch 30, Batch 23/100] Loss: 0.0492 | RMSE: 0.0460 | Consistency: 0.0105 | SSIM: 0.0315 | Grad: 121155.039\n",
      "[Epoch 30, Batch 24/100] Loss: 0.0632 | RMSE: 0.0588 | Consistency: 0.0215 | SSIM: 0.0419 | Grad: 84987.430\n",
      "[Epoch 30, Batch 25/100] Loss: 0.0581 | RMSE: 0.0539 | Consistency: 0.0188 | SSIM: 0.0402 | Grad: 102473.922\n",
      "[Epoch 30, Batch 26/100] Loss: 0.0491 | RMSE: 0.0457 | Consistency: 0.0115 | SSIM: 0.0330 | Grad: 106388.102\n",
      "[Epoch 30, Batch 27/100] Loss: 0.0514 | RMSE: 0.0480 | Consistency: 0.0121 | SSIM: 0.0328 | Grad: 105377.383\n",
      "[Epoch 30, Batch 28/100] Loss: 0.0500 | RMSE: 0.0465 | Consistency: 0.0110 | SSIM: 0.0339 | Grad: 101440.766\n",
      "[Epoch 30, Batch 29/100] Loss: 0.0503 | RMSE: 0.0464 | Consistency: 0.0128 | SSIM: 0.0373 | Grad: 146729.328\n",
      "[Epoch 30, Batch 30/100] Loss: 0.0562 | RMSE: 0.0522 | Consistency: 0.0142 | SSIM: 0.0380 | Grad: 68232.133\n",
      "[Epoch 30, Batch 31/100] Loss: 0.0494 | RMSE: 0.0460 | Consistency: 0.0137 | SSIM: 0.0322 | Grad: 95599.531\n",
      "[Epoch 30, Batch 32/100] Loss: 0.0489 | RMSE: 0.0459 | Consistency: 0.0102 | SSIM: 0.0289 | Grad: 61556.840\n",
      "[Epoch 30, Batch 33/100] Loss: 0.0440 | RMSE: 0.0412 | Consistency: 0.0074 | SSIM: 0.0272 | Grad: 102031.305\n",
      "[Epoch 30, Batch 34/100] Loss: 0.0552 | RMSE: 0.0518 | Consistency: 0.0125 | SSIM: 0.0321 | Grad: 75958.031\n",
      "[Epoch 30, Batch 35/100] Loss: 0.0518 | RMSE: 0.0479 | Consistency: 0.0111 | SSIM: 0.0377 | Grad: 84029.211\n",
      "[Epoch 30, Batch 36/100] Loss: 0.0559 | RMSE: 0.0520 | Consistency: 0.0136 | SSIM: 0.0368 | Grad: 83312.844\n",
      "[Epoch 30, Batch 37/100] Loss: 0.0531 | RMSE: 0.0488 | Consistency: 0.0125 | SSIM: 0.0423 | Grad: 76072.289\n",
      "[Epoch 30, Batch 38/100] Loss: 0.0455 | RMSE: 0.0415 | Consistency: 0.0105 | SSIM: 0.0391 | Grad: 73072.695\n",
      "[Epoch 30, Batch 39/100] Loss: 0.0581 | RMSE: 0.0542 | Consistency: 0.0117 | SSIM: 0.0381 | Grad: 116538.906\n",
      "[Epoch 30, Batch 40/100] Loss: 0.0510 | RMSE: 0.0478 | Consistency: 0.0101 | SSIM: 0.0312 | Grad: 100838.523\n",
      "[Epoch 30, Batch 41/100] Loss: 0.0635 | RMSE: 0.0595 | Consistency: 0.0244 | SSIM: 0.0375 | Grad: 91559.922\n",
      "[Epoch 30, Batch 42/100] Loss: 0.0502 | RMSE: 0.0465 | Consistency: 0.0133 | SSIM: 0.0360 | Grad: 72485.109\n",
      "[Epoch 30, Batch 43/100] Loss: 0.0549 | RMSE: 0.0513 | Consistency: 0.0121 | SSIM: 0.0350 | Grad: 90232.828\n",
      "[Epoch 30, Batch 44/100] Loss: 0.0476 | RMSE: 0.0439 | Consistency: 0.0094 | SSIM: 0.0353 | Grad: 78540.523\n",
      "[Epoch 30, Batch 45/100] Loss: 0.0426 | RMSE: 0.0399 | Consistency: 0.0091 | SSIM: 0.0265 | Grad: 73072.234\n",
      "[Epoch 30, Batch 46/100] Loss: 0.0481 | RMSE: 0.0450 | Consistency: 0.0119 | SSIM: 0.0305 | Grad: 83056.555\n",
      "[Epoch 30, Batch 47/100] Loss: 0.0427 | RMSE: 0.0404 | Consistency: 0.0082 | SSIM: 0.0226 | Grad: 48249.719\n",
      "[Epoch 30, Batch 48/100] Loss: 0.0518 | RMSE: 0.0482 | Consistency: 0.0112 | SSIM: 0.0348 | Grad: 18481.803\n",
      "[Epoch 30, Batch 49/100] Loss: 0.0470 | RMSE: 0.0437 | Consistency: 0.0106 | SSIM: 0.0318 | Grad: 100341.047\n",
      "[Epoch 30, Batch 50/100] Loss: 0.0526 | RMSE: 0.0488 | Consistency: 0.0136 | SSIM: 0.0362 | Grad: 57861.516\n",
      "[Epoch 30, Batch 51/100] Loss: 0.0589 | RMSE: 0.0554 | Consistency: 0.0137 | SSIM: 0.0345 | Grad: 82505.133\n",
      "[Epoch 30, Batch 52/100] Loss: 0.0840 | RMSE: 0.0789 | Consistency: 0.0269 | SSIM: 0.0484 | Grad: 144991.234\n",
      "[Epoch 30, Batch 53/100] Loss: 0.0530 | RMSE: 0.0496 | Consistency: 0.0140 | SSIM: 0.0336 | Grad: 118143.570\n",
      "[Epoch 30, Batch 54/100] Loss: 0.0515 | RMSE: 0.0484 | Consistency: 0.0104 | SSIM: 0.0300 | Grad: 68124.367\n",
      "[Epoch 30, Batch 55/100] Loss: 0.0511 | RMSE: 0.0477 | Consistency: 0.0125 | SSIM: 0.0324 | Grad: 74637.453\n",
      "[Epoch 30, Batch 56/100] Loss: 0.0558 | RMSE: 0.0520 | Consistency: 0.0146 | SSIM: 0.0364 | Grad: 38550.504\n",
      "[Epoch 30, Batch 57/100] Loss: 0.0519 | RMSE: 0.0481 | Consistency: 0.0132 | SSIM: 0.0367 | Grad: 124774.109\n",
      "[Epoch 30, Batch 58/100] Loss: 0.0506 | RMSE: 0.0476 | Consistency: 0.0124 | SSIM: 0.0290 | Grad: 48755.809\n",
      "[Epoch 30, Batch 59/100] Loss: 0.0431 | RMSE: 0.0400 | Consistency: 0.0079 | SSIM: 0.0302 | Grad: 49701.266\n",
      "[Epoch 30, Batch 60/100] Loss: 0.0472 | RMSE: 0.0438 | Consistency: 0.0091 | SSIM: 0.0334 | Grad: 51502.176\n",
      "[Epoch 30, Batch 61/100] Loss: 0.0554 | RMSE: 0.0519 | Consistency: 0.0139 | SSIM: 0.0338 | Grad: 99292.750\n",
      "[Epoch 30, Batch 62/100] Loss: 0.0553 | RMSE: 0.0514 | Consistency: 0.0120 | SSIM: 0.0377 | Grad: 109473.102\n",
      "[Epoch 30, Batch 63/100] Loss: 0.0516 | RMSE: 0.0485 | Consistency: 0.0121 | SSIM: 0.0299 | Grad: 83566.742\n",
      "[Epoch 30, Batch 64/100] Loss: 0.0463 | RMSE: 0.0434 | Consistency: 0.0081 | SSIM: 0.0286 | Grad: 56883.047\n",
      "[Epoch 30, Batch 65/100] Loss: 0.0522 | RMSE: 0.0488 | Consistency: 0.0137 | SSIM: 0.0319 | Grad: 106576.000\n",
      "[Epoch 30, Batch 66/100] Loss: 0.0487 | RMSE: 0.0453 | Consistency: 0.0111 | SSIM: 0.0329 | Grad: 83720.773\n",
      "[Epoch 30, Batch 67/100] Loss: 0.0453 | RMSE: 0.0420 | Consistency: 0.0107 | SSIM: 0.0316 | Grad: 29722.250\n",
      "[Epoch 30, Batch 68/100] Loss: 0.0568 | RMSE: 0.0534 | Consistency: 0.0121 | SSIM: 0.0320 | Grad: 69657.453\n",
      "[Epoch 30, Batch 69/100] Loss: 0.0529 | RMSE: 0.0492 | Consistency: 0.0107 | SSIM: 0.0359 | Grad: 85179.945\n",
      "[Epoch 30, Batch 70/100] Loss: 0.0521 | RMSE: 0.0490 | Consistency: 0.0110 | SSIM: 0.0307 | Grad: 115705.078\n",
      "[Epoch 30, Batch 71/100] Loss: 0.0524 | RMSE: 0.0491 | Consistency: 0.0125 | SSIM: 0.0324 | Grad: 77770.109\n",
      "[Epoch 30, Batch 72/100] Loss: 0.0608 | RMSE: 0.0559 | Consistency: 0.0163 | SSIM: 0.0468 | Grad: 57509.758\n",
      "[Epoch 30, Batch 73/100] Loss: 0.0536 | RMSE: 0.0500 | Consistency: 0.0168 | SSIM: 0.0339 | Grad: 114089.320\n",
      "[Epoch 30, Batch 74/100] Loss: 0.0495 | RMSE: 0.0465 | Consistency: 0.0111 | SSIM: 0.0286 | Grad: 97213.391\n",
      "[Epoch 30, Batch 75/100] Loss: 0.0463 | RMSE: 0.0425 | Consistency: 0.0100 | SSIM: 0.0368 | Grad: 34284.930\n",
      "[Epoch 30, Batch 76/100] Loss: 0.0519 | RMSE: 0.0483 | Consistency: 0.0154 | SSIM: 0.0345 | Grad: 140423.953\n",
      "[Epoch 30, Batch 77/100] Loss: 0.0592 | RMSE: 0.0561 | Consistency: 0.0139 | SSIM: 0.0300 | Grad: 101773.297\n",
      "[Epoch 30, Batch 78/100] Loss: 0.0591 | RMSE: 0.0554 | Consistency: 0.0144 | SSIM: 0.0361 | Grad: 165030.109\n",
      "[Epoch 30, Batch 79/100] Loss: 0.0547 | RMSE: 0.0508 | Consistency: 0.0148 | SSIM: 0.0378 | Grad: 65982.969\n",
      "[Epoch 30, Batch 80/100] Loss: 0.0520 | RMSE: 0.0489 | Consistency: 0.0129 | SSIM: 0.0301 | Grad: 98040.258\n",
      "[Epoch 30, Batch 81/100] Loss: 0.0514 | RMSE: 0.0479 | Consistency: 0.0123 | SSIM: 0.0335 | Grad: 132398.656\n",
      "[Epoch 30, Batch 82/100] Loss: 0.0610 | RMSE: 0.0571 | Consistency: 0.0164 | SSIM: 0.0368 | Grad: 133599.500\n",
      "[Epoch 30, Batch 83/100] Loss: 0.0469 | RMSE: 0.0435 | Consistency: 0.0125 | SSIM: 0.0325 | Grad: 65186.848\n",
      "[Epoch 30, Batch 84/100] Loss: 0.0574 | RMSE: 0.0534 | Consistency: 0.0128 | SSIM: 0.0381 | Grad: 118876.281\n",
      "[Epoch 30, Batch 85/100] Loss: 0.0490 | RMSE: 0.0453 | Consistency: 0.0131 | SSIM: 0.0362 | Grad: 56363.484\n",
      "[Epoch 30, Batch 86/100] Loss: 0.0450 | RMSE: 0.0416 | Consistency: 0.0100 | SSIM: 0.0324 | Grad: 74285.352\n",
      "[Epoch 30, Batch 87/100] Loss: 0.0454 | RMSE: 0.0426 | Consistency: 0.0086 | SSIM: 0.0271 | Grad: 46006.801\n",
      "[Epoch 30, Batch 88/100] Loss: 0.0503 | RMSE: 0.0468 | Consistency: 0.0111 | SSIM: 0.0341 | Grad: 86345.836\n",
      "[Epoch 30, Batch 89/100] Loss: 0.0493 | RMSE: 0.0462 | Consistency: 0.0142 | SSIM: 0.0302 | Grad: 147759.062\n",
      "[Epoch 30, Batch 90/100] Loss: 0.0542 | RMSE: 0.0507 | Consistency: 0.0127 | SSIM: 0.0333 | Grad: 116120.102\n",
      "[Epoch 30, Batch 91/100] Loss: 0.0493 | RMSE: 0.0463 | Consistency: 0.0123 | SSIM: 0.0287 | Grad: 53826.945\n",
      "[Epoch 30, Batch 92/100] Loss: 0.0455 | RMSE: 0.0425 | Consistency: 0.0111 | SSIM: 0.0286 | Grad: 40658.102\n",
      "[Epoch 30, Batch 93/100] Loss: 0.0474 | RMSE: 0.0445 | Consistency: 0.0093 | SSIM: 0.0277 | Grad: 44303.434\n",
      "[Epoch 30, Batch 94/100] Loss: 0.0559 | RMSE: 0.0523 | Consistency: 0.0123 | SSIM: 0.0347 | Grad: 113661.664\n",
      "[Epoch 30, Batch 95/100] Loss: 0.0522 | RMSE: 0.0487 | Consistency: 0.0116 | SSIM: 0.0336 | Grad: 55812.371\n",
      "[Epoch 30, Batch 96/100] Loss: 0.0493 | RMSE: 0.0460 | Consistency: 0.0114 | SSIM: 0.0325 | Grad: 51106.027\n",
      "[Epoch 30, Batch 97/100] Loss: 0.0458 | RMSE: 0.0430 | Consistency: 0.0090 | SSIM: 0.0268 | Grad: 110368.734\n",
      "[Epoch 30, Batch 98/100] Loss: 0.0514 | RMSE: 0.0480 | Consistency: 0.0137 | SSIM: 0.0320 | Grad: 90467.203\n",
      "[Epoch 30, Batch 99/100] Loss: 0.0578 | RMSE: 0.0542 | Consistency: 0.0154 | SSIM: 0.0347 | Grad: 64585.340\n",
      "[Epoch 30, Batch 100/100] Loss: 0.0497 | RMSE: 0.0461 | Consistency: 0.0128 | SSIM: 0.0346 | Grad: 122273.789\n",
      "✅ Epoch 30 완료!\n",
      "   📈 평균 Loss: 0.052140\n",
      "   📊 평균 RMSE: 0.048675\n",
      "   ⚙️  학습률: 0.000787\n",
      "   🏆 NEW BEST! RMSE: 0.048675\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 31/80 시작...\n",
      "[Epoch 31, Batch 1/100] Loss: 0.0462 | RMSE: 0.0428 | Consistency: 0.0110 | SSIM: 0.0330 | Grad: 103940.047\n",
      "[Epoch 31, Batch 2/100] Loss: 0.0495 | RMSE: 0.0451 | Consistency: 0.0115 | SSIM: 0.0430 | Grad: 59522.500\n",
      "[Epoch 31, Batch 3/100] Loss: 0.0484 | RMSE: 0.0455 | Consistency: 0.0102 | SSIM: 0.0280 | Grad: 130841.930\n",
      "[Epoch 31, Batch 4/100] Loss: 0.0520 | RMSE: 0.0487 | Consistency: 0.0132 | SSIM: 0.0317 | Grad: 139344.031\n",
      "[Epoch 31, Batch 5/100] Loss: 0.0454 | RMSE: 0.0425 | Consistency: 0.0099 | SSIM: 0.0282 | Grad: 100435.289\n",
      "[Epoch 31, Batch 6/100] Loss: 0.0493 | RMSE: 0.0457 | Consistency: 0.0111 | SSIM: 0.0351 | Grad: 67594.586\n",
      "[Epoch 31, Batch 7/100] Loss: 0.0543 | RMSE: 0.0504 | Consistency: 0.0117 | SSIM: 0.0379 | Grad: 116638.188\n",
      "[Epoch 31, Batch 8/100] Loss: 0.0472 | RMSE: 0.0444 | Consistency: 0.0093 | SSIM: 0.0276 | Grad: 91638.617\n",
      "[Epoch 31, Batch 9/100] Loss: 0.0489 | RMSE: 0.0459 | Consistency: 0.0109 | SSIM: 0.0283 | Grad: 78552.922\n",
      "[Epoch 31, Batch 10/100] Loss: 0.0488 | RMSE: 0.0458 | Consistency: 0.0101 | SSIM: 0.0291 | Grad: 124766.273\n",
      "[Epoch 31, Batch 11/100] Loss: 0.0465 | RMSE: 0.0436 | Consistency: 0.0097 | SSIM: 0.0280 | Grad: 140452.016\n",
      "[Epoch 31, Batch 12/100] Loss: 0.0533 | RMSE: 0.0500 | Consistency: 0.0123 | SSIM: 0.0318 | Grad: 122419.242\n",
      "[Epoch 31, Batch 13/100] Loss: 0.0511 | RMSE: 0.0478 | Consistency: 0.0100 | SSIM: 0.0322 | Grad: 109105.703\n",
      "[Epoch 31, Batch 14/100] Loss: 0.0485 | RMSE: 0.0456 | Consistency: 0.0114 | SSIM: 0.0280 | Grad: 67491.688\n",
      "[Epoch 31, Batch 15/100] Loss: 0.0505 | RMSE: 0.0479 | Consistency: 0.0090 | SSIM: 0.0245 | Grad: 132255.672\n",
      "[Epoch 31, Batch 16/100] Loss: 0.0532 | RMSE: 0.0501 | Consistency: 0.0116 | SSIM: 0.0304 | Grad: 154659.031\n",
      "[Epoch 31, Batch 17/100] Loss: 0.0442 | RMSE: 0.0409 | Consistency: 0.0092 | SSIM: 0.0323 | Grad: 93156.555\n",
      "[Epoch 31, Batch 18/100] Loss: 0.0487 | RMSE: 0.0455 | Consistency: 0.0130 | SSIM: 0.0310 | Grad: 31398.869\n",
      "[Epoch 31, Batch 19/100] Loss: 0.0469 | RMSE: 0.0437 | Consistency: 0.0091 | SSIM: 0.0309 | Grad: 115229.438\n",
      "[Epoch 31, Batch 20/100] Loss: 0.0487 | RMSE: 0.0451 | Consistency: 0.0097 | SSIM: 0.0354 | Grad: 46157.758\n",
      "[Epoch 31, Batch 21/100] Loss: 0.0529 | RMSE: 0.0495 | Consistency: 0.0123 | SSIM: 0.0327 | Grad: 52925.863\n",
      "[Epoch 31, Batch 22/100] Loss: 0.0490 | RMSE: 0.0455 | Consistency: 0.0116 | SSIM: 0.0338 | Grad: 117021.289\n",
      "[Epoch 31, Batch 23/100] Loss: 0.0580 | RMSE: 0.0543 | Consistency: 0.0108 | SSIM: 0.0358 | Grad: 154504.297\n",
      "[Epoch 31, Batch 24/100] Loss: 0.0496 | RMSE: 0.0466 | Consistency: 0.0107 | SSIM: 0.0292 | Grad: 72597.711\n",
      "[Epoch 31, Batch 25/100] Loss: 0.0525 | RMSE: 0.0495 | Consistency: 0.0091 | SSIM: 0.0291 | Grad: 80724.602\n",
      "[Epoch 31, Batch 26/100] Loss: 0.0574 | RMSE: 0.0537 | Consistency: 0.0123 | SSIM: 0.0359 | Grad: 124148.570\n",
      "[Epoch 31, Batch 27/100] Loss: 0.0482 | RMSE: 0.0451 | Consistency: 0.0080 | SSIM: 0.0299 | Grad: 131576.594\n",
      "[Epoch 31, Batch 28/100] Loss: 0.0519 | RMSE: 0.0488 | Consistency: 0.0095 | SSIM: 0.0299 | Grad: 106648.273\n",
      "[Epoch 31, Batch 29/100] Loss: 0.0527 | RMSE: 0.0496 | Consistency: 0.0114 | SSIM: 0.0299 | Grad: 84886.758\n",
      "[Epoch 31, Batch 30/100] Loss: 0.0477 | RMSE: 0.0447 | Consistency: 0.0093 | SSIM: 0.0284 | Grad: 98265.789\n",
      "[Epoch 31, Batch 31/100] Loss: 0.0557 | RMSE: 0.0515 | Consistency: 0.0121 | SSIM: 0.0404 | Grad: 137266.812\n",
      "[Epoch 31, Batch 32/100] Loss: 0.0451 | RMSE: 0.0412 | Consistency: 0.0095 | SSIM: 0.0378 | Grad: 109957.375\n",
      "[Epoch 31, Batch 33/100] Loss: 0.0486 | RMSE: 0.0455 | Consistency: 0.0103 | SSIM: 0.0298 | Grad: 106695.961\n",
      "[Epoch 31, Batch 34/100] Loss: 0.0534 | RMSE: 0.0502 | Consistency: 0.0122 | SSIM: 0.0309 | Grad: 40843.965\n",
      "[Epoch 31, Batch 35/100] Loss: 0.0489 | RMSE: 0.0455 | Consistency: 0.0093 | SSIM: 0.0333 | Grad: 76212.953\n",
      "[Epoch 31, Batch 36/100] Loss: 0.0467 | RMSE: 0.0433 | Consistency: 0.0105 | SSIM: 0.0337 | Grad: 72223.336\n",
      "[Epoch 31, Batch 37/100] Loss: 0.0454 | RMSE: 0.0425 | Consistency: 0.0089 | SSIM: 0.0274 | Grad: 110075.852\n",
      "[Epoch 31, Batch 38/100] Loss: 0.0576 | RMSE: 0.0542 | Consistency: 0.0134 | SSIM: 0.0323 | Grad: 88236.617\n",
      "[Epoch 31, Batch 39/100] Loss: 0.0498 | RMSE: 0.0469 | Consistency: 0.0094 | SSIM: 0.0287 | Grad: 49485.332\n",
      "[Epoch 31, Batch 40/100] Loss: 0.0483 | RMSE: 0.0449 | Consistency: 0.0101 | SSIM: 0.0330 | Grad: 51469.855\n",
      "[Epoch 31, Batch 41/100] Loss: 0.0447 | RMSE: 0.0421 | Consistency: 0.0089 | SSIM: 0.0256 | Grad: 110403.586\n",
      "[Epoch 31, Batch 42/100] Loss: 0.0471 | RMSE: 0.0445 | Consistency: 0.0096 | SSIM: 0.0250 | Grad: 90474.156\n",
      "[Epoch 31, Batch 43/100] Loss: 0.0470 | RMSE: 0.0443 | Consistency: 0.0099 | SSIM: 0.0268 | Grad: 86516.766\n",
      "[Epoch 31, Batch 44/100] Loss: 0.0509 | RMSE: 0.0474 | Consistency: 0.0109 | SSIM: 0.0337 | Grad: 101092.000\n",
      "[Epoch 31, Batch 45/100] Loss: 0.0453 | RMSE: 0.0420 | Consistency: 0.0111 | SSIM: 0.0312 | Grad: 76776.656\n",
      "[Epoch 31, Batch 46/100] Loss: 0.0509 | RMSE: 0.0477 | Consistency: 0.0140 | SSIM: 0.0302 | Grad: 81695.844\n",
      "[Epoch 31, Batch 47/100] Loss: 0.0583 | RMSE: 0.0548 | Consistency: 0.0123 | SSIM: 0.0339 | Grad: 91697.141\n",
      "[Epoch 31, Batch 48/100] Loss: 0.0554 | RMSE: 0.0513 | Consistency: 0.0103 | SSIM: 0.0398 | Grad: 148907.625\n",
      "[Epoch 31, Batch 49/100] Loss: 0.0498 | RMSE: 0.0468 | Consistency: 0.0112 | SSIM: 0.0294 | Grad: 62160.766\n",
      "[Epoch 31, Batch 50/100] Loss: 0.0523 | RMSE: 0.0493 | Consistency: 0.0093 | SSIM: 0.0287 | Grad: 35379.586\n",
      "[Epoch 31, Batch 51/100] Loss: 0.0452 | RMSE: 0.0428 | Consistency: 0.0105 | SSIM: 0.0234 | Grad: 113896.062\n",
      "[Epoch 31, Batch 52/100] Loss: 0.0497 | RMSE: 0.0465 | Consistency: 0.0093 | SSIM: 0.0307 | Grad: 87302.359\n",
      "[Epoch 31, Batch 53/100] Loss: 0.0481 | RMSE: 0.0448 | Consistency: 0.0118 | SSIM: 0.0316 | Grad: 65207.152\n",
      "[Epoch 31, Batch 54/100] Loss: 0.0547 | RMSE: 0.0508 | Consistency: 0.0130 | SSIM: 0.0382 | Grad: 102074.273\n",
      "[Epoch 31, Batch 55/100] Loss: 0.0523 | RMSE: 0.0488 | Consistency: 0.0136 | SSIM: 0.0340 | Grad: 101630.883\n",
      "[Epoch 31, Batch 56/100] Loss: 0.0557 | RMSE: 0.0519 | Consistency: 0.0116 | SSIM: 0.0362 | Grad: 140050.141\n",
      "[Epoch 31, Batch 57/100] Loss: 0.0489 | RMSE: 0.0453 | Consistency: 0.0105 | SSIM: 0.0350 | Grad: 81915.055\n",
      "[Epoch 31, Batch 58/100] Loss: 0.0704 | RMSE: 0.0660 | Consistency: 0.0289 | SSIM: 0.0414 | Grad: 78818.023\n",
      "[Epoch 31, Batch 59/100] Loss: 0.0511 | RMSE: 0.0479 | Consistency: 0.0104 | SSIM: 0.0312 | Grad: 135097.953\n",
      "[Epoch 31, Batch 60/100] Loss: 0.0535 | RMSE: 0.0501 | Consistency: 0.0122 | SSIM: 0.0326 | Grad: 82644.883\n",
      "[Epoch 31, Batch 61/100] Loss: 0.0524 | RMSE: 0.0490 | Consistency: 0.0124 | SSIM: 0.0328 | Grad: 104014.086\n",
      "[Epoch 31, Batch 62/100] Loss: 0.0552 | RMSE: 0.0518 | Consistency: 0.0172 | SSIM: 0.0325 | Grad: 132010.812\n",
      "[Epoch 31, Batch 63/100] Loss: 0.0612 | RMSE: 0.0565 | Consistency: 0.0167 | SSIM: 0.0448 | Grad: 115686.742\n",
      "[Epoch 31, Batch 64/100] Loss: 0.0569 | RMSE: 0.0536 | Consistency: 0.0141 | SSIM: 0.0311 | Grad: 88867.633\n",
      "[Epoch 31, Batch 65/100] Loss: 0.0480 | RMSE: 0.0441 | Consistency: 0.0124 | SSIM: 0.0379 | Grad: 116190.906\n",
      "[Epoch 31, Batch 66/100] Loss: 0.0489 | RMSE: 0.0458 | Consistency: 0.0119 | SSIM: 0.0299 | Grad: 79519.930\n",
      "[Epoch 31, Batch 67/100] Loss: 0.0489 | RMSE: 0.0458 | Consistency: 0.0101 | SSIM: 0.0308 | Grad: 107308.719\n",
      "[Epoch 31, Batch 68/100] Loss: 0.0499 | RMSE: 0.0469 | Consistency: 0.0107 | SSIM: 0.0291 | Grad: 97793.531\n",
      "[Epoch 31, Batch 69/100] Loss: 0.0449 | RMSE: 0.0417 | Consistency: 0.0088 | SSIM: 0.0308 | Grad: 75377.586\n",
      "[Epoch 31, Batch 70/100] Loss: 0.0475 | RMSE: 0.0449 | Consistency: 0.0077 | SSIM: 0.0247 | Grad: 145772.359\n",
      "[Epoch 31, Batch 71/100] Loss: 0.0578 | RMSE: 0.0544 | Consistency: 0.0144 | SSIM: 0.0325 | Grad: 174585.828\n",
      "[Epoch 31, Batch 72/100] Loss: 0.0525 | RMSE: 0.0489 | Consistency: 0.0121 | SSIM: 0.0349 | Grad: 85474.680\n",
      "[Epoch 31, Batch 73/100] Loss: 0.0485 | RMSE: 0.0455 | Consistency: 0.0115 | SSIM: 0.0293 | Grad: 85587.172\n",
      "[Epoch 31, Batch 74/100] Loss: 0.0492 | RMSE: 0.0465 | Consistency: 0.0090 | SSIM: 0.0267 | Grad: 75866.477\n",
      "[Epoch 31, Batch 75/100] Loss: 0.0436 | RMSE: 0.0405 | Consistency: 0.0096 | SSIM: 0.0300 | Grad: 34845.281\n",
      "[Epoch 31, Batch 76/100] Loss: 0.0458 | RMSE: 0.0433 | Consistency: 0.0085 | SSIM: 0.0246 | Grad: 93412.438\n",
      "[Epoch 31, Batch 77/100] Loss: 0.0522 | RMSE: 0.0488 | Consistency: 0.0124 | SSIM: 0.0323 | Grad: 97860.094\n",
      "[Epoch 31, Batch 78/100] Loss: 0.0496 | RMSE: 0.0463 | Consistency: 0.0088 | SSIM: 0.0316 | Grad: 88713.578\n",
      "[Epoch 31, Batch 79/100] Loss: 0.0517 | RMSE: 0.0478 | Consistency: 0.0116 | SSIM: 0.0379 | Grad: 103515.680\n",
      "[Epoch 31, Batch 80/100] Loss: 0.0583 | RMSE: 0.0547 | Consistency: 0.0154 | SSIM: 0.0352 | Grad: 96131.719\n",
      "[Epoch 31, Batch 81/100] Loss: 0.0568 | RMSE: 0.0529 | Consistency: 0.0170 | SSIM: 0.0365 | Grad: 58828.367\n",
      "[Epoch 31, Batch 82/100] Loss: 0.0498 | RMSE: 0.0461 | Consistency: 0.0104 | SSIM: 0.0357 | Grad: 108749.062\n",
      "[Epoch 31, Batch 83/100] Loss: 0.0533 | RMSE: 0.0497 | Consistency: 0.0135 | SSIM: 0.0344 | Grad: 102007.398\n",
      "[Epoch 31, Batch 84/100] Loss: 0.0509 | RMSE: 0.0479 | Consistency: 0.0116 | SSIM: 0.0294 | Grad: 102320.938\n",
      "[Epoch 31, Batch 85/100] Loss: 0.0433 | RMSE: 0.0403 | Consistency: 0.0070 | SSIM: 0.0291 | Grad: 77531.328\n",
      "[Epoch 31, Batch 86/100] Loss: 0.0446 | RMSE: 0.0416 | Consistency: 0.0085 | SSIM: 0.0292 | Grad: 111505.109\n",
      "[Epoch 31, Batch 87/100] Loss: 0.0507 | RMSE: 0.0467 | Consistency: 0.0105 | SSIM: 0.0388 | Grad: 51899.094\n",
      "[Epoch 31, Batch 88/100] Loss: 0.0454 | RMSE: 0.0425 | Consistency: 0.0093 | SSIM: 0.0280 | Grad: 81391.281\n",
      "[Epoch 31, Batch 89/100] Loss: 0.0566 | RMSE: 0.0527 | Consistency: 0.0128 | SSIM: 0.0373 | Grad: 95891.516\n",
      "[Epoch 31, Batch 90/100] Loss: 0.0485 | RMSE: 0.0452 | Consistency: 0.0119 | SSIM: 0.0319 | Grad: 95090.109\n",
      "[Epoch 31, Batch 91/100] Loss: 0.0558 | RMSE: 0.0518 | Consistency: 0.0170 | SSIM: 0.0386 | Grad: 135234.281\n",
      "[Epoch 31, Batch 92/100] Loss: 0.0543 | RMSE: 0.0507 | Consistency: 0.0156 | SSIM: 0.0346 | Grad: 95376.164\n",
      "[Epoch 31, Batch 93/100] Loss: 0.0482 | RMSE: 0.0455 | Consistency: 0.0136 | SSIM: 0.0255 | Grad: 144688.141\n",
      "[Epoch 31, Batch 94/100] Loss: 0.0590 | RMSE: 0.0552 | Consistency: 0.0220 | SSIM: 0.0357 | Grad: 183931.016\n",
      "[Epoch 31, Batch 95/100] Loss: 0.0494 | RMSE: 0.0466 | Consistency: 0.0133 | SSIM: 0.0268 | Grad: 120255.648\n",
      "[Epoch 31, Batch 96/100] Loss: 0.0489 | RMSE: 0.0458 | Consistency: 0.0117 | SSIM: 0.0303 | Grad: 79570.703\n",
      "[Epoch 31, Batch 97/100] Loss: 0.0473 | RMSE: 0.0440 | Consistency: 0.0107 | SSIM: 0.0314 | Grad: 111078.953\n",
      "[Epoch 31, Batch 98/100] Loss: 0.0450 | RMSE: 0.0422 | Consistency: 0.0111 | SSIM: 0.0272 | Grad: 99068.844\n",
      "[Epoch 31, Batch 99/100] Loss: 0.0561 | RMSE: 0.0524 | Consistency: 0.0150 | SSIM: 0.0354 | Grad: 79180.664\n",
      "[Epoch 31, Batch 100/100] Loss: 0.0530 | RMSE: 0.0493 | Consistency: 0.0108 | SSIM: 0.0358 | Grad: 51375.000\n",
      "✅ Epoch 31 완료!\n",
      "   📈 평균 Loss: 0.050722\n",
      "   📊 평균 RMSE: 0.047409\n",
      "   ⚙️  학습률: 0.000768\n",
      "   🏆 NEW BEST! RMSE: 0.047409\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 32/80 시작...\n",
      "[Epoch 32, Batch 1/100] Loss: 0.0458 | RMSE: 0.0419 | Consistency: 0.0122 | SSIM: 0.0376 | Grad: 116345.367\n",
      "[Epoch 32, Batch 2/100] Loss: 0.0550 | RMSE: 0.0513 | Consistency: 0.0174 | SSIM: 0.0353 | Grad: 148956.625\n",
      "[Epoch 32, Batch 3/100] Loss: 0.0553 | RMSE: 0.0513 | Consistency: 0.0133 | SSIM: 0.0388 | Grad: 117513.336\n",
      "[Epoch 32, Batch 4/100] Loss: 0.0591 | RMSE: 0.0556 | Consistency: 0.0122 | SSIM: 0.0339 | Grad: 90419.047\n",
      "[Epoch 32, Batch 5/100] Loss: 0.0522 | RMSE: 0.0484 | Consistency: 0.0158 | SSIM: 0.0359 | Grad: 115115.078\n",
      "[Epoch 32, Batch 6/100] Loss: 0.0532 | RMSE: 0.0493 | Consistency: 0.0117 | SSIM: 0.0381 | Grad: 110764.227\n",
      "[Epoch 32, Batch 7/100] Loss: 0.0570 | RMSE: 0.0537 | Consistency: 0.0171 | SSIM: 0.0312 | Grad: 112515.383\n",
      "[Epoch 32, Batch 8/100] Loss: 0.0604 | RMSE: 0.0566 | Consistency: 0.0155 | SSIM: 0.0361 | Grad: 59559.660\n",
      "[Epoch 32, Batch 9/100] Loss: 0.0536 | RMSE: 0.0499 | Consistency: 0.0170 | SSIM: 0.0351 | Grad: 152938.891\n",
      "[Epoch 32, Batch 10/100] Loss: 0.0650 | RMSE: 0.0608 | Consistency: 0.0203 | SSIM: 0.0399 | Grad: 146266.641\n",
      "[Epoch 32, Batch 11/100] Loss: 0.0650 | RMSE: 0.0606 | Consistency: 0.0209 | SSIM: 0.0419 | Grad: 59587.699\n",
      "[Epoch 32, Batch 12/100] Loss: 0.0558 | RMSE: 0.0520 | Consistency: 0.0123 | SSIM: 0.0373 | Grad: 73990.852\n",
      "[Epoch 32, Batch 13/100] Loss: 0.0500 | RMSE: 0.0467 | Consistency: 0.0103 | SSIM: 0.0321 | Grad: 73621.570\n",
      "[Epoch 32, Batch 14/100] Loss: 0.0501 | RMSE: 0.0465 | Consistency: 0.0122 | SSIM: 0.0350 | Grad: 111980.352\n",
      "[Epoch 32, Batch 15/100] Loss: 0.0606 | RMSE: 0.0562 | Consistency: 0.0208 | SSIM: 0.0417 | Grad: 37137.578\n",
      "[Epoch 32, Batch 16/100] Loss: 0.0558 | RMSE: 0.0519 | Consistency: 0.0137 | SSIM: 0.0379 | Grad: 56788.297\n",
      "[Epoch 32, Batch 17/100] Loss: 0.0492 | RMSE: 0.0460 | Consistency: 0.0116 | SSIM: 0.0310 | Grad: 92359.656\n",
      "[Epoch 32, Batch 18/100] Loss: 0.0562 | RMSE: 0.0523 | Consistency: 0.0163 | SSIM: 0.0375 | Grad: 53464.906\n",
      "[Epoch 32, Batch 19/100] Loss: 0.0535 | RMSE: 0.0502 | Consistency: 0.0122 | SSIM: 0.0312 | Grad: 73843.070\n",
      "[Epoch 32, Batch 20/100] Loss: 0.0461 | RMSE: 0.0434 | Consistency: 0.0101 | SSIM: 0.0270 | Grad: 41680.684\n",
      "[Epoch 32, Batch 21/100] Loss: 0.0560 | RMSE: 0.0518 | Consistency: 0.0167 | SSIM: 0.0410 | Grad: 129004.617\n",
      "[Epoch 32, Batch 22/100] Loss: 0.0484 | RMSE: 0.0458 | Consistency: 0.0132 | SSIM: 0.0246 | Grad: 112093.750\n",
      "[Epoch 32, Batch 23/100] Loss: 0.0505 | RMSE: 0.0475 | Consistency: 0.0105 | SSIM: 0.0283 | Grad: 92918.672\n",
      "[Epoch 32, Batch 24/100] Loss: 0.0493 | RMSE: 0.0460 | Consistency: 0.0109 | SSIM: 0.0316 | Grad: 104511.070\n",
      "[Epoch 32, Batch 25/100] Loss: 0.0520 | RMSE: 0.0489 | Consistency: 0.0135 | SSIM: 0.0296 | Grad: 101285.828\n",
      "[Epoch 32, Batch 26/100] Loss: 0.0447 | RMSE: 0.0417 | Consistency: 0.0108 | SSIM: 0.0290 | Grad: 89668.070\n",
      "[Epoch 32, Batch 27/100] Loss: 0.0516 | RMSE: 0.0480 | Consistency: 0.0109 | SSIM: 0.0351 | Grad: 94273.984\n",
      "[Epoch 32, Batch 28/100] Loss: 0.0548 | RMSE: 0.0509 | Consistency: 0.0144 | SSIM: 0.0380 | Grad: 75425.984\n",
      "[Epoch 32, Batch 29/100] Loss: 0.0545 | RMSE: 0.0508 | Consistency: 0.0126 | SSIM: 0.0356 | Grad: 27676.143\n",
      "[Epoch 32, Batch 30/100] Loss: 0.0586 | RMSE: 0.0543 | Consistency: 0.0103 | SSIM: 0.0424 | Grad: 152205.766\n",
      "[Epoch 32, Batch 31/100] Loss: 0.0541 | RMSE: 0.0510 | Consistency: 0.0120 | SSIM: 0.0295 | Grad: 121532.219\n",
      "[Epoch 32, Batch 32/100] Loss: 0.0631 | RMSE: 0.0587 | Consistency: 0.0248 | SSIM: 0.0416 | Grad: 99567.664\n",
      "[Epoch 32, Batch 33/100] Loss: 0.0527 | RMSE: 0.0495 | Consistency: 0.0117 | SSIM: 0.0311 | Grad: 97068.352\n",
      "[Epoch 32, Batch 34/100] Loss: 0.0485 | RMSE: 0.0451 | Consistency: 0.0094 | SSIM: 0.0334 | Grad: 87457.305\n",
      "[Epoch 32, Batch 35/100] Loss: 0.0505 | RMSE: 0.0475 | Consistency: 0.0117 | SSIM: 0.0291 | Grad: 65185.922\n",
      "[Epoch 32, Batch 36/100] Loss: 0.0477 | RMSE: 0.0440 | Consistency: 0.0102 | SSIM: 0.0362 | Grad: 81327.562\n",
      "[Epoch 32, Batch 37/100] Loss: 0.0507 | RMSE: 0.0471 | Consistency: 0.0097 | SSIM: 0.0355 | Grad: 103894.508\n",
      "[Epoch 32, Batch 38/100] Loss: 0.0474 | RMSE: 0.0441 | Consistency: 0.0097 | SSIM: 0.0321 | Grad: 85637.078\n",
      "[Epoch 32, Batch 39/100] Loss: 0.0427 | RMSE: 0.0398 | Consistency: 0.0079 | SSIM: 0.0284 | Grad: 78407.758\n",
      "[Epoch 32, Batch 40/100] Loss: 0.0512 | RMSE: 0.0479 | Consistency: 0.0115 | SSIM: 0.0317 | Grad: 58667.184\n",
      "[Epoch 32, Batch 41/100] Loss: 0.0465 | RMSE: 0.0438 | Consistency: 0.0096 | SSIM: 0.0268 | Grad: 41774.145\n",
      "[Epoch 32, Batch 42/100] Loss: 0.0520 | RMSE: 0.0491 | Consistency: 0.0110 | SSIM: 0.0284 | Grad: 122437.195\n",
      "[Epoch 32, Batch 43/100] Loss: 0.0583 | RMSE: 0.0548 | Consistency: 0.0125 | SSIM: 0.0335 | Grad: 129287.227\n",
      "[Epoch 32, Batch 44/100] Loss: 0.0503 | RMSE: 0.0471 | Consistency: 0.0114 | SSIM: 0.0308 | Grad: 97549.320\n",
      "[Epoch 32, Batch 45/100] Loss: 0.0496 | RMSE: 0.0459 | Consistency: 0.0093 | SSIM: 0.0360 | Grad: 141345.828\n",
      "[Epoch 32, Batch 46/100] Loss: 0.0512 | RMSE: 0.0475 | Consistency: 0.0102 | SSIM: 0.0364 | Grad: 122755.750\n",
      "[Epoch 32, Batch 47/100] Loss: 0.0522 | RMSE: 0.0488 | Consistency: 0.0118 | SSIM: 0.0332 | Grad: 111136.922\n",
      "[Epoch 32, Batch 48/100] Loss: 0.0464 | RMSE: 0.0439 | Consistency: 0.0113 | SSIM: 0.0241 | Grad: 80399.984\n",
      "[Epoch 32, Batch 49/100] Loss: 0.0577 | RMSE: 0.0541 | Consistency: 0.0111 | SSIM: 0.0349 | Grad: 111838.047\n",
      "[Epoch 32, Batch 50/100] Loss: 0.0431 | RMSE: 0.0402 | Consistency: 0.0087 | SSIM: 0.0282 | Grad: 103475.883\n",
      "[Epoch 32, Batch 51/100] Loss: 0.0515 | RMSE: 0.0476 | Consistency: 0.0117 | SSIM: 0.0370 | Grad: 85056.164\n",
      "[Epoch 32, Batch 52/100] Loss: 0.0451 | RMSE: 0.0423 | Consistency: 0.0096 | SSIM: 0.0274 | Grad: 74436.375\n",
      "[Epoch 32, Batch 53/100] Loss: 0.0508 | RMSE: 0.0472 | Consistency: 0.0107 | SSIM: 0.0341 | Grad: 30940.086\n",
      "[Epoch 32, Batch 54/100] Loss: 0.0458 | RMSE: 0.0426 | Consistency: 0.0096 | SSIM: 0.0317 | Grad: 77415.047\n",
      "[Epoch 32, Batch 55/100] Loss: 0.0477 | RMSE: 0.0435 | Consistency: 0.0117 | SSIM: 0.0406 | Grad: 82940.250\n",
      "[Epoch 32, Batch 56/100] Loss: 0.0563 | RMSE: 0.0529 | Consistency: 0.0131 | SSIM: 0.0322 | Grad: 112743.086\n",
      "[Epoch 32, Batch 57/100] Loss: 0.0522 | RMSE: 0.0489 | Consistency: 0.0115 | SSIM: 0.0316 | Grad: 92455.031\n",
      "[Epoch 32, Batch 58/100] Loss: 0.0583 | RMSE: 0.0546 | Consistency: 0.0144 | SSIM: 0.0353 | Grad: 83959.078\n",
      "[Epoch 32, Batch 59/100] Loss: 0.0514 | RMSE: 0.0481 | Consistency: 0.0123 | SSIM: 0.0309 | Grad: 70299.148\n",
      "[Epoch 32, Batch 60/100] Loss: 0.0525 | RMSE: 0.0492 | Consistency: 0.0120 | SSIM: 0.0318 | Grad: 42650.504\n",
      "[Epoch 32, Batch 61/100] Loss: 0.0595 | RMSE: 0.0560 | Consistency: 0.0140 | SSIM: 0.0338 | Grad: 68527.633\n",
      "[Epoch 32, Batch 62/100] Loss: 0.0458 | RMSE: 0.0431 | Consistency: 0.0094 | SSIM: 0.0261 | Grad: 60274.320\n",
      "[Epoch 32, Batch 63/100] Loss: 0.0516 | RMSE: 0.0480 | Consistency: 0.0081 | SSIM: 0.0355 | Grad: 109559.555\n",
      "[Epoch 32, Batch 64/100] Loss: 0.0569 | RMSE: 0.0527 | Consistency: 0.0170 | SSIM: 0.0406 | Grad: 79857.312\n",
      "[Epoch 32, Batch 65/100] Loss: 0.0565 | RMSE: 0.0532 | Consistency: 0.0150 | SSIM: 0.0314 | Grad: 192409.438\n",
      "[Epoch 32, Batch 66/100] Loss: 0.0526 | RMSE: 0.0491 | Consistency: 0.0104 | SSIM: 0.0343 | Grad: 121791.172\n",
      "[Epoch 32, Batch 67/100] Loss: 0.0558 | RMSE: 0.0522 | Consistency: 0.0123 | SSIM: 0.0339 | Grad: 101821.984\n",
      "[Epoch 32, Batch 68/100] Loss: 0.0467 | RMSE: 0.0439 | Consistency: 0.0096 | SSIM: 0.0268 | Grad: 134617.500\n",
      "[Epoch 32, Batch 69/100] Loss: 0.0484 | RMSE: 0.0453 | Consistency: 0.0096 | SSIM: 0.0292 | Grad: 85181.234\n",
      "[Epoch 32, Batch 70/100] Loss: 0.0509 | RMSE: 0.0473 | Consistency: 0.0124 | SSIM: 0.0348 | Grad: 96431.422\n",
      "[Epoch 32, Batch 71/100] Loss: 0.0519 | RMSE: 0.0484 | Consistency: 0.0124 | SSIM: 0.0339 | Grad: 68480.742\n",
      "[Epoch 32, Batch 72/100] Loss: 0.0486 | RMSE: 0.0453 | Consistency: 0.0120 | SSIM: 0.0320 | Grad: 111412.859\n",
      "[Epoch 32, Batch 73/100] Loss: 0.0548 | RMSE: 0.0513 | Consistency: 0.0118 | SSIM: 0.0330 | Grad: 143874.484\n",
      "[Epoch 32, Batch 74/100] Loss: 0.0529 | RMSE: 0.0492 | Consistency: 0.0117 | SSIM: 0.0358 | Grad: 101517.383\n",
      "[Epoch 32, Batch 75/100] Loss: 0.0480 | RMSE: 0.0451 | Consistency: 0.0121 | SSIM: 0.0282 | Grad: 58617.664\n",
      "[Epoch 32, Batch 76/100] Loss: 0.0474 | RMSE: 0.0442 | Consistency: 0.0095 | SSIM: 0.0312 | Grad: 90965.570\n",
      "[Epoch 32, Batch 77/100] Loss: 0.0672 | RMSE: 0.0632 | Consistency: 0.0253 | SSIM: 0.0375 | Grad: 82554.523\n",
      "[Epoch 32, Batch 78/100] Loss: 0.0555 | RMSE: 0.0514 | Consistency: 0.0105 | SSIM: 0.0399 | Grad: 133952.984\n",
      "[Epoch 32, Batch 79/100] Loss: 0.0466 | RMSE: 0.0434 | Consistency: 0.0097 | SSIM: 0.0313 | Grad: 96031.289\n",
      "[Epoch 32, Batch 80/100] Loss: 0.0561 | RMSE: 0.0525 | Consistency: 0.0136 | SSIM: 0.0344 | Grad: 116420.195\n",
      "[Epoch 32, Batch 81/100] Loss: 0.0523 | RMSE: 0.0486 | Consistency: 0.0119 | SSIM: 0.0358 | Grad: 121742.898\n",
      "[Epoch 32, Batch 82/100] Loss: 0.0459 | RMSE: 0.0430 | Consistency: 0.0087 | SSIM: 0.0287 | Grad: 109787.836\n",
      "[Epoch 32, Batch 83/100] Loss: 0.0509 | RMSE: 0.0477 | Consistency: 0.0115 | SSIM: 0.0303 | Grad: 102284.398\n",
      "[Epoch 32, Batch 84/100] Loss: 0.0523 | RMSE: 0.0489 | Consistency: 0.0122 | SSIM: 0.0331 | Grad: 103098.148\n",
      "[Epoch 32, Batch 85/100] Loss: 0.0494 | RMSE: 0.0456 | Consistency: 0.0112 | SSIM: 0.0365 | Grad: 119102.070\n",
      "[Epoch 32, Batch 86/100] Loss: 0.0590 | RMSE: 0.0548 | Consistency: 0.0143 | SSIM: 0.0398 | Grad: 117060.031\n",
      "[Epoch 32, Batch 87/100] Loss: 0.0513 | RMSE: 0.0481 | Consistency: 0.0107 | SSIM: 0.0313 | Grad: 129093.156\n",
      "[Epoch 32, Batch 88/100] Loss: 0.0456 | RMSE: 0.0426 | Consistency: 0.0106 | SSIM: 0.0289 | Grad: 108970.461\n",
      "[Epoch 32, Batch 89/100] Loss: 0.0407 | RMSE: 0.0381 | Consistency: 0.0078 | SSIM: 0.0257 | Grad: 72208.109\n",
      "[Epoch 32, Batch 90/100] Loss: 0.0464 | RMSE: 0.0422 | Consistency: 0.0126 | SSIM: 0.0409 | Grad: 77862.922\n",
      "[Epoch 32, Batch 91/100] Loss: 0.0449 | RMSE: 0.0419 | Consistency: 0.0082 | SSIM: 0.0284 | Grad: 44633.188\n",
      "[Epoch 32, Batch 92/100] Loss: 0.0393 | RMSE: 0.0367 | Consistency: 0.0061 | SSIM: 0.0257 | Grad: 68086.547\n",
      "[Epoch 32, Batch 93/100] Loss: 0.0448 | RMSE: 0.0417 | Consistency: 0.0084 | SSIM: 0.0294 | Grad: 54803.777\n",
      "[Epoch 32, Batch 94/100] Loss: 0.0499 | RMSE: 0.0462 | Consistency: 0.0127 | SSIM: 0.0357 | Grad: 31791.600\n",
      "[Epoch 32, Batch 95/100] Loss: 0.0482 | RMSE: 0.0455 | Consistency: 0.0110 | SSIM: 0.0260 | Grad: 89978.148\n",
      "[Epoch 32, Batch 96/100] Loss: 0.0499 | RMSE: 0.0465 | Consistency: 0.0126 | SSIM: 0.0323 | Grad: 82861.250\n",
      "[Epoch 32, Batch 97/100] Loss: 0.0463 | RMSE: 0.0432 | Consistency: 0.0121 | SSIM: 0.0299 | Grad: 114055.055\n",
      "[Epoch 32, Batch 98/100] Loss: 0.0485 | RMSE: 0.0457 | Consistency: 0.0104 | SSIM: 0.0262 | Grad: 72685.484\n",
      "[Epoch 32, Batch 99/100] Loss: 0.0496 | RMSE: 0.0465 | Consistency: 0.0106 | SSIM: 0.0300 | Grad: 100660.875\n",
      "[Epoch 32, Batch 100/100] Loss: 0.0499 | RMSE: 0.0472 | Consistency: 0.0114 | SSIM: 0.0263 | Grad: 86346.250\n",
      "✅ Epoch 32 완료!\n",
      "   📈 평균 Loss: 0.051651\n",
      "   📊 평균 RMSE: 0.048221\n",
      "   ⚙️  학습률: 0.000750\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 33/80 시작...\n",
      "[Epoch 33, Batch 1/100] Loss: 0.0519 | RMSE: 0.0483 | Consistency: 0.0101 | SSIM: 0.0351 | Grad: 68648.062\n",
      "[Epoch 33, Batch 2/100] Loss: 0.0499 | RMSE: 0.0467 | Consistency: 0.0099 | SSIM: 0.0309 | Grad: 111001.641\n",
      "[Epoch 33, Batch 3/100] Loss: 0.0519 | RMSE: 0.0489 | Consistency: 0.0109 | SSIM: 0.0283 | Grad: 123474.336\n",
      "[Epoch 33, Batch 4/100] Loss: 0.0485 | RMSE: 0.0455 | Consistency: 0.0113 | SSIM: 0.0290 | Grad: 88327.297\n",
      "[Epoch 33, Batch 5/100] Loss: 0.0429 | RMSE: 0.0404 | Consistency: 0.0073 | SSIM: 0.0239 | Grad: 76773.227\n",
      "[Epoch 33, Batch 6/100] Loss: 0.0503 | RMSE: 0.0475 | Consistency: 0.0091 | SSIM: 0.0270 | Grad: 135393.594\n",
      "[Epoch 33, Batch 7/100] Loss: 0.0471 | RMSE: 0.0437 | Consistency: 0.0099 | SSIM: 0.0327 | Grad: 97461.906\n",
      "[Epoch 33, Batch 8/100] Loss: 0.0544 | RMSE: 0.0506 | Consistency: 0.0135 | SSIM: 0.0368 | Grad: 90967.406\n",
      "[Epoch 33, Batch 9/100] Loss: 0.0456 | RMSE: 0.0429 | Consistency: 0.0095 | SSIM: 0.0262 | Grad: 88758.477\n",
      "[Epoch 33, Batch 10/100] Loss: 0.0490 | RMSE: 0.0459 | Consistency: 0.0104 | SSIM: 0.0306 | Grad: 53680.586\n",
      "[Epoch 33, Batch 11/100] Loss: 0.0446 | RMSE: 0.0415 | Consistency: 0.0074 | SSIM: 0.0298 | Grad: 134330.469\n",
      "[Epoch 33, Batch 12/100] Loss: 0.0469 | RMSE: 0.0440 | Consistency: 0.0093 | SSIM: 0.0288 | Grad: 95616.789\n",
      "[Epoch 33, Batch 13/100] Loss: 0.0480 | RMSE: 0.0449 | Consistency: 0.0108 | SSIM: 0.0293 | Grad: 109904.812\n",
      "[Epoch 33, Batch 14/100] Loss: 0.0508 | RMSE: 0.0474 | Consistency: 0.0131 | SSIM: 0.0320 | Grad: 64055.746\n",
      "[Epoch 33, Batch 15/100] Loss: 0.0569 | RMSE: 0.0537 | Consistency: 0.0127 | SSIM: 0.0302 | Grad: 126051.352\n",
      "[Epoch 33, Batch 16/100] Loss: 0.0530 | RMSE: 0.0495 | Consistency: 0.0132 | SSIM: 0.0336 | Grad: 129620.578\n",
      "[Epoch 33, Batch 17/100] Loss: 0.0548 | RMSE: 0.0517 | Consistency: 0.0132 | SSIM: 0.0302 | Grad: 105348.602\n",
      "[Epoch 33, Batch 18/100] Loss: 0.0457 | RMSE: 0.0430 | Consistency: 0.0086 | SSIM: 0.0258 | Grad: 75620.945\n",
      "[Epoch 33, Batch 19/100] Loss: 0.0532 | RMSE: 0.0502 | Consistency: 0.0096 | SSIM: 0.0297 | Grad: 130242.188\n",
      "[Epoch 33, Batch 20/100] Loss: 0.0570 | RMSE: 0.0534 | Consistency: 0.0129 | SSIM: 0.0342 | Grad: 140600.766\n",
      "[Epoch 33, Batch 21/100] Loss: 0.0451 | RMSE: 0.0422 | Consistency: 0.0091 | SSIM: 0.0277 | Grad: 106914.961\n",
      "[Epoch 33, Batch 22/100] Loss: 0.0514 | RMSE: 0.0480 | Consistency: 0.0097 | SSIM: 0.0327 | Grad: 93320.141\n",
      "[Epoch 33, Batch 23/100] Loss: 0.0551 | RMSE: 0.0513 | Consistency: 0.0125 | SSIM: 0.0370 | Grad: 108475.375\n",
      "[Epoch 33, Batch 24/100] Loss: 0.0522 | RMSE: 0.0487 | Consistency: 0.0115 | SSIM: 0.0341 | Grad: 74884.188\n",
      "[Epoch 33, Batch 25/100] Loss: 0.0438 | RMSE: 0.0406 | Consistency: 0.0085 | SSIM: 0.0315 | Grad: 71495.227\n",
      "[Epoch 33, Batch 26/100] Loss: 0.0488 | RMSE: 0.0456 | Consistency: 0.0110 | SSIM: 0.0304 | Grad: 136811.641\n",
      "[Epoch 33, Batch 27/100] Loss: 0.0459 | RMSE: 0.0428 | Consistency: 0.0097 | SSIM: 0.0298 | Grad: 125206.906\n",
      "[Epoch 33, Batch 28/100] Loss: 0.0543 | RMSE: 0.0509 | Consistency: 0.0135 | SSIM: 0.0321 | Grad: 125451.578\n",
      "[Epoch 33, Batch 29/100] Loss: 0.0571 | RMSE: 0.0533 | Consistency: 0.0141 | SSIM: 0.0366 | Grad: 103681.188\n",
      "[Epoch 33, Batch 30/100] Loss: 0.0527 | RMSE: 0.0493 | Consistency: 0.0114 | SSIM: 0.0326 | Grad: 72735.680\n",
      "[Epoch 33, Batch 31/100] Loss: 0.0605 | RMSE: 0.0566 | Consistency: 0.0188 | SSIM: 0.0376 | Grad: 88561.242\n",
      "[Epoch 33, Batch 32/100] Loss: 0.0487 | RMSE: 0.0459 | Consistency: 0.0109 | SSIM: 0.0266 | Grad: 104373.023\n",
      "[Epoch 33, Batch 33/100] Loss: 0.0428 | RMSE: 0.0404 | Consistency: 0.0077 | SSIM: 0.0236 | Grad: 51928.539\n",
      "[Epoch 33, Batch 34/100] Loss: 0.0523 | RMSE: 0.0492 | Consistency: 0.0135 | SSIM: 0.0300 | Grad: 140459.766\n",
      "[Epoch 33, Batch 35/100] Loss: 0.0525 | RMSE: 0.0490 | Consistency: 0.0107 | SSIM: 0.0340 | Grad: 142234.094\n",
      "[Epoch 33, Batch 36/100] Loss: 0.0594 | RMSE: 0.0558 | Consistency: 0.0110 | SSIM: 0.0343 | Grad: 153533.094\n",
      "[Epoch 33, Batch 37/100] Loss: 0.0496 | RMSE: 0.0464 | Consistency: 0.0095 | SSIM: 0.0309 | Grad: 110141.266\n",
      "[Epoch 33, Batch 38/100] Loss: 0.0638 | RMSE: 0.0598 | Consistency: 0.0180 | SSIM: 0.0382 | Grad: 126762.078\n",
      "[Epoch 33, Batch 39/100] Loss: 0.0474 | RMSE: 0.0445 | Consistency: 0.0096 | SSIM: 0.0281 | Grad: 108995.188\n",
      "[Epoch 33, Batch 40/100] Loss: 0.0484 | RMSE: 0.0453 | Consistency: 0.0109 | SSIM: 0.0296 | Grad: 112745.219\n",
      "[Epoch 33, Batch 41/100] Loss: 0.0447 | RMSE: 0.0419 | Consistency: 0.0092 | SSIM: 0.0277 | Grad: 28229.453\n",
      "[Epoch 33, Batch 42/100] Loss: 0.0465 | RMSE: 0.0436 | Consistency: 0.0088 | SSIM: 0.0281 | Grad: 22596.088\n",
      "[Epoch 33, Batch 43/100] Loss: 0.0519 | RMSE: 0.0487 | Consistency: 0.0097 | SSIM: 0.0307 | Grad: 174579.984\n",
      "[Epoch 33, Batch 44/100] Loss: 0.0647 | RMSE: 0.0602 | Consistency: 0.0181 | SSIM: 0.0430 | Grad: 152710.188\n",
      "[Epoch 33, Batch 45/100] Loss: 0.0571 | RMSE: 0.0530 | Consistency: 0.0140 | SSIM: 0.0392 | Grad: 92476.109\n",
      "[Epoch 33, Batch 46/100] Loss: 0.0554 | RMSE: 0.0514 | Consistency: 0.0112 | SSIM: 0.0391 | Grad: 78485.586\n",
      "[Epoch 33, Batch 47/100] Loss: 0.0488 | RMSE: 0.0457 | Consistency: 0.0107 | SSIM: 0.0305 | Grad: 119169.125\n",
      "[Epoch 33, Batch 48/100] Loss: 0.0555 | RMSE: 0.0518 | Consistency: 0.0139 | SSIM: 0.0355 | Grad: 70401.680\n",
      "[Epoch 33, Batch 49/100] Loss: 0.0531 | RMSE: 0.0497 | Consistency: 0.0115 | SSIM: 0.0327 | Grad: 77724.211\n",
      "[Epoch 33, Batch 50/100] Loss: 0.0501 | RMSE: 0.0470 | Consistency: 0.0107 | SSIM: 0.0299 | Grad: 140042.312\n",
      "[Epoch 33, Batch 51/100] Loss: 0.0510 | RMSE: 0.0472 | Consistency: 0.0121 | SSIM: 0.0370 | Grad: 98660.734\n",
      "[Epoch 33, Batch 52/100] Loss: 0.0528 | RMSE: 0.0492 | Consistency: 0.0108 | SSIM: 0.0346 | Grad: 84800.758\n",
      "[Epoch 33, Batch 53/100] Loss: 0.0585 | RMSE: 0.0551 | Consistency: 0.0129 | SSIM: 0.0327 | Grad: 85331.195\n",
      "[Epoch 33, Batch 54/100] Loss: 0.0552 | RMSE: 0.0517 | Consistency: 0.0101 | SSIM: 0.0346 | Grad: 94020.820\n",
      "[Epoch 33, Batch 55/100] Loss: 0.0516 | RMSE: 0.0480 | Consistency: 0.0128 | SSIM: 0.0351 | Grad: 87050.445\n",
      "[Epoch 33, Batch 56/100] Loss: 0.0534 | RMSE: 0.0501 | Consistency: 0.0132 | SSIM: 0.0313 | Grad: 114121.070\n",
      "[Epoch 33, Batch 57/100] Loss: 0.0575 | RMSE: 0.0538 | Consistency: 0.0137 | SSIM: 0.0353 | Grad: 133278.938\n",
      "[Epoch 33, Batch 58/100] Loss: 0.0657 | RMSE: 0.0618 | Consistency: 0.0165 | SSIM: 0.0371 | Grad: 151201.578\n",
      "[Epoch 33, Batch 59/100] Loss: 0.0532 | RMSE: 0.0499 | Consistency: 0.0097 | SSIM: 0.0311 | Grad: 138203.000\n",
      "[Epoch 33, Batch 60/100] Loss: 0.0642 | RMSE: 0.0601 | Consistency: 0.0142 | SSIM: 0.0395 | Grad: 85718.930\n",
      "[Epoch 33, Batch 61/100] Loss: 0.0475 | RMSE: 0.0449 | Consistency: 0.0091 | SSIM: 0.0249 | Grad: 137746.719\n",
      "[Epoch 33, Batch 62/100] Loss: 0.0545 | RMSE: 0.0508 | Consistency: 0.0100 | SSIM: 0.0361 | Grad: 135700.844\n",
      "[Epoch 33, Batch 63/100] Loss: 0.0592 | RMSE: 0.0544 | Consistency: 0.0113 | SSIM: 0.0468 | Grad: 172724.906\n",
      "[Epoch 33, Batch 64/100] Loss: 0.0525 | RMSE: 0.0491 | Consistency: 0.0111 | SSIM: 0.0331 | Grad: 128582.148\n",
      "[Epoch 33, Batch 65/100] Loss: 0.0539 | RMSE: 0.0503 | Consistency: 0.0115 | SSIM: 0.0350 | Grad: 122199.617\n",
      "[Epoch 33, Batch 66/100] Loss: 0.0553 | RMSE: 0.0519 | Consistency: 0.0119 | SSIM: 0.0326 | Grad: 134775.188\n",
      "[Epoch 33, Batch 67/100] Loss: 0.0442 | RMSE: 0.0414 | Consistency: 0.0076 | SSIM: 0.0274 | Grad: 104712.258\n",
      "[Epoch 33, Batch 68/100] Loss: 0.0490 | RMSE: 0.0458 | Consistency: 0.0109 | SSIM: 0.0311 | Grad: 68559.086\n",
      "[Epoch 33, Batch 69/100] Loss: 0.0536 | RMSE: 0.0498 | Consistency: 0.0116 | SSIM: 0.0364 | Grad: 75516.938\n",
      "[Epoch 33, Batch 70/100] Loss: 0.0491 | RMSE: 0.0459 | Consistency: 0.0112 | SSIM: 0.0305 | Grad: 83720.930\n",
      "[Epoch 33, Batch 71/100] Loss: 0.0514 | RMSE: 0.0476 | Consistency: 0.0130 | SSIM: 0.0367 | Grad: 90624.484\n",
      "[Epoch 33, Batch 72/100] Loss: 0.0485 | RMSE: 0.0454 | Consistency: 0.0115 | SSIM: 0.0294 | Grad: 101352.180\n",
      "[Epoch 33, Batch 73/100] Loss: 0.0474 | RMSE: 0.0438 | Consistency: 0.0091 | SSIM: 0.0351 | Grad: 91990.352\n",
      "[Epoch 33, Batch 74/100] Loss: 0.0407 | RMSE: 0.0382 | Consistency: 0.0070 | SSIM: 0.0240 | Grad: 94267.547\n",
      "[Epoch 33, Batch 75/100] Loss: 0.0429 | RMSE: 0.0403 | Consistency: 0.0090 | SSIM: 0.0250 | Grad: 76763.922\n",
      "[Epoch 33, Batch 76/100] Loss: 0.0439 | RMSE: 0.0410 | Consistency: 0.0092 | SSIM: 0.0284 | Grad: 119453.609\n",
      "[Epoch 33, Batch 77/100] Loss: 0.0534 | RMSE: 0.0498 | Consistency: 0.0104 | SSIM: 0.0354 | Grad: 116826.039\n",
      "[Epoch 33, Batch 78/100] Loss: 0.0428 | RMSE: 0.0398 | Consistency: 0.0089 | SSIM: 0.0293 | Grad: 50044.543\n",
      "[Epoch 33, Batch 79/100] Loss: 0.0396 | RMSE: 0.0371 | Consistency: 0.0079 | SSIM: 0.0244 | Grad: 105225.820\n",
      "[Epoch 33, Batch 80/100] Loss: 0.0524 | RMSE: 0.0491 | Consistency: 0.0130 | SSIM: 0.0315 | Grad: 81400.000\n",
      "[Epoch 33, Batch 81/100] Loss: 0.0489 | RMSE: 0.0456 | Consistency: 0.0100 | SSIM: 0.0320 | Grad: 101889.320\n",
      "[Epoch 33, Batch 82/100] Loss: 0.0439 | RMSE: 0.0413 | Consistency: 0.0092 | SSIM: 0.0249 | Grad: 44397.711\n",
      "[Epoch 33, Batch 83/100] Loss: 0.0467 | RMSE: 0.0436 | Consistency: 0.0086 | SSIM: 0.0299 | Grad: 99383.836\n",
      "[Epoch 33, Batch 84/100] Loss: 0.0485 | RMSE: 0.0449 | Consistency: 0.0110 | SSIM: 0.0351 | Grad: 108145.438\n",
      "[Epoch 33, Batch 85/100] Loss: 0.0459 | RMSE: 0.0433 | Consistency: 0.0107 | SSIM: 0.0252 | Grad: 97113.930\n",
      "[Epoch 33, Batch 86/100] Loss: 0.0449 | RMSE: 0.0418 | Consistency: 0.0089 | SSIM: 0.0299 | Grad: 108811.547\n",
      "[Epoch 33, Batch 87/100] Loss: 0.0503 | RMSE: 0.0468 | Consistency: 0.0108 | SSIM: 0.0344 | Grad: 97727.242\n",
      "[Epoch 33, Batch 88/100] Loss: 0.0449 | RMSE: 0.0416 | Consistency: 0.0100 | SSIM: 0.0322 | Grad: 97552.141\n",
      "[Epoch 33, Batch 89/100] Loss: 0.0452 | RMSE: 0.0423 | Consistency: 0.0099 | SSIM: 0.0276 | Grad: 94036.727\n",
      "[Epoch 33, Batch 90/100] Loss: 0.0434 | RMSE: 0.0407 | Consistency: 0.0088 | SSIM: 0.0265 | Grad: 56739.938\n",
      "[Epoch 33, Batch 91/100] Loss: 0.0442 | RMSE: 0.0419 | Consistency: 0.0084 | SSIM: 0.0220 | Grad: 139019.109\n",
      "[Epoch 33, Batch 92/100] Loss: 0.0461 | RMSE: 0.0425 | Consistency: 0.0099 | SSIM: 0.0344 | Grad: 50183.957\n",
      "[Epoch 33, Batch 93/100] Loss: 0.0507 | RMSE: 0.0470 | Consistency: 0.0099 | SSIM: 0.0356 | Grad: 126998.039\n",
      "[Epoch 33, Batch 94/100] Loss: 0.0541 | RMSE: 0.0510 | Consistency: 0.0117 | SSIM: 0.0298 | Grad: 136475.641\n",
      "[Epoch 33, Batch 95/100] Loss: 0.0441 | RMSE: 0.0413 | Consistency: 0.0093 | SSIM: 0.0268 | Grad: 81102.414\n",
      "[Epoch 33, Batch 96/100] Loss: 0.0418 | RMSE: 0.0386 | Consistency: 0.0089 | SSIM: 0.0307 | Grad: 96469.461\n",
      "[Epoch 33, Batch 97/100] Loss: 0.0516 | RMSE: 0.0487 | Consistency: 0.0102 | SSIM: 0.0273 | Grad: 90142.828\n",
      "[Epoch 33, Batch 98/100] Loss: 0.0504 | RMSE: 0.0470 | Consistency: 0.0100 | SSIM: 0.0327 | Grad: 86912.344\n",
      "[Epoch 33, Batch 99/100] Loss: 0.0472 | RMSE: 0.0445 | Consistency: 0.0094 | SSIM: 0.0264 | Grad: 93993.383\n",
      "[Epoch 33, Batch 100/100] Loss: 0.0538 | RMSE: 0.0507 | Consistency: 0.0132 | SSIM: 0.0301 | Grad: 151195.828\n",
      "✅ Epoch 33 완료!\n",
      "   📈 평균 Loss: 0.050532\n",
      "   📊 평균 RMSE: 0.047269\n",
      "   ⚙️  학습률: 0.000731\n",
      "   🏆 NEW BEST! RMSE: 0.047269\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 34/80 시작...\n",
      "[Epoch 34, Batch 1/100] Loss: 0.0469 | RMSE: 0.0433 | Consistency: 0.0107 | SSIM: 0.0355 | Grad: 45186.887\n",
      "[Epoch 34, Batch 2/100] Loss: 0.0511 | RMSE: 0.0483 | Consistency: 0.0109 | SSIM: 0.0268 | Grad: 88551.320\n",
      "[Epoch 34, Batch 3/100] Loss: 0.0488 | RMSE: 0.0458 | Consistency: 0.0119 | SSIM: 0.0295 | Grad: 93655.109\n",
      "[Epoch 34, Batch 4/100] Loss: 0.0415 | RMSE: 0.0388 | Consistency: 0.0071 | SSIM: 0.0259 | Grad: 88163.523\n",
      "[Epoch 34, Batch 5/100] Loss: 0.0460 | RMSE: 0.0425 | Consistency: 0.0102 | SSIM: 0.0331 | Grad: 44204.332\n",
      "[Epoch 34, Batch 6/100] Loss: 0.0455 | RMSE: 0.0426 | Consistency: 0.0100 | SSIM: 0.0286 | Grad: 126237.977\n",
      "[Epoch 34, Batch 7/100] Loss: 0.0516 | RMSE: 0.0482 | Consistency: 0.0131 | SSIM: 0.0331 | Grad: 154512.531\n",
      "[Epoch 34, Batch 8/100] Loss: 0.0498 | RMSE: 0.0465 | Consistency: 0.0120 | SSIM: 0.0324 | Grad: 19495.580\n",
      "[Epoch 34, Batch 9/100] Loss: 0.0472 | RMSE: 0.0442 | Consistency: 0.0118 | SSIM: 0.0289 | Grad: 74527.797\n",
      "[Epoch 34, Batch 10/100] Loss: 0.0591 | RMSE: 0.0555 | Consistency: 0.0152 | SSIM: 0.0352 | Grad: 106376.086\n",
      "[Epoch 34, Batch 11/100] Loss: 0.0508 | RMSE: 0.0471 | Consistency: 0.0131 | SSIM: 0.0350 | Grad: 52118.234\n",
      "[Epoch 34, Batch 12/100] Loss: 0.0564 | RMSE: 0.0524 | Consistency: 0.0158 | SSIM: 0.0379 | Grad: 45246.090\n",
      "[Epoch 34, Batch 13/100] Loss: 0.0537 | RMSE: 0.0498 | Consistency: 0.0102 | SSIM: 0.0376 | Grad: 128100.617\n",
      "[Epoch 34, Batch 14/100] Loss: 0.0493 | RMSE: 0.0461 | Consistency: 0.0131 | SSIM: 0.0310 | Grad: 55548.277\n",
      "[Epoch 34, Batch 15/100] Loss: 0.0579 | RMSE: 0.0530 | Consistency: 0.0157 | SSIM: 0.0478 | Grad: 59349.922\n",
      "[Epoch 34, Batch 16/100] Loss: 0.0548 | RMSE: 0.0513 | Consistency: 0.0127 | SSIM: 0.0332 | Grad: 80827.500\n",
      "[Epoch 34, Batch 17/100] Loss: 0.0597 | RMSE: 0.0563 | Consistency: 0.0121 | SSIM: 0.0331 | Grad: 164357.219\n",
      "[Epoch 34, Batch 18/100] Loss: 0.0600 | RMSE: 0.0561 | Consistency: 0.0122 | SSIM: 0.0383 | Grad: 138124.359\n",
      "[Epoch 34, Batch 19/100] Loss: 0.0554 | RMSE: 0.0516 | Consistency: 0.0165 | SSIM: 0.0359 | Grad: 120099.484\n",
      "[Epoch 34, Batch 20/100] Loss: 0.0505 | RMSE: 0.0472 | Consistency: 0.0116 | SSIM: 0.0318 | Grad: 75579.633\n",
      "[Epoch 34, Batch 21/100] Loss: 0.0534 | RMSE: 0.0498 | Consistency: 0.0109 | SSIM: 0.0348 | Grad: 127730.188\n",
      "[Epoch 34, Batch 22/100] Loss: 0.0520 | RMSE: 0.0488 | Consistency: 0.0126 | SSIM: 0.0300 | Grad: 135538.766\n",
      "[Epoch 34, Batch 23/100] Loss: 0.0479 | RMSE: 0.0443 | Consistency: 0.0096 | SSIM: 0.0353 | Grad: 56719.891\n",
      "[Epoch 34, Batch 24/100] Loss: 0.0520 | RMSE: 0.0479 | Consistency: 0.0101 | SSIM: 0.0395 | Grad: 113518.352\n",
      "[Epoch 34, Batch 25/100] Loss: 0.0550 | RMSE: 0.0509 | Consistency: 0.0152 | SSIM: 0.0396 | Grad: 102064.641\n",
      "[Epoch 34, Batch 26/100] Loss: 0.0522 | RMSE: 0.0481 | Consistency: 0.0138 | SSIM: 0.0396 | Grad: 97167.617\n",
      "[Epoch 34, Batch 27/100] Loss: 0.0472 | RMSE: 0.0435 | Consistency: 0.0094 | SSIM: 0.0360 | Grad: 61997.500\n",
      "[Epoch 34, Batch 28/100] Loss: 0.0497 | RMSE: 0.0463 | Consistency: 0.0094 | SSIM: 0.0328 | Grad: 124981.359\n",
      "[Epoch 34, Batch 29/100] Loss: 0.0549 | RMSE: 0.0512 | Consistency: 0.0124 | SSIM: 0.0356 | Grad: 133049.984\n",
      "[Epoch 34, Batch 30/100] Loss: 0.0481 | RMSE: 0.0448 | Consistency: 0.0102 | SSIM: 0.0318 | Grad: 111521.281\n",
      "[Epoch 34, Batch 31/100] Loss: 0.0522 | RMSE: 0.0482 | Consistency: 0.0108 | SSIM: 0.0389 | Grad: 74995.336\n",
      "[Epoch 34, Batch 32/100] Loss: 0.0405 | RMSE: 0.0377 | Consistency: 0.0084 | SSIM: 0.0266 | Grad: 71972.164\n",
      "[Epoch 34, Batch 33/100] Loss: 0.0542 | RMSE: 0.0504 | Consistency: 0.0164 | SSIM: 0.0359 | Grad: 65661.656\n",
      "[Epoch 34, Batch 34/100] Loss: 0.0450 | RMSE: 0.0421 | Consistency: 0.0093 | SSIM: 0.0278 | Grad: 58403.262\n",
      "[Epoch 34, Batch 35/100] Loss: 0.0442 | RMSE: 0.0414 | Consistency: 0.0105 | SSIM: 0.0266 | Grad: 85892.688\n",
      "[Epoch 34, Batch 36/100] Loss: 0.0444 | RMSE: 0.0413 | Consistency: 0.0080 | SSIM: 0.0299 | Grad: 57359.035\n",
      "[Epoch 34, Batch 37/100] Loss: 0.0461 | RMSE: 0.0432 | Consistency: 0.0092 | SSIM: 0.0285 | Grad: 76227.391\n",
      "[Epoch 34, Batch 38/100] Loss: 0.0474 | RMSE: 0.0444 | Consistency: 0.0122 | SSIM: 0.0292 | Grad: 64332.555\n",
      "[Epoch 34, Batch 39/100] Loss: 0.0504 | RMSE: 0.0474 | Consistency: 0.0094 | SSIM: 0.0295 | Grad: 106946.578\n",
      "[Epoch 34, Batch 40/100] Loss: 0.0409 | RMSE: 0.0381 | Consistency: 0.0089 | SSIM: 0.0277 | Grad: 45360.738\n",
      "[Epoch 34, Batch 41/100] Loss: 0.0416 | RMSE: 0.0387 | Consistency: 0.0090 | SSIM: 0.0281 | Grad: 39246.449\n",
      "[Epoch 34, Batch 42/100] Loss: 0.0475 | RMSE: 0.0443 | Consistency: 0.0108 | SSIM: 0.0309 | Grad: 80198.852\n",
      "[Epoch 34, Batch 43/100] Loss: 0.0460 | RMSE: 0.0432 | Consistency: 0.0107 | SSIM: 0.0271 | Grad: 72180.656\n",
      "[Epoch 34, Batch 44/100] Loss: 0.0580 | RMSE: 0.0540 | Consistency: 0.0130 | SSIM: 0.0390 | Grad: 148226.938\n",
      "[Epoch 34, Batch 45/100] Loss: 0.0515 | RMSE: 0.0480 | Consistency: 0.0124 | SSIM: 0.0336 | Grad: 117719.594\n",
      "[Epoch 34, Batch 46/100] Loss: 0.0502 | RMSE: 0.0467 | Consistency: 0.0116 | SSIM: 0.0334 | Grad: 65966.359\n",
      "[Epoch 34, Batch 47/100] Loss: 0.0464 | RMSE: 0.0432 | Consistency: 0.0093 | SSIM: 0.0311 | Grad: 118979.055\n",
      "[Epoch 34, Batch 48/100] Loss: 0.0447 | RMSE: 0.0410 | Consistency: 0.0076 | SSIM: 0.0357 | Grad: 134133.719\n",
      "[Epoch 34, Batch 49/100] Loss: 0.0508 | RMSE: 0.0475 | Consistency: 0.0118 | SSIM: 0.0320 | Grad: 107276.781\n",
      "[Epoch 34, Batch 50/100] Loss: 0.0564 | RMSE: 0.0524 | Consistency: 0.0157 | SSIM: 0.0386 | Grad: 113208.523\n",
      "[Epoch 34, Batch 51/100] Loss: 0.0548 | RMSE: 0.0508 | Consistency: 0.0132 | SSIM: 0.0382 | Grad: 107890.195\n",
      "[Epoch 34, Batch 52/100] Loss: 0.0488 | RMSE: 0.0457 | Consistency: 0.0106 | SSIM: 0.0301 | Grad: 29055.803\n",
      "[Epoch 34, Batch 53/100] Loss: 0.0474 | RMSE: 0.0443 | Consistency: 0.0108 | SSIM: 0.0299 | Grad: 97743.992\n",
      "[Epoch 34, Batch 54/100] Loss: 0.0557 | RMSE: 0.0523 | Consistency: 0.0130 | SSIM: 0.0328 | Grad: 79642.211\n",
      "[Epoch 34, Batch 55/100] Loss: 0.0489 | RMSE: 0.0452 | Consistency: 0.0120 | SSIM: 0.0357 | Grad: 36082.395\n",
      "[Epoch 34, Batch 56/100] Loss: 0.0500 | RMSE: 0.0461 | Consistency: 0.0103 | SSIM: 0.0376 | Grad: 85145.125\n",
      "[Epoch 34, Batch 57/100] Loss: 0.0530 | RMSE: 0.0500 | Consistency: 0.0131 | SSIM: 0.0287 | Grad: 84077.688\n",
      "[Epoch 34, Batch 58/100] Loss: 0.0476 | RMSE: 0.0444 | Consistency: 0.0111 | SSIM: 0.0311 | Grad: 84445.344\n",
      "[Epoch 34, Batch 59/100] Loss: 0.0496 | RMSE: 0.0467 | Consistency: 0.0123 | SSIM: 0.0279 | Grad: 79595.641\n",
      "[Epoch 34, Batch 60/100] Loss: 0.0462 | RMSE: 0.0433 | Consistency: 0.0096 | SSIM: 0.0274 | Grad: 62877.188\n",
      "[Epoch 34, Batch 61/100] Loss: 0.0575 | RMSE: 0.0537 | Consistency: 0.0169 | SSIM: 0.0363 | Grad: 103589.055\n",
      "[Epoch 34, Batch 62/100] Loss: 0.0501 | RMSE: 0.0463 | Consistency: 0.0133 | SSIM: 0.0368 | Grad: 114119.445\n",
      "[Epoch 34, Batch 63/100] Loss: 0.0468 | RMSE: 0.0429 | Consistency: 0.0101 | SSIM: 0.0380 | Grad: 60501.359\n",
      "[Epoch 34, Batch 64/100] Loss: 0.0508 | RMSE: 0.0476 | Consistency: 0.0138 | SSIM: 0.0303 | Grad: 86027.766\n",
      "[Epoch 34, Batch 65/100] Loss: 0.0512 | RMSE: 0.0479 | Consistency: 0.0098 | SSIM: 0.0312 | Grad: 151956.109\n",
      "[Epoch 34, Batch 66/100] Loss: 0.0554 | RMSE: 0.0517 | Consistency: 0.0142 | SSIM: 0.0358 | Grad: 52588.398\n",
      "[Epoch 34, Batch 67/100] Loss: 0.0499 | RMSE: 0.0463 | Consistency: 0.0134 | SSIM: 0.0344 | Grad: 87205.461\n",
      "[Epoch 34, Batch 68/100] Loss: 0.0448 | RMSE: 0.0416 | Consistency: 0.0093 | SSIM: 0.0314 | Grad: 42028.754\n",
      "[Epoch 34, Batch 69/100] Loss: 0.0470 | RMSE: 0.0435 | Consistency: 0.0104 | SSIM: 0.0347 | Grad: 125316.938\n",
      "[Epoch 34, Batch 70/100] Loss: 0.0473 | RMSE: 0.0438 | Consistency: 0.0104 | SSIM: 0.0345 | Grad: 74563.281\n",
      "[Epoch 34, Batch 71/100] Loss: 0.0507 | RMSE: 0.0477 | Consistency: 0.0113 | SSIM: 0.0291 | Grad: 121478.305\n",
      "[Epoch 34, Batch 72/100] Loss: 0.0462 | RMSE: 0.0428 | Consistency: 0.0105 | SSIM: 0.0331 | Grad: 77491.055\n",
      "[Epoch 34, Batch 73/100] Loss: 0.0534 | RMSE: 0.0498 | Consistency: 0.0125 | SSIM: 0.0349 | Grad: 113494.086\n",
      "[Epoch 34, Batch 74/100] Loss: 0.0599 | RMSE: 0.0558 | Consistency: 0.0189 | SSIM: 0.0387 | Grad: 59968.477\n",
      "[Epoch 34, Batch 75/100] Loss: 0.0493 | RMSE: 0.0462 | Consistency: 0.0114 | SSIM: 0.0296 | Grad: 139217.297\n",
      "[Epoch 34, Batch 76/100] Loss: 0.0511 | RMSE: 0.0482 | Consistency: 0.0116 | SSIM: 0.0277 | Grad: 119181.383\n",
      "[Epoch 34, Batch 77/100] Loss: 0.0507 | RMSE: 0.0480 | Consistency: 0.0113 | SSIM: 0.0265 | Grad: 142263.359\n",
      "[Epoch 34, Batch 78/100] Loss: 0.0525 | RMSE: 0.0493 | Consistency: 0.0117 | SSIM: 0.0306 | Grad: 127288.688\n",
      "[Epoch 34, Batch 79/100] Loss: 0.0538 | RMSE: 0.0503 | Consistency: 0.0128 | SSIM: 0.0330 | Grad: 122958.492\n",
      "[Epoch 34, Batch 80/100] Loss: 0.0489 | RMSE: 0.0455 | Consistency: 0.0136 | SSIM: 0.0326 | Grad: 71101.750\n",
      "[Epoch 34, Batch 81/100] Loss: 0.0464 | RMSE: 0.0436 | Consistency: 0.0091 | SSIM: 0.0278 | Grad: 127889.234\n",
      "[Epoch 34, Batch 82/100] Loss: 0.0459 | RMSE: 0.0428 | Consistency: 0.0095 | SSIM: 0.0304 | Grad: 111826.328\n",
      "[Epoch 34, Batch 83/100] Loss: 0.0475 | RMSE: 0.0445 | Consistency: 0.0117 | SSIM: 0.0289 | Grad: 118446.578\n",
      "[Epoch 34, Batch 84/100] Loss: 0.0549 | RMSE: 0.0515 | Consistency: 0.0146 | SSIM: 0.0323 | Grad: 97179.367\n",
      "[Epoch 34, Batch 85/100] Loss: 0.0572 | RMSE: 0.0536 | Consistency: 0.0178 | SSIM: 0.0347 | Grad: 112999.547\n",
      "[Epoch 34, Batch 86/100] Loss: 0.0495 | RMSE: 0.0453 | Consistency: 0.0105 | SSIM: 0.0408 | Grad: 77712.445\n",
      "[Epoch 34, Batch 87/100] Loss: 0.0461 | RMSE: 0.0430 | Consistency: 0.0100 | SSIM: 0.0302 | Grad: 64838.992\n",
      "[Epoch 34, Batch 88/100] Loss: 0.0435 | RMSE: 0.0410 | Consistency: 0.0094 | SSIM: 0.0243 | Grad: 113918.188\n",
      "[Epoch 34, Batch 89/100] Loss: 0.0540 | RMSE: 0.0498 | Consistency: 0.0147 | SSIM: 0.0408 | Grad: 138434.266\n",
      "[Epoch 34, Batch 90/100] Loss: 0.0486 | RMSE: 0.0449 | Consistency: 0.0089 | SSIM: 0.0363 | Grad: 128758.375\n",
      "[Epoch 34, Batch 91/100] Loss: 0.0465 | RMSE: 0.0438 | Consistency: 0.0099 | SSIM: 0.0258 | Grad: 112938.805\n",
      "[Epoch 34, Batch 92/100] Loss: 0.0438 | RMSE: 0.0413 | Consistency: 0.0085 | SSIM: 0.0238 | Grad: 83898.266\n",
      "[Epoch 34, Batch 93/100] Loss: 0.0475 | RMSE: 0.0448 | Consistency: 0.0090 | SSIM: 0.0260 | Grad: 123851.047\n",
      "[Epoch 34, Batch 94/100] Loss: 0.0462 | RMSE: 0.0433 | Consistency: 0.0096 | SSIM: 0.0277 | Grad: 109771.305\n",
      "[Epoch 34, Batch 95/100] Loss: 0.0487 | RMSE: 0.0463 | Consistency: 0.0107 | SSIM: 0.0235 | Grad: 63950.516\n",
      "[Epoch 34, Batch 96/100] Loss: 0.0546 | RMSE: 0.0503 | Consistency: 0.0119 | SSIM: 0.0411 | Grad: 102884.555\n",
      "[Epoch 34, Batch 97/100] Loss: 0.0476 | RMSE: 0.0448 | Consistency: 0.0121 | SSIM: 0.0269 | Grad: 60068.816\n",
      "[Epoch 34, Batch 98/100] Loss: 0.0501 | RMSE: 0.0468 | Consistency: 0.0107 | SSIM: 0.0317 | Grad: 97595.586\n",
      "[Epoch 34, Batch 99/100] Loss: 0.0430 | RMSE: 0.0404 | Consistency: 0.0096 | SSIM: 0.0252 | Grad: 85265.844\n",
      "[Epoch 34, Batch 100/100] Loss: 0.0480 | RMSE: 0.0442 | Consistency: 0.0105 | SSIM: 0.0368 | Grad: 41599.156\n",
      "✅ Epoch 34 완료!\n",
      "   📈 평균 Loss: 0.049959\n",
      "   📊 평균 RMSE: 0.046594\n",
      "   ⚙️  학습률: 0.000711\n",
      "   🏆 NEW BEST! RMSE: 0.046594\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 35/80 시작...\n",
      "[Epoch 35, Batch 1/100] Loss: 0.0384 | RMSE: 0.0361 | Consistency: 0.0084 | SSIM: 0.0226 | Grad: 107430.773\n",
      "[Epoch 35, Batch 2/100] Loss: 0.0538 | RMSE: 0.0506 | Consistency: 0.0117 | SSIM: 0.0309 | Grad: 134852.703\n",
      "[Epoch 35, Batch 3/100] Loss: 0.0554 | RMSE: 0.0517 | Consistency: 0.0137 | SSIM: 0.0351 | Grad: 120059.828\n",
      "[Epoch 35, Batch 4/100] Loss: 0.0583 | RMSE: 0.0547 | Consistency: 0.0140 | SSIM: 0.0348 | Grad: 89803.023\n",
      "[Epoch 35, Batch 5/100] Loss: 0.0494 | RMSE: 0.0456 | Consistency: 0.0115 | SSIM: 0.0363 | Grad: 79540.445\n",
      "[Epoch 35, Batch 6/100] Loss: 0.0532 | RMSE: 0.0502 | Consistency: 0.0111 | SSIM: 0.0294 | Grad: 106069.562\n",
      "[Epoch 35, Batch 7/100] Loss: 0.0419 | RMSE: 0.0393 | Consistency: 0.0087 | SSIM: 0.0250 | Grad: 56759.461\n",
      "[Epoch 35, Batch 8/100] Loss: 0.0403 | RMSE: 0.0374 | Consistency: 0.0079 | SSIM: 0.0279 | Grad: 53257.324\n",
      "[Epoch 35, Batch 9/100] Loss: 0.0441 | RMSE: 0.0402 | Consistency: 0.0081 | SSIM: 0.0378 | Grad: 26585.721\n",
      "[Epoch 35, Batch 10/100] Loss: 0.0517 | RMSE: 0.0485 | Consistency: 0.0111 | SSIM: 0.0309 | Grad: 66065.562\n",
      "[Epoch 35, Batch 11/100] Loss: 0.0450 | RMSE: 0.0425 | Consistency: 0.0082 | SSIM: 0.0243 | Grad: 24241.127\n",
      "[Epoch 35, Batch 12/100] Loss: 0.0472 | RMSE: 0.0442 | Consistency: 0.0096 | SSIM: 0.0289 | Grad: 93827.070\n",
      "[Epoch 35, Batch 13/100] Loss: 0.0462 | RMSE: 0.0431 | Consistency: 0.0086 | SSIM: 0.0294 | Grad: 128001.633\n",
      "[Epoch 35, Batch 14/100] Loss: 0.0471 | RMSE: 0.0441 | Consistency: 0.0109 | SSIM: 0.0294 | Grad: 77455.570\n",
      "[Epoch 35, Batch 15/100] Loss: 0.0467 | RMSE: 0.0431 | Consistency: 0.0094 | SSIM: 0.0352 | Grad: 34831.375\n",
      "[Epoch 35, Batch 16/100] Loss: 0.0475 | RMSE: 0.0443 | Consistency: 0.0111 | SSIM: 0.0309 | Grad: 71237.234\n",
      "[Epoch 35, Batch 17/100] Loss: 0.0471 | RMSE: 0.0442 | Consistency: 0.0105 | SSIM: 0.0270 | Grad: 86281.555\n",
      "[Epoch 35, Batch 18/100] Loss: 0.0502 | RMSE: 0.0466 | Consistency: 0.0110 | SSIM: 0.0348 | Grad: 94828.891\n",
      "[Epoch 35, Batch 19/100] Loss: 0.0539 | RMSE: 0.0504 | Consistency: 0.0139 | SSIM: 0.0341 | Grad: 94231.539\n",
      "[Epoch 35, Batch 20/100] Loss: 0.0472 | RMSE: 0.0444 | Consistency: 0.0092 | SSIM: 0.0274 | Grad: 91696.430\n",
      "[Epoch 35, Batch 21/100] Loss: 0.0448 | RMSE: 0.0420 | Consistency: 0.0095 | SSIM: 0.0279 | Grad: 44757.965\n",
      "[Epoch 35, Batch 22/100] Loss: 0.0473 | RMSE: 0.0440 | Consistency: 0.0106 | SSIM: 0.0316 | Grad: 85329.094\n",
      "[Epoch 35, Batch 23/100] Loss: 0.0478 | RMSE: 0.0445 | Consistency: 0.0096 | SSIM: 0.0323 | Grad: 57904.430\n",
      "[Epoch 35, Batch 24/100] Loss: 0.0523 | RMSE: 0.0485 | Consistency: 0.0134 | SSIM: 0.0365 | Grad: 88906.969\n",
      "[Epoch 35, Batch 25/100] Loss: 0.0440 | RMSE: 0.0414 | Consistency: 0.0078 | SSIM: 0.0255 | Grad: 128923.625\n",
      "[Epoch 35, Batch 26/100] Loss: 0.0500 | RMSE: 0.0467 | Consistency: 0.0111 | SSIM: 0.0321 | Grad: 82734.445\n",
      "[Epoch 35, Batch 27/100] Loss: 0.0421 | RMSE: 0.0393 | Consistency: 0.0075 | SSIM: 0.0265 | Grad: 61944.504\n",
      "[Epoch 35, Batch 28/100] Loss: 0.0532 | RMSE: 0.0498 | Consistency: 0.0107 | SSIM: 0.0329 | Grad: 89156.477\n",
      "[Epoch 35, Batch 29/100] Loss: 0.0468 | RMSE: 0.0440 | Consistency: 0.0102 | SSIM: 0.0270 | Grad: 88438.711\n",
      "[Epoch 35, Batch 30/100] Loss: 0.0480 | RMSE: 0.0451 | Consistency: 0.0105 | SSIM: 0.0280 | Grad: 94068.461\n",
      "[Epoch 35, Batch 31/100] Loss: 0.0480 | RMSE: 0.0453 | Consistency: 0.0100 | SSIM: 0.0260 | Grad: 79350.430\n",
      "[Epoch 35, Batch 32/100] Loss: 0.0493 | RMSE: 0.0462 | Consistency: 0.0116 | SSIM: 0.0298 | Grad: 95367.969\n",
      "[Epoch 35, Batch 33/100] Loss: 0.0469 | RMSE: 0.0441 | Consistency: 0.0095 | SSIM: 0.0265 | Grad: 74755.844\n",
      "[Epoch 35, Batch 34/100] Loss: 0.0615 | RMSE: 0.0573 | Consistency: 0.0210 | SSIM: 0.0392 | Grad: 41485.723\n",
      "[Epoch 35, Batch 35/100] Loss: 0.0529 | RMSE: 0.0500 | Consistency: 0.0139 | SSIM: 0.0280 | Grad: 143012.875\n",
      "[Epoch 35, Batch 36/100] Loss: 0.0487 | RMSE: 0.0456 | Consistency: 0.0108 | SSIM: 0.0296 | Grad: 95275.734\n",
      "[Epoch 35, Batch 37/100] Loss: 0.0467 | RMSE: 0.0433 | Consistency: 0.0103 | SSIM: 0.0327 | Grad: 74752.320\n",
      "[Epoch 35, Batch 38/100] Loss: 0.0476 | RMSE: 0.0441 | Consistency: 0.0089 | SSIM: 0.0339 | Grad: 78115.289\n",
      "[Epoch 35, Batch 39/100] Loss: 0.0456 | RMSE: 0.0422 | Consistency: 0.0090 | SSIM: 0.0334 | Grad: 60197.645\n",
      "[Epoch 35, Batch 40/100] Loss: 0.0426 | RMSE: 0.0402 | Consistency: 0.0092 | SSIM: 0.0230 | Grad: 86486.336\n",
      "[Epoch 35, Batch 41/100] Loss: 0.0447 | RMSE: 0.0416 | Consistency: 0.0081 | SSIM: 0.0298 | Grad: 99988.609\n",
      "[Epoch 35, Batch 42/100] Loss: 0.0395 | RMSE: 0.0371 | Consistency: 0.0073 | SSIM: 0.0241 | Grad: 57173.789\n",
      "[Epoch 35, Batch 43/100] Loss: 0.0565 | RMSE: 0.0537 | Consistency: 0.0138 | SSIM: 0.0265 | Grad: 118079.523\n",
      "[Epoch 35, Batch 44/100] Loss: 0.0408 | RMSE: 0.0380 | Consistency: 0.0086 | SSIM: 0.0271 | Grad: 47636.336\n",
      "[Epoch 35, Batch 45/100] Loss: 0.0498 | RMSE: 0.0465 | Consistency: 0.0119 | SSIM: 0.0320 | Grad: 79636.750\n",
      "[Epoch 35, Batch 46/100] Loss: 0.0438 | RMSE: 0.0413 | Consistency: 0.0096 | SSIM: 0.0245 | Grad: 142694.969\n",
      "[Epoch 35, Batch 47/100] Loss: 0.0569 | RMSE: 0.0536 | Consistency: 0.0139 | SSIM: 0.0313 | Grad: 160261.719\n",
      "[Epoch 35, Batch 48/100] Loss: 0.0489 | RMSE: 0.0453 | Consistency: 0.0110 | SSIM: 0.0342 | Grad: 99765.789\n",
      "[Epoch 35, Batch 49/100] Loss: 0.0528 | RMSE: 0.0497 | Consistency: 0.0125 | SSIM: 0.0304 | Grad: 102579.320\n",
      "[Epoch 35, Batch 50/100] Loss: 0.0555 | RMSE: 0.0516 | Consistency: 0.0134 | SSIM: 0.0380 | Grad: 118593.961\n",
      "[Epoch 35, Batch 51/100] Loss: 0.0520 | RMSE: 0.0487 | Consistency: 0.0113 | SSIM: 0.0324 | Grad: 143877.109\n",
      "[Epoch 35, Batch 52/100] Loss: 0.0479 | RMSE: 0.0452 | Consistency: 0.0080 | SSIM: 0.0262 | Grad: 108393.906\n",
      "[Epoch 35, Batch 53/100] Loss: 0.0439 | RMSE: 0.0410 | Consistency: 0.0094 | SSIM: 0.0278 | Grad: 64077.734\n",
      "[Epoch 35, Batch 54/100] Loss: 0.0679 | RMSE: 0.0639 | Consistency: 0.0229 | SSIM: 0.0377 | Grad: 100461.445\n",
      "[Epoch 35, Batch 55/100] Loss: 0.0414 | RMSE: 0.0386 | Consistency: 0.0081 | SSIM: 0.0276 | Grad: 57636.605\n",
      "[Epoch 35, Batch 56/100] Loss: 0.0405 | RMSE: 0.0379 | Consistency: 0.0082 | SSIM: 0.0255 | Grad: 107493.289\n",
      "[Epoch 35, Batch 57/100] Loss: 0.0476 | RMSE: 0.0450 | Consistency: 0.0090 | SSIM: 0.0249 | Grad: 105022.023\n",
      "[Epoch 35, Batch 58/100] Loss: 0.0401 | RMSE: 0.0373 | Consistency: 0.0080 | SSIM: 0.0267 | Grad: 68582.461\n",
      "[Epoch 35, Batch 59/100] Loss: 0.0427 | RMSE: 0.0398 | Consistency: 0.0095 | SSIM: 0.0283 | Grad: 50078.992\n",
      "[Epoch 35, Batch 60/100] Loss: 0.0422 | RMSE: 0.0393 | Consistency: 0.0078 | SSIM: 0.0287 | Grad: 104923.195\n",
      "[Epoch 35, Batch 61/100] Loss: 0.0500 | RMSE: 0.0467 | Consistency: 0.0121 | SSIM: 0.0318 | Grad: 81174.375\n",
      "[Epoch 35, Batch 62/100] Loss: 0.0490 | RMSE: 0.0459 | Consistency: 0.0109 | SSIM: 0.0306 | Grad: 68335.539\n",
      "[Epoch 35, Batch 63/100] Loss: 0.0464 | RMSE: 0.0433 | Consistency: 0.0110 | SSIM: 0.0303 | Grad: 75353.414\n",
      "[Epoch 35, Batch 64/100] Loss: 0.0479 | RMSE: 0.0446 | Consistency: 0.0117 | SSIM: 0.0317 | Grad: 77498.203\n",
      "[Epoch 35, Batch 65/100] Loss: 0.0431 | RMSE: 0.0404 | Consistency: 0.0092 | SSIM: 0.0258 | Grad: 90943.156\n",
      "[Epoch 35, Batch 66/100] Loss: 0.0466 | RMSE: 0.0434 | Consistency: 0.0105 | SSIM: 0.0309 | Grad: 74017.633\n",
      "[Epoch 35, Batch 67/100] Loss: 0.0451 | RMSE: 0.0420 | Consistency: 0.0105 | SSIM: 0.0297 | Grad: 75774.633\n",
      "[Epoch 35, Batch 68/100] Loss: 0.0400 | RMSE: 0.0373 | Consistency: 0.0076 | SSIM: 0.0261 | Grad: 37500.734\n",
      "[Epoch 35, Batch 69/100] Loss: 0.0427 | RMSE: 0.0401 | Consistency: 0.0081 | SSIM: 0.0260 | Grad: 84182.203\n",
      "[Epoch 35, Batch 70/100] Loss: 0.0449 | RMSE: 0.0422 | Consistency: 0.0109 | SSIM: 0.0260 | Grad: 107338.188\n",
      "[Epoch 35, Batch 71/100] Loss: 0.0617 | RMSE: 0.0579 | Consistency: 0.0177 | SSIM: 0.0358 | Grad: 137515.234\n",
      "[Epoch 35, Batch 72/100] Loss: 0.0463 | RMSE: 0.0430 | Consistency: 0.0096 | SSIM: 0.0327 | Grad: 68455.727\n",
      "[Epoch 35, Batch 73/100] Loss: 0.0435 | RMSE: 0.0405 | Consistency: 0.0082 | SSIM: 0.0294 | Grad: 91446.062\n",
      "[Epoch 35, Batch 74/100] Loss: 0.0453 | RMSE: 0.0426 | Consistency: 0.0091 | SSIM: 0.0263 | Grad: 100097.367\n",
      "[Epoch 35, Batch 75/100] Loss: 0.0417 | RMSE: 0.0390 | Consistency: 0.0072 | SSIM: 0.0255 | Grad: 52368.871\n",
      "[Epoch 35, Batch 76/100] Loss: 0.0439 | RMSE: 0.0411 | Consistency: 0.0114 | SSIM: 0.0268 | Grad: 107987.164\n",
      "[Epoch 35, Batch 77/100] Loss: 0.0545 | RMSE: 0.0511 | Consistency: 0.0125 | SSIM: 0.0318 | Grad: 22706.477\n",
      "[Epoch 35, Batch 78/100] Loss: 0.0417 | RMSE: 0.0387 | Consistency: 0.0083 | SSIM: 0.0286 | Grad: 77834.508\n",
      "[Epoch 35, Batch 79/100] Loss: 0.0402 | RMSE: 0.0371 | Consistency: 0.0080 | SSIM: 0.0307 | Grad: 75588.195\n",
      "[Epoch 35, Batch 80/100] Loss: 0.0535 | RMSE: 0.0496 | Consistency: 0.0104 | SSIM: 0.0377 | Grad: 64901.082\n",
      "[Epoch 35, Batch 81/100] Loss: 0.0387 | RMSE: 0.0355 | Consistency: 0.0070 | SSIM: 0.0315 | Grad: 17934.832\n",
      "[Epoch 35, Batch 82/100] Loss: 0.0577 | RMSE: 0.0540 | Consistency: 0.0179 | SSIM: 0.0360 | Grad: 97177.375\n",
      "[Epoch 35, Batch 83/100] Loss: 0.0455 | RMSE: 0.0423 | Consistency: 0.0098 | SSIM: 0.0308 | Grad: 85382.125\n",
      "[Epoch 35, Batch 84/100] Loss: 0.0530 | RMSE: 0.0498 | Consistency: 0.0122 | SSIM: 0.0310 | Grad: 103998.445\n",
      "[Epoch 35, Batch 85/100] Loss: 0.0555 | RMSE: 0.0521 | Consistency: 0.0107 | SSIM: 0.0331 | Grad: 80312.102\n",
      "[Epoch 35, Batch 86/100] Loss: 0.0443 | RMSE: 0.0416 | Consistency: 0.0093 | SSIM: 0.0256 | Grad: 36225.613\n",
      "[Epoch 35, Batch 87/100] Loss: 0.0554 | RMSE: 0.0520 | Consistency: 0.0118 | SSIM: 0.0326 | Grad: 61908.961\n",
      "[Epoch 35, Batch 88/100] Loss: 0.0502 | RMSE: 0.0464 | Consistency: 0.0097 | SSIM: 0.0371 | Grad: 109019.953\n",
      "[Epoch 35, Batch 89/100] Loss: 0.0545 | RMSE: 0.0510 | Consistency: 0.0135 | SSIM: 0.0332 | Grad: 93412.883\n",
      "[Epoch 35, Batch 90/100] Loss: 0.0528 | RMSE: 0.0491 | Consistency: 0.0137 | SSIM: 0.0356 | Grad: 67240.039\n",
      "[Epoch 35, Batch 91/100] Loss: 0.0562 | RMSE: 0.0521 | Consistency: 0.0154 | SSIM: 0.0402 | Grad: 44433.594\n",
      "[Epoch 35, Batch 92/100] Loss: 0.0634 | RMSE: 0.0581 | Consistency: 0.0152 | SSIM: 0.0519 | Grad: 179089.562\n",
      "[Epoch 35, Batch 93/100] Loss: 0.0598 | RMSE: 0.0559 | Consistency: 0.0144 | SSIM: 0.0373 | Grad: 146352.109\n",
      "[Epoch 35, Batch 94/100] Loss: 0.0523 | RMSE: 0.0488 | Consistency: 0.0120 | SSIM: 0.0345 | Grad: 110660.203\n",
      "[Epoch 35, Batch 95/100] Loss: 0.0549 | RMSE: 0.0513 | Consistency: 0.0114 | SSIM: 0.0348 | Grad: 91113.961\n",
      "[Epoch 35, Batch 96/100] Loss: 0.0476 | RMSE: 0.0447 | Consistency: 0.0084 | SSIM: 0.0281 | Grad: 74408.969\n",
      "[Epoch 35, Batch 97/100] Loss: 0.0468 | RMSE: 0.0429 | Consistency: 0.0110 | SSIM: 0.0369 | Grad: 55838.629\n",
      "[Epoch 35, Batch 98/100] Loss: 0.0406 | RMSE: 0.0383 | Consistency: 0.0081 | SSIM: 0.0221 | Grad: 31618.682\n",
      "[Epoch 35, Batch 99/100] Loss: 0.0400 | RMSE: 0.0369 | Consistency: 0.0086 | SSIM: 0.0301 | Grad: 71733.133\n",
      "[Epoch 35, Batch 100/100] Loss: 0.0418 | RMSE: 0.0389 | Consistency: 0.0082 | SSIM: 0.0283 | Grad: 19630.523\n",
      "✅ Epoch 35 완료!\n",
      "   📈 평균 Loss: 0.048250\n",
      "   📊 평균 RMSE: 0.045080\n",
      "   ⚙️  학습률: 0.000691\n",
      "   🏆 NEW BEST! RMSE: 0.045080\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 36/80 시작...\n",
      "[Epoch 36, Batch 1/100] Loss: 0.0406 | RMSE: 0.0372 | Consistency: 0.0073 | SSIM: 0.0336 | Grad: 59898.855\n",
      "[Epoch 36, Batch 2/100] Loss: 0.0462 | RMSE: 0.0431 | Consistency: 0.0105 | SSIM: 0.0296 | Grad: 58421.012\n",
      "[Epoch 36, Batch 3/100] Loss: 0.0477 | RMSE: 0.0451 | Consistency: 0.0098 | SSIM: 0.0255 | Grad: 77646.719\n",
      "[Epoch 36, Batch 4/100] Loss: 0.0434 | RMSE: 0.0410 | Consistency: 0.0078 | SSIM: 0.0237 | Grad: 67026.375\n",
      "[Epoch 36, Batch 5/100] Loss: 0.0458 | RMSE: 0.0427 | Consistency: 0.0113 | SSIM: 0.0298 | Grad: 46504.504\n",
      "[Epoch 36, Batch 6/100] Loss: 0.0417 | RMSE: 0.0390 | Consistency: 0.0071 | SSIM: 0.0265 | Grad: 94018.492\n",
      "[Epoch 36, Batch 7/100] Loss: 0.0488 | RMSE: 0.0457 | Consistency: 0.0097 | SSIM: 0.0300 | Grad: 96288.656\n",
      "[Epoch 36, Batch 8/100] Loss: 0.0424 | RMSE: 0.0398 | Consistency: 0.0088 | SSIM: 0.0253 | Grad: 82767.938\n",
      "[Epoch 36, Batch 9/100] Loss: 0.0488 | RMSE: 0.0457 | Consistency: 0.0095 | SSIM: 0.0299 | Grad: 124779.469\n",
      "[Epoch 36, Batch 10/100] Loss: 0.0511 | RMSE: 0.0479 | Consistency: 0.0106 | SSIM: 0.0313 | Grad: 111029.711\n",
      "[Epoch 36, Batch 11/100] Loss: 0.0550 | RMSE: 0.0509 | Consistency: 0.0149 | SSIM: 0.0396 | Grad: 60665.668\n",
      "[Epoch 36, Batch 12/100] Loss: 0.0429 | RMSE: 0.0400 | Consistency: 0.0082 | SSIM: 0.0282 | Grad: 95357.258\n",
      "[Epoch 36, Batch 13/100] Loss: 0.0540 | RMSE: 0.0500 | Consistency: 0.0114 | SSIM: 0.0385 | Grad: 117963.156\n",
      "[Epoch 36, Batch 14/100] Loss: 0.0471 | RMSE: 0.0442 | Consistency: 0.0108 | SSIM: 0.0286 | Grad: 124202.102\n",
      "[Epoch 36, Batch 15/100] Loss: 0.0563 | RMSE: 0.0521 | Consistency: 0.0189 | SSIM: 0.0400 | Grad: 108176.500\n",
      "[Epoch 36, Batch 16/100] Loss: 0.0433 | RMSE: 0.0405 | Consistency: 0.0088 | SSIM: 0.0264 | Grad: 32036.039\n",
      "[Epoch 36, Batch 17/100] Loss: 0.0484 | RMSE: 0.0451 | Consistency: 0.0109 | SSIM: 0.0319 | Grad: 57917.074\n",
      "[Epoch 36, Batch 18/100] Loss: 0.0562 | RMSE: 0.0524 | Consistency: 0.0137 | SSIM: 0.0375 | Grad: 102163.766\n",
      "[Epoch 36, Batch 19/100] Loss: 0.0608 | RMSE: 0.0572 | Consistency: 0.0146 | SSIM: 0.0346 | Grad: 66515.609\n",
      "[Epoch 36, Batch 20/100] Loss: 0.0440 | RMSE: 0.0405 | Consistency: 0.0097 | SSIM: 0.0342 | Grad: 50658.793\n",
      "[Epoch 36, Batch 21/100] Loss: 0.0527 | RMSE: 0.0487 | Consistency: 0.0135 | SSIM: 0.0388 | Grad: 81012.031\n",
      "[Epoch 36, Batch 22/100] Loss: 0.0422 | RMSE: 0.0394 | Consistency: 0.0092 | SSIM: 0.0275 | Grad: 34243.141\n",
      "[Epoch 36, Batch 23/100] Loss: 0.0589 | RMSE: 0.0555 | Consistency: 0.0147 | SSIM: 0.0327 | Grad: 87773.852\n",
      "[Epoch 36, Batch 24/100] Loss: 0.0453 | RMSE: 0.0414 | Consistency: 0.0082 | SSIM: 0.0377 | Grad: 49645.262\n",
      "[Epoch 36, Batch 25/100] Loss: 0.0450 | RMSE: 0.0420 | Consistency: 0.0091 | SSIM: 0.0291 | Grad: 71025.766\n",
      "[Epoch 36, Batch 26/100] Loss: 0.0670 | RMSE: 0.0621 | Consistency: 0.0250 | SSIM: 0.0467 | Grad: 109016.023\n",
      "[Epoch 36, Batch 27/100] Loss: 0.0498 | RMSE: 0.0469 | Consistency: 0.0103 | SSIM: 0.0273 | Grad: 102486.297\n",
      "[Epoch 36, Batch 28/100] Loss: 0.0516 | RMSE: 0.0481 | Consistency: 0.0137 | SSIM: 0.0339 | Grad: 105961.320\n",
      "[Epoch 36, Batch 29/100] Loss: 0.0475 | RMSE: 0.0433 | Consistency: 0.0120 | SSIM: 0.0402 | Grad: 80067.859\n",
      "[Epoch 36, Batch 30/100] Loss: 0.0435 | RMSE: 0.0404 | Consistency: 0.0083 | SSIM: 0.0295 | Grad: 52747.270\n",
      "[Epoch 36, Batch 31/100] Loss: 0.0472 | RMSE: 0.0443 | Consistency: 0.0105 | SSIM: 0.0282 | Grad: 76858.734\n",
      "[Epoch 36, Batch 32/100] Loss: 0.0495 | RMSE: 0.0459 | Consistency: 0.0121 | SSIM: 0.0347 | Grad: 106589.609\n",
      "[Epoch 36, Batch 33/100] Loss: 0.0460 | RMSE: 0.0432 | Consistency: 0.0088 | SSIM: 0.0262 | Grad: 117773.336\n",
      "[Epoch 36, Batch 34/100] Loss: 0.0447 | RMSE: 0.0421 | Consistency: 0.0079 | SSIM: 0.0251 | Grad: 85019.609\n",
      "[Epoch 36, Batch 35/100] Loss: 0.0458 | RMSE: 0.0429 | Consistency: 0.0087 | SSIM: 0.0276 | Grad: 55074.566\n",
      "[Epoch 36, Batch 36/100] Loss: 0.0467 | RMSE: 0.0437 | Consistency: 0.0102 | SSIM: 0.0292 | Grad: 91899.914\n",
      "[Epoch 36, Batch 37/100] Loss: 0.0577 | RMSE: 0.0534 | Consistency: 0.0122 | SSIM: 0.0412 | Grad: 158506.000\n",
      "[Epoch 36, Batch 38/100] Loss: 0.0603 | RMSE: 0.0565 | Consistency: 0.0200 | SSIM: 0.0361 | Grad: 130335.930\n",
      "[Epoch 36, Batch 39/100] Loss: 0.0421 | RMSE: 0.0394 | Consistency: 0.0090 | SSIM: 0.0267 | Grad: 100016.484\n",
      "[Epoch 36, Batch 40/100] Loss: 0.0478 | RMSE: 0.0449 | Consistency: 0.0109 | SSIM: 0.0271 | Grad: 85675.195\n",
      "[Epoch 36, Batch 41/100] Loss: 0.0442 | RMSE: 0.0405 | Consistency: 0.0086 | SSIM: 0.0366 | Grad: 103768.648\n",
      "[Epoch 36, Batch 42/100] Loss: 0.0464 | RMSE: 0.0432 | Consistency: 0.0116 | SSIM: 0.0308 | Grad: 143527.500\n",
      "[Epoch 36, Batch 43/100] Loss: 0.0434 | RMSE: 0.0409 | Consistency: 0.0093 | SSIM: 0.0235 | Grad: 123641.516\n",
      "[Epoch 36, Batch 44/100] Loss: 0.0479 | RMSE: 0.0441 | Consistency: 0.0106 | SSIM: 0.0373 | Grad: 86115.383\n",
      "[Epoch 36, Batch 45/100] Loss: 0.0486 | RMSE: 0.0455 | Consistency: 0.0117 | SSIM: 0.0296 | Grad: 93034.977\n",
      "[Epoch 36, Batch 46/100] Loss: 0.0500 | RMSE: 0.0465 | Consistency: 0.0135 | SSIM: 0.0338 | Grad: 122655.445\n",
      "[Epoch 36, Batch 47/100] Loss: 0.0459 | RMSE: 0.0430 | Consistency: 0.0090 | SSIM: 0.0290 | Grad: 44832.324\n",
      "[Epoch 36, Batch 48/100] Loss: 0.0399 | RMSE: 0.0370 | Consistency: 0.0077 | SSIM: 0.0276 | Grad: 69784.961\n",
      "[Epoch 36, Batch 49/100] Loss: 0.0569 | RMSE: 0.0538 | Consistency: 0.0166 | SSIM: 0.0302 | Grad: 95407.805\n",
      "[Epoch 36, Batch 50/100] Loss: 0.0492 | RMSE: 0.0462 | Consistency: 0.0101 | SSIM: 0.0294 | Grad: 92646.234\n",
      "[Epoch 36, Batch 51/100] Loss: 0.0422 | RMSE: 0.0394 | Consistency: 0.0070 | SSIM: 0.0275 | Grad: 92569.875\n",
      "[Epoch 36, Batch 52/100] Loss: 0.0418 | RMSE: 0.0392 | Consistency: 0.0064 | SSIM: 0.0253 | Grad: 102815.984\n",
      "[Epoch 36, Batch 53/100] Loss: 0.0483 | RMSE: 0.0451 | Consistency: 0.0108 | SSIM: 0.0316 | Grad: 81536.000\n",
      "[Epoch 36, Batch 54/100] Loss: 0.0411 | RMSE: 0.0383 | Consistency: 0.0082 | SSIM: 0.0273 | Grad: 55987.797\n",
      "[Epoch 36, Batch 55/100] Loss: 0.0526 | RMSE: 0.0491 | Consistency: 0.0120 | SSIM: 0.0336 | Grad: 82392.094\n",
      "[Epoch 36, Batch 56/100] Loss: 0.0492 | RMSE: 0.0460 | Consistency: 0.0146 | SSIM: 0.0306 | Grad: 102849.656\n",
      "[Epoch 36, Batch 57/100] Loss: 0.0413 | RMSE: 0.0384 | Consistency: 0.0089 | SSIM: 0.0277 | Grad: 97506.430\n",
      "[Epoch 36, Batch 58/100] Loss: 0.0412 | RMSE: 0.0376 | Consistency: 0.0085 | SSIM: 0.0349 | Grad: 70180.477\n",
      "[Epoch 36, Batch 59/100] Loss: 0.0386 | RMSE: 0.0363 | Consistency: 0.0074 | SSIM: 0.0222 | Grad: 70408.078\n",
      "[Epoch 36, Batch 60/100] Loss: 0.0432 | RMSE: 0.0400 | Consistency: 0.0087 | SSIM: 0.0318 | Grad: 110467.062\n",
      "[Epoch 36, Batch 61/100] Loss: 0.0503 | RMSE: 0.0471 | Consistency: 0.0101 | SSIM: 0.0317 | Grad: 123538.383\n",
      "[Epoch 36, Batch 62/100] Loss: 0.0463 | RMSE: 0.0432 | Consistency: 0.0114 | SSIM: 0.0302 | Grad: 49314.828\n",
      "[Epoch 36, Batch 63/100] Loss: 0.0450 | RMSE: 0.0421 | Consistency: 0.0090 | SSIM: 0.0280 | Grad: 96504.141\n",
      "[Epoch 36, Batch 64/100] Loss: 0.0404 | RMSE: 0.0377 | Consistency: 0.0080 | SSIM: 0.0270 | Grad: 73449.719\n",
      "[Epoch 36, Batch 65/100] Loss: 0.0452 | RMSE: 0.0424 | Consistency: 0.0087 | SSIM: 0.0270 | Grad: 100036.016\n",
      "[Epoch 36, Batch 66/100] Loss: 0.0497 | RMSE: 0.0458 | Consistency: 0.0089 | SSIM: 0.0382 | Grad: 55484.723\n",
      "[Epoch 36, Batch 67/100] Loss: 0.0505 | RMSE: 0.0469 | Consistency: 0.0116 | SSIM: 0.0349 | Grad: 37096.973\n",
      "[Epoch 36, Batch 68/100] Loss: 0.0416 | RMSE: 0.0386 | Consistency: 0.0070 | SSIM: 0.0291 | Grad: 66984.438\n",
      "[Epoch 36, Batch 69/100] Loss: 0.0508 | RMSE: 0.0479 | Consistency: 0.0106 | SSIM: 0.0280 | Grad: 91766.234\n",
      "[Epoch 36, Batch 70/100] Loss: 0.0459 | RMSE: 0.0428 | Consistency: 0.0087 | SSIM: 0.0301 | Grad: 63198.395\n",
      "[Epoch 36, Batch 71/100] Loss: 0.0451 | RMSE: 0.0421 | Consistency: 0.0084 | SSIM: 0.0291 | Grad: 106007.164\n",
      "[Epoch 36, Batch 72/100] Loss: 0.0478 | RMSE: 0.0443 | Consistency: 0.0108 | SSIM: 0.0332 | Grad: 64172.934\n",
      "[Epoch 36, Batch 73/100] Loss: 0.0622 | RMSE: 0.0589 | Consistency: 0.0206 | SSIM: 0.0310 | Grad: 101129.297\n",
      "[Epoch 36, Batch 74/100] Loss: 0.0447 | RMSE: 0.0420 | Consistency: 0.0081 | SSIM: 0.0264 | Grad: 107177.742\n",
      "[Epoch 36, Batch 75/100] Loss: 0.0489 | RMSE: 0.0458 | Consistency: 0.0115 | SSIM: 0.0297 | Grad: 115451.812\n",
      "[Epoch 36, Batch 76/100] Loss: 0.0497 | RMSE: 0.0471 | Consistency: 0.0124 | SSIM: 0.0246 | Grad: 129403.727\n",
      "[Epoch 36, Batch 77/100] Loss: 0.0504 | RMSE: 0.0471 | Consistency: 0.0108 | SSIM: 0.0320 | Grad: 93766.953\n",
      "[Epoch 36, Batch 78/100] Loss: 0.0413 | RMSE: 0.0385 | Consistency: 0.0075 | SSIM: 0.0268 | Grad: 60977.531\n",
      "[Epoch 36, Batch 79/100] Loss: 0.0488 | RMSE: 0.0456 | Consistency: 0.0114 | SSIM: 0.0307 | Grad: 77747.312\n",
      "[Epoch 36, Batch 80/100] Loss: 0.0445 | RMSE: 0.0413 | Consistency: 0.0089 | SSIM: 0.0310 | Grad: 93412.727\n",
      "[Epoch 36, Batch 81/100] Loss: 0.0397 | RMSE: 0.0372 | Consistency: 0.0070 | SSIM: 0.0245 | Grad: 80383.359\n",
      "[Epoch 36, Batch 82/100] Loss: 0.0425 | RMSE: 0.0396 | Consistency: 0.0084 | SSIM: 0.0276 | Grad: 69209.734\n",
      "[Epoch 36, Batch 83/100] Loss: 0.0526 | RMSE: 0.0495 | Consistency: 0.0108 | SSIM: 0.0299 | Grad: 65326.785\n",
      "[Epoch 36, Batch 84/100] Loss: 0.0479 | RMSE: 0.0449 | Consistency: 0.0090 | SSIM: 0.0296 | Grad: 99997.461\n",
      "[Epoch 36, Batch 85/100] Loss: 0.0420 | RMSE: 0.0392 | Consistency: 0.0087 | SSIM: 0.0267 | Grad: 97744.586\n",
      "[Epoch 36, Batch 86/100] Loss: 0.0427 | RMSE: 0.0396 | Consistency: 0.0087 | SSIM: 0.0304 | Grad: 73042.625\n",
      "[Epoch 36, Batch 87/100] Loss: 0.0472 | RMSE: 0.0442 | Consistency: 0.0108 | SSIM: 0.0291 | Grad: 108174.484\n",
      "[Epoch 36, Batch 88/100] Loss: 0.0505 | RMSE: 0.0468 | Consistency: 0.0129 | SSIM: 0.0354 | Grad: 98373.266\n",
      "[Epoch 36, Batch 89/100] Loss: 0.0390 | RMSE: 0.0365 | Consistency: 0.0071 | SSIM: 0.0238 | Grad: 86269.984\n",
      "[Epoch 36, Batch 90/100] Loss: 0.0573 | RMSE: 0.0532 | Consistency: 0.0164 | SSIM: 0.0394 | Grad: 77203.883\n",
      "[Epoch 36, Batch 91/100] Loss: 0.0459 | RMSE: 0.0428 | Consistency: 0.0119 | SSIM: 0.0300 | Grad: 90203.531\n",
      "[Epoch 36, Batch 92/100] Loss: 0.0455 | RMSE: 0.0424 | Consistency: 0.0116 | SSIM: 0.0300 | Grad: 125928.812\n",
      "[Epoch 36, Batch 93/100] Loss: 0.0483 | RMSE: 0.0452 | Consistency: 0.0118 | SSIM: 0.0299 | Grad: 95155.570\n",
      "[Epoch 36, Batch 94/100] Loss: 0.0540 | RMSE: 0.0509 | Consistency: 0.0168 | SSIM: 0.0298 | Grad: 91817.602\n",
      "[Epoch 36, Batch 95/100] Loss: 0.0592 | RMSE: 0.0551 | Consistency: 0.0147 | SSIM: 0.0388 | Grad: 76479.688\n",
      "[Epoch 36, Batch 96/100] Loss: 0.0465 | RMSE: 0.0437 | Consistency: 0.0098 | SSIM: 0.0270 | Grad: 99890.195\n",
      "[Epoch 36, Batch 97/100] Loss: 0.0475 | RMSE: 0.0436 | Consistency: 0.0095 | SSIM: 0.0377 | Grad: 85572.688\n",
      "[Epoch 36, Batch 98/100] Loss: 0.0416 | RMSE: 0.0390 | Consistency: 0.0083 | SSIM: 0.0251 | Grad: 102514.445\n",
      "[Epoch 36, Batch 99/100] Loss: 0.0483 | RMSE: 0.0456 | Consistency: 0.0113 | SSIM: 0.0257 | Grad: 149038.312\n",
      "[Epoch 36, Batch 100/100] Loss: 0.0508 | RMSE: 0.0478 | Consistency: 0.0124 | SSIM: 0.0290 | Grad: 146081.828\n",
      "✅ Epoch 36 완료!\n",
      "   📈 평균 Loss: 0.047660\n",
      "   📊 평균 RMSE: 0.044484\n",
      "   ⚙️  학습률: 0.000671\n",
      "   🏆 NEW BEST! RMSE: 0.044484\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 37/80 시작...\n",
      "[Epoch 37, Batch 1/100] Loss: 0.0449 | RMSE: 0.0419 | Consistency: 0.0083 | SSIM: 0.0284 | Grad: 95907.609\n",
      "[Epoch 37, Batch 2/100] Loss: 0.0509 | RMSE: 0.0477 | Consistency: 0.0107 | SSIM: 0.0312 | Grad: 37786.199\n",
      "[Epoch 37, Batch 3/100] Loss: 0.0469 | RMSE: 0.0442 | Consistency: 0.0088 | SSIM: 0.0261 | Grad: 91454.672\n",
      "[Epoch 37, Batch 4/100] Loss: 0.0500 | RMSE: 0.0460 | Consistency: 0.0117 | SSIM: 0.0381 | Grad: 88737.992\n",
      "[Epoch 37, Batch 5/100] Loss: 0.0494 | RMSE: 0.0460 | Consistency: 0.0086 | SSIM: 0.0325 | Grad: 69557.648\n",
      "[Epoch 37, Batch 6/100] Loss: 0.0458 | RMSE: 0.0430 | Consistency: 0.0095 | SSIM: 0.0269 | Grad: 89778.156\n",
      "[Epoch 37, Batch 7/100] Loss: 0.0441 | RMSE: 0.0412 | Consistency: 0.0097 | SSIM: 0.0282 | Grad: 29581.512\n",
      "[Epoch 37, Batch 8/100] Loss: 0.0500 | RMSE: 0.0462 | Consistency: 0.0096 | SSIM: 0.0365 | Grad: 137203.734\n",
      "[Epoch 37, Batch 9/100] Loss: 0.0533 | RMSE: 0.0501 | Consistency: 0.0121 | SSIM: 0.0314 | Grad: 166587.188\n",
      "[Epoch 37, Batch 10/100] Loss: 0.0489 | RMSE: 0.0461 | Consistency: 0.0090 | SSIM: 0.0274 | Grad: 88425.977\n",
      "[Epoch 37, Batch 11/100] Loss: 0.0468 | RMSE: 0.0438 | Consistency: 0.0102 | SSIM: 0.0288 | Grad: 50147.008\n",
      "[Epoch 37, Batch 12/100] Loss: 0.0433 | RMSE: 0.0409 | Consistency: 0.0070 | SSIM: 0.0238 | Grad: 82589.164\n",
      "[Epoch 37, Batch 13/100] Loss: 0.0452 | RMSE: 0.0421 | Consistency: 0.0097 | SSIM: 0.0306 | Grad: 55443.340\n",
      "[Epoch 37, Batch 14/100] Loss: 0.0530 | RMSE: 0.0491 | Consistency: 0.0145 | SSIM: 0.0375 | Grad: 39742.645\n",
      "[Epoch 37, Batch 15/100] Loss: 0.0505 | RMSE: 0.0474 | Consistency: 0.0124 | SSIM: 0.0297 | Grad: 106975.516\n",
      "[Epoch 37, Batch 16/100] Loss: 0.0480 | RMSE: 0.0454 | Consistency: 0.0122 | SSIM: 0.0253 | Grad: 100749.852\n",
      "[Epoch 37, Batch 17/100] Loss: 0.0491 | RMSE: 0.0460 | Consistency: 0.0105 | SSIM: 0.0301 | Grad: 116768.375\n",
      "[Epoch 37, Batch 18/100] Loss: 0.0534 | RMSE: 0.0502 | Consistency: 0.0156 | SSIM: 0.0303 | Grad: 126817.859\n",
      "[Epoch 37, Batch 19/100] Loss: 0.0461 | RMSE: 0.0431 | Consistency: 0.0093 | SSIM: 0.0291 | Grad: 75521.453\n",
      "[Epoch 37, Batch 20/100] Loss: 0.0525 | RMSE: 0.0489 | Consistency: 0.0105 | SSIM: 0.0345 | Grad: 109896.883\n",
      "[Epoch 37, Batch 21/100] Loss: 0.0467 | RMSE: 0.0435 | Consistency: 0.0093 | SSIM: 0.0304 | Grad: 94428.695\n",
      "[Epoch 37, Batch 22/100] Loss: 0.0496 | RMSE: 0.0465 | Consistency: 0.0112 | SSIM: 0.0304 | Grad: 100307.547\n",
      "[Epoch 37, Batch 23/100] Loss: 0.0424 | RMSE: 0.0393 | Consistency: 0.0088 | SSIM: 0.0301 | Grad: 64110.602\n",
      "[Epoch 37, Batch 24/100] Loss: 0.0421 | RMSE: 0.0389 | Consistency: 0.0088 | SSIM: 0.0313 | Grad: 70431.445\n",
      "[Epoch 37, Batch 25/100] Loss: 0.0401 | RMSE: 0.0375 | Consistency: 0.0072 | SSIM: 0.0247 | Grad: 48184.848\n",
      "[Epoch 37, Batch 26/100] Loss: 0.0471 | RMSE: 0.0431 | Consistency: 0.0108 | SSIM: 0.0381 | Grad: 75178.125\n",
      "[Epoch 37, Batch 27/100] Loss: 0.0452 | RMSE: 0.0419 | Consistency: 0.0081 | SSIM: 0.0327 | Grad: 43072.930\n",
      "[Epoch 37, Batch 28/100] Loss: 0.0485 | RMSE: 0.0448 | Consistency: 0.0114 | SSIM: 0.0358 | Grad: 40847.547\n",
      "[Epoch 37, Batch 29/100] Loss: 0.0474 | RMSE: 0.0442 | Consistency: 0.0107 | SSIM: 0.0311 | Grad: 132695.250\n",
      "[Epoch 37, Batch 30/100] Loss: 0.0460 | RMSE: 0.0428 | Consistency: 0.0102 | SSIM: 0.0304 | Grad: 91441.773\n",
      "[Epoch 37, Batch 31/100] Loss: 0.0458 | RMSE: 0.0426 | Consistency: 0.0105 | SSIM: 0.0310 | Grad: 116133.555\n",
      "[Epoch 37, Batch 32/100] Loss: 0.0500 | RMSE: 0.0463 | Consistency: 0.0113 | SSIM: 0.0361 | Grad: 120391.289\n",
      "[Epoch 37, Batch 33/100] Loss: 0.0409 | RMSE: 0.0376 | Consistency: 0.0078 | SSIM: 0.0328 | Grad: 58927.812\n",
      "[Epoch 37, Batch 34/100] Loss: 0.0440 | RMSE: 0.0409 | Consistency: 0.0096 | SSIM: 0.0301 | Grad: 82547.078\n",
      "[Epoch 37, Batch 35/100] Loss: 0.0506 | RMSE: 0.0473 | Consistency: 0.0127 | SSIM: 0.0320 | Grad: 83190.086\n",
      "[Epoch 37, Batch 36/100] Loss: 0.0588 | RMSE: 0.0549 | Consistency: 0.0150 | SSIM: 0.0370 | Grad: 67157.938\n",
      "[Epoch 37, Batch 37/100] Loss: 0.0588 | RMSE: 0.0555 | Consistency: 0.0125 | SSIM: 0.0312 | Grad: 93653.812\n",
      "[Epoch 37, Batch 38/100] Loss: 0.0476 | RMSE: 0.0445 | Consistency: 0.0113 | SSIM: 0.0298 | Grad: 53035.082\n",
      "[Epoch 37, Batch 39/100] Loss: 0.0454 | RMSE: 0.0430 | Consistency: 0.0077 | SSIM: 0.0232 | Grad: 138091.438\n",
      "[Epoch 37, Batch 40/100] Loss: 0.0537 | RMSE: 0.0507 | Consistency: 0.0099 | SSIM: 0.0291 | Grad: 144888.375\n",
      "[Epoch 37, Batch 41/100] Loss: 0.0495 | RMSE: 0.0464 | Consistency: 0.0123 | SSIM: 0.0300 | Grad: 134890.453\n",
      "[Epoch 37, Batch 42/100] Loss: 0.0489 | RMSE: 0.0451 | Consistency: 0.0134 | SSIM: 0.0367 | Grad: 97585.562\n",
      "[Epoch 37, Batch 43/100] Loss: 0.0511 | RMSE: 0.0480 | Consistency: 0.0097 | SSIM: 0.0293 | Grad: 116507.664\n",
      "[Epoch 37, Batch 44/100] Loss: 0.0490 | RMSE: 0.0456 | Consistency: 0.0106 | SSIM: 0.0324 | Grad: 113006.555\n",
      "[Epoch 37, Batch 45/100] Loss: 0.0399 | RMSE: 0.0373 | Consistency: 0.0084 | SSIM: 0.0251 | Grad: 120912.320\n",
      "[Epoch 37, Batch 46/100] Loss: 0.0409 | RMSE: 0.0385 | Consistency: 0.0072 | SSIM: 0.0236 | Grad: 89970.539\n",
      "[Epoch 37, Batch 47/100] Loss: 0.0495 | RMSE: 0.0466 | Consistency: 0.0112 | SSIM: 0.0276 | Grad: 95140.820\n",
      "[Epoch 37, Batch 48/100] Loss: 0.0530 | RMSE: 0.0495 | Consistency: 0.0093 | SSIM: 0.0335 | Grad: 49514.023\n",
      "[Epoch 37, Batch 49/100] Loss: 0.0374 | RMSE: 0.0351 | Consistency: 0.0061 | SSIM: 0.0224 | Grad: 22946.383\n",
      "[Epoch 37, Batch 50/100] Loss: 0.0661 | RMSE: 0.0624 | Consistency: 0.0228 | SSIM: 0.0357 | Grad: 100996.516\n",
      "[Epoch 37, Batch 51/100] Loss: 0.0482 | RMSE: 0.0452 | Consistency: 0.0113 | SSIM: 0.0285 | Grad: 64513.848\n",
      "[Epoch 37, Batch 52/100] Loss: 0.0465 | RMSE: 0.0431 | Consistency: 0.0086 | SSIM: 0.0337 | Grad: 68311.203\n",
      "[Epoch 37, Batch 53/100] Loss: 0.0438 | RMSE: 0.0414 | Consistency: 0.0071 | SSIM: 0.0236 | Grad: 69612.664\n",
      "[Epoch 37, Batch 54/100] Loss: 0.0412 | RMSE: 0.0388 | Consistency: 0.0082 | SSIM: 0.0230 | Grad: 79221.250\n",
      "[Epoch 37, Batch 55/100] Loss: 0.0477 | RMSE: 0.0447 | Consistency: 0.0121 | SSIM: 0.0297 | Grad: 111709.633\n",
      "[Epoch 37, Batch 56/100] Loss: 0.0507 | RMSE: 0.0471 | Consistency: 0.0104 | SSIM: 0.0342 | Grad: 127950.258\n",
      "[Epoch 37, Batch 57/100] Loss: 0.0479 | RMSE: 0.0447 | Consistency: 0.0120 | SSIM: 0.0307 | Grad: 78326.680\n",
      "[Epoch 37, Batch 58/100] Loss: 0.0454 | RMSE: 0.0418 | Consistency: 0.0110 | SSIM: 0.0351 | Grad: 86091.758\n",
      "[Epoch 37, Batch 59/100] Loss: 0.0511 | RMSE: 0.0477 | Consistency: 0.0115 | SSIM: 0.0325 | Grad: 112013.531\n",
      "[Epoch 37, Batch 60/100] Loss: 0.0488 | RMSE: 0.0453 | Consistency: 0.0114 | SSIM: 0.0342 | Grad: 79044.734\n",
      "[Epoch 37, Batch 61/100] Loss: 0.0416 | RMSE: 0.0388 | Consistency: 0.0091 | SSIM: 0.0274 | Grad: 33998.301\n",
      "[Epoch 37, Batch 62/100] Loss: 0.0467 | RMSE: 0.0434 | Consistency: 0.0072 | SSIM: 0.0317 | Grad: 117882.109\n",
      "[Epoch 37, Batch 63/100] Loss: 0.0464 | RMSE: 0.0435 | Consistency: 0.0086 | SSIM: 0.0287 | Grad: 108866.664\n",
      "[Epoch 37, Batch 64/100] Loss: 0.0440 | RMSE: 0.0409 | Consistency: 0.0085 | SSIM: 0.0293 | Grad: 72998.086\n",
      "[Epoch 37, Batch 65/100] Loss: 0.0500 | RMSE: 0.0471 | Consistency: 0.0101 | SSIM: 0.0274 | Grad: 110104.344\n",
      "[Epoch 37, Batch 66/100] Loss: 0.0600 | RMSE: 0.0560 | Consistency: 0.0166 | SSIM: 0.0378 | Grad: 75263.508\n",
      "[Epoch 37, Batch 67/100] Loss: 0.0487 | RMSE: 0.0454 | Consistency: 0.0090 | SSIM: 0.0319 | Grad: 50094.754\n",
      "[Epoch 37, Batch 68/100] Loss: 0.0427 | RMSE: 0.0402 | Consistency: 0.0094 | SSIM: 0.0238 | Grad: 95163.531\n",
      "[Epoch 37, Batch 69/100] Loss: 0.0502 | RMSE: 0.0465 | Consistency: 0.0105 | SSIM: 0.0361 | Grad: 84043.375\n",
      "[Epoch 37, Batch 70/100] Loss: 0.0446 | RMSE: 0.0418 | Consistency: 0.0096 | SSIM: 0.0268 | Grad: 54593.137\n",
      "[Epoch 37, Batch 71/100] Loss: 0.0471 | RMSE: 0.0444 | Consistency: 0.0084 | SSIM: 0.0262 | Grad: 107951.594\n",
      "[Epoch 37, Batch 72/100] Loss: 0.0416 | RMSE: 0.0386 | Consistency: 0.0084 | SSIM: 0.0294 | Grad: 85112.430\n",
      "[Epoch 37, Batch 73/100] Loss: 0.0475 | RMSE: 0.0444 | Consistency: 0.0116 | SSIM: 0.0293 | Grad: 105237.492\n",
      "[Epoch 37, Batch 74/100] Loss: 0.0466 | RMSE: 0.0438 | Consistency: 0.0118 | SSIM: 0.0273 | Grad: 81360.656\n",
      "[Epoch 37, Batch 75/100] Loss: 0.0458 | RMSE: 0.0426 | Consistency: 0.0086 | SSIM: 0.0307 | Grad: 91426.070\n",
      "[Epoch 37, Batch 76/100] Loss: 0.0577 | RMSE: 0.0540 | Consistency: 0.0183 | SSIM: 0.0354 | Grad: 46642.340\n",
      "[Epoch 37, Batch 77/100] Loss: 0.0460 | RMSE: 0.0427 | Consistency: 0.0110 | SSIM: 0.0318 | Grad: 91044.078\n",
      "[Epoch 37, Batch 78/100] Loss: 0.0493 | RMSE: 0.0455 | Consistency: 0.0112 | SSIM: 0.0368 | Grad: 47632.691\n",
      "[Epoch 37, Batch 79/100] Loss: 0.0400 | RMSE: 0.0373 | Consistency: 0.0069 | SSIM: 0.0265 | Grad: 54123.574\n",
      "[Epoch 37, Batch 80/100] Loss: 0.0447 | RMSE: 0.0420 | Consistency: 0.0096 | SSIM: 0.0258 | Grad: 80762.562\n",
      "[Epoch 37, Batch 81/100] Loss: 0.0423 | RMSE: 0.0396 | Consistency: 0.0068 | SSIM: 0.0261 | Grad: 112385.141\n",
      "[Epoch 37, Batch 82/100] Loss: 0.0434 | RMSE: 0.0404 | Consistency: 0.0083 | SSIM: 0.0295 | Grad: 100092.422\n",
      "[Epoch 37, Batch 83/100] Loss: 0.0463 | RMSE: 0.0432 | Consistency: 0.0096 | SSIM: 0.0303 | Grad: 44265.379\n",
      "[Epoch 37, Batch 84/100] Loss: 0.0433 | RMSE: 0.0404 | Consistency: 0.0074 | SSIM: 0.0277 | Grad: 98074.234\n",
      "[Epoch 37, Batch 85/100] Loss: 0.0518 | RMSE: 0.0484 | Consistency: 0.0132 | SSIM: 0.0322 | Grad: 106475.305\n",
      "[Epoch 37, Batch 86/100] Loss: 0.0446 | RMSE: 0.0417 | Consistency: 0.0103 | SSIM: 0.0276 | Grad: 99823.750\n",
      "[Epoch 37, Batch 87/100] Loss: 0.0462 | RMSE: 0.0430 | Consistency: 0.0082 | SSIM: 0.0317 | Grad: 56307.445\n",
      "[Epoch 37, Batch 88/100] Loss: 0.0485 | RMSE: 0.0456 | Consistency: 0.0081 | SSIM: 0.0281 | Grad: 109779.547\n",
      "[Epoch 37, Batch 89/100] Loss: 0.0481 | RMSE: 0.0447 | Consistency: 0.0095 | SSIM: 0.0322 | Grad: 103268.836\n",
      "[Epoch 37, Batch 90/100] Loss: 0.0525 | RMSE: 0.0483 | Consistency: 0.0106 | SSIM: 0.0406 | Grad: 129921.719\n",
      "[Epoch 37, Batch 91/100] Loss: 0.0447 | RMSE: 0.0416 | Consistency: 0.0100 | SSIM: 0.0302 | Grad: 47454.941\n",
      "[Epoch 37, Batch 92/100] Loss: 0.0498 | RMSE: 0.0464 | Consistency: 0.0111 | SSIM: 0.0328 | Grad: 107113.992\n",
      "[Epoch 37, Batch 93/100] Loss: 0.0430 | RMSE: 0.0404 | Consistency: 0.0091 | SSIM: 0.0254 | Grad: 131219.156\n",
      "[Epoch 37, Batch 94/100] Loss: 0.0565 | RMSE: 0.0527 | Consistency: 0.0178 | SSIM: 0.0365 | Grad: 68126.555\n",
      "[Epoch 37, Batch 95/100] Loss: 0.0454 | RMSE: 0.0427 | Consistency: 0.0093 | SSIM: 0.0267 | Grad: 81487.742\n",
      "[Epoch 37, Batch 96/100] Loss: 0.0519 | RMSE: 0.0482 | Consistency: 0.0111 | SSIM: 0.0354 | Grad: 28050.504\n",
      "[Epoch 37, Batch 97/100] Loss: 0.0454 | RMSE: 0.0422 | Consistency: 0.0109 | SSIM: 0.0317 | Grad: 122115.102\n",
      "[Epoch 37, Batch 98/100] Loss: 0.0468 | RMSE: 0.0444 | Consistency: 0.0098 | SSIM: 0.0229 | Grad: 172218.172\n",
      "[Epoch 37, Batch 99/100] Loss: 0.0444 | RMSE: 0.0420 | Consistency: 0.0084 | SSIM: 0.0235 | Grad: 124522.320\n",
      "[Epoch 37, Batch 100/100] Loss: 0.0406 | RMSE: 0.0381 | Consistency: 0.0083 | SSIM: 0.0245 | Grad: 94556.133\n",
      "✅ Epoch 37 완료!\n",
      "   📈 평균 Loss: 0.047555\n",
      "   📊 평균 RMSE: 0.044421\n",
      "   ⚙️  학습률: 0.000650\n",
      "   🏆 NEW BEST! RMSE: 0.044421\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 38/80 시작...\n",
      "[Epoch 38, Batch 1/100] Loss: 0.0515 | RMSE: 0.0480 | Consistency: 0.0098 | SSIM: 0.0341 | Grad: 138818.703\n",
      "[Epoch 38, Batch 2/100] Loss: 0.0512 | RMSE: 0.0482 | Consistency: 0.0121 | SSIM: 0.0294 | Grad: 150490.125\n",
      "[Epoch 38, Batch 3/100] Loss: 0.0464 | RMSE: 0.0431 | Consistency: 0.0103 | SSIM: 0.0322 | Grad: 84194.375\n",
      "[Epoch 38, Batch 4/100] Loss: 0.0525 | RMSE: 0.0491 | Consistency: 0.0099 | SSIM: 0.0329 | Grad: 101392.930\n",
      "[Epoch 38, Batch 5/100] Loss: 0.0426 | RMSE: 0.0399 | Consistency: 0.0081 | SSIM: 0.0262 | Grad: 99484.148\n",
      "[Epoch 38, Batch 6/100] Loss: 0.0509 | RMSE: 0.0483 | Consistency: 0.0099 | SSIM: 0.0259 | Grad: 91019.883\n",
      "[Epoch 38, Batch 7/100] Loss: 0.0535 | RMSE: 0.0501 | Consistency: 0.0113 | SSIM: 0.0332 | Grad: 77627.430\n",
      "[Epoch 38, Batch 8/100] Loss: 0.0470 | RMSE: 0.0440 | Consistency: 0.0087 | SSIM: 0.0291 | Grad: 92960.391\n",
      "[Epoch 38, Batch 9/100] Loss: 0.0421 | RMSE: 0.0394 | Consistency: 0.0086 | SSIM: 0.0256 | Grad: 107855.383\n",
      "[Epoch 38, Batch 10/100] Loss: 0.0523 | RMSE: 0.0491 | Consistency: 0.0095 | SSIM: 0.0306 | Grad: 63692.793\n",
      "[Epoch 38, Batch 11/100] Loss: 0.0454 | RMSE: 0.0425 | Consistency: 0.0095 | SSIM: 0.0289 | Grad: 105598.055\n",
      "[Epoch 38, Batch 12/100] Loss: 0.0496 | RMSE: 0.0465 | Consistency: 0.0123 | SSIM: 0.0299 | Grad: 127884.617\n",
      "[Epoch 38, Batch 13/100] Loss: 0.0505 | RMSE: 0.0471 | Consistency: 0.0110 | SSIM: 0.0325 | Grad: 88304.961\n",
      "[Epoch 38, Batch 14/100] Loss: 0.0478 | RMSE: 0.0451 | Consistency: 0.0111 | SSIM: 0.0260 | Grad: 70472.281\n",
      "[Epoch 38, Batch 15/100] Loss: 0.0426 | RMSE: 0.0399 | Consistency: 0.0080 | SSIM: 0.0262 | Grad: 89105.016\n",
      "[Epoch 38, Batch 16/100] Loss: 0.0522 | RMSE: 0.0487 | Consistency: 0.0132 | SSIM: 0.0333 | Grad: 124831.109\n",
      "[Epoch 38, Batch 17/100] Loss: 0.0434 | RMSE: 0.0402 | Consistency: 0.0088 | SSIM: 0.0307 | Grad: 95645.359\n",
      "[Epoch 38, Batch 18/100] Loss: 0.0512 | RMSE: 0.0478 | Consistency: 0.0118 | SSIM: 0.0332 | Grad: 87109.305\n",
      "[Epoch 38, Batch 19/100] Loss: 0.0409 | RMSE: 0.0382 | Consistency: 0.0073 | SSIM: 0.0261 | Grad: 45205.613\n",
      "[Epoch 38, Batch 20/100] Loss: 0.0499 | RMSE: 0.0463 | Consistency: 0.0132 | SSIM: 0.0350 | Grad: 134043.188\n",
      "[Epoch 38, Batch 21/100] Loss: 0.0466 | RMSE: 0.0435 | Consistency: 0.0116 | SSIM: 0.0296 | Grad: 106258.031\n",
      "[Epoch 38, Batch 22/100] Loss: 0.0521 | RMSE: 0.0487 | Consistency: 0.0128 | SSIM: 0.0325 | Grad: 85605.273\n",
      "[Epoch 38, Batch 23/100] Loss: 0.0395 | RMSE: 0.0366 | Consistency: 0.0079 | SSIM: 0.0288 | Grad: 44071.328\n",
      "[Epoch 38, Batch 24/100] Loss: 0.0596 | RMSE: 0.0562 | Consistency: 0.0183 | SSIM: 0.0322 | Grad: 103483.188\n",
      "[Epoch 38, Batch 25/100] Loss: 0.0585 | RMSE: 0.0551 | Consistency: 0.0239 | SSIM: 0.0322 | Grad: 163453.188\n",
      "[Epoch 38, Batch 26/100] Loss: 0.0598 | RMSE: 0.0564 | Consistency: 0.0219 | SSIM: 0.0322 | Grad: 172224.094\n",
      "[Epoch 38, Batch 27/100] Loss: 0.0576 | RMSE: 0.0537 | Consistency: 0.0179 | SSIM: 0.0367 | Grad: 126512.312\n",
      "[Epoch 38, Batch 28/100] Loss: 0.0410 | RMSE: 0.0381 | Consistency: 0.0083 | SSIM: 0.0286 | Grad: 63892.555\n",
      "[Epoch 38, Batch 29/100] Loss: 0.0582 | RMSE: 0.0547 | Consistency: 0.0185 | SSIM: 0.0332 | Grad: 144200.328\n",
      "[Epoch 38, Batch 30/100] Loss: 0.0544 | RMSE: 0.0508 | Consistency: 0.0139 | SSIM: 0.0341 | Grad: 135587.922\n",
      "[Epoch 38, Batch 31/100] Loss: 0.0506 | RMSE: 0.0471 | Consistency: 0.0108 | SSIM: 0.0332 | Grad: 116608.445\n",
      "[Epoch 38, Batch 32/100] Loss: 0.0422 | RMSE: 0.0398 | Consistency: 0.0087 | SSIM: 0.0235 | Grad: 102016.641\n",
      "[Epoch 38, Batch 33/100] Loss: 0.0449 | RMSE: 0.0417 | Consistency: 0.0087 | SSIM: 0.0303 | Grad: 81165.844\n",
      "[Epoch 38, Batch 34/100] Loss: 0.0626 | RMSE: 0.0588 | Consistency: 0.0125 | SSIM: 0.0373 | Grad: 29263.102\n",
      "[Epoch 38, Batch 35/100] Loss: 0.0434 | RMSE: 0.0404 | Consistency: 0.0071 | SSIM: 0.0297 | Grad: 118725.711\n",
      "[Epoch 38, Batch 36/100] Loss: 0.0539 | RMSE: 0.0505 | Consistency: 0.0129 | SSIM: 0.0331 | Grad: 84898.633\n",
      "[Epoch 38, Batch 37/100] Loss: 0.0434 | RMSE: 0.0409 | Consistency: 0.0077 | SSIM: 0.0250 | Grad: 81137.242\n",
      "[Epoch 38, Batch 38/100] Loss: 0.0510 | RMSE: 0.0479 | Consistency: 0.0127 | SSIM: 0.0301 | Grad: 75484.289\n",
      "[Epoch 38, Batch 39/100] Loss: 0.0485 | RMSE: 0.0449 | Consistency: 0.0109 | SSIM: 0.0349 | Grad: 90255.773\n",
      "[Epoch 38, Batch 40/100] Loss: 0.0438 | RMSE: 0.0411 | Consistency: 0.0093 | SSIM: 0.0255 | Grad: 94708.312\n",
      "[Epoch 38, Batch 41/100] Loss: 0.0471 | RMSE: 0.0441 | Consistency: 0.0105 | SSIM: 0.0288 | Grad: 106476.766\n",
      "[Epoch 38, Batch 42/100] Loss: 0.0550 | RMSE: 0.0517 | Consistency: 0.0120 | SSIM: 0.0318 | Grad: 79523.281\n",
      "[Epoch 38, Batch 43/100] Loss: 0.0457 | RMSE: 0.0420 | Consistency: 0.0088 | SSIM: 0.0357 | Grad: 37776.738\n",
      "[Epoch 38, Batch 44/100] Loss: 0.0551 | RMSE: 0.0517 | Consistency: 0.0168 | SSIM: 0.0321 | Grad: 70596.055\n",
      "[Epoch 38, Batch 45/100] Loss: 0.0439 | RMSE: 0.0413 | Consistency: 0.0099 | SSIM: 0.0250 | Grad: 70703.297\n",
      "[Epoch 38, Batch 46/100] Loss: 0.0528 | RMSE: 0.0491 | Consistency: 0.0120 | SSIM: 0.0355 | Grad: 143879.656\n",
      "[Epoch 38, Batch 47/100] Loss: 0.0496 | RMSE: 0.0465 | Consistency: 0.0096 | SSIM: 0.0306 | Grad: 116007.742\n",
      "[Epoch 38, Batch 48/100] Loss: 0.0407 | RMSE: 0.0379 | Consistency: 0.0073 | SSIM: 0.0275 | Grad: 67199.703\n",
      "[Epoch 38, Batch 49/100] Loss: 0.0600 | RMSE: 0.0556 | Consistency: 0.0169 | SSIM: 0.0419 | Grad: 80179.547\n",
      "[Epoch 38, Batch 50/100] Loss: 0.0513 | RMSE: 0.0481 | Consistency: 0.0101 | SSIM: 0.0305 | Grad: 101213.930\n",
      "[Epoch 38, Batch 51/100] Loss: 0.0482 | RMSE: 0.0453 | Consistency: 0.0092 | SSIM: 0.0282 | Grad: 137602.688\n",
      "[Epoch 38, Batch 52/100] Loss: 0.0472 | RMSE: 0.0438 | Consistency: 0.0111 | SSIM: 0.0326 | Grad: 84669.242\n",
      "[Epoch 38, Batch 53/100] Loss: 0.0459 | RMSE: 0.0431 | Consistency: 0.0097 | SSIM: 0.0275 | Grad: 55477.965\n",
      "[Epoch 38, Batch 54/100] Loss: 0.0489 | RMSE: 0.0457 | Consistency: 0.0098 | SSIM: 0.0310 | Grad: 123375.312\n",
      "[Epoch 38, Batch 55/100] Loss: 0.0563 | RMSE: 0.0530 | Consistency: 0.0106 | SSIM: 0.0323 | Grad: 135729.266\n",
      "[Epoch 38, Batch 56/100] Loss: 0.0593 | RMSE: 0.0551 | Consistency: 0.0178 | SSIM: 0.0399 | Grad: 163626.219\n",
      "[Epoch 38, Batch 57/100] Loss: 0.0470 | RMSE: 0.0436 | Consistency: 0.0107 | SSIM: 0.0328 | Grad: 116509.797\n",
      "[Epoch 38, Batch 58/100] Loss: 0.0451 | RMSE: 0.0424 | Consistency: 0.0099 | SSIM: 0.0261 | Grad: 96922.727\n",
      "[Epoch 38, Batch 59/100] Loss: 0.0470 | RMSE: 0.0433 | Consistency: 0.0100 | SSIM: 0.0351 | Grad: 54997.066\n",
      "[Epoch 38, Batch 60/100] Loss: 0.0423 | RMSE: 0.0388 | Consistency: 0.0088 | SSIM: 0.0342 | Grad: 87381.133\n",
      "[Epoch 38, Batch 61/100] Loss: 0.0484 | RMSE: 0.0453 | Consistency: 0.0103 | SSIM: 0.0293 | Grad: 111771.055\n",
      "[Epoch 38, Batch 62/100] Loss: 0.0457 | RMSE: 0.0427 | Consistency: 0.0080 | SSIM: 0.0296 | Grad: 102442.523\n",
      "[Epoch 38, Batch 63/100] Loss: 0.0446 | RMSE: 0.0412 | Consistency: 0.0090 | SSIM: 0.0336 | Grad: 22269.393\n",
      "[Epoch 38, Batch 64/100] Loss: 0.0583 | RMSE: 0.0550 | Consistency: 0.0149 | SSIM: 0.0314 | Grad: 111642.594\n",
      "[Epoch 38, Batch 65/100] Loss: 0.0531 | RMSE: 0.0501 | Consistency: 0.0119 | SSIM: 0.0289 | Grad: 124791.242\n",
      "[Epoch 38, Batch 66/100] Loss: 0.0597 | RMSE: 0.0561 | Consistency: 0.0119 | SSIM: 0.0347 | Grad: 104285.250\n",
      "[Epoch 38, Batch 67/100] Loss: 0.0601 | RMSE: 0.0564 | Consistency: 0.0120 | SSIM: 0.0359 | Grad: 132865.578\n",
      "[Epoch 38, Batch 68/100] Loss: 0.0538 | RMSE: 0.0504 | Consistency: 0.0118 | SSIM: 0.0322 | Grad: 77768.219\n",
      "[Epoch 38, Batch 69/100] Loss: 0.0529 | RMSE: 0.0495 | Consistency: 0.0124 | SSIM: 0.0326 | Grad: 110213.281\n",
      "[Epoch 38, Batch 70/100] Loss: 0.0481 | RMSE: 0.0453 | Consistency: 0.0096 | SSIM: 0.0269 | Grad: 85808.836\n",
      "[Epoch 38, Batch 71/100] Loss: 0.0483 | RMSE: 0.0449 | Consistency: 0.0102 | SSIM: 0.0324 | Grad: 47225.578\n",
      "[Epoch 38, Batch 72/100] Loss: 0.0586 | RMSE: 0.0543 | Consistency: 0.0128 | SSIM: 0.0413 | Grad: 132295.375\n",
      "[Epoch 38, Batch 73/100] Loss: 0.0524 | RMSE: 0.0486 | Consistency: 0.0106 | SSIM: 0.0377 | Grad: 145507.906\n",
      "[Epoch 38, Batch 74/100] Loss: 0.0530 | RMSE: 0.0495 | Consistency: 0.0123 | SSIM: 0.0331 | Grad: 53418.043\n",
      "[Epoch 38, Batch 75/100] Loss: 0.0443 | RMSE: 0.0413 | Consistency: 0.0093 | SSIM: 0.0285 | Grad: 34777.691\n",
      "[Epoch 38, Batch 76/100] Loss: 0.0418 | RMSE: 0.0389 | Consistency: 0.0087 | SSIM: 0.0273 | Grad: 96714.539\n",
      "[Epoch 38, Batch 77/100] Loss: 0.0597 | RMSE: 0.0554 | Consistency: 0.0147 | SSIM: 0.0420 | Grad: 81995.195\n",
      "[Epoch 38, Batch 78/100] Loss: 0.0491 | RMSE: 0.0461 | Consistency: 0.0101 | SSIM: 0.0286 | Grad: 57347.852\n",
      "[Epoch 38, Batch 79/100] Loss: 0.0473 | RMSE: 0.0438 | Consistency: 0.0095 | SSIM: 0.0346 | Grad: 105409.414\n",
      "[Epoch 38, Batch 80/100] Loss: 0.0500 | RMSE: 0.0464 | Consistency: 0.0106 | SSIM: 0.0351 | Grad: 91719.352\n",
      "[Epoch 38, Batch 81/100] Loss: 0.0518 | RMSE: 0.0483 | Consistency: 0.0146 | SSIM: 0.0335 | Grad: 137760.219\n",
      "[Epoch 38, Batch 82/100] Loss: 0.0479 | RMSE: 0.0444 | Consistency: 0.0114 | SSIM: 0.0331 | Grad: 104405.680\n",
      "[Epoch 38, Batch 83/100] Loss: 0.0508 | RMSE: 0.0474 | Consistency: 0.0116 | SSIM: 0.0324 | Grad: 110312.023\n",
      "[Epoch 38, Batch 84/100] Loss: 0.0495 | RMSE: 0.0458 | Consistency: 0.0120 | SSIM: 0.0355 | Grad: 82051.016\n",
      "[Epoch 38, Batch 85/100] Loss: 0.0522 | RMSE: 0.0481 | Consistency: 0.0124 | SSIM: 0.0399 | Grad: 79037.727\n",
      "[Epoch 38, Batch 86/100] Loss: 0.0420 | RMSE: 0.0395 | Consistency: 0.0081 | SSIM: 0.0233 | Grad: 85860.992\n",
      "[Epoch 38, Batch 87/100] Loss: 0.0479 | RMSE: 0.0445 | Consistency: 0.0103 | SSIM: 0.0332 | Grad: 100571.047\n",
      "[Epoch 38, Batch 88/100] Loss: 0.0489 | RMSE: 0.0455 | Consistency: 0.0101 | SSIM: 0.0331 | Grad: 142410.109\n",
      "[Epoch 38, Batch 89/100] Loss: 0.0527 | RMSE: 0.0494 | Consistency: 0.0110 | SSIM: 0.0322 | Grad: 143215.984\n",
      "[Epoch 38, Batch 90/100] Loss: 0.0595 | RMSE: 0.0559 | Consistency: 0.0125 | SSIM: 0.0339 | Grad: 87314.992\n",
      "[Epoch 38, Batch 91/100] Loss: 0.0465 | RMSE: 0.0430 | Consistency: 0.0092 | SSIM: 0.0339 | Grad: 104141.867\n",
      "[Epoch 38, Batch 92/100] Loss: 0.0473 | RMSE: 0.0439 | Consistency: 0.0111 | SSIM: 0.0329 | Grad: 63711.176\n",
      "[Epoch 38, Batch 93/100] Loss: 0.0453 | RMSE: 0.0422 | Consistency: 0.0090 | SSIM: 0.0300 | Grad: 68174.234\n",
      "[Epoch 38, Batch 94/100] Loss: 0.0479 | RMSE: 0.0450 | Consistency: 0.0097 | SSIM: 0.0281 | Grad: 103016.820\n",
      "[Epoch 38, Batch 95/100] Loss: 0.0435 | RMSE: 0.0404 | Consistency: 0.0082 | SSIM: 0.0307 | Grad: 113226.539\n",
      "[Epoch 38, Batch 96/100] Loss: 0.0509 | RMSE: 0.0475 | Consistency: 0.0108 | SSIM: 0.0324 | Grad: 118728.688\n",
      "[Epoch 38, Batch 97/100] Loss: 0.0498 | RMSE: 0.0461 | Consistency: 0.0121 | SSIM: 0.0354 | Grad: 27284.688\n",
      "[Epoch 38, Batch 98/100] Loss: 0.0484 | RMSE: 0.0454 | Consistency: 0.0091 | SSIM: 0.0284 | Grad: 107988.180\n",
      "[Epoch 38, Batch 99/100] Loss: 0.0506 | RMSE: 0.0466 | Consistency: 0.0113 | SSIM: 0.0389 | Grad: 105348.414\n",
      "[Epoch 38, Batch 100/100] Loss: 0.0511 | RMSE: 0.0476 | Consistency: 0.0114 | SSIM: 0.0334 | Grad: 111275.422\n",
      "✅ Epoch 38 완료!\n",
      "   📈 평균 Loss: 0.049768\n",
      "   📊 평균 RMSE: 0.046483\n",
      "   ⚙️  학습률: 0.000629\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 39/80 시작...\n",
      "[Epoch 39, Batch 1/100] Loss: 0.0507 | RMSE: 0.0470 | Consistency: 0.0128 | SSIM: 0.0355 | Grad: 91618.055\n",
      "[Epoch 39, Batch 2/100] Loss: 0.0435 | RMSE: 0.0408 | Consistency: 0.0086 | SSIM: 0.0261 | Grad: 61115.270\n",
      "[Epoch 39, Batch 3/100] Loss: 0.0501 | RMSE: 0.0469 | Consistency: 0.0115 | SSIM: 0.0303 | Grad: 78135.039\n",
      "[Epoch 39, Batch 4/100] Loss: 0.0400 | RMSE: 0.0374 | Consistency: 0.0070 | SSIM: 0.0252 | Grad: 115222.562\n",
      "[Epoch 39, Batch 5/100] Loss: 0.0509 | RMSE: 0.0469 | Consistency: 0.0126 | SSIM: 0.0379 | Grad: 64361.836\n",
      "[Epoch 39, Batch 6/100] Loss: 0.0525 | RMSE: 0.0486 | Consistency: 0.0122 | SSIM: 0.0380 | Grad: 85288.156\n",
      "[Epoch 39, Batch 7/100] Loss: 0.0392 | RMSE: 0.0364 | Consistency: 0.0064 | SSIM: 0.0279 | Grad: 56389.871\n",
      "[Epoch 39, Batch 8/100] Loss: 0.0456 | RMSE: 0.0428 | Consistency: 0.0085 | SSIM: 0.0270 | Grad: 86278.602\n",
      "[Epoch 39, Batch 9/100] Loss: 0.0473 | RMSE: 0.0443 | Consistency: 0.0111 | SSIM: 0.0287 | Grad: 96458.203\n",
      "[Epoch 39, Batch 10/100] Loss: 0.0419 | RMSE: 0.0385 | Consistency: 0.0084 | SSIM: 0.0327 | Grad: 61236.570\n",
      "[Epoch 39, Batch 11/100] Loss: 0.0433 | RMSE: 0.0397 | Consistency: 0.0076 | SSIM: 0.0347 | Grad: 70457.172\n",
      "[Epoch 39, Batch 12/100] Loss: 0.0405 | RMSE: 0.0376 | Consistency: 0.0077 | SSIM: 0.0287 | Grad: 99529.336\n",
      "[Epoch 39, Batch 13/100] Loss: 0.0562 | RMSE: 0.0522 | Consistency: 0.0140 | SSIM: 0.0390 | Grad: 127534.469\n",
      "[Epoch 39, Batch 14/100] Loss: 0.0505 | RMSE: 0.0475 | Consistency: 0.0118 | SSIM: 0.0292 | Grad: 92173.406\n",
      "[Epoch 39, Batch 15/100] Loss: 0.0546 | RMSE: 0.0509 | Consistency: 0.0113 | SSIM: 0.0360 | Grad: 128226.617\n",
      "[Epoch 39, Batch 16/100] Loss: 0.0454 | RMSE: 0.0423 | Consistency: 0.0089 | SSIM: 0.0306 | Grad: 50053.602\n",
      "[Epoch 39, Batch 17/100] Loss: 0.0482 | RMSE: 0.0449 | Consistency: 0.0103 | SSIM: 0.0325 | Grad: 87466.820\n",
      "[Epoch 39, Batch 18/100] Loss: 0.0474 | RMSE: 0.0441 | Consistency: 0.0083 | SSIM: 0.0329 | Grad: 126028.953\n",
      "[Epoch 39, Batch 19/100] Loss: 0.0434 | RMSE: 0.0406 | Consistency: 0.0094 | SSIM: 0.0273 | Grad: 75658.195\n",
      "[Epoch 39, Batch 20/100] Loss: 0.0465 | RMSE: 0.0429 | Consistency: 0.0100 | SSIM: 0.0356 | Grad: 64604.355\n",
      "[Epoch 39, Batch 21/100] Loss: 0.0442 | RMSE: 0.0416 | Consistency: 0.0097 | SSIM: 0.0250 | Grad: 62670.176\n",
      "[Epoch 39, Batch 22/100] Loss: 0.0539 | RMSE: 0.0506 | Consistency: 0.0085 | SSIM: 0.0322 | Grad: 131866.094\n",
      "[Epoch 39, Batch 23/100] Loss: 0.0444 | RMSE: 0.0418 | Consistency: 0.0077 | SSIM: 0.0260 | Grad: 107724.656\n",
      "[Epoch 39, Batch 24/100] Loss: 0.0441 | RMSE: 0.0413 | Consistency: 0.0084 | SSIM: 0.0265 | Grad: 103912.289\n",
      "[Epoch 39, Batch 25/100] Loss: 0.0502 | RMSE: 0.0470 | Consistency: 0.0108 | SSIM: 0.0315 | Grad: 37345.914\n",
      "[Epoch 39, Batch 26/100] Loss: 0.0495 | RMSE: 0.0467 | Consistency: 0.0119 | SSIM: 0.0265 | Grad: 132256.781\n",
      "[Epoch 39, Batch 27/100] Loss: 0.0465 | RMSE: 0.0439 | Consistency: 0.0093 | SSIM: 0.0247 | Grad: 125075.586\n",
      "[Epoch 39, Batch 28/100] Loss: 0.0494 | RMSE: 0.0464 | Consistency: 0.0104 | SSIM: 0.0292 | Grad: 89471.094\n",
      "[Epoch 39, Batch 29/100] Loss: 0.0471 | RMSE: 0.0445 | Consistency: 0.0099 | SSIM: 0.0250 | Grad: 69691.383\n",
      "[Epoch 39, Batch 30/100] Loss: 0.0461 | RMSE: 0.0425 | Consistency: 0.0101 | SSIM: 0.0345 | Grad: 80037.523\n",
      "[Epoch 39, Batch 31/100] Loss: 0.0498 | RMSE: 0.0466 | Consistency: 0.0112 | SSIM: 0.0307 | Grad: 71612.344\n",
      "[Epoch 39, Batch 32/100] Loss: 0.0519 | RMSE: 0.0485 | Consistency: 0.0133 | SSIM: 0.0326 | Grad: 121648.953\n",
      "[Epoch 39, Batch 33/100] Loss: 0.0591 | RMSE: 0.0552 | Consistency: 0.0173 | SSIM: 0.0368 | Grad: 77647.797\n",
      "[Epoch 39, Batch 34/100] Loss: 0.0475 | RMSE: 0.0447 | Consistency: 0.0092 | SSIM: 0.0270 | Grad: 72011.578\n",
      "[Epoch 39, Batch 35/100] Loss: 0.0468 | RMSE: 0.0437 | Consistency: 0.0092 | SSIM: 0.0304 | Grad: 57050.152\n",
      "[Epoch 39, Batch 36/100] Loss: 0.0440 | RMSE: 0.0406 | Consistency: 0.0078 | SSIM: 0.0331 | Grad: 122039.281\n",
      "[Epoch 39, Batch 37/100] Loss: 0.0434 | RMSE: 0.0404 | Consistency: 0.0101 | SSIM: 0.0292 | Grad: 103274.195\n",
      "[Epoch 39, Batch 38/100] Loss: 0.0450 | RMSE: 0.0416 | Consistency: 0.0096 | SSIM: 0.0334 | Grad: 18792.447\n",
      "[Epoch 39, Batch 39/100] Loss: 0.0427 | RMSE: 0.0397 | Consistency: 0.0072 | SSIM: 0.0295 | Grad: 118369.273\n",
      "[Epoch 39, Batch 40/100] Loss: 0.0541 | RMSE: 0.0507 | Consistency: 0.0093 | SSIM: 0.0332 | Grad: 134598.078\n",
      "[Epoch 39, Batch 41/100] Loss: 0.0496 | RMSE: 0.0465 | Consistency: 0.0107 | SSIM: 0.0296 | Grad: 107044.312\n",
      "[Epoch 39, Batch 42/100] Loss: 0.0472 | RMSE: 0.0439 | Consistency: 0.0119 | SSIM: 0.0320 | Grad: 56625.039\n",
      "[Epoch 39, Batch 43/100] Loss: 0.0454 | RMSE: 0.0427 | Consistency: 0.0085 | SSIM: 0.0255 | Grad: 80104.383\n",
      "[Epoch 39, Batch 44/100] Loss: 0.0599 | RMSE: 0.0560 | Consistency: 0.0125 | SSIM: 0.0376 | Grad: 159685.969\n",
      "[Epoch 39, Batch 45/100] Loss: 0.0530 | RMSE: 0.0499 | Consistency: 0.0091 | SSIM: 0.0297 | Grad: 150729.562\n",
      "[Epoch 39, Batch 46/100] Loss: 0.0593 | RMSE: 0.0547 | Consistency: 0.0130 | SSIM: 0.0451 | Grad: 111746.734\n",
      "[Epoch 39, Batch 47/100] Loss: 0.0450 | RMSE: 0.0420 | Consistency: 0.0086 | SSIM: 0.0287 | Grad: 96869.570\n",
      "[Epoch 39, Batch 48/100] Loss: 0.0431 | RMSE: 0.0401 | Consistency: 0.0091 | SSIM: 0.0291 | Grad: 73680.852\n",
      "[Epoch 39, Batch 49/100] Loss: 0.0456 | RMSE: 0.0428 | Consistency: 0.0092 | SSIM: 0.0270 | Grad: 58120.637\n",
      "[Epoch 39, Batch 50/100] Loss: 0.0569 | RMSE: 0.0533 | Consistency: 0.0159 | SSIM: 0.0345 | Grad: 66206.797\n",
      "[Epoch 39, Batch 51/100] Loss: 0.0439 | RMSE: 0.0411 | Consistency: 0.0107 | SSIM: 0.0268 | Grad: 116501.039\n",
      "[Epoch 39, Batch 52/100] Loss: 0.0501 | RMSE: 0.0473 | Consistency: 0.0141 | SSIM: 0.0272 | Grad: 128378.703\n",
      "[Epoch 39, Batch 53/100] Loss: 0.0489 | RMSE: 0.0457 | Consistency: 0.0123 | SSIM: 0.0311 | Grad: 135000.344\n",
      "[Epoch 39, Batch 54/100] Loss: 0.0534 | RMSE: 0.0492 | Consistency: 0.0104 | SSIM: 0.0408 | Grad: 111486.656\n",
      "[Epoch 39, Batch 55/100] Loss: 0.0480 | RMSE: 0.0443 | Consistency: 0.0107 | SSIM: 0.0353 | Grad: 96659.039\n",
      "[Epoch 39, Batch 56/100] Loss: 0.0559 | RMSE: 0.0521 | Consistency: 0.0142 | SSIM: 0.0366 | Grad: 84073.930\n",
      "[Epoch 39, Batch 57/100] Loss: 0.0404 | RMSE: 0.0379 | Consistency: 0.0072 | SSIM: 0.0243 | Grad: 84683.352\n",
      "[Epoch 39, Batch 58/100] Loss: 0.0481 | RMSE: 0.0449 | Consistency: 0.0121 | SSIM: 0.0306 | Grad: 17025.701\n",
      "[Epoch 39, Batch 59/100] Loss: 0.0524 | RMSE: 0.0493 | Consistency: 0.0120 | SSIM: 0.0301 | Grad: 108563.680\n",
      "[Epoch 39, Batch 60/100] Loss: 0.0483 | RMSE: 0.0446 | Consistency: 0.0121 | SSIM: 0.0351 | Grad: 82062.508\n",
      "[Epoch 39, Batch 61/100] Loss: 0.0504 | RMSE: 0.0468 | Consistency: 0.0123 | SSIM: 0.0346 | Grad: 104539.523\n",
      "[Epoch 39, Batch 62/100] Loss: 0.0562 | RMSE: 0.0524 | Consistency: 0.0123 | SSIM: 0.0370 | Grad: 93417.305\n",
      "[Epoch 39, Batch 63/100] Loss: 0.0540 | RMSE: 0.0506 | Consistency: 0.0134 | SSIM: 0.0328 | Grad: 62088.516\n",
      "[Epoch 39, Batch 64/100] Loss: 0.0562 | RMSE: 0.0519 | Consistency: 0.0158 | SSIM: 0.0413 | Grad: 75514.508\n",
      "[Epoch 39, Batch 65/100] Loss: 0.0599 | RMSE: 0.0554 | Consistency: 0.0188 | SSIM: 0.0429 | Grad: 119699.953\n",
      "[Epoch 39, Batch 66/100] Loss: 0.0562 | RMSE: 0.0530 | Consistency: 0.0134 | SSIM: 0.0302 | Grad: 113822.617\n",
      "[Epoch 39, Batch 67/100] Loss: 0.0497 | RMSE: 0.0465 | Consistency: 0.0102 | SSIM: 0.0304 | Grad: 87657.719\n",
      "[Epoch 39, Batch 68/100] Loss: 0.0414 | RMSE: 0.0383 | Consistency: 0.0085 | SSIM: 0.0301 | Grad: 33365.383\n",
      "[Epoch 39, Batch 69/100] Loss: 0.0470 | RMSE: 0.0438 | Consistency: 0.0089 | SSIM: 0.0318 | Grad: 115504.547\n",
      "[Epoch 39, Batch 70/100] Loss: 0.0620 | RMSE: 0.0584 | Consistency: 0.0121 | SSIM: 0.0346 | Grad: 168459.734\n",
      "[Epoch 39, Batch 71/100] Loss: 0.0601 | RMSE: 0.0569 | Consistency: 0.0111 | SSIM: 0.0314 | Grad: 148089.438\n",
      "[Epoch 39, Batch 72/100] Loss: 0.0499 | RMSE: 0.0463 | Consistency: 0.0127 | SSIM: 0.0345 | Grad: 75547.047\n",
      "[Epoch 39, Batch 73/100] Loss: 0.0526 | RMSE: 0.0489 | Consistency: 0.0120 | SSIM: 0.0358 | Grad: 108261.328\n",
      "[Epoch 39, Batch 74/100] Loss: 0.0561 | RMSE: 0.0526 | Consistency: 0.0121 | SSIM: 0.0334 | Grad: 127045.305\n",
      "[Epoch 39, Batch 75/100] Loss: 0.0529 | RMSE: 0.0492 | Consistency: 0.0109 | SSIM: 0.0356 | Grad: 66559.086\n",
      "[Epoch 39, Batch 76/100] Loss: 0.0582 | RMSE: 0.0546 | Consistency: 0.0154 | SSIM: 0.0344 | Grad: 111519.562\n",
      "[Epoch 39, Batch 77/100] Loss: 0.0460 | RMSE: 0.0423 | Consistency: 0.0103 | SSIM: 0.0353 | Grad: 108574.836\n",
      "[Epoch 39, Batch 78/100] Loss: 0.0474 | RMSE: 0.0443 | Consistency: 0.0097 | SSIM: 0.0300 | Grad: 100689.664\n",
      "[Epoch 39, Batch 79/100] Loss: 0.0506 | RMSE: 0.0471 | Consistency: 0.0111 | SSIM: 0.0340 | Grad: 124508.367\n",
      "[Epoch 39, Batch 80/100] Loss: 0.0535 | RMSE: 0.0499 | Consistency: 0.0127 | SSIM: 0.0352 | Grad: 71095.594\n",
      "[Epoch 39, Batch 81/100] Loss: 0.0435 | RMSE: 0.0402 | Consistency: 0.0092 | SSIM: 0.0324 | Grad: 82740.844\n",
      "[Epoch 39, Batch 82/100] Loss: 0.0442 | RMSE: 0.0416 | Consistency: 0.0084 | SSIM: 0.0248 | Grad: 118322.805\n",
      "[Epoch 39, Batch 83/100] Loss: 0.0556 | RMSE: 0.0521 | Consistency: 0.0106 | SSIM: 0.0344 | Grad: 163844.828\n",
      "[Epoch 39, Batch 84/100] Loss: 0.0531 | RMSE: 0.0495 | Consistency: 0.0101 | SSIM: 0.0343 | Grad: 143813.969\n",
      "[Epoch 39, Batch 85/100] Loss: 0.0467 | RMSE: 0.0440 | Consistency: 0.0081 | SSIM: 0.0262 | Grad: 154638.828\n",
      "[Epoch 39, Batch 86/100] Loss: 0.0456 | RMSE: 0.0427 | Consistency: 0.0089 | SSIM: 0.0283 | Grad: 44125.930\n",
      "[Epoch 39, Batch 87/100] Loss: 0.0451 | RMSE: 0.0423 | Consistency: 0.0077 | SSIM: 0.0275 | Grad: 67912.109\n",
      "[Epoch 39, Batch 88/100] Loss: 0.0500 | RMSE: 0.0467 | Consistency: 0.0098 | SSIM: 0.0322 | Grad: 79585.859\n",
      "[Epoch 39, Batch 89/100] Loss: 0.0447 | RMSE: 0.0419 | Consistency: 0.0084 | SSIM: 0.0269 | Grad: 73628.547\n",
      "[Epoch 39, Batch 90/100] Loss: 0.0444 | RMSE: 0.0413 | Consistency: 0.0088 | SSIM: 0.0294 | Grad: 68549.867\n",
      "[Epoch 39, Batch 91/100] Loss: 0.0463 | RMSE: 0.0430 | Consistency: 0.0097 | SSIM: 0.0326 | Grad: 85999.617\n",
      "[Epoch 39, Batch 92/100] Loss: 0.0404 | RMSE: 0.0378 | Consistency: 0.0080 | SSIM: 0.0255 | Grad: 51375.020\n",
      "[Epoch 39, Batch 93/100] Loss: 0.0430 | RMSE: 0.0399 | Consistency: 0.0082 | SSIM: 0.0300 | Grad: 114845.281\n",
      "[Epoch 39, Batch 94/100] Loss: 0.0424 | RMSE: 0.0394 | Consistency: 0.0082 | SSIM: 0.0291 | Grad: 101375.719\n",
      "[Epoch 39, Batch 95/100] Loss: 0.0573 | RMSE: 0.0539 | Consistency: 0.0153 | SSIM: 0.0324 | Grad: 116443.008\n",
      "[Epoch 39, Batch 96/100] Loss: 0.0423 | RMSE: 0.0400 | Consistency: 0.0073 | SSIM: 0.0223 | Grad: 78066.844\n",
      "[Epoch 39, Batch 97/100] Loss: 0.0396 | RMSE: 0.0370 | Consistency: 0.0082 | SSIM: 0.0253 | Grad: 70293.211\n",
      "[Epoch 39, Batch 98/100] Loss: 0.0481 | RMSE: 0.0452 | Consistency: 0.0103 | SSIM: 0.0283 | Grad: 119962.625\n",
      "[Epoch 39, Batch 99/100] Loss: 0.0423 | RMSE: 0.0391 | Consistency: 0.0093 | SSIM: 0.0307 | Grad: 103379.906\n",
      "[Epoch 39, Batch 100/100] Loss: 0.0402 | RMSE: 0.0379 | Consistency: 0.0076 | SSIM: 0.0223 | Grad: 29276.416\n",
      "✅ Epoch 39 완료!\n",
      "   📈 평균 Loss: 0.048674\n",
      "   📊 평균 RMSE: 0.045439\n",
      "   ⚙️  학습률: 0.000608\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 40/80 시작...\n",
      "[Epoch 40, Batch 1/100] Loss: 0.0392 | RMSE: 0.0369 | Consistency: 0.0083 | SSIM: 0.0223 | Grad: 61621.965\n",
      "[Epoch 40, Batch 2/100] Loss: 0.0497 | RMSE: 0.0466 | Consistency: 0.0121 | SSIM: 0.0302 | Grad: 94945.984\n",
      "[Epoch 40, Batch 3/100] Loss: 0.0378 | RMSE: 0.0356 | Consistency: 0.0066 | SSIM: 0.0216 | Grad: 54161.629\n",
      "[Epoch 40, Batch 4/100] Loss: 0.0437 | RMSE: 0.0409 | Consistency: 0.0081 | SSIM: 0.0273 | Grad: 67107.211\n",
      "[Epoch 40, Batch 5/100] Loss: 0.0464 | RMSE: 0.0434 | Consistency: 0.0122 | SSIM: 0.0285 | Grad: 89912.562\n",
      "[Epoch 40, Batch 6/100] Loss: 0.0502 | RMSE: 0.0474 | Consistency: 0.0167 | SSIM: 0.0264 | Grad: 139157.172\n",
      "[Epoch 40, Batch 7/100] Loss: 0.0472 | RMSE: 0.0441 | Consistency: 0.0142 | SSIM: 0.0295 | Grad: 102340.250\n",
      "[Epoch 40, Batch 8/100] Loss: 0.0421 | RMSE: 0.0399 | Consistency: 0.0084 | SSIM: 0.0208 | Grad: 91489.195\n",
      "[Epoch 40, Batch 9/100] Loss: 0.0508 | RMSE: 0.0479 | Consistency: 0.0099 | SSIM: 0.0277 | Grad: 100850.383\n",
      "[Epoch 40, Batch 10/100] Loss: 0.0456 | RMSE: 0.0431 | Consistency: 0.0089 | SSIM: 0.0238 | Grad: 124596.484\n",
      "[Epoch 40, Batch 11/100] Loss: 0.0491 | RMSE: 0.0458 | Consistency: 0.0089 | SSIM: 0.0324 | Grad: 66410.250\n",
      "[Epoch 40, Batch 12/100] Loss: 0.0432 | RMSE: 0.0407 | Consistency: 0.0092 | SSIM: 0.0243 | Grad: 79333.672\n",
      "[Epoch 40, Batch 13/100] Loss: 0.0430 | RMSE: 0.0406 | Consistency: 0.0065 | SSIM: 0.0232 | Grad: 144560.672\n",
      "[Epoch 40, Batch 14/100] Loss: 0.0481 | RMSE: 0.0451 | Consistency: 0.0103 | SSIM: 0.0298 | Grad: 126958.281\n",
      "[Epoch 40, Batch 15/100] Loss: 0.0416 | RMSE: 0.0390 | Consistency: 0.0068 | SSIM: 0.0250 | Grad: 130511.531\n",
      "[Epoch 40, Batch 16/100] Loss: 0.0460 | RMSE: 0.0429 | Consistency: 0.0100 | SSIM: 0.0301 | Grad: 94478.734\n",
      "[Epoch 40, Batch 17/100] Loss: 0.0430 | RMSE: 0.0400 | Consistency: 0.0075 | SSIM: 0.0291 | Grad: 99061.484\n",
      "[Epoch 40, Batch 18/100] Loss: 0.0454 | RMSE: 0.0423 | Consistency: 0.0087 | SSIM: 0.0302 | Grad: 65485.328\n",
      "[Epoch 40, Batch 19/100] Loss: 0.0449 | RMSE: 0.0417 | Consistency: 0.0090 | SSIM: 0.0313 | Grad: 71929.039\n",
      "[Epoch 40, Batch 20/100] Loss: 0.0387 | RMSE: 0.0362 | Consistency: 0.0067 | SSIM: 0.0243 | Grad: 85753.289\n",
      "[Epoch 40, Batch 21/100] Loss: 0.0587 | RMSE: 0.0551 | Consistency: 0.0170 | SSIM: 0.0343 | Grad: 98321.289\n",
      "[Epoch 40, Batch 22/100] Loss: 0.0413 | RMSE: 0.0384 | Consistency: 0.0068 | SSIM: 0.0283 | Grad: 88646.938\n",
      "[Epoch 40, Batch 23/100] Loss: 0.0445 | RMSE: 0.0414 | Consistency: 0.0091 | SSIM: 0.0302 | Grad: 35798.918\n",
      "[Epoch 40, Batch 24/100] Loss: 0.0439 | RMSE: 0.0408 | Consistency: 0.0092 | SSIM: 0.0294 | Grad: 100497.312\n",
      "[Epoch 40, Batch 25/100] Loss: 0.0471 | RMSE: 0.0437 | Consistency: 0.0113 | SSIM: 0.0330 | Grad: 73579.766\n",
      "[Epoch 40, Batch 26/100] Loss: 0.0393 | RMSE: 0.0369 | Consistency: 0.0068 | SSIM: 0.0235 | Grad: 129144.273\n",
      "[Epoch 40, Batch 27/100] Loss: 0.0525 | RMSE: 0.0490 | Consistency: 0.0124 | SSIM: 0.0339 | Grad: 121006.086\n",
      "[Epoch 40, Batch 28/100] Loss: 0.0464 | RMSE: 0.0436 | Consistency: 0.0082 | SSIM: 0.0275 | Grad: 95731.922\n",
      "[Epoch 40, Batch 29/100] Loss: 0.0470 | RMSE: 0.0443 | Consistency: 0.0097 | SSIM: 0.0253 | Grad: 117935.203\n",
      "[Epoch 40, Batch 30/100] Loss: 0.0562 | RMSE: 0.0530 | Consistency: 0.0126 | SSIM: 0.0314 | Grad: 152973.344\n",
      "[Epoch 40, Batch 31/100] Loss: 0.0470 | RMSE: 0.0442 | Consistency: 0.0113 | SSIM: 0.0272 | Grad: 133723.406\n",
      "[Epoch 40, Batch 32/100] Loss: 0.0447 | RMSE: 0.0415 | Consistency: 0.0078 | SSIM: 0.0320 | Grad: 88261.820\n",
      "[Epoch 40, Batch 33/100] Loss: 0.0413 | RMSE: 0.0389 | Consistency: 0.0082 | SSIM: 0.0236 | Grad: 66935.133\n",
      "[Epoch 40, Batch 34/100] Loss: 0.0458 | RMSE: 0.0428 | Consistency: 0.0098 | SSIM: 0.0288 | Grad: 111360.508\n",
      "[Epoch 40, Batch 35/100] Loss: 0.0551 | RMSE: 0.0516 | Consistency: 0.0135 | SSIM: 0.0329 | Grad: 61965.871\n",
      "[Epoch 40, Batch 36/100] Loss: 0.0441 | RMSE: 0.0411 | Consistency: 0.0087 | SSIM: 0.0295 | Grad: 57201.203\n",
      "[Epoch 40, Batch 37/100] Loss: 0.0414 | RMSE: 0.0388 | Consistency: 0.0077 | SSIM: 0.0251 | Grad: 96403.641\n",
      "[Epoch 40, Batch 38/100] Loss: 0.0419 | RMSE: 0.0388 | Consistency: 0.0076 | SSIM: 0.0309 | Grad: 67052.391\n",
      "[Epoch 40, Batch 39/100] Loss: 0.0444 | RMSE: 0.0410 | Consistency: 0.0084 | SSIM: 0.0336 | Grad: 48970.301\n",
      "[Epoch 40, Batch 40/100] Loss: 0.0465 | RMSE: 0.0437 | Consistency: 0.0092 | SSIM: 0.0273 | Grad: 115165.445\n",
      "[Epoch 40, Batch 41/100] Loss: 0.0567 | RMSE: 0.0528 | Consistency: 0.0184 | SSIM: 0.0369 | Grad: 58679.492\n",
      "[Epoch 40, Batch 42/100] Loss: 0.0441 | RMSE: 0.0413 | Consistency: 0.0096 | SSIM: 0.0273 | Grad: 113946.789\n",
      "[Epoch 40, Batch 43/100] Loss: 0.0475 | RMSE: 0.0450 | Consistency: 0.0081 | SSIM: 0.0243 | Grad: 89077.641\n",
      "[Epoch 40, Batch 44/100] Loss: 0.0471 | RMSE: 0.0436 | Consistency: 0.0099 | SSIM: 0.0336 | Grad: 80403.383\n",
      "[Epoch 40, Batch 45/100] Loss: 0.0416 | RMSE: 0.0384 | Consistency: 0.0083 | SSIM: 0.0310 | Grad: 38068.266\n",
      "[Epoch 40, Batch 46/100] Loss: 0.0390 | RMSE: 0.0364 | Consistency: 0.0067 | SSIM: 0.0259 | Grad: 71875.703\n",
      "[Epoch 40, Batch 47/100] Loss: 0.0363 | RMSE: 0.0335 | Consistency: 0.0067 | SSIM: 0.0277 | Grad: 70594.078\n",
      "[Epoch 40, Batch 48/100] Loss: 0.0446 | RMSE: 0.0419 | Consistency: 0.0091 | SSIM: 0.0254 | Grad: 115689.023\n",
      "[Epoch 40, Batch 49/100] Loss: 0.0509 | RMSE: 0.0474 | Consistency: 0.0127 | SSIM: 0.0329 | Grad: 76573.859\n",
      "[Epoch 40, Batch 50/100] Loss: 0.0481 | RMSE: 0.0453 | Consistency: 0.0108 | SSIM: 0.0270 | Grad: 70660.586\n",
      "[Epoch 40, Batch 51/100] Loss: 0.0403 | RMSE: 0.0374 | Consistency: 0.0075 | SSIM: 0.0280 | Grad: 73442.531\n",
      "[Epoch 40, Batch 52/100] Loss: 0.0417 | RMSE: 0.0395 | Consistency: 0.0062 | SSIM: 0.0215 | Grad: 39972.496\n",
      "[Epoch 40, Batch 53/100] Loss: 0.0407 | RMSE: 0.0381 | Consistency: 0.0076 | SSIM: 0.0257 | Grad: 59455.617\n",
      "[Epoch 40, Batch 54/100] Loss: 0.0563 | RMSE: 0.0526 | Consistency: 0.0152 | SSIM: 0.0362 | Grad: 123021.688\n",
      "[Epoch 40, Batch 55/100] Loss: 0.0431 | RMSE: 0.0405 | Consistency: 0.0076 | SSIM: 0.0255 | Grad: 112900.125\n",
      "[Epoch 40, Batch 56/100] Loss: 0.0372 | RMSE: 0.0350 | Consistency: 0.0069 | SSIM: 0.0214 | Grad: 64879.723\n",
      "[Epoch 40, Batch 57/100] Loss: 0.0547 | RMSE: 0.0515 | Consistency: 0.0108 | SSIM: 0.0311 | Grad: 118080.609\n",
      "[Epoch 40, Batch 58/100] Loss: 0.0523 | RMSE: 0.0488 | Consistency: 0.0160 | SSIM: 0.0342 | Grad: 142923.672\n",
      "[Epoch 40, Batch 59/100] Loss: 0.0481 | RMSE: 0.0446 | Consistency: 0.0107 | SSIM: 0.0338 | Grad: 84484.477\n",
      "[Epoch 40, Batch 60/100] Loss: 0.0463 | RMSE: 0.0436 | Consistency: 0.0095 | SSIM: 0.0255 | Grad: 61469.355\n",
      "[Epoch 40, Batch 61/100] Loss: 0.0455 | RMSE: 0.0428 | Consistency: 0.0112 | SSIM: 0.0261 | Grad: 92369.234\n",
      "[Epoch 40, Batch 62/100] Loss: 0.0458 | RMSE: 0.0428 | Consistency: 0.0098 | SSIM: 0.0292 | Grad: 159840.531\n",
      "[Epoch 40, Batch 63/100] Loss: 0.0624 | RMSE: 0.0580 | Consistency: 0.0220 | SSIM: 0.0424 | Grad: 135352.188\n",
      "[Epoch 40, Batch 64/100] Loss: 0.0471 | RMSE: 0.0442 | Consistency: 0.0098 | SSIM: 0.0280 | Grad: 109483.602\n",
      "[Epoch 40, Batch 65/100] Loss: 0.0482 | RMSE: 0.0449 | Consistency: 0.0100 | SSIM: 0.0317 | Grad: 118171.953\n",
      "[Epoch 40, Batch 66/100] Loss: 0.0406 | RMSE: 0.0382 | Consistency: 0.0080 | SSIM: 0.0231 | Grad: 36856.246\n",
      "[Epoch 40, Batch 67/100] Loss: 0.0408 | RMSE: 0.0382 | Consistency: 0.0088 | SSIM: 0.0250 | Grad: 117971.742\n",
      "[Epoch 40, Batch 68/100] Loss: 0.0437 | RMSE: 0.0403 | Consistency: 0.0105 | SSIM: 0.0329 | Grad: 117949.172\n",
      "[Epoch 40, Batch 69/100] Loss: 0.0486 | RMSE: 0.0454 | Consistency: 0.0137 | SSIM: 0.0309 | Grad: 121969.297\n",
      "[Epoch 40, Batch 70/100] Loss: 0.0477 | RMSE: 0.0448 | Consistency: 0.0127 | SSIM: 0.0283 | Grad: 132305.609\n",
      "[Epoch 40, Batch 71/100] Loss: 0.0423 | RMSE: 0.0390 | Consistency: 0.0077 | SSIM: 0.0328 | Grad: 108416.562\n",
      "[Epoch 40, Batch 72/100] Loss: 0.0482 | RMSE: 0.0452 | Consistency: 0.0129 | SSIM: 0.0288 | Grad: 80605.219\n",
      "[Epoch 40, Batch 73/100] Loss: 0.0555 | RMSE: 0.0516 | Consistency: 0.0201 | SSIM: 0.0362 | Grad: 137899.797\n",
      "[Epoch 40, Batch 74/100] Loss: 0.0442 | RMSE: 0.0413 | Consistency: 0.0099 | SSIM: 0.0284 | Grad: 97389.953\n",
      "[Epoch 40, Batch 75/100] Loss: 0.0401 | RMSE: 0.0374 | Consistency: 0.0070 | SSIM: 0.0265 | Grad: 95467.148\n",
      "[Epoch 40, Batch 76/100] Loss: 0.0484 | RMSE: 0.0454 | Consistency: 0.0106 | SSIM: 0.0292 | Grad: 82626.977\n",
      "[Epoch 40, Batch 77/100] Loss: 0.0480 | RMSE: 0.0452 | Consistency: 0.0096 | SSIM: 0.0275 | Grad: 52505.031\n",
      "[Epoch 40, Batch 78/100] Loss: 0.0454 | RMSE: 0.0427 | Consistency: 0.0104 | SSIM: 0.0264 | Grad: 118448.109\n",
      "[Epoch 40, Batch 79/100] Loss: 0.0440 | RMSE: 0.0410 | Consistency: 0.0091 | SSIM: 0.0285 | Grad: 101700.891\n",
      "[Epoch 40, Batch 80/100] Loss: 0.0441 | RMSE: 0.0414 | Consistency: 0.0100 | SSIM: 0.0263 | Grad: 95452.805\n",
      "[Epoch 40, Batch 81/100] Loss: 0.0408 | RMSE: 0.0381 | Consistency: 0.0078 | SSIM: 0.0262 | Grad: 81484.461\n",
      "[Epoch 40, Batch 82/100] Loss: 0.0423 | RMSE: 0.0399 | Consistency: 0.0082 | SSIM: 0.0231 | Grad: 102306.586\n",
      "[Epoch 40, Batch 83/100] Loss: 0.0429 | RMSE: 0.0404 | Consistency: 0.0077 | SSIM: 0.0243 | Grad: 140144.641\n",
      "[Epoch 40, Batch 84/100] Loss: 0.0420 | RMSE: 0.0392 | Consistency: 0.0090 | SSIM: 0.0269 | Grad: 80851.188\n",
      "[Epoch 40, Batch 85/100] Loss: 0.0490 | RMSE: 0.0460 | Consistency: 0.0102 | SSIM: 0.0291 | Grad: 125122.383\n",
      "[Epoch 40, Batch 86/100] Loss: 0.0442 | RMSE: 0.0412 | Consistency: 0.0091 | SSIM: 0.0297 | Grad: 95869.414\n",
      "[Epoch 40, Batch 87/100] Loss: 0.0471 | RMSE: 0.0436 | Consistency: 0.0097 | SSIM: 0.0339 | Grad: 72558.523\n",
      "[Epoch 40, Batch 88/100] Loss: 0.0406 | RMSE: 0.0371 | Consistency: 0.0076 | SSIM: 0.0346 | Grad: 76250.562\n",
      "[Epoch 40, Batch 89/100] Loss: 0.0496 | RMSE: 0.0464 | Consistency: 0.0114 | SSIM: 0.0305 | Grad: 76526.359\n",
      "[Epoch 40, Batch 90/100] Loss: 0.0441 | RMSE: 0.0413 | Consistency: 0.0099 | SSIM: 0.0269 | Grad: 98622.109\n",
      "[Epoch 40, Batch 91/100] Loss: 0.0441 | RMSE: 0.0415 | Consistency: 0.0081 | SSIM: 0.0251 | Grad: 126169.664\n",
      "[Epoch 40, Batch 92/100] Loss: 0.0467 | RMSE: 0.0441 | Consistency: 0.0108 | SSIM: 0.0253 | Grad: 141858.797\n",
      "[Epoch 40, Batch 93/100] Loss: 0.0420 | RMSE: 0.0392 | Consistency: 0.0091 | SSIM: 0.0272 | Grad: 62483.320\n",
      "[Epoch 40, Batch 94/100] Loss: 0.0392 | RMSE: 0.0367 | Consistency: 0.0066 | SSIM: 0.0240 | Grad: 77604.055\n",
      "[Epoch 40, Batch 95/100] Loss: 0.0621 | RMSE: 0.0587 | Consistency: 0.0197 | SSIM: 0.0321 | Grad: 101638.719\n",
      "[Epoch 40, Batch 96/100] Loss: 0.0480 | RMSE: 0.0449 | Consistency: 0.0112 | SSIM: 0.0307 | Grad: 133407.047\n",
      "[Epoch 40, Batch 97/100] Loss: 0.0514 | RMSE: 0.0475 | Consistency: 0.0116 | SSIM: 0.0382 | Grad: 95475.375\n",
      "[Epoch 40, Batch 98/100] Loss: 0.0399 | RMSE: 0.0376 | Consistency: 0.0077 | SSIM: 0.0223 | Grad: 98414.328\n",
      "[Epoch 40, Batch 99/100] Loss: 0.0522 | RMSE: 0.0487 | Consistency: 0.0094 | SSIM: 0.0347 | Grad: 148612.375\n",
      "[Epoch 40, Batch 100/100] Loss: 0.0471 | RMSE: 0.0442 | Consistency: 0.0125 | SSIM: 0.0277 | Grad: 146816.859\n",
      "✅ Epoch 40 완료!\n",
      "   📈 평균 Loss: 0.045876\n",
      "   📊 평균 RMSE: 0.042915\n",
      "   ⚙️  학습률: 0.000587\n",
      "   🏆 NEW BEST! RMSE: 0.042915\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 41/80 시작...\n",
      "[Epoch 41, Batch 1/100] Loss: 0.0519 | RMSE: 0.0484 | Consistency: 0.0121 | SSIM: 0.0340 | Grad: 146762.641\n",
      "[Epoch 41, Batch 2/100] Loss: 0.0377 | RMSE: 0.0350 | Consistency: 0.0068 | SSIM: 0.0256 | Grad: 57482.910\n",
      "[Epoch 41, Batch 3/100] Loss: 0.0458 | RMSE: 0.0425 | Consistency: 0.0095 | SSIM: 0.0319 | Grad: 25098.047\n",
      "[Epoch 41, Batch 4/100] Loss: 0.0539 | RMSE: 0.0503 | Consistency: 0.0134 | SSIM: 0.0350 | Grad: 150972.969\n",
      "[Epoch 41, Batch 5/100] Loss: 0.0571 | RMSE: 0.0534 | Consistency: 0.0137 | SSIM: 0.0364 | Grad: 156815.391\n",
      "[Epoch 41, Batch 6/100] Loss: 0.0620 | RMSE: 0.0583 | Consistency: 0.0180 | SSIM: 0.0346 | Grad: 160013.375\n",
      "[Epoch 41, Batch 7/100] Loss: 0.0565 | RMSE: 0.0535 | Consistency: 0.0121 | SSIM: 0.0281 | Grad: 99655.266\n",
      "[Epoch 41, Batch 8/100] Loss: 0.0542 | RMSE: 0.0504 | Consistency: 0.0133 | SSIM: 0.0373 | Grad: 73329.836\n",
      "[Epoch 41, Batch 9/100] Loss: 0.0600 | RMSE: 0.0557 | Consistency: 0.0163 | SSIM: 0.0415 | Grad: 86364.422\n",
      "[Epoch 41, Batch 10/100] Loss: 0.0535 | RMSE: 0.0503 | Consistency: 0.0150 | SSIM: 0.0304 | Grad: 122779.344\n",
      "[Epoch 41, Batch 11/100] Loss: 0.0557 | RMSE: 0.0516 | Consistency: 0.0160 | SSIM: 0.0397 | Grad: 125883.398\n",
      "[Epoch 41, Batch 12/100] Loss: 0.0480 | RMSE: 0.0448 | Consistency: 0.0114 | SSIM: 0.0304 | Grad: 80905.297\n",
      "[Epoch 41, Batch 13/100] Loss: 0.0557 | RMSE: 0.0519 | Consistency: 0.0164 | SSIM: 0.0361 | Grad: 73303.227\n",
      "[Epoch 41, Batch 14/100] Loss: 0.0466 | RMSE: 0.0433 | Consistency: 0.0117 | SSIM: 0.0314 | Grad: 99956.484\n",
      "[Epoch 41, Batch 15/100] Loss: 0.0395 | RMSE: 0.0366 | Consistency: 0.0074 | SSIM: 0.0285 | Grad: 63227.184\n",
      "[Epoch 41, Batch 16/100] Loss: 0.0397 | RMSE: 0.0374 | Consistency: 0.0072 | SSIM: 0.0231 | Grad: 76615.578\n",
      "[Epoch 41, Batch 17/100] Loss: 0.0467 | RMSE: 0.0437 | Consistency: 0.0096 | SSIM: 0.0291 | Grad: 43509.297\n",
      "[Epoch 41, Batch 18/100] Loss: 0.0415 | RMSE: 0.0391 | Consistency: 0.0075 | SSIM: 0.0236 | Grad: 90962.805\n",
      "[Epoch 41, Batch 19/100] Loss: 0.0453 | RMSE: 0.0420 | Consistency: 0.0096 | SSIM: 0.0319 | Grad: 114077.992\n",
      "[Epoch 41, Batch 20/100] Loss: 0.0453 | RMSE: 0.0423 | Consistency: 0.0089 | SSIM: 0.0289 | Grad: 110186.297\n",
      "[Epoch 41, Batch 21/100] Loss: 0.0418 | RMSE: 0.0388 | Consistency: 0.0090 | SSIM: 0.0294 | Grad: 77189.859\n",
      "[Epoch 41, Batch 22/100] Loss: 0.0428 | RMSE: 0.0392 | Consistency: 0.0084 | SSIM: 0.0352 | Grad: 63799.547\n",
      "[Epoch 41, Batch 23/100] Loss: 0.0425 | RMSE: 0.0398 | Consistency: 0.0078 | SSIM: 0.0268 | Grad: 85847.141\n",
      "[Epoch 41, Batch 24/100] Loss: 0.0429 | RMSE: 0.0400 | Consistency: 0.0087 | SSIM: 0.0285 | Grad: 32164.611\n",
      "[Epoch 41, Batch 25/100] Loss: 0.0468 | RMSE: 0.0440 | Consistency: 0.0095 | SSIM: 0.0268 | Grad: 67706.648\n",
      "[Epoch 41, Batch 26/100] Loss: 0.0403 | RMSE: 0.0376 | Consistency: 0.0089 | SSIM: 0.0258 | Grad: 87928.016\n",
      "[Epoch 41, Batch 27/100] Loss: 0.0398 | RMSE: 0.0369 | Consistency: 0.0072 | SSIM: 0.0283 | Grad: 95054.844\n",
      "[Epoch 41, Batch 28/100] Loss: 0.0371 | RMSE: 0.0347 | Consistency: 0.0064 | SSIM: 0.0239 | Grad: 69518.656\n",
      "[Epoch 41, Batch 29/100] Loss: 0.0571 | RMSE: 0.0539 | Consistency: 0.0173 | SSIM: 0.0306 | Grad: 98800.406\n",
      "[Epoch 41, Batch 30/100] Loss: 0.0450 | RMSE: 0.0421 | Consistency: 0.0088 | SSIM: 0.0278 | Grad: 59433.574\n",
      "[Epoch 41, Batch 31/100] Loss: 0.0464 | RMSE: 0.0427 | Consistency: 0.0093 | SSIM: 0.0360 | Grad: 79298.492\n",
      "[Epoch 41, Batch 32/100] Loss: 0.0411 | RMSE: 0.0384 | Consistency: 0.0074 | SSIM: 0.0264 | Grad: 95123.031\n",
      "[Epoch 41, Batch 33/100] Loss: 0.0490 | RMSE: 0.0453 | Consistency: 0.0089 | SSIM: 0.0352 | Grad: 128310.078\n",
      "[Epoch 41, Batch 34/100] Loss: 0.0537 | RMSE: 0.0498 | Consistency: 0.0102 | SSIM: 0.0378 | Grad: 122358.352\n",
      "[Epoch 41, Batch 35/100] Loss: 0.0462 | RMSE: 0.0426 | Consistency: 0.0090 | SSIM: 0.0352 | Grad: 72607.148\n",
      "[Epoch 41, Batch 36/100] Loss: 0.0388 | RMSE: 0.0358 | Consistency: 0.0070 | SSIM: 0.0298 | Grad: 53196.633\n",
      "[Epoch 41, Batch 37/100] Loss: 0.0383 | RMSE: 0.0355 | Consistency: 0.0069 | SSIM: 0.0273 | Grad: 50661.926\n",
      "[Epoch 41, Batch 38/100] Loss: 0.0431 | RMSE: 0.0400 | Consistency: 0.0078 | SSIM: 0.0296 | Grad: 63193.914\n",
      "[Epoch 41, Batch 39/100] Loss: 0.0428 | RMSE: 0.0399 | Consistency: 0.0090 | SSIM: 0.0276 | Grad: 56997.281\n",
      "[Epoch 41, Batch 40/100] Loss: 0.0427 | RMSE: 0.0398 | Consistency: 0.0083 | SSIM: 0.0282 | Grad: 56960.164\n",
      "[Epoch 41, Batch 41/100] Loss: 0.0425 | RMSE: 0.0396 | Consistency: 0.0095 | SSIM: 0.0275 | Grad: 31832.016\n",
      "[Epoch 41, Batch 42/100] Loss: 0.0439 | RMSE: 0.0407 | Consistency: 0.0066 | SSIM: 0.0311 | Grad: 120474.984\n",
      "[Epoch 41, Batch 43/100] Loss: 0.0519 | RMSE: 0.0489 | Consistency: 0.0108 | SSIM: 0.0288 | Grad: 113522.883\n",
      "[Epoch 41, Batch 44/100] Loss: 0.0436 | RMSE: 0.0408 | Consistency: 0.0085 | SSIM: 0.0266 | Grad: 76813.945\n",
      "[Epoch 41, Batch 45/100] Loss: 0.0497 | RMSE: 0.0467 | Consistency: 0.0117 | SSIM: 0.0287 | Grad: 63142.008\n",
      "[Epoch 41, Batch 46/100] Loss: 0.0462 | RMSE: 0.0436 | Consistency: 0.0068 | SSIM: 0.0257 | Grad: 89618.594\n",
      "[Epoch 41, Batch 47/100] Loss: 0.0428 | RMSE: 0.0400 | Consistency: 0.0079 | SSIM: 0.0275 | Grad: 97464.359\n",
      "[Epoch 41, Batch 48/100] Loss: 0.0462 | RMSE: 0.0436 | Consistency: 0.0089 | SSIM: 0.0250 | Grad: 120781.945\n",
      "[Epoch 41, Batch 49/100] Loss: 0.0397 | RMSE: 0.0364 | Consistency: 0.0081 | SSIM: 0.0323 | Grad: 62080.129\n",
      "[Epoch 41, Batch 50/100] Loss: 0.0396 | RMSE: 0.0370 | Consistency: 0.0072 | SSIM: 0.0254 | Grad: 46213.508\n",
      "[Epoch 41, Batch 51/100] Loss: 0.0375 | RMSE: 0.0352 | Consistency: 0.0068 | SSIM: 0.0220 | Grad: 114526.539\n",
      "[Epoch 41, Batch 52/100] Loss: 0.0567 | RMSE: 0.0537 | Consistency: 0.0132 | SSIM: 0.0286 | Grad: 152495.531\n",
      "[Epoch 41, Batch 53/100] Loss: 0.0388 | RMSE: 0.0361 | Consistency: 0.0077 | SSIM: 0.0263 | Grad: 31317.043\n",
      "[Epoch 41, Batch 54/100] Loss: 0.0396 | RMSE: 0.0366 | Consistency: 0.0078 | SSIM: 0.0292 | Grad: 80937.625\n",
      "[Epoch 41, Batch 55/100] Loss: 0.0416 | RMSE: 0.0392 | Consistency: 0.0080 | SSIM: 0.0236 | Grad: 40260.379\n",
      "[Epoch 41, Batch 56/100] Loss: 0.0492 | RMSE: 0.0459 | Consistency: 0.0118 | SSIM: 0.0311 | Grad: 77877.086\n",
      "[Epoch 41, Batch 57/100] Loss: 0.0541 | RMSE: 0.0508 | Consistency: 0.0123 | SSIM: 0.0319 | Grad: 136922.922\n",
      "[Epoch 41, Batch 58/100] Loss: 0.0511 | RMSE: 0.0483 | Consistency: 0.0134 | SSIM: 0.0271 | Grad: 116968.984\n",
      "[Epoch 41, Batch 59/100] Loss: 0.0500 | RMSE: 0.0472 | Consistency: 0.0111 | SSIM: 0.0265 | Grad: 113969.828\n",
      "[Epoch 41, Batch 60/100] Loss: 0.0430 | RMSE: 0.0401 | Consistency: 0.0096 | SSIM: 0.0275 | Grad: 39430.984\n",
      "[Epoch 41, Batch 61/100] Loss: 0.0412 | RMSE: 0.0389 | Consistency: 0.0070 | SSIM: 0.0227 | Grad: 72017.109\n",
      "[Epoch 41, Batch 62/100] Loss: 0.0462 | RMSE: 0.0432 | Consistency: 0.0082 | SSIM: 0.0286 | Grad: 136071.000\n",
      "[Epoch 41, Batch 63/100] Loss: 0.0458 | RMSE: 0.0430 | Consistency: 0.0074 | SSIM: 0.0269 | Grad: 118774.703\n",
      "[Epoch 41, Batch 64/100] Loss: 0.0484 | RMSE: 0.0454 | Consistency: 0.0090 | SSIM: 0.0292 | Grad: 108208.672\n",
      "[Epoch 41, Batch 65/100] Loss: 0.0439 | RMSE: 0.0407 | Consistency: 0.0092 | SSIM: 0.0305 | Grad: 51365.828\n",
      "[Epoch 41, Batch 66/100] Loss: 0.0446 | RMSE: 0.0422 | Consistency: 0.0101 | SSIM: 0.0231 | Grad: 157248.703\n",
      "[Epoch 41, Batch 67/100] Loss: 0.0507 | RMSE: 0.0476 | Consistency: 0.0118 | SSIM: 0.0302 | Grad: 151111.891\n",
      "[Epoch 41, Batch 68/100] Loss: 0.0511 | RMSE: 0.0477 | Consistency: 0.0125 | SSIM: 0.0332 | Grad: 110844.414\n",
      "[Epoch 41, Batch 69/100] Loss: 0.0474 | RMSE: 0.0442 | Consistency: 0.0109 | SSIM: 0.0312 | Grad: 70995.859\n",
      "[Epoch 41, Batch 70/100] Loss: 0.0461 | RMSE: 0.0434 | Consistency: 0.0109 | SSIM: 0.0259 | Grad: 102726.258\n",
      "[Epoch 41, Batch 71/100] Loss: 0.0470 | RMSE: 0.0439 | Consistency: 0.0095 | SSIM: 0.0301 | Grad: 120996.289\n",
      "[Epoch 41, Batch 72/100] Loss: 0.0509 | RMSE: 0.0476 | Consistency: 0.0113 | SSIM: 0.0313 | Grad: 122710.961\n",
      "[Epoch 41, Batch 73/100] Loss: 0.0477 | RMSE: 0.0445 | Consistency: 0.0096 | SSIM: 0.0303 | Grad: 85948.438\n",
      "[Epoch 41, Batch 74/100] Loss: 0.0348 | RMSE: 0.0320 | Consistency: 0.0053 | SSIM: 0.0279 | Grad: 81181.352\n",
      "[Epoch 41, Batch 75/100] Loss: 0.0583 | RMSE: 0.0552 | Consistency: 0.0165 | SSIM: 0.0296 | Grad: 67152.000\n",
      "[Epoch 41, Batch 76/100] Loss: 0.0428 | RMSE: 0.0403 | Consistency: 0.0087 | SSIM: 0.0241 | Grad: 93558.547\n",
      "[Epoch 41, Batch 77/100] Loss: 0.0504 | RMSE: 0.0470 | Consistency: 0.0102 | SSIM: 0.0337 | Grad: 77441.680\n",
      "[Epoch 41, Batch 78/100] Loss: 0.0517 | RMSE: 0.0480 | Consistency: 0.0113 | SSIM: 0.0358 | Grad: 56407.023\n",
      "[Epoch 41, Batch 79/100] Loss: 0.0419 | RMSE: 0.0392 | Consistency: 0.0073 | SSIM: 0.0266 | Grad: 107277.859\n",
      "[Epoch 41, Batch 80/100] Loss: 0.0458 | RMSE: 0.0427 | Consistency: 0.0084 | SSIM: 0.0306 | Grad: 63367.250\n",
      "[Epoch 41, Batch 81/100] Loss: 0.0425 | RMSE: 0.0395 | Consistency: 0.0085 | SSIM: 0.0288 | Grad: 98300.242\n",
      "[Epoch 41, Batch 82/100] Loss: 0.0425 | RMSE: 0.0397 | Consistency: 0.0066 | SSIM: 0.0275 | Grad: 86003.883\n",
      "[Epoch 41, Batch 83/100] Loss: 0.0398 | RMSE: 0.0376 | Consistency: 0.0079 | SSIM: 0.0217 | Grad: 118792.844\n",
      "[Epoch 41, Batch 84/100] Loss: 0.0415 | RMSE: 0.0390 | Consistency: 0.0083 | SSIM: 0.0237 | Grad: 44087.938\n",
      "[Epoch 41, Batch 85/100] Loss: 0.0476 | RMSE: 0.0448 | Consistency: 0.0113 | SSIM: 0.0272 | Grad: 54432.199\n",
      "[Epoch 41, Batch 86/100] Loss: 0.0466 | RMSE: 0.0434 | Consistency: 0.0127 | SSIM: 0.0302 | Grad: 106117.906\n",
      "[Epoch 41, Batch 87/100] Loss: 0.0464 | RMSE: 0.0433 | Consistency: 0.0108 | SSIM: 0.0299 | Grad: 73578.047\n",
      "[Epoch 41, Batch 88/100] Loss: 0.0448 | RMSE: 0.0424 | Consistency: 0.0093 | SSIM: 0.0231 | Grad: 99450.039\n",
      "[Epoch 41, Batch 89/100] Loss: 0.0520 | RMSE: 0.0485 | Consistency: 0.0121 | SSIM: 0.0344 | Grad: 73090.188\n",
      "[Epoch 41, Batch 90/100] Loss: 0.0397 | RMSE: 0.0367 | Consistency: 0.0071 | SSIM: 0.0285 | Grad: 75510.461\n",
      "[Epoch 41, Batch 91/100] Loss: 0.0460 | RMSE: 0.0431 | Consistency: 0.0099 | SSIM: 0.0273 | Grad: 117831.141\n",
      "[Epoch 41, Batch 92/100] Loss: 0.0474 | RMSE: 0.0436 | Consistency: 0.0107 | SSIM: 0.0362 | Grad: 98001.852\n",
      "[Epoch 41, Batch 93/100] Loss: 0.0412 | RMSE: 0.0384 | Consistency: 0.0074 | SSIM: 0.0279 | Grad: 104824.281\n",
      "[Epoch 41, Batch 94/100] Loss: 0.0440 | RMSE: 0.0414 | Consistency: 0.0091 | SSIM: 0.0252 | Grad: 55209.262\n",
      "[Epoch 41, Batch 95/100] Loss: 0.0428 | RMSE: 0.0401 | Consistency: 0.0097 | SSIM: 0.0257 | Grad: 103222.297\n",
      "[Epoch 41, Batch 96/100] Loss: 0.0455 | RMSE: 0.0426 | Consistency: 0.0086 | SSIM: 0.0280 | Grad: 87990.547\n",
      "[Epoch 41, Batch 97/100] Loss: 0.0411 | RMSE: 0.0381 | Consistency: 0.0081 | SSIM: 0.0287 | Grad: 73205.227\n",
      "[Epoch 41, Batch 98/100] Loss: 0.0501 | RMSE: 0.0463 | Consistency: 0.0116 | SSIM: 0.0367 | Grad: 71219.375\n",
      "[Epoch 41, Batch 99/100] Loss: 0.0444 | RMSE: 0.0417 | Consistency: 0.0102 | SSIM: 0.0258 | Grad: 64525.062\n",
      "[Epoch 41, Batch 100/100] Loss: 0.0519 | RMSE: 0.0483 | Consistency: 0.0141 | SSIM: 0.0346 | Grad: 139314.766\n",
      "✅ Epoch 41 완료!\n",
      "   📈 평균 Loss: 0.046167\n",
      "   📊 평균 RMSE: 0.043129\n",
      "   ⚙️  학습률: 0.000565\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 42/80 시작...\n",
      "[Epoch 42, Batch 1/100] Loss: 0.0510 | RMSE: 0.0474 | Consistency: 0.0100 | SSIM: 0.0343 | Grad: 165145.188\n",
      "[Epoch 42, Batch 2/100] Loss: 0.0624 | RMSE: 0.0586 | Consistency: 0.0122 | SSIM: 0.0367 | Grad: 184418.766\n",
      "[Epoch 42, Batch 3/100] Loss: 0.0513 | RMSE: 0.0476 | Consistency: 0.0108 | SSIM: 0.0367 | Grad: 162097.500\n",
      "[Epoch 42, Batch 4/100] Loss: 0.0425 | RMSE: 0.0402 | Consistency: 0.0085 | SSIM: 0.0228 | Grad: 101882.938\n",
      "[Epoch 42, Batch 5/100] Loss: 0.0521 | RMSE: 0.0487 | Consistency: 0.0128 | SSIM: 0.0322 | Grad: 43929.203\n",
      "[Epoch 42, Batch 6/100] Loss: 0.0445 | RMSE: 0.0417 | Consistency: 0.0086 | SSIM: 0.0272 | Grad: 113768.922\n",
      "[Epoch 42, Batch 7/100] Loss: 0.0442 | RMSE: 0.0416 | Consistency: 0.0095 | SSIM: 0.0250 | Grad: 79246.375\n",
      "[Epoch 42, Batch 8/100] Loss: 0.0440 | RMSE: 0.0404 | Consistency: 0.0084 | SSIM: 0.0348 | Grad: 89183.008\n",
      "[Epoch 42, Batch 9/100] Loss: 0.0459 | RMSE: 0.0432 | Consistency: 0.0092 | SSIM: 0.0258 | Grad: 102048.852\n",
      "[Epoch 42, Batch 10/100] Loss: 0.0572 | RMSE: 0.0538 | Consistency: 0.0145 | SSIM: 0.0326 | Grad: 39821.871\n",
      "[Epoch 42, Batch 11/100] Loss: 0.0427 | RMSE: 0.0398 | Consistency: 0.0076 | SSIM: 0.0274 | Grad: 135198.359\n",
      "[Epoch 42, Batch 12/100] Loss: 0.0373 | RMSE: 0.0349 | Consistency: 0.0061 | SSIM: 0.0234 | Grad: 73640.188\n",
      "[Epoch 42, Batch 13/100] Loss: 0.0405 | RMSE: 0.0379 | Consistency: 0.0067 | SSIM: 0.0250 | Grad: 75303.789\n",
      "[Epoch 42, Batch 14/100] Loss: 0.0432 | RMSE: 0.0406 | Consistency: 0.0072 | SSIM: 0.0253 | Grad: 69316.336\n",
      "[Epoch 42, Batch 15/100] Loss: 0.0521 | RMSE: 0.0482 | Consistency: 0.0135 | SSIM: 0.0373 | Grad: 90071.070\n",
      "[Epoch 42, Batch 16/100] Loss: 0.0479 | RMSE: 0.0448 | Consistency: 0.0130 | SSIM: 0.0297 | Grad: 93125.805\n",
      "[Epoch 42, Batch 17/100] Loss: 0.0440 | RMSE: 0.0412 | Consistency: 0.0084 | SSIM: 0.0278 | Grad: 71218.898\n",
      "[Epoch 42, Batch 18/100] Loss: 0.0508 | RMSE: 0.0476 | Consistency: 0.0101 | SSIM: 0.0307 | Grad: 77528.742\n",
      "[Epoch 42, Batch 19/100] Loss: 0.0434 | RMSE: 0.0406 | Consistency: 0.0100 | SSIM: 0.0267 | Grad: 55575.449\n",
      "[Epoch 42, Batch 20/100] Loss: 0.0522 | RMSE: 0.0486 | Consistency: 0.0143 | SSIM: 0.0341 | Grad: 96938.086\n",
      "[Epoch 42, Batch 21/100] Loss: 0.0459 | RMSE: 0.0426 | Consistency: 0.0093 | SSIM: 0.0322 | Grad: 129715.070\n",
      "[Epoch 42, Batch 22/100] Loss: 0.0435 | RMSE: 0.0407 | Consistency: 0.0087 | SSIM: 0.0275 | Grad: 78286.039\n",
      "[Epoch 42, Batch 23/100] Loss: 0.0447 | RMSE: 0.0409 | Consistency: 0.0084 | SSIM: 0.0372 | Grad: 75957.477\n",
      "[Epoch 42, Batch 24/100] Loss: 0.0402 | RMSE: 0.0374 | Consistency: 0.0072 | SSIM: 0.0273 | Grad: 50242.391\n",
      "[Epoch 42, Batch 25/100] Loss: 0.0483 | RMSE: 0.0451 | Consistency: 0.0121 | SSIM: 0.0315 | Grad: 71601.664\n",
      "[Epoch 42, Batch 26/100] Loss: 0.0425 | RMSE: 0.0397 | Consistency: 0.0081 | SSIM: 0.0270 | Grad: 75351.078\n",
      "[Epoch 42, Batch 27/100] Loss: 0.0469 | RMSE: 0.0441 | Consistency: 0.0080 | SSIM: 0.0271 | Grad: 122935.391\n",
      "[Epoch 42, Batch 28/100] Loss: 0.0488 | RMSE: 0.0456 | Consistency: 0.0106 | SSIM: 0.0304 | Grad: 51537.121\n",
      "[Epoch 42, Batch 29/100] Loss: 0.0442 | RMSE: 0.0411 | Consistency: 0.0080 | SSIM: 0.0304 | Grad: 61526.641\n",
      "[Epoch 42, Batch 30/100] Loss: 0.0390 | RMSE: 0.0369 | Consistency: 0.0070 | SSIM: 0.0203 | Grad: 77831.680\n",
      "[Epoch 42, Batch 31/100] Loss: 0.0442 | RMSE: 0.0419 | Consistency: 0.0102 | SSIM: 0.0224 | Grad: 109062.547\n",
      "[Epoch 42, Batch 32/100] Loss: 0.0464 | RMSE: 0.0436 | Consistency: 0.0109 | SSIM: 0.0267 | Grad: 113259.664\n",
      "[Epoch 42, Batch 33/100] Loss: 0.0477 | RMSE: 0.0440 | Consistency: 0.0100 | SSIM: 0.0359 | Grad: 96582.211\n",
      "[Epoch 42, Batch 34/100] Loss: 0.0427 | RMSE: 0.0402 | Consistency: 0.0083 | SSIM: 0.0246 | Grad: 111402.883\n",
      "[Epoch 42, Batch 35/100] Loss: 0.0481 | RMSE: 0.0451 | Consistency: 0.0109 | SSIM: 0.0295 | Grad: 91833.852\n",
      "[Epoch 42, Batch 36/100] Loss: 0.0457 | RMSE: 0.0429 | Consistency: 0.0096 | SSIM: 0.0263 | Grad: 39120.699\n",
      "[Epoch 42, Batch 37/100] Loss: 0.0593 | RMSE: 0.0556 | Consistency: 0.0132 | SSIM: 0.0359 | Grad: 75312.641\n",
      "[Epoch 42, Batch 38/100] Loss: 0.0509 | RMSE: 0.0477 | Consistency: 0.0101 | SSIM: 0.0312 | Grad: 107312.102\n",
      "[Epoch 42, Batch 39/100] Loss: 0.0479 | RMSE: 0.0449 | Consistency: 0.0106 | SSIM: 0.0293 | Grad: 129682.156\n",
      "[Epoch 42, Batch 40/100] Loss: 0.0423 | RMSE: 0.0396 | Consistency: 0.0075 | SSIM: 0.0263 | Grad: 106070.000\n",
      "[Epoch 42, Batch 41/100] Loss: 0.0509 | RMSE: 0.0474 | Consistency: 0.0121 | SSIM: 0.0344 | Grad: 32363.072\n",
      "[Epoch 42, Batch 42/100] Loss: 0.0408 | RMSE: 0.0384 | Consistency: 0.0074 | SSIM: 0.0241 | Grad: 79362.555\n",
      "[Epoch 42, Batch 43/100] Loss: 0.0404 | RMSE: 0.0378 | Consistency: 0.0081 | SSIM: 0.0249 | Grad: 26580.584\n",
      "[Epoch 42, Batch 44/100] Loss: 0.0440 | RMSE: 0.0412 | Consistency: 0.0074 | SSIM: 0.0276 | Grad: 116665.844\n",
      "[Epoch 42, Batch 45/100] Loss: 0.0452 | RMSE: 0.0429 | Consistency: 0.0092 | SSIM: 0.0222 | Grad: 59107.379\n",
      "[Epoch 42, Batch 46/100] Loss: 0.0477 | RMSE: 0.0439 | Consistency: 0.0107 | SSIM: 0.0374 | Grad: 114808.523\n",
      "[Epoch 42, Batch 47/100] Loss: 0.0422 | RMSE: 0.0396 | Consistency: 0.0081 | SSIM: 0.0252 | Grad: 67269.031\n",
      "[Epoch 42, Batch 48/100] Loss: 0.0467 | RMSE: 0.0436 | Consistency: 0.0084 | SSIM: 0.0304 | Grad: 31321.404\n",
      "[Epoch 42, Batch 49/100] Loss: 0.0433 | RMSE: 0.0406 | Consistency: 0.0090 | SSIM: 0.0257 | Grad: 85200.008\n",
      "[Epoch 42, Batch 50/100] Loss: 0.0421 | RMSE: 0.0392 | Consistency: 0.0091 | SSIM: 0.0282 | Grad: 75864.484\n",
      "[Epoch 42, Batch 51/100] Loss: 0.0451 | RMSE: 0.0424 | Consistency: 0.0094 | SSIM: 0.0264 | Grad: 84388.906\n",
      "[Epoch 42, Batch 52/100] Loss: 0.0488 | RMSE: 0.0457 | Consistency: 0.0098 | SSIM: 0.0300 | Grad: 43505.855\n",
      "[Epoch 42, Batch 53/100] Loss: 0.0407 | RMSE: 0.0384 | Consistency: 0.0081 | SSIM: 0.0222 | Grad: 24180.172\n",
      "[Epoch 42, Batch 54/100] Loss: 0.0414 | RMSE: 0.0386 | Consistency: 0.0077 | SSIM: 0.0271 | Grad: 64526.488\n",
      "[Epoch 42, Batch 55/100] Loss: 0.0444 | RMSE: 0.0413 | Consistency: 0.0085 | SSIM: 0.0303 | Grad: 33364.609\n",
      "[Epoch 42, Batch 56/100] Loss: 0.0424 | RMSE: 0.0398 | Consistency: 0.0068 | SSIM: 0.0252 | Grad: 103322.969\n",
      "[Epoch 42, Batch 57/100] Loss: 0.0488 | RMSE: 0.0454 | Consistency: 0.0098 | SSIM: 0.0328 | Grad: 97915.961\n",
      "[Epoch 42, Batch 58/100] Loss: 0.0466 | RMSE: 0.0435 | Consistency: 0.0102 | SSIM: 0.0306 | Grad: 76212.961\n",
      "[Epoch 42, Batch 59/100] Loss: 0.0518 | RMSE: 0.0488 | Consistency: 0.0117 | SSIM: 0.0293 | Grad: 157051.891\n",
      "[Epoch 42, Batch 60/100] Loss: 0.0580 | RMSE: 0.0546 | Consistency: 0.0117 | SSIM: 0.0329 | Grad: 146748.688\n",
      "[Epoch 42, Batch 61/100] Loss: 0.0517 | RMSE: 0.0481 | Consistency: 0.0126 | SSIM: 0.0348 | Grad: 109257.695\n",
      "[Epoch 42, Batch 62/100] Loss: 0.0449 | RMSE: 0.0423 | Consistency: 0.0084 | SSIM: 0.0253 | Grad: 104667.742\n",
      "[Epoch 42, Batch 63/100] Loss: 0.0571 | RMSE: 0.0539 | Consistency: 0.0133 | SSIM: 0.0315 | Grad: 112692.273\n",
      "[Epoch 42, Batch 64/100] Loss: 0.0459 | RMSE: 0.0426 | Consistency: 0.0092 | SSIM: 0.0318 | Grad: 50641.457\n",
      "[Epoch 42, Batch 65/100] Loss: 0.0446 | RMSE: 0.0416 | Consistency: 0.0094 | SSIM: 0.0285 | Grad: 71676.562\n",
      "[Epoch 42, Batch 66/100] Loss: 0.0497 | RMSE: 0.0461 | Consistency: 0.0103 | SSIM: 0.0352 | Grad: 65388.914\n",
      "[Epoch 42, Batch 67/100] Loss: 0.0498 | RMSE: 0.0466 | Consistency: 0.0101 | SSIM: 0.0303 | Grad: 108828.125\n",
      "[Epoch 42, Batch 68/100] Loss: 0.0514 | RMSE: 0.0479 | Consistency: 0.0100 | SSIM: 0.0342 | Grad: 133819.891\n",
      "[Epoch 42, Batch 69/100] Loss: 0.0415 | RMSE: 0.0386 | Consistency: 0.0084 | SSIM: 0.0285 | Grad: 112104.945\n",
      "[Epoch 42, Batch 70/100] Loss: 0.0551 | RMSE: 0.0518 | Consistency: 0.0151 | SSIM: 0.0313 | Grad: 80245.562\n",
      "[Epoch 42, Batch 71/100] Loss: 0.0447 | RMSE: 0.0417 | Consistency: 0.0086 | SSIM: 0.0291 | Grad: 65652.875\n",
      "[Epoch 42, Batch 72/100] Loss: 0.0472 | RMSE: 0.0443 | Consistency: 0.0096 | SSIM: 0.0274 | Grad: 78630.602\n",
      "[Epoch 42, Batch 73/100] Loss: 0.0479 | RMSE: 0.0446 | Consistency: 0.0107 | SSIM: 0.0317 | Grad: 73830.727\n",
      "[Epoch 42, Batch 74/100] Loss: 0.0401 | RMSE: 0.0377 | Consistency: 0.0070 | SSIM: 0.0238 | Grad: 67584.352\n",
      "[Epoch 42, Batch 75/100] Loss: 0.0540 | RMSE: 0.0503 | Consistency: 0.0123 | SSIM: 0.0351 | Grad: 76175.750\n",
      "[Epoch 42, Batch 76/100] Loss: 0.0434 | RMSE: 0.0407 | Consistency: 0.0086 | SSIM: 0.0261 | Grad: 73177.656\n",
      "[Epoch 42, Batch 77/100] Loss: 0.0420 | RMSE: 0.0394 | Consistency: 0.0069 | SSIM: 0.0251 | Grad: 104229.273\n",
      "[Epoch 42, Batch 78/100] Loss: 0.0449 | RMSE: 0.0422 | Consistency: 0.0088 | SSIM: 0.0266 | Grad: 66843.734\n",
      "[Epoch 42, Batch 79/100] Loss: 0.0447 | RMSE: 0.0422 | Consistency: 0.0083 | SSIM: 0.0239 | Grad: 99942.312\n",
      "[Epoch 42, Batch 80/100] Loss: 0.0398 | RMSE: 0.0370 | Consistency: 0.0070 | SSIM: 0.0275 | Grad: 44705.812\n",
      "[Epoch 42, Batch 81/100] Loss: 0.0549 | RMSE: 0.0512 | Consistency: 0.0172 | SSIM: 0.0356 | Grad: 41726.562\n",
      "[Epoch 42, Batch 82/100] Loss: 0.0450 | RMSE: 0.0423 | Consistency: 0.0098 | SSIM: 0.0258 | Grad: 122153.391\n",
      "[Epoch 42, Batch 83/100] Loss: 0.0514 | RMSE: 0.0479 | Consistency: 0.0141 | SSIM: 0.0336 | Grad: 80798.844\n",
      "[Epoch 42, Batch 84/100] Loss: 0.0465 | RMSE: 0.0438 | Consistency: 0.0112 | SSIM: 0.0256 | Grad: 130099.797\n",
      "[Epoch 42, Batch 85/100] Loss: 0.0450 | RMSE: 0.0411 | Consistency: 0.0094 | SSIM: 0.0380 | Grad: 93984.492\n",
      "[Epoch 42, Batch 86/100] Loss: 0.0519 | RMSE: 0.0489 | Consistency: 0.0106 | SSIM: 0.0296 | Grad: 101459.398\n",
      "[Epoch 42, Batch 87/100] Loss: 0.0455 | RMSE: 0.0424 | Consistency: 0.0100 | SSIM: 0.0307 | Grad: 90051.633\n",
      "[Epoch 42, Batch 88/100] Loss: 0.0416 | RMSE: 0.0383 | Consistency: 0.0088 | SSIM: 0.0322 | Grad: 77739.578\n",
      "[Epoch 42, Batch 89/100] Loss: 0.0427 | RMSE: 0.0397 | Consistency: 0.0081 | SSIM: 0.0296 | Grad: 124298.492\n",
      "[Epoch 42, Batch 90/100] Loss: 0.0503 | RMSE: 0.0475 | Consistency: 0.0088 | SSIM: 0.0275 | Grad: 129243.133\n",
      "[Epoch 42, Batch 91/100] Loss: 0.0431 | RMSE: 0.0400 | Consistency: 0.0091 | SSIM: 0.0295 | Grad: 127367.609\n",
      "[Epoch 42, Batch 92/100] Loss: 0.0434 | RMSE: 0.0407 | Consistency: 0.0082 | SSIM: 0.0263 | Grad: 79423.109\n",
      "[Epoch 42, Batch 93/100] Loss: 0.0504 | RMSE: 0.0460 | Consistency: 0.0121 | SSIM: 0.0429 | Grad: 66223.375\n",
      "[Epoch 42, Batch 94/100] Loss: 0.0408 | RMSE: 0.0380 | Consistency: 0.0084 | SSIM: 0.0272 | Grad: 84929.328\n",
      "[Epoch 42, Batch 95/100] Loss: 0.0471 | RMSE: 0.0442 | Consistency: 0.0101 | SSIM: 0.0277 | Grad: 116892.648\n",
      "[Epoch 42, Batch 96/100] Loss: 0.0428 | RMSE: 0.0398 | Consistency: 0.0077 | SSIM: 0.0292 | Grad: 88882.227\n",
      "[Epoch 42, Batch 97/100] Loss: 0.0369 | RMSE: 0.0341 | Consistency: 0.0056 | SSIM: 0.0270 | Grad: 55285.324\n",
      "[Epoch 42, Batch 98/100] Loss: 0.0452 | RMSE: 0.0427 | Consistency: 0.0077 | SSIM: 0.0247 | Grad: 110257.039\n",
      "[Epoch 42, Batch 99/100] Loss: 0.0440 | RMSE: 0.0414 | Consistency: 0.0098 | SSIM: 0.0252 | Grad: 92544.602\n",
      "[Epoch 42, Batch 100/100] Loss: 0.0405 | RMSE: 0.0381 | Consistency: 0.0072 | SSIM: 0.0228 | Grad: 86599.320\n",
      "✅ Epoch 42 완료!\n",
      "   📈 평균 Loss: 0.046294\n",
      "   📊 평균 RMSE: 0.043277\n",
      "   ⚙️  학습률: 0.000543\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 43/80 시작...\n",
      "[Epoch 43, Batch 1/100] Loss: 0.0432 | RMSE: 0.0401 | Consistency: 0.0097 | SSIM: 0.0306 | Grad: 74725.578\n",
      "[Epoch 43, Batch 2/100] Loss: 0.0409 | RMSE: 0.0378 | Consistency: 0.0072 | SSIM: 0.0300 | Grad: 85425.219\n",
      "[Epoch 43, Batch 3/100] Loss: 0.0460 | RMSE: 0.0428 | Consistency: 0.0089 | SSIM: 0.0306 | Grad: 98331.234\n",
      "[Epoch 43, Batch 4/100] Loss: 0.0410 | RMSE: 0.0379 | Consistency: 0.0088 | SSIM: 0.0303 | Grad: 62592.055\n",
      "[Epoch 43, Batch 5/100] Loss: 0.0367 | RMSE: 0.0343 | Consistency: 0.0067 | SSIM: 0.0234 | Grad: 54914.742\n",
      "[Epoch 43, Batch 6/100] Loss: 0.0384 | RMSE: 0.0357 | Consistency: 0.0081 | SSIM: 0.0259 | Grad: 91767.195\n",
      "[Epoch 43, Batch 7/100] Loss: 0.0457 | RMSE: 0.0426 | Consistency: 0.0104 | SSIM: 0.0307 | Grad: 72517.961\n",
      "[Epoch 43, Batch 8/100] Loss: 0.0492 | RMSE: 0.0458 | Consistency: 0.0134 | SSIM: 0.0327 | Grad: 47330.508\n",
      "[Epoch 43, Batch 9/100] Loss: 0.0457 | RMSE: 0.0430 | Consistency: 0.0099 | SSIM: 0.0255 | Grad: 42549.348\n",
      "[Epoch 43, Batch 10/100] Loss: 0.0405 | RMSE: 0.0380 | Consistency: 0.0077 | SSIM: 0.0248 | Grad: 53541.062\n",
      "[Epoch 43, Batch 11/100] Loss: 0.0386 | RMSE: 0.0358 | Consistency: 0.0066 | SSIM: 0.0271 | Grad: 83353.289\n",
      "[Epoch 43, Batch 12/100] Loss: 0.0490 | RMSE: 0.0455 | Consistency: 0.0109 | SSIM: 0.0335 | Grad: 115663.859\n",
      "[Epoch 43, Batch 13/100] Loss: 0.0397 | RMSE: 0.0373 | Consistency: 0.0078 | SSIM: 0.0236 | Grad: 86056.352\n",
      "[Epoch 43, Batch 14/100] Loss: 0.0437 | RMSE: 0.0407 | Consistency: 0.0075 | SSIM: 0.0299 | Grad: 100095.398\n",
      "[Epoch 43, Batch 15/100] Loss: 0.0437 | RMSE: 0.0409 | Consistency: 0.0076 | SSIM: 0.0265 | Grad: 137384.406\n",
      "[Epoch 43, Batch 16/100] Loss: 0.0415 | RMSE: 0.0390 | Consistency: 0.0076 | SSIM: 0.0249 | Grad: 114140.977\n",
      "[Epoch 43, Batch 17/100] Loss: 0.0457 | RMSE: 0.0424 | Consistency: 0.0114 | SSIM: 0.0317 | Grad: 124475.852\n",
      "[Epoch 43, Batch 18/100] Loss: 0.0447 | RMSE: 0.0418 | Consistency: 0.0076 | SSIM: 0.0284 | Grad: 98655.078\n",
      "[Epoch 43, Batch 19/100] Loss: 0.0497 | RMSE: 0.0465 | Consistency: 0.0108 | SSIM: 0.0308 | Grad: 70993.188\n",
      "[Epoch 43, Batch 20/100] Loss: 0.0420 | RMSE: 0.0390 | Consistency: 0.0073 | SSIM: 0.0286 | Grad: 87594.430\n",
      "[Epoch 43, Batch 21/100] Loss: 0.0432 | RMSE: 0.0404 | Consistency: 0.0088 | SSIM: 0.0276 | Grad: 86890.609\n",
      "[Epoch 43, Batch 22/100] Loss: 0.0496 | RMSE: 0.0466 | Consistency: 0.0142 | SSIM: 0.0285 | Grad: 98579.242\n",
      "[Epoch 43, Batch 23/100] Loss: 0.0430 | RMSE: 0.0406 | Consistency: 0.0071 | SSIM: 0.0232 | Grad: 124165.469\n",
      "[Epoch 43, Batch 24/100] Loss: 0.0436 | RMSE: 0.0408 | Consistency: 0.0078 | SSIM: 0.0275 | Grad: 77108.672\n",
      "[Epoch 43, Batch 25/100] Loss: 0.0432 | RMSE: 0.0404 | Consistency: 0.0083 | SSIM: 0.0275 | Grad: 43989.941\n",
      "[Epoch 43, Batch 26/100] Loss: 0.0501 | RMSE: 0.0470 | Consistency: 0.0109 | SSIM: 0.0305 | Grad: 69428.914\n",
      "[Epoch 43, Batch 27/100] Loss: 0.0435 | RMSE: 0.0408 | Consistency: 0.0104 | SSIM: 0.0260 | Grad: 91257.297\n",
      "[Epoch 43, Batch 28/100] Loss: 0.0419 | RMSE: 0.0395 | Consistency: 0.0093 | SSIM: 0.0229 | Grad: 67668.000\n",
      "[Epoch 43, Batch 29/100] Loss: 0.0432 | RMSE: 0.0400 | Consistency: 0.0093 | SSIM: 0.0314 | Grad: 42685.547\n",
      "[Epoch 43, Batch 30/100] Loss: 0.0397 | RMSE: 0.0372 | Consistency: 0.0068 | SSIM: 0.0239 | Grad: 76151.031\n",
      "[Epoch 43, Batch 31/100] Loss: 0.0375 | RMSE: 0.0348 | Consistency: 0.0072 | SSIM: 0.0267 | Grad: 69456.398\n",
      "[Epoch 43, Batch 32/100] Loss: 0.0642 | RMSE: 0.0603 | Consistency: 0.0169 | SSIM: 0.0370 | Grad: 114272.859\n",
      "[Epoch 43, Batch 33/100] Loss: 0.0391 | RMSE: 0.0368 | Consistency: 0.0072 | SSIM: 0.0222 | Grad: 106847.289\n",
      "[Epoch 43, Batch 34/100] Loss: 0.0482 | RMSE: 0.0454 | Consistency: 0.0091 | SSIM: 0.0270 | Grad: 79470.086\n",
      "[Epoch 43, Batch 35/100] Loss: 0.0426 | RMSE: 0.0403 | Consistency: 0.0064 | SSIM: 0.0223 | Grad: 80745.930\n",
      "[Epoch 43, Batch 36/100] Loss: 0.0439 | RMSE: 0.0413 | Consistency: 0.0087 | SSIM: 0.0259 | Grad: 85204.875\n",
      "[Epoch 43, Batch 37/100] Loss: 0.0443 | RMSE: 0.0415 | Consistency: 0.0091 | SSIM: 0.0278 | Grad: 85676.891\n",
      "[Epoch 43, Batch 38/100] Loss: 0.0483 | RMSE: 0.0449 | Consistency: 0.0106 | SSIM: 0.0334 | Grad: 70511.344\n",
      "[Epoch 43, Batch 39/100] Loss: 0.0522 | RMSE: 0.0487 | Consistency: 0.0104 | SSIM: 0.0332 | Grad: 43889.578\n",
      "[Epoch 43, Batch 40/100] Loss: 0.0398 | RMSE: 0.0371 | Consistency: 0.0072 | SSIM: 0.0263 | Grad: 43503.867\n",
      "[Epoch 43, Batch 41/100] Loss: 0.0474 | RMSE: 0.0442 | Consistency: 0.0099 | SSIM: 0.0312 | Grad: 71282.117\n",
      "[Epoch 43, Batch 42/100] Loss: 0.0421 | RMSE: 0.0390 | Consistency: 0.0080 | SSIM: 0.0310 | Grad: 49167.211\n",
      "[Epoch 43, Batch 43/100] Loss: 0.0503 | RMSE: 0.0466 | Consistency: 0.0116 | SSIM: 0.0365 | Grad: 61628.535\n",
      "[Epoch 43, Batch 44/100] Loss: 0.0445 | RMSE: 0.0415 | Consistency: 0.0115 | SSIM: 0.0287 | Grad: 53961.438\n",
      "[Epoch 43, Batch 45/100] Loss: 0.0471 | RMSE: 0.0441 | Consistency: 0.0101 | SSIM: 0.0288 | Grad: 100357.109\n",
      "[Epoch 43, Batch 46/100] Loss: 0.0453 | RMSE: 0.0426 | Consistency: 0.0090 | SSIM: 0.0270 | Grad: 115050.625\n",
      "[Epoch 43, Batch 47/100] Loss: 0.0418 | RMSE: 0.0387 | Consistency: 0.0077 | SSIM: 0.0301 | Grad: 108442.328\n",
      "[Epoch 43, Batch 48/100] Loss: 0.0403 | RMSE: 0.0375 | Consistency: 0.0088 | SSIM: 0.0264 | Grad: 61921.793\n",
      "[Epoch 43, Batch 49/100] Loss: 0.0520 | RMSE: 0.0484 | Consistency: 0.0111 | SSIM: 0.0350 | Grad: 116977.547\n",
      "[Epoch 43, Batch 50/100] Loss: 0.0494 | RMSE: 0.0458 | Consistency: 0.0111 | SSIM: 0.0351 | Grad: 106106.242\n",
      "[Epoch 43, Batch 51/100] Loss: 0.0437 | RMSE: 0.0406 | Consistency: 0.0077 | SSIM: 0.0307 | Grad: 119056.273\n",
      "[Epoch 43, Batch 52/100] Loss: 0.0466 | RMSE: 0.0433 | Consistency: 0.0081 | SSIM: 0.0327 | Grad: 100669.141\n",
      "[Epoch 43, Batch 53/100] Loss: 0.0412 | RMSE: 0.0388 | Consistency: 0.0071 | SSIM: 0.0238 | Grad: 54170.328\n",
      "[Epoch 43, Batch 54/100] Loss: 0.0630 | RMSE: 0.0591 | Consistency: 0.0158 | SSIM: 0.0373 | Grad: 71308.664\n",
      "[Epoch 43, Batch 55/100] Loss: 0.0445 | RMSE: 0.0413 | Consistency: 0.0096 | SSIM: 0.0318 | Grad: 56655.734\n",
      "[Epoch 43, Batch 56/100] Loss: 0.0402 | RMSE: 0.0377 | Consistency: 0.0075 | SSIM: 0.0243 | Grad: 76883.164\n",
      "[Epoch 43, Batch 57/100] Loss: 0.0417 | RMSE: 0.0385 | Consistency: 0.0078 | SSIM: 0.0314 | Grad: 53712.023\n",
      "[Epoch 43, Batch 58/100] Loss: 0.0588 | RMSE: 0.0547 | Consistency: 0.0176 | SSIM: 0.0393 | Grad: 85531.758\n",
      "[Epoch 43, Batch 59/100] Loss: 0.0485 | RMSE: 0.0457 | Consistency: 0.0095 | SSIM: 0.0270 | Grad: 112540.977\n",
      "[Epoch 43, Batch 60/100] Loss: 0.0433 | RMSE: 0.0405 | Consistency: 0.0080 | SSIM: 0.0273 | Grad: 112357.383\n",
      "[Epoch 43, Batch 61/100] Loss: 0.0479 | RMSE: 0.0447 | Consistency: 0.0105 | SSIM: 0.0316 | Grad: 80277.727\n",
      "[Epoch 43, Batch 62/100] Loss: 0.0400 | RMSE: 0.0377 | Consistency: 0.0072 | SSIM: 0.0224 | Grad: 102973.711\n",
      "[Epoch 43, Batch 63/100] Loss: 0.0481 | RMSE: 0.0444 | Consistency: 0.0096 | SSIM: 0.0367 | Grad: 86785.016\n",
      "[Epoch 43, Batch 64/100] Loss: 0.0485 | RMSE: 0.0453 | Consistency: 0.0103 | SSIM: 0.0303 | Grad: 70408.461\n",
      "[Epoch 43, Batch 65/100] Loss: 0.0508 | RMSE: 0.0476 | Consistency: 0.0119 | SSIM: 0.0307 | Grad: 49578.020\n",
      "[Epoch 43, Batch 66/100] Loss: 0.0478 | RMSE: 0.0450 | Consistency: 0.0107 | SSIM: 0.0272 | Grad: 108727.398\n",
      "[Epoch 43, Batch 67/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0077 | SSIM: 0.0238 | Grad: 37639.254\n",
      "[Epoch 43, Batch 68/100] Loss: 0.0370 | RMSE: 0.0344 | Consistency: 0.0065 | SSIM: 0.0252 | Grad: 92638.555\n",
      "[Epoch 43, Batch 69/100] Loss: 0.0386 | RMSE: 0.0361 | Consistency: 0.0077 | SSIM: 0.0248 | Grad: 65370.906\n",
      "[Epoch 43, Batch 70/100] Loss: 0.0350 | RMSE: 0.0326 | Consistency: 0.0062 | SSIM: 0.0241 | Grad: 48689.008\n",
      "[Epoch 43, Batch 71/100] Loss: 0.0461 | RMSE: 0.0432 | Consistency: 0.0099 | SSIM: 0.0277 | Grad: 60107.809\n",
      "[Epoch 43, Batch 72/100] Loss: 0.0419 | RMSE: 0.0397 | Consistency: 0.0075 | SSIM: 0.0220 | Grad: 55324.418\n",
      "[Epoch 43, Batch 73/100] Loss: 0.0471 | RMSE: 0.0443 | Consistency: 0.0103 | SSIM: 0.0267 | Grad: 71056.648\n",
      "[Epoch 43, Batch 74/100] Loss: 0.0471 | RMSE: 0.0435 | Consistency: 0.0101 | SSIM: 0.0348 | Grad: 45267.719\n",
      "[Epoch 43, Batch 75/100] Loss: 0.0429 | RMSE: 0.0403 | Consistency: 0.0086 | SSIM: 0.0251 | Grad: 68055.195\n",
      "[Epoch 43, Batch 76/100] Loss: 0.0424 | RMSE: 0.0399 | Consistency: 0.0076 | SSIM: 0.0245 | Grad: 94133.344\n",
      "[Epoch 43, Batch 77/100] Loss: 0.0493 | RMSE: 0.0467 | Consistency: 0.0079 | SSIM: 0.0257 | Grad: 79504.648\n",
      "[Epoch 43, Batch 78/100] Loss: 0.0415 | RMSE: 0.0389 | Consistency: 0.0080 | SSIM: 0.0254 | Grad: 80851.477\n",
      "[Epoch 43, Batch 79/100] Loss: 0.0460 | RMSE: 0.0436 | Consistency: 0.0096 | SSIM: 0.0235 | Grad: 100052.375\n",
      "[Epoch 43, Batch 80/100] Loss: 0.0483 | RMSE: 0.0450 | Consistency: 0.0080 | SSIM: 0.0321 | Grad: 131884.438\n",
      "[Epoch 43, Batch 81/100] Loss: 0.0438 | RMSE: 0.0414 | Consistency: 0.0068 | SSIM: 0.0229 | Grad: 154577.828\n",
      "[Epoch 43, Batch 82/100] Loss: 0.0509 | RMSE: 0.0475 | Consistency: 0.0094 | SSIM: 0.0328 | Grad: 117810.602\n",
      "[Epoch 43, Batch 83/100] Loss: 0.0488 | RMSE: 0.0461 | Consistency: 0.0076 | SSIM: 0.0268 | Grad: 54907.809\n",
      "[Epoch 43, Batch 84/100] Loss: 0.0377 | RMSE: 0.0350 | Consistency: 0.0060 | SSIM: 0.0266 | Grad: 76607.578\n",
      "[Epoch 43, Batch 85/100] Loss: 0.0359 | RMSE: 0.0334 | Consistency: 0.0058 | SSIM: 0.0247 | Grad: 40862.512\n",
      "[Epoch 43, Batch 86/100] Loss: 0.0411 | RMSE: 0.0384 | Consistency: 0.0073 | SSIM: 0.0262 | Grad: 93048.602\n",
      "[Epoch 43, Batch 87/100] Loss: 0.0448 | RMSE: 0.0416 | Consistency: 0.0107 | SSIM: 0.0316 | Grad: 147437.422\n",
      "[Epoch 43, Batch 88/100] Loss: 0.0465 | RMSE: 0.0434 | Consistency: 0.0118 | SSIM: 0.0305 | Grad: 137482.672\n",
      "[Epoch 43, Batch 89/100] Loss: 0.0417 | RMSE: 0.0389 | Consistency: 0.0088 | SSIM: 0.0266 | Grad: 90152.117\n",
      "[Epoch 43, Batch 90/100] Loss: 0.0439 | RMSE: 0.0415 | Consistency: 0.0086 | SSIM: 0.0228 | Grad: 127266.109\n",
      "[Epoch 43, Batch 91/100] Loss: 0.0445 | RMSE: 0.0417 | Consistency: 0.0099 | SSIM: 0.0277 | Grad: 89122.320\n",
      "[Epoch 43, Batch 92/100] Loss: 0.0441 | RMSE: 0.0411 | Consistency: 0.0073 | SSIM: 0.0302 | Grad: 89965.594\n",
      "[Epoch 43, Batch 93/100] Loss: 0.0535 | RMSE: 0.0501 | Consistency: 0.0149 | SSIM: 0.0322 | Grad: 54382.270\n",
      "[Epoch 43, Batch 94/100] Loss: 0.0432 | RMSE: 0.0401 | Consistency: 0.0097 | SSIM: 0.0298 | Grad: 86784.617\n",
      "[Epoch 43, Batch 95/100] Loss: 0.0404 | RMSE: 0.0382 | Consistency: 0.0063 | SSIM: 0.0216 | Grad: 51779.199\n",
      "[Epoch 43, Batch 96/100] Loss: 0.0417 | RMSE: 0.0383 | Consistency: 0.0069 | SSIM: 0.0338 | Grad: 31192.250\n",
      "[Epoch 43, Batch 97/100] Loss: 0.0474 | RMSE: 0.0445 | Consistency: 0.0095 | SSIM: 0.0277 | Grad: 60651.965\n",
      "[Epoch 43, Batch 98/100] Loss: 0.0409 | RMSE: 0.0381 | Consistency: 0.0072 | SSIM: 0.0273 | Grad: 105779.578\n",
      "[Epoch 43, Batch 99/100] Loss: 0.0519 | RMSE: 0.0479 | Consistency: 0.0098 | SSIM: 0.0390 | Grad: 93037.414\n",
      "[Epoch 43, Batch 100/100] Loss: 0.0442 | RMSE: 0.0413 | Consistency: 0.0085 | SSIM: 0.0278 | Grad: 28414.455\n",
      "✅ Epoch 43 완료!\n",
      "   📈 평균 Loss: 0.044719\n",
      "   📊 평균 RMSE: 0.041780\n",
      "   ⚙️  학습률: 0.000522\n",
      "   🏆 NEW BEST! RMSE: 0.041780\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 44/80 시작...\n",
      "[Epoch 44, Batch 1/100] Loss: 0.0429 | RMSE: 0.0395 | Consistency: 0.0079 | SSIM: 0.0328 | Grad: 91164.555\n",
      "[Epoch 44, Batch 2/100] Loss: 0.0428 | RMSE: 0.0402 | Consistency: 0.0077 | SSIM: 0.0253 | Grad: 49018.461\n",
      "[Epoch 44, Batch 3/100] Loss: 0.0470 | RMSE: 0.0440 | Consistency: 0.0102 | SSIM: 0.0295 | Grad: 79177.023\n",
      "[Epoch 44, Batch 4/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0066 | SSIM: 0.0229 | Grad: 58700.023\n",
      "[Epoch 44, Batch 5/100] Loss: 0.0521 | RMSE: 0.0487 | Consistency: 0.0125 | SSIM: 0.0326 | Grad: 93850.539\n",
      "[Epoch 44, Batch 6/100] Loss: 0.0434 | RMSE: 0.0405 | Consistency: 0.0080 | SSIM: 0.0282 | Grad: 102072.594\n",
      "[Epoch 44, Batch 7/100] Loss: 0.0463 | RMSE: 0.0427 | Consistency: 0.0104 | SSIM: 0.0354 | Grad: 99645.578\n",
      "[Epoch 44, Batch 8/100] Loss: 0.0441 | RMSE: 0.0405 | Consistency: 0.0088 | SSIM: 0.0352 | Grad: 51438.445\n",
      "[Epoch 44, Batch 9/100] Loss: 0.0461 | RMSE: 0.0427 | Consistency: 0.0101 | SSIM: 0.0328 | Grad: 52392.359\n",
      "[Epoch 44, Batch 10/100] Loss: 0.0403 | RMSE: 0.0377 | Consistency: 0.0079 | SSIM: 0.0253 | Grad: 102395.406\n",
      "[Epoch 44, Batch 11/100] Loss: 0.0431 | RMSE: 0.0405 | Consistency: 0.0091 | SSIM: 0.0251 | Grad: 61073.617\n",
      "[Epoch 44, Batch 12/100] Loss: 0.0458 | RMSE: 0.0428 | Consistency: 0.0094 | SSIM: 0.0292 | Grad: 118033.438\n",
      "[Epoch 44, Batch 13/100] Loss: 0.0419 | RMSE: 0.0395 | Consistency: 0.0059 | SSIM: 0.0228 | Grad: 105127.703\n",
      "[Epoch 44, Batch 14/100] Loss: 0.0425 | RMSE: 0.0397 | Consistency: 0.0083 | SSIM: 0.0272 | Grad: 84633.250\n",
      "[Epoch 44, Batch 15/100] Loss: 0.0408 | RMSE: 0.0384 | Consistency: 0.0076 | SSIM: 0.0225 | Grad: 40535.984\n",
      "[Epoch 44, Batch 16/100] Loss: 0.0457 | RMSE: 0.0425 | Consistency: 0.0086 | SSIM: 0.0310 | Grad: 45818.457\n",
      "[Epoch 44, Batch 17/100] Loss: 0.0482 | RMSE: 0.0448 | Consistency: 0.0099 | SSIM: 0.0330 | Grad: 93060.852\n",
      "[Epoch 44, Batch 18/100] Loss: 0.0581 | RMSE: 0.0547 | Consistency: 0.0143 | SSIM: 0.0321 | Grad: 115394.219\n",
      "[Epoch 44, Batch 19/100] Loss: 0.0465 | RMSE: 0.0435 | Consistency: 0.0109 | SSIM: 0.0293 | Grad: 92627.133\n",
      "[Epoch 44, Batch 20/100] Loss: 0.0480 | RMSE: 0.0449 | Consistency: 0.0091 | SSIM: 0.0300 | Grad: 57711.301\n",
      "[Epoch 44, Batch 21/100] Loss: 0.0447 | RMSE: 0.0412 | Consistency: 0.0080 | SSIM: 0.0348 | Grad: 86676.922\n",
      "[Epoch 44, Batch 22/100] Loss: 0.0427 | RMSE: 0.0400 | Consistency: 0.0076 | SSIM: 0.0261 | Grad: 99033.500\n",
      "[Epoch 44, Batch 23/100] Loss: 0.0435 | RMSE: 0.0411 | Consistency: 0.0082 | SSIM: 0.0227 | Grad: 96043.055\n",
      "[Epoch 44, Batch 24/100] Loss: 0.0424 | RMSE: 0.0390 | Consistency: 0.0065 | SSIM: 0.0328 | Grad: 121503.125\n",
      "[Epoch 44, Batch 25/100] Loss: 0.0417 | RMSE: 0.0391 | Consistency: 0.0075 | SSIM: 0.0251 | Grad: 86206.930\n",
      "[Epoch 44, Batch 26/100] Loss: 0.0392 | RMSE: 0.0363 | Consistency: 0.0078 | SSIM: 0.0282 | Grad: 103407.828\n",
      "[Epoch 44, Batch 27/100] Loss: 0.0444 | RMSE: 0.0415 | Consistency: 0.0097 | SSIM: 0.0272 | Grad: 76507.938\n",
      "[Epoch 44, Batch 28/100] Loss: 0.0444 | RMSE: 0.0415 | Consistency: 0.0090 | SSIM: 0.0281 | Grad: 19320.207\n",
      "[Epoch 44, Batch 29/100] Loss: 0.0552 | RMSE: 0.0520 | Consistency: 0.0114 | SSIM: 0.0308 | Grad: 95590.750\n",
      "[Epoch 44, Batch 30/100] Loss: 0.0464 | RMSE: 0.0435 | Consistency: 0.0095 | SSIM: 0.0288 | Grad: 117529.906\n",
      "[Epoch 44, Batch 31/100] Loss: 0.0423 | RMSE: 0.0395 | Consistency: 0.0089 | SSIM: 0.0277 | Grad: 57806.977\n",
      "[Epoch 44, Batch 32/100] Loss: 0.0469 | RMSE: 0.0436 | Consistency: 0.0076 | SSIM: 0.0326 | Grad: 41640.160\n",
      "[Epoch 44, Batch 33/100] Loss: 0.0378 | RMSE: 0.0356 | Consistency: 0.0069 | SSIM: 0.0218 | Grad: 87187.156\n",
      "[Epoch 44, Batch 34/100] Loss: 0.0437 | RMSE: 0.0406 | Consistency: 0.0093 | SSIM: 0.0297 | Grad: 80773.641\n",
      "[Epoch 44, Batch 35/100] Loss: 0.0396 | RMSE: 0.0370 | Consistency: 0.0070 | SSIM: 0.0254 | Grad: 54443.035\n",
      "[Epoch 44, Batch 36/100] Loss: 0.0427 | RMSE: 0.0396 | Consistency: 0.0093 | SSIM: 0.0301 | Grad: 87510.609\n",
      "[Epoch 44, Batch 37/100] Loss: 0.0418 | RMSE: 0.0390 | Consistency: 0.0087 | SSIM: 0.0272 | Grad: 78223.047\n",
      "[Epoch 44, Batch 38/100] Loss: 0.0503 | RMSE: 0.0471 | Consistency: 0.0120 | SSIM: 0.0308 | Grad: 94273.125\n",
      "[Epoch 44, Batch 39/100] Loss: 0.0446 | RMSE: 0.0412 | Consistency: 0.0098 | SSIM: 0.0329 | Grad: 86052.867\n",
      "[Epoch 44, Batch 40/100] Loss: 0.0389 | RMSE: 0.0366 | Consistency: 0.0064 | SSIM: 0.0226 | Grad: 29165.789\n",
      "[Epoch 44, Batch 41/100] Loss: 0.0532 | RMSE: 0.0495 | Consistency: 0.0139 | SSIM: 0.0355 | Grad: 104073.773\n",
      "[Epoch 44, Batch 42/100] Loss: 0.0485 | RMSE: 0.0448 | Consistency: 0.0114 | SSIM: 0.0360 | Grad: 82032.875\n",
      "[Epoch 44, Batch 43/100] Loss: 0.0407 | RMSE: 0.0383 | Consistency: 0.0065 | SSIM: 0.0225 | Grad: 107590.703\n",
      "[Epoch 44, Batch 44/100] Loss: 0.0392 | RMSE: 0.0366 | Consistency: 0.0085 | SSIM: 0.0246 | Grad: 35911.484\n",
      "[Epoch 44, Batch 45/100] Loss: 0.0507 | RMSE: 0.0473 | Consistency: 0.0115 | SSIM: 0.0321 | Grad: 113495.234\n",
      "[Epoch 44, Batch 46/100] Loss: 0.0480 | RMSE: 0.0445 | Consistency: 0.0106 | SSIM: 0.0344 | Grad: 75938.117\n",
      "[Epoch 44, Batch 47/100] Loss: 0.0413 | RMSE: 0.0388 | Consistency: 0.0091 | SSIM: 0.0248 | Grad: 106606.828\n",
      "[Epoch 44, Batch 48/100] Loss: 0.0502 | RMSE: 0.0470 | Consistency: 0.0126 | SSIM: 0.0303 | Grad: 78536.641\n",
      "[Epoch 44, Batch 49/100] Loss: 0.0446 | RMSE: 0.0421 | Consistency: 0.0101 | SSIM: 0.0248 | Grad: 84440.164\n",
      "[Epoch 44, Batch 50/100] Loss: 0.0375 | RMSE: 0.0349 | Consistency: 0.0069 | SSIM: 0.0254 | Grad: 91093.984\n",
      "[Epoch 44, Batch 51/100] Loss: 0.0461 | RMSE: 0.0433 | Consistency: 0.0092 | SSIM: 0.0272 | Grad: 116569.773\n",
      "[Epoch 44, Batch 52/100] Loss: 0.0447 | RMSE: 0.0414 | Consistency: 0.0104 | SSIM: 0.0317 | Grad: 95061.664\n",
      "[Epoch 44, Batch 53/100] Loss: 0.0406 | RMSE: 0.0378 | Consistency: 0.0078 | SSIM: 0.0276 | Grad: 85711.664\n",
      "[Epoch 44, Batch 54/100] Loss: 0.0531 | RMSE: 0.0496 | Consistency: 0.0095 | SSIM: 0.0336 | Grad: 34153.371\n",
      "[Epoch 44, Batch 55/100] Loss: 0.0431 | RMSE: 0.0402 | Consistency: 0.0082 | SSIM: 0.0283 | Grad: 59126.195\n",
      "[Epoch 44, Batch 56/100] Loss: 0.0513 | RMSE: 0.0483 | Consistency: 0.0098 | SSIM: 0.0299 | Grad: 82757.695\n",
      "[Epoch 44, Batch 57/100] Loss: 0.0421 | RMSE: 0.0393 | Consistency: 0.0077 | SSIM: 0.0275 | Grad: 113661.344\n",
      "[Epoch 44, Batch 58/100] Loss: 0.0442 | RMSE: 0.0414 | Consistency: 0.0086 | SSIM: 0.0273 | Grad: 110605.914\n",
      "[Epoch 44, Batch 59/100] Loss: 0.0426 | RMSE: 0.0405 | Consistency: 0.0077 | SSIM: 0.0200 | Grad: 153031.281\n",
      "[Epoch 44, Batch 60/100] Loss: 0.0491 | RMSE: 0.0464 | Consistency: 0.0097 | SSIM: 0.0259 | Grad: 48556.309\n",
      "[Epoch 44, Batch 61/100] Loss: 0.0517 | RMSE: 0.0484 | Consistency: 0.0141 | SSIM: 0.0320 | Grad: 104953.469\n",
      "[Epoch 44, Batch 62/100] Loss: 0.0465 | RMSE: 0.0431 | Consistency: 0.0096 | SSIM: 0.0330 | Grad: 111144.062\n",
      "[Epoch 44, Batch 63/100] Loss: 0.0543 | RMSE: 0.0508 | Consistency: 0.0131 | SSIM: 0.0336 | Grad: 188888.250\n",
      "[Epoch 44, Batch 64/100] Loss: 0.0528 | RMSE: 0.0492 | Consistency: 0.0127 | SSIM: 0.0350 | Grad: 135761.328\n",
      "[Epoch 44, Batch 65/100] Loss: 0.0448 | RMSE: 0.0420 | Consistency: 0.0089 | SSIM: 0.0277 | Grad: 137600.812\n",
      "[Epoch 44, Batch 66/100] Loss: 0.0407 | RMSE: 0.0376 | Consistency: 0.0085 | SSIM: 0.0306 | Grad: 91848.984\n",
      "[Epoch 44, Batch 67/100] Loss: 0.0432 | RMSE: 0.0407 | Consistency: 0.0063 | SSIM: 0.0251 | Grad: 55345.055\n",
      "[Epoch 44, Batch 68/100] Loss: 0.0422 | RMSE: 0.0395 | Consistency: 0.0076 | SSIM: 0.0258 | Grad: 109880.383\n",
      "[Epoch 44, Batch 69/100] Loss: 0.0504 | RMSE: 0.0467 | Consistency: 0.0099 | SSIM: 0.0353 | Grad: 109745.242\n",
      "[Epoch 44, Batch 70/100] Loss: 0.0493 | RMSE: 0.0463 | Consistency: 0.0112 | SSIM: 0.0290 | Grad: 121090.250\n",
      "[Epoch 44, Batch 71/100] Loss: 0.0385 | RMSE: 0.0356 | Consistency: 0.0075 | SSIM: 0.0282 | Grad: 74611.242\n",
      "[Epoch 44, Batch 72/100] Loss: 0.0432 | RMSE: 0.0406 | Consistency: 0.0079 | SSIM: 0.0256 | Grad: 72389.820\n",
      "[Epoch 44, Batch 73/100] Loss: 0.0428 | RMSE: 0.0403 | Consistency: 0.0073 | SSIM: 0.0250 | Grad: 91031.547\n",
      "[Epoch 44, Batch 74/100] Loss: 0.0473 | RMSE: 0.0442 | Consistency: 0.0096 | SSIM: 0.0297 | Grad: 93025.344\n",
      "[Epoch 44, Batch 75/100] Loss: 0.0427 | RMSE: 0.0404 | Consistency: 0.0091 | SSIM: 0.0229 | Grad: 116670.750\n",
      "[Epoch 44, Batch 76/100] Loss: 0.0395 | RMSE: 0.0368 | Consistency: 0.0079 | SSIM: 0.0261 | Grad: 86724.484\n",
      "[Epoch 44, Batch 77/100] Loss: 0.0389 | RMSE: 0.0365 | Consistency: 0.0064 | SSIM: 0.0236 | Grad: 103008.117\n",
      "[Epoch 44, Batch 78/100] Loss: 0.0511 | RMSE: 0.0482 | Consistency: 0.0104 | SSIM: 0.0286 | Grad: 95816.109\n",
      "[Epoch 44, Batch 79/100] Loss: 0.0424 | RMSE: 0.0401 | Consistency: 0.0094 | SSIM: 0.0224 | Grad: 69493.422\n",
      "[Epoch 44, Batch 80/100] Loss: 0.0406 | RMSE: 0.0377 | Consistency: 0.0074 | SSIM: 0.0287 | Grad: 94141.648\n",
      "[Epoch 44, Batch 81/100] Loss: 0.0613 | RMSE: 0.0577 | Consistency: 0.0214 | SSIM: 0.0332 | Grad: 85067.492\n",
      "[Epoch 44, Batch 82/100] Loss: 0.0469 | RMSE: 0.0438 | Consistency: 0.0097 | SSIM: 0.0293 | Grad: 102514.133\n",
      "[Epoch 44, Batch 83/100] Loss: 0.0446 | RMSE: 0.0416 | Consistency: 0.0083 | SSIM: 0.0287 | Grad: 146533.750\n",
      "[Epoch 44, Batch 84/100] Loss: 0.0506 | RMSE: 0.0472 | Consistency: 0.0106 | SSIM: 0.0335 | Grad: 127561.812\n",
      "[Epoch 44, Batch 85/100] Loss: 0.0480 | RMSE: 0.0455 | Consistency: 0.0108 | SSIM: 0.0238 | Grad: 157856.859\n",
      "[Epoch 44, Batch 86/100] Loss: 0.0427 | RMSE: 0.0402 | Consistency: 0.0093 | SSIM: 0.0241 | Grad: 59582.328\n",
      "[Epoch 44, Batch 87/100] Loss: 0.0456 | RMSE: 0.0426 | Consistency: 0.0077 | SSIM: 0.0300 | Grad: 109708.711\n",
      "[Epoch 44, Batch 88/100] Loss: 0.0455 | RMSE: 0.0428 | Consistency: 0.0082 | SSIM: 0.0263 | Grad: 140123.359\n",
      "[Epoch 44, Batch 89/100] Loss: 0.0437 | RMSE: 0.0407 | Consistency: 0.0085 | SSIM: 0.0294 | Grad: 123467.258\n",
      "[Epoch 44, Batch 90/100] Loss: 0.0384 | RMSE: 0.0356 | Consistency: 0.0072 | SSIM: 0.0277 | Grad: 68613.633\n",
      "[Epoch 44, Batch 91/100] Loss: 0.0399 | RMSE: 0.0376 | Consistency: 0.0061 | SSIM: 0.0227 | Grad: 61573.785\n",
      "[Epoch 44, Batch 92/100] Loss: 0.0381 | RMSE: 0.0359 | Consistency: 0.0058 | SSIM: 0.0219 | Grad: 91892.656\n",
      "[Epoch 44, Batch 93/100] Loss: 0.0451 | RMSE: 0.0423 | Consistency: 0.0086 | SSIM: 0.0265 | Grad: 41408.465\n",
      "[Epoch 44, Batch 94/100] Loss: 0.0364 | RMSE: 0.0337 | Consistency: 0.0058 | SSIM: 0.0259 | Grad: 95527.984\n",
      "[Epoch 44, Batch 95/100] Loss: 0.0424 | RMSE: 0.0397 | Consistency: 0.0091 | SSIM: 0.0262 | Grad: 52134.211\n",
      "[Epoch 44, Batch 96/100] Loss: 0.0397 | RMSE: 0.0371 | Consistency: 0.0059 | SSIM: 0.0250 | Grad: 70147.719\n",
      "[Epoch 44, Batch 97/100] Loss: 0.0438 | RMSE: 0.0405 | Consistency: 0.0088 | SSIM: 0.0315 | Grad: 83993.609\n",
      "[Epoch 44, Batch 98/100] Loss: 0.0406 | RMSE: 0.0377 | Consistency: 0.0076 | SSIM: 0.0283 | Grad: 37643.582\n",
      "[Epoch 44, Batch 99/100] Loss: 0.0453 | RMSE: 0.0424 | Consistency: 0.0104 | SSIM: 0.0281 | Grad: 107635.117\n",
      "[Epoch 44, Batch 100/100] Loss: 0.0434 | RMSE: 0.0406 | Consistency: 0.0095 | SSIM: 0.0279 | Grad: 126633.930\n",
      "✅ Epoch 44 완료!\n",
      "   📈 평균 Loss: 0.044726\n",
      "   📊 평균 RMSE: 0.041800\n",
      "   ⚙️  학습률: 0.000500\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 45/80 시작...\n",
      "[Epoch 45, Batch 1/100] Loss: 0.0505 | RMSE: 0.0471 | Consistency: 0.0131 | SSIM: 0.0325 | Grad: 74402.477\n",
      "[Epoch 45, Batch 2/100] Loss: 0.0433 | RMSE: 0.0407 | Consistency: 0.0086 | SSIM: 0.0251 | Grad: 68917.172\n",
      "[Epoch 45, Batch 3/100] Loss: 0.0402 | RMSE: 0.0377 | Consistency: 0.0068 | SSIM: 0.0236 | Grad: 75367.844\n",
      "[Epoch 45, Batch 4/100] Loss: 0.0443 | RMSE: 0.0413 | Consistency: 0.0091 | SSIM: 0.0289 | Grad: 111117.906\n",
      "[Epoch 45, Batch 5/100] Loss: 0.0510 | RMSE: 0.0480 | Consistency: 0.0095 | SSIM: 0.0294 | Grad: 163187.250\n",
      "[Epoch 45, Batch 6/100] Loss: 0.0422 | RMSE: 0.0397 | Consistency: 0.0063 | SSIM: 0.0237 | Grad: 107333.930\n",
      "[Epoch 45, Batch 7/100] Loss: 0.0401 | RMSE: 0.0374 | Consistency: 0.0068 | SSIM: 0.0264 | Grad: 75040.641\n",
      "[Epoch 45, Batch 8/100] Loss: 0.0468 | RMSE: 0.0442 | Consistency: 0.0082 | SSIM: 0.0253 | Grad: 130414.094\n",
      "[Epoch 45, Batch 9/100] Loss: 0.0499 | RMSE: 0.0472 | Consistency: 0.0118 | SSIM: 0.0260 | Grad: 82796.148\n",
      "[Epoch 45, Batch 10/100] Loss: 0.0385 | RMSE: 0.0358 | Consistency: 0.0066 | SSIM: 0.0262 | Grad: 76356.352\n",
      "[Epoch 45, Batch 11/100] Loss: 0.0381 | RMSE: 0.0357 | Consistency: 0.0076 | SSIM: 0.0228 | Grad: 82876.562\n",
      "[Epoch 45, Batch 12/100] Loss: 0.0455 | RMSE: 0.0430 | Consistency: 0.0107 | SSIM: 0.0247 | Grad: 115879.062\n",
      "[Epoch 45, Batch 13/100] Loss: 0.0544 | RMSE: 0.0510 | Consistency: 0.0112 | SSIM: 0.0329 | Grad: 89899.406\n",
      "[Epoch 45, Batch 14/100] Loss: 0.0541 | RMSE: 0.0503 | Consistency: 0.0145 | SSIM: 0.0363 | Grad: 91473.641\n",
      "[Epoch 45, Batch 15/100] Loss: 0.0414 | RMSE: 0.0389 | Consistency: 0.0071 | SSIM: 0.0239 | Grad: 69335.438\n",
      "[Epoch 45, Batch 16/100] Loss: 0.0458 | RMSE: 0.0427 | Consistency: 0.0122 | SSIM: 0.0300 | Grad: 84732.961\n",
      "[Epoch 45, Batch 17/100] Loss: 0.0406 | RMSE: 0.0381 | Consistency: 0.0071 | SSIM: 0.0245 | Grad: 86993.602\n",
      "[Epoch 45, Batch 18/100] Loss: 0.0361 | RMSE: 0.0342 | Consistency: 0.0048 | SSIM: 0.0187 | Grad: 112623.539\n",
      "[Epoch 45, Batch 19/100] Loss: 0.0433 | RMSE: 0.0402 | Consistency: 0.0074 | SSIM: 0.0304 | Grad: 103579.414\n",
      "[Epoch 45, Batch 20/100] Loss: 0.0435 | RMSE: 0.0403 | Consistency: 0.0094 | SSIM: 0.0311 | Grad: 60782.113\n",
      "[Epoch 45, Batch 21/100] Loss: 0.0480 | RMSE: 0.0449 | Consistency: 0.0104 | SSIM: 0.0298 | Grad: 88966.117\n",
      "[Epoch 45, Batch 22/100] Loss: 0.0402 | RMSE: 0.0375 | Consistency: 0.0074 | SSIM: 0.0262 | Grad: 97226.688\n",
      "[Epoch 45, Batch 23/100] Loss: 0.0429 | RMSE: 0.0406 | Consistency: 0.0072 | SSIM: 0.0223 | Grad: 116425.914\n",
      "[Epoch 45, Batch 24/100] Loss: 0.0423 | RMSE: 0.0401 | Consistency: 0.0081 | SSIM: 0.0216 | Grad: 73038.820\n",
      "[Epoch 45, Batch 25/100] Loss: 0.0476 | RMSE: 0.0445 | Consistency: 0.0105 | SSIM: 0.0294 | Grad: 66492.625\n",
      "[Epoch 45, Batch 26/100] Loss: 0.0477 | RMSE: 0.0450 | Consistency: 0.0093 | SSIM: 0.0261 | Grad: 124812.641\n",
      "[Epoch 45, Batch 27/100] Loss: 0.0439 | RMSE: 0.0411 | Consistency: 0.0093 | SSIM: 0.0269 | Grad: 57334.352\n",
      "[Epoch 45, Batch 28/100] Loss: 0.0471 | RMSE: 0.0439 | Consistency: 0.0111 | SSIM: 0.0306 | Grad: 113235.797\n",
      "[Epoch 45, Batch 29/100] Loss: 0.0412 | RMSE: 0.0386 | Consistency: 0.0068 | SSIM: 0.0252 | Grad: 100277.617\n",
      "[Epoch 45, Batch 30/100] Loss: 0.0476 | RMSE: 0.0444 | Consistency: 0.0118 | SSIM: 0.0308 | Grad: 110199.398\n",
      "[Epoch 45, Batch 31/100] Loss: 0.0425 | RMSE: 0.0402 | Consistency: 0.0093 | SSIM: 0.0222 | Grad: 112498.250\n",
      "[Epoch 45, Batch 32/100] Loss: 0.0462 | RMSE: 0.0433 | Consistency: 0.0085 | SSIM: 0.0281 | Grad: 119745.961\n",
      "[Epoch 45, Batch 33/100] Loss: 0.0485 | RMSE: 0.0456 | Consistency: 0.0097 | SSIM: 0.0286 | Grad: 105412.438\n",
      "[Epoch 45, Batch 34/100] Loss: 0.0510 | RMSE: 0.0478 | Consistency: 0.0131 | SSIM: 0.0311 | Grad: 74556.766\n",
      "[Epoch 45, Batch 35/100] Loss: 0.0473 | RMSE: 0.0438 | Consistency: 0.0108 | SSIM: 0.0337 | Grad: 130091.586\n",
      "[Epoch 45, Batch 36/100] Loss: 0.0399 | RMSE: 0.0376 | Consistency: 0.0073 | SSIM: 0.0221 | Grad: 115981.922\n",
      "[Epoch 45, Batch 37/100] Loss: 0.0383 | RMSE: 0.0359 | Consistency: 0.0063 | SSIM: 0.0233 | Grad: 89705.977\n",
      "[Epoch 45, Batch 38/100] Loss: 0.0461 | RMSE: 0.0424 | Consistency: 0.0101 | SSIM: 0.0356 | Grad: 63362.895\n",
      "[Epoch 45, Batch 39/100] Loss: 0.0468 | RMSE: 0.0434 | Consistency: 0.0106 | SSIM: 0.0330 | Grad: 103867.570\n",
      "[Epoch 45, Batch 40/100] Loss: 0.0399 | RMSE: 0.0377 | Consistency: 0.0074 | SSIM: 0.0217 | Grad: 104638.758\n",
      "[Epoch 45, Batch 41/100] Loss: 0.0491 | RMSE: 0.0458 | Consistency: 0.0101 | SSIM: 0.0317 | Grad: 42572.781\n",
      "[Epoch 45, Batch 42/100] Loss: 0.0523 | RMSE: 0.0487 | Consistency: 0.0136 | SSIM: 0.0353 | Grad: 102906.508\n",
      "[Epoch 45, Batch 43/100] Loss: 0.0409 | RMSE: 0.0385 | Consistency: 0.0073 | SSIM: 0.0227 | Grad: 73240.305\n",
      "[Epoch 45, Batch 44/100] Loss: 0.0434 | RMSE: 0.0405 | Consistency: 0.0091 | SSIM: 0.0287 | Grad: 65462.414\n",
      "[Epoch 45, Batch 45/100] Loss: 0.0448 | RMSE: 0.0421 | Consistency: 0.0085 | SSIM: 0.0264 | Grad: 53437.516\n",
      "[Epoch 45, Batch 46/100] Loss: 0.0469 | RMSE: 0.0438 | Consistency: 0.0106 | SSIM: 0.0303 | Grad: 68320.172\n",
      "[Epoch 45, Batch 47/100] Loss: 0.0514 | RMSE: 0.0484 | Consistency: 0.0123 | SSIM: 0.0285 | Grad: 57796.434\n",
      "[Epoch 45, Batch 48/100] Loss: 0.0402 | RMSE: 0.0378 | Consistency: 0.0070 | SSIM: 0.0236 | Grad: 128392.875\n",
      "[Epoch 45, Batch 49/100] Loss: 0.0451 | RMSE: 0.0425 | Consistency: 0.0090 | SSIM: 0.0250 | Grad: 126276.453\n",
      "[Epoch 45, Batch 50/100] Loss: 0.0398 | RMSE: 0.0377 | Consistency: 0.0056 | SSIM: 0.0204 | Grad: 119074.266\n",
      "[Epoch 45, Batch 51/100] Loss: 0.0419 | RMSE: 0.0395 | Consistency: 0.0060 | SSIM: 0.0235 | Grad: 119727.422\n",
      "[Epoch 45, Batch 52/100] Loss: 0.0475 | RMSE: 0.0437 | Consistency: 0.0112 | SSIM: 0.0372 | Grad: 76577.688\n",
      "[Epoch 45, Batch 53/100] Loss: 0.0443 | RMSE: 0.0413 | Consistency: 0.0074 | SSIM: 0.0293 | Grad: 96604.141\n",
      "[Epoch 45, Batch 54/100] Loss: 0.0596 | RMSE: 0.0565 | Consistency: 0.0152 | SSIM: 0.0297 | Grad: 124553.977\n",
      "[Epoch 45, Batch 55/100] Loss: 0.0387 | RMSE: 0.0363 | Consistency: 0.0073 | SSIM: 0.0235 | Grad: 90208.312\n",
      "[Epoch 45, Batch 56/100] Loss: 0.0417 | RMSE: 0.0393 | Consistency: 0.0060 | SSIM: 0.0228 | Grad: 135889.203\n",
      "[Epoch 45, Batch 57/100] Loss: 0.0438 | RMSE: 0.0411 | Consistency: 0.0076 | SSIM: 0.0259 | Grad: 89638.359\n",
      "[Epoch 45, Batch 58/100] Loss: 0.0451 | RMSE: 0.0423 | Consistency: 0.0089 | SSIM: 0.0274 | Grad: 41128.066\n",
      "[Epoch 45, Batch 59/100] Loss: 0.0376 | RMSE: 0.0350 | Consistency: 0.0068 | SSIM: 0.0251 | Grad: 26516.941\n",
      "[Epoch 45, Batch 60/100] Loss: 0.0439 | RMSE: 0.0407 | Consistency: 0.0071 | SSIM: 0.0315 | Grad: 104571.648\n",
      "[Epoch 45, Batch 61/100] Loss: 0.0435 | RMSE: 0.0403 | Consistency: 0.0081 | SSIM: 0.0307 | Grad: 89755.695\n",
      "[Epoch 45, Batch 62/100] Loss: 0.0498 | RMSE: 0.0466 | Consistency: 0.0087 | SSIM: 0.0308 | Grad: 132046.328\n",
      "[Epoch 45, Batch 63/100] Loss: 0.0479 | RMSE: 0.0447 | Consistency: 0.0100 | SSIM: 0.0303 | Grad: 144014.109\n",
      "[Epoch 45, Batch 64/100] Loss: 0.0523 | RMSE: 0.0494 | Consistency: 0.0107 | SSIM: 0.0284 | Grad: 144190.734\n",
      "[Epoch 45, Batch 65/100] Loss: 0.0557 | RMSE: 0.0519 | Consistency: 0.0150 | SSIM: 0.0359 | Grad: 60413.203\n",
      "[Epoch 45, Batch 66/100] Loss: 0.0407 | RMSE: 0.0378 | Consistency: 0.0072 | SSIM: 0.0282 | Grad: 118525.180\n",
      "[Epoch 45, Batch 67/100] Loss: 0.0552 | RMSE: 0.0514 | Consistency: 0.0133 | SSIM: 0.0364 | Grad: 172689.312\n",
      "[Epoch 45, Batch 68/100] Loss: 0.0488 | RMSE: 0.0454 | Consistency: 0.0113 | SSIM: 0.0332 | Grad: 153994.984\n",
      "[Epoch 45, Batch 69/100] Loss: 0.0481 | RMSE: 0.0452 | Consistency: 0.0105 | SSIM: 0.0276 | Grad: 139974.891\n",
      "[Epoch 45, Batch 70/100] Loss: 0.0454 | RMSE: 0.0424 | Consistency: 0.0096 | SSIM: 0.0293 | Grad: 80725.578\n",
      "[Epoch 45, Batch 71/100] Loss: 0.0368 | RMSE: 0.0347 | Consistency: 0.0055 | SSIM: 0.0212 | Grad: 53251.539\n",
      "[Epoch 45, Batch 72/100] Loss: 0.0390 | RMSE: 0.0366 | Consistency: 0.0069 | SSIM: 0.0231 | Grad: 96978.820\n",
      "[Epoch 45, Batch 73/100] Loss: 0.0516 | RMSE: 0.0488 | Consistency: 0.0108 | SSIM: 0.0272 | Grad: 181452.047\n",
      "[Epoch 45, Batch 74/100] Loss: 0.0468 | RMSE: 0.0441 | Consistency: 0.0102 | SSIM: 0.0257 | Grad: 130367.250\n",
      "[Epoch 45, Batch 75/100] Loss: 0.0467 | RMSE: 0.0432 | Consistency: 0.0106 | SSIM: 0.0336 | Grad: 132794.531\n",
      "[Epoch 45, Batch 76/100] Loss: 0.0448 | RMSE: 0.0414 | Consistency: 0.0091 | SSIM: 0.0333 | Grad: 72722.391\n",
      "[Epoch 45, Batch 77/100] Loss: 0.0457 | RMSE: 0.0421 | Consistency: 0.0110 | SSIM: 0.0353 | Grad: 51559.602\n",
      "[Epoch 45, Batch 78/100] Loss: 0.0471 | RMSE: 0.0440 | Consistency: 0.0102 | SSIM: 0.0299 | Grad: 132840.281\n",
      "[Epoch 45, Batch 79/100] Loss: 0.0438 | RMSE: 0.0413 | Consistency: 0.0085 | SSIM: 0.0240 | Grad: 142165.141\n",
      "[Epoch 45, Batch 80/100] Loss: 0.0400 | RMSE: 0.0373 | Consistency: 0.0070 | SSIM: 0.0267 | Grad: 103694.336\n",
      "[Epoch 45, Batch 81/100] Loss: 0.0515 | RMSE: 0.0482 | Consistency: 0.0136 | SSIM: 0.0311 | Grad: 45087.715\n",
      "[Epoch 45, Batch 82/100] Loss: 0.0464 | RMSE: 0.0438 | Consistency: 0.0085 | SSIM: 0.0256 | Grad: 24816.615\n",
      "[Epoch 45, Batch 83/100] Loss: 0.0491 | RMSE: 0.0456 | Consistency: 0.0101 | SSIM: 0.0332 | Grad: 139802.438\n",
      "[Epoch 45, Batch 84/100] Loss: 0.0461 | RMSE: 0.0432 | Consistency: 0.0087 | SSIM: 0.0282 | Grad: 114130.828\n",
      "[Epoch 45, Batch 85/100] Loss: 0.0541 | RMSE: 0.0505 | Consistency: 0.0128 | SSIM: 0.0345 | Grad: 95324.523\n",
      "[Epoch 45, Batch 86/100] Loss: 0.0463 | RMSE: 0.0434 | Consistency: 0.0109 | SSIM: 0.0283 | Grad: 68661.758\n",
      "[Epoch 45, Batch 87/100] Loss: 0.0433 | RMSE: 0.0405 | Consistency: 0.0094 | SSIM: 0.0274 | Grad: 94115.359\n",
      "[Epoch 45, Batch 88/100] Loss: 0.0533 | RMSE: 0.0498 | Consistency: 0.0118 | SSIM: 0.0341 | Grad: 87893.617\n",
      "[Epoch 45, Batch 89/100] Loss: 0.0434 | RMSE: 0.0407 | Consistency: 0.0087 | SSIM: 0.0262 | Grad: 76983.375\n",
      "[Epoch 45, Batch 90/100] Loss: 0.0466 | RMSE: 0.0433 | Consistency: 0.0099 | SSIM: 0.0321 | Grad: 77150.664\n",
      "[Epoch 45, Batch 91/100] Loss: 0.0451 | RMSE: 0.0417 | Consistency: 0.0106 | SSIM: 0.0338 | Grad: 65410.285\n",
      "[Epoch 45, Batch 92/100] Loss: 0.0439 | RMSE: 0.0409 | Consistency: 0.0095 | SSIM: 0.0283 | Grad: 86014.703\n",
      "[Epoch 45, Batch 93/100] Loss: 0.0499 | RMSE: 0.0471 | Consistency: 0.0090 | SSIM: 0.0270 | Grad: 65788.539\n",
      "[Epoch 45, Batch 94/100] Loss: 0.0373 | RMSE: 0.0348 | Consistency: 0.0061 | SSIM: 0.0248 | Grad: 70131.406\n",
      "[Epoch 45, Batch 95/100] Loss: 0.0437 | RMSE: 0.0406 | Consistency: 0.0075 | SSIM: 0.0306 | Grad: 56008.133\n",
      "[Epoch 45, Batch 96/100] Loss: 0.0482 | RMSE: 0.0445 | Consistency: 0.0123 | SSIM: 0.0358 | Grad: 104809.867\n",
      "[Epoch 45, Batch 97/100] Loss: 0.0446 | RMSE: 0.0421 | Consistency: 0.0087 | SSIM: 0.0243 | Grad: 90271.672\n",
      "[Epoch 45, Batch 98/100] Loss: 0.0409 | RMSE: 0.0383 | Consistency: 0.0084 | SSIM: 0.0254 | Grad: 22424.344\n",
      "[Epoch 45, Batch 99/100] Loss: 0.0375 | RMSE: 0.0348 | Consistency: 0.0059 | SSIM: 0.0263 | Grad: 100153.234\n",
      "[Epoch 45, Batch 100/100] Loss: 0.0438 | RMSE: 0.0413 | Consistency: 0.0087 | SSIM: 0.0246 | Grad: 60840.711\n",
      "✅ Epoch 45 완료!\n",
      "   📈 평균 Loss: 0.045273\n",
      "   📊 평균 RMSE: 0.042369\n",
      "   ⚙️  학습률: 0.000478\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 46/80 시작...\n",
      "[Epoch 46, Batch 1/100] Loss: 0.0428 | RMSE: 0.0400 | Consistency: 0.0089 | SSIM: 0.0272 | Grad: 90902.562\n",
      "[Epoch 46, Batch 2/100] Loss: 0.0457 | RMSE: 0.0425 | Consistency: 0.0091 | SSIM: 0.0310 | Grad: 59010.406\n",
      "[Epoch 46, Batch 3/100] Loss: 0.0468 | RMSE: 0.0431 | Consistency: 0.0096 | SSIM: 0.0359 | Grad: 78589.039\n",
      "[Epoch 46, Batch 4/100] Loss: 0.0535 | RMSE: 0.0505 | Consistency: 0.0114 | SSIM: 0.0295 | Grad: 110490.469\n",
      "[Epoch 46, Batch 5/100] Loss: 0.0380 | RMSE: 0.0355 | Consistency: 0.0074 | SSIM: 0.0245 | Grad: 70612.938\n",
      "[Epoch 46, Batch 6/100] Loss: 0.0380 | RMSE: 0.0355 | Consistency: 0.0071 | SSIM: 0.0234 | Grad: 91473.656\n",
      "[Epoch 46, Batch 7/100] Loss: 0.0370 | RMSE: 0.0347 | Consistency: 0.0058 | SSIM: 0.0225 | Grad: 79334.555\n",
      "[Epoch 46, Batch 8/100] Loss: 0.0420 | RMSE: 0.0393 | Consistency: 0.0081 | SSIM: 0.0268 | Grad: 34760.656\n",
      "[Epoch 46, Batch 9/100] Loss: 0.0388 | RMSE: 0.0360 | Consistency: 0.0082 | SSIM: 0.0264 | Grad: 43217.805\n",
      "[Epoch 46, Batch 10/100] Loss: 0.0418 | RMSE: 0.0385 | Consistency: 0.0076 | SSIM: 0.0317 | Grad: 79037.055\n",
      "[Epoch 46, Batch 11/100] Loss: 0.0387 | RMSE: 0.0367 | Consistency: 0.0078 | SSIM: 0.0197 | Grad: 57211.934\n",
      "[Epoch 46, Batch 12/100] Loss: 0.0424 | RMSE: 0.0395 | Consistency: 0.0097 | SSIM: 0.0281 | Grad: 99696.219\n",
      "[Epoch 46, Batch 13/100] Loss: 0.0454 | RMSE: 0.0422 | Consistency: 0.0088 | SSIM: 0.0308 | Grad: 79993.125\n",
      "[Epoch 46, Batch 14/100] Loss: 0.0411 | RMSE: 0.0383 | Consistency: 0.0092 | SSIM: 0.0271 | Grad: 111410.930\n",
      "[Epoch 46, Batch 15/100] Loss: 0.0488 | RMSE: 0.0452 | Consistency: 0.0125 | SSIM: 0.0352 | Grad: 66203.242\n",
      "[Epoch 46, Batch 16/100] Loss: 0.0506 | RMSE: 0.0476 | Consistency: 0.0128 | SSIM: 0.0291 | Grad: 119600.695\n",
      "[Epoch 46, Batch 17/100] Loss: 0.0488 | RMSE: 0.0460 | Consistency: 0.0140 | SSIM: 0.0264 | Grad: 123115.359\n",
      "[Epoch 46, Batch 18/100] Loss: 0.0458 | RMSE: 0.0432 | Consistency: 0.0091 | SSIM: 0.0258 | Grad: 92533.953\n",
      "[Epoch 46, Batch 19/100] Loss: 0.0439 | RMSE: 0.0409 | Consistency: 0.0078 | SSIM: 0.0295 | Grad: 66401.992\n",
      "[Epoch 46, Batch 20/100] Loss: 0.0450 | RMSE: 0.0420 | Consistency: 0.0112 | SSIM: 0.0290 | Grad: 67273.914\n",
      "[Epoch 46, Batch 21/100] Loss: 0.0503 | RMSE: 0.0472 | Consistency: 0.0119 | SSIM: 0.0300 | Grad: 112444.859\n",
      "[Epoch 46, Batch 22/100] Loss: 0.0483 | RMSE: 0.0450 | Consistency: 0.0129 | SSIM: 0.0316 | Grad: 93273.758\n",
      "[Epoch 46, Batch 23/100] Loss: 0.0436 | RMSE: 0.0410 | Consistency: 0.0100 | SSIM: 0.0252 | Grad: 98383.992\n",
      "[Epoch 46, Batch 24/100] Loss: 0.0421 | RMSE: 0.0395 | Consistency: 0.0100 | SSIM: 0.0255 | Grad: 68405.953\n",
      "[Epoch 46, Batch 25/100] Loss: 0.0384 | RMSE: 0.0362 | Consistency: 0.0079 | SSIM: 0.0206 | Grad: 88698.922\n",
      "[Epoch 46, Batch 26/100] Loss: 0.0356 | RMSE: 0.0334 | Consistency: 0.0068 | SSIM: 0.0215 | Grad: 37991.254\n",
      "[Epoch 46, Batch 27/100] Loss: 0.0425 | RMSE: 0.0397 | Consistency: 0.0076 | SSIM: 0.0274 | Grad: 64630.008\n",
      "[Epoch 46, Batch 28/100] Loss: 0.0404 | RMSE: 0.0377 | Consistency: 0.0080 | SSIM: 0.0257 | Grad: 86420.555\n",
      "[Epoch 46, Batch 29/100] Loss: 0.0393 | RMSE: 0.0363 | Consistency: 0.0072 | SSIM: 0.0292 | Grad: 74535.094\n",
      "[Epoch 46, Batch 30/100] Loss: 0.0351 | RMSE: 0.0329 | Consistency: 0.0053 | SSIM: 0.0216 | Grad: 56940.723\n",
      "[Epoch 46, Batch 31/100] Loss: 0.0458 | RMSE: 0.0430 | Consistency: 0.0095 | SSIM: 0.0272 | Grad: 112628.977\n",
      "[Epoch 46, Batch 32/100] Loss: 0.0497 | RMSE: 0.0464 | Consistency: 0.0135 | SSIM: 0.0313 | Grad: 132854.984\n",
      "[Epoch 46, Batch 33/100] Loss: 0.0448 | RMSE: 0.0418 | Consistency: 0.0112 | SSIM: 0.0282 | Grad: 130559.719\n",
      "[Epoch 46, Batch 34/100] Loss: 0.0443 | RMSE: 0.0410 | Consistency: 0.0070 | SSIM: 0.0318 | Grad: 123147.680\n",
      "[Epoch 46, Batch 35/100] Loss: 0.0527 | RMSE: 0.0490 | Consistency: 0.0122 | SSIM: 0.0353 | Grad: 61475.789\n",
      "[Epoch 46, Batch 36/100] Loss: 0.0490 | RMSE: 0.0463 | Consistency: 0.0097 | SSIM: 0.0262 | Grad: 139291.859\n",
      "[Epoch 46, Batch 37/100] Loss: 0.0476 | RMSE: 0.0448 | Consistency: 0.0099 | SSIM: 0.0272 | Grad: 107088.625\n",
      "[Epoch 46, Batch 38/100] Loss: 0.0381 | RMSE: 0.0356 | Consistency: 0.0078 | SSIM: 0.0245 | Grad: 92826.398\n",
      "[Epoch 46, Batch 39/100] Loss: 0.0426 | RMSE: 0.0404 | Consistency: 0.0085 | SSIM: 0.0214 | Grad: 56022.578\n",
      "[Epoch 46, Batch 40/100] Loss: 0.0447 | RMSE: 0.0420 | Consistency: 0.0088 | SSIM: 0.0270 | Grad: 81882.953\n",
      "[Epoch 46, Batch 41/100] Loss: 0.0410 | RMSE: 0.0375 | Consistency: 0.0072 | SSIM: 0.0342 | Grad: 61367.633\n",
      "[Epoch 46, Batch 42/100] Loss: 0.0457 | RMSE: 0.0429 | Consistency: 0.0104 | SSIM: 0.0266 | Grad: 107500.242\n",
      "[Epoch 46, Batch 43/100] Loss: 0.0385 | RMSE: 0.0363 | Consistency: 0.0070 | SSIM: 0.0207 | Grad: 59045.387\n",
      "[Epoch 46, Batch 44/100] Loss: 0.0356 | RMSE: 0.0336 | Consistency: 0.0057 | SSIM: 0.0196 | Grad: 94693.523\n",
      "[Epoch 46, Batch 45/100] Loss: 0.0417 | RMSE: 0.0385 | Consistency: 0.0076 | SSIM: 0.0313 | Grad: 56364.742\n",
      "[Epoch 46, Batch 46/100] Loss: 0.0435 | RMSE: 0.0411 | Consistency: 0.0081 | SSIM: 0.0233 | Grad: 85259.227\n",
      "[Epoch 46, Batch 47/100] Loss: 0.0497 | RMSE: 0.0463 | Consistency: 0.0097 | SSIM: 0.0330 | Grad: 102115.203\n",
      "[Epoch 46, Batch 48/100] Loss: 0.0475 | RMSE: 0.0451 | Consistency: 0.0083 | SSIM: 0.0226 | Grad: 113344.094\n",
      "[Epoch 46, Batch 49/100] Loss: 0.0492 | RMSE: 0.0461 | Consistency: 0.0114 | SSIM: 0.0293 | Grad: 82421.773\n",
      "[Epoch 46, Batch 50/100] Loss: 0.0424 | RMSE: 0.0394 | Consistency: 0.0076 | SSIM: 0.0294 | Grad: 61528.164\n",
      "[Epoch 46, Batch 51/100] Loss: 0.0399 | RMSE: 0.0371 | Consistency: 0.0069 | SSIM: 0.0267 | Grad: 36042.961\n",
      "[Epoch 46, Batch 52/100] Loss: 0.0415 | RMSE: 0.0393 | Consistency: 0.0071 | SSIM: 0.0207 | Grad: 69036.164\n",
      "[Epoch 46, Batch 53/100] Loss: 0.0398 | RMSE: 0.0367 | Consistency: 0.0076 | SSIM: 0.0297 | Grad: 68125.625\n",
      "[Epoch 46, Batch 54/100] Loss: 0.0432 | RMSE: 0.0404 | Consistency: 0.0092 | SSIM: 0.0273 | Grad: 99208.820\n",
      "[Epoch 46, Batch 55/100] Loss: 0.0440 | RMSE: 0.0416 | Consistency: 0.0105 | SSIM: 0.0229 | Grad: 143366.453\n",
      "[Epoch 46, Batch 56/100] Loss: 0.0447 | RMSE: 0.0421 | Consistency: 0.0082 | SSIM: 0.0257 | Grad: 145685.719\n",
      "[Epoch 46, Batch 57/100] Loss: 0.0423 | RMSE: 0.0395 | Consistency: 0.0084 | SSIM: 0.0268 | Grad: 24893.223\n",
      "[Epoch 46, Batch 58/100] Loss: 0.0443 | RMSE: 0.0416 | Consistency: 0.0065 | SSIM: 0.0262 | Grad: 66911.578\n",
      "[Epoch 46, Batch 59/100] Loss: 0.0388 | RMSE: 0.0367 | Consistency: 0.0077 | SSIM: 0.0208 | Grad: 116095.219\n",
      "[Epoch 46, Batch 60/100] Loss: 0.0434 | RMSE: 0.0407 | Consistency: 0.0090 | SSIM: 0.0265 | Grad: 81667.258\n",
      "[Epoch 46, Batch 61/100] Loss: 0.0417 | RMSE: 0.0394 | Consistency: 0.0085 | SSIM: 0.0224 | Grad: 127391.234\n",
      "[Epoch 46, Batch 62/100] Loss: 0.0392 | RMSE: 0.0369 | Consistency: 0.0070 | SSIM: 0.0218 | Grad: 80715.984\n",
      "[Epoch 46, Batch 63/100] Loss: 0.0399 | RMSE: 0.0378 | Consistency: 0.0072 | SSIM: 0.0202 | Grad: 42993.840\n",
      "[Epoch 46, Batch 64/100] Loss: 0.0454 | RMSE: 0.0420 | Consistency: 0.0087 | SSIM: 0.0330 | Grad: 32947.562\n",
      "[Epoch 46, Batch 65/100] Loss: 0.0442 | RMSE: 0.0413 | Consistency: 0.0118 | SSIM: 0.0274 | Grad: 88971.109\n",
      "[Epoch 46, Batch 66/100] Loss: 0.0420 | RMSE: 0.0386 | Consistency: 0.0064 | SSIM: 0.0332 | Grad: 84138.727\n",
      "[Epoch 46, Batch 67/100] Loss: 0.0485 | RMSE: 0.0454 | Consistency: 0.0106 | SSIM: 0.0291 | Grad: 48088.707\n",
      "[Epoch 46, Batch 68/100] Loss: 0.0554 | RMSE: 0.0517 | Consistency: 0.0155 | SSIM: 0.0355 | Grad: 114017.297\n",
      "[Epoch 46, Batch 69/100] Loss: 0.0395 | RMSE: 0.0370 | Consistency: 0.0065 | SSIM: 0.0236 | Grad: 28868.877\n",
      "[Epoch 46, Batch 70/100] Loss: 0.0431 | RMSE: 0.0401 | Consistency: 0.0073 | SSIM: 0.0293 | Grad: 55019.555\n",
      "[Epoch 46, Batch 71/100] Loss: 0.0397 | RMSE: 0.0375 | Consistency: 0.0075 | SSIM: 0.0215 | Grad: 75634.570\n",
      "[Epoch 46, Batch 72/100] Loss: 0.0347 | RMSE: 0.0327 | Consistency: 0.0061 | SSIM: 0.0195 | Grad: 94427.891\n",
      "[Epoch 46, Batch 73/100] Loss: 0.0455 | RMSE: 0.0421 | Consistency: 0.0079 | SSIM: 0.0336 | Grad: 91973.086\n",
      "[Epoch 46, Batch 74/100] Loss: 0.0409 | RMSE: 0.0382 | Consistency: 0.0087 | SSIM: 0.0261 | Grad: 56488.324\n",
      "[Epoch 46, Batch 75/100] Loss: 0.0401 | RMSE: 0.0372 | Consistency: 0.0081 | SSIM: 0.0285 | Grad: 93661.672\n",
      "[Epoch 46, Batch 76/100] Loss: 0.0378 | RMSE: 0.0352 | Consistency: 0.0062 | SSIM: 0.0252 | Grad: 81950.141\n",
      "[Epoch 46, Batch 77/100] Loss: 0.0571 | RMSE: 0.0537 | Consistency: 0.0195 | SSIM: 0.0323 | Grad: 48573.648\n",
      "[Epoch 46, Batch 78/100] Loss: 0.0461 | RMSE: 0.0432 | Consistency: 0.0112 | SSIM: 0.0284 | Grad: 22736.365\n",
      "[Epoch 46, Batch 79/100] Loss: 0.0461 | RMSE: 0.0429 | Consistency: 0.0113 | SSIM: 0.0308 | Grad: 73407.547\n",
      "[Epoch 46, Batch 80/100] Loss: 0.0420 | RMSE: 0.0386 | Consistency: 0.0082 | SSIM: 0.0326 | Grad: 67819.383\n",
      "[Epoch 46, Batch 81/100] Loss: 0.0444 | RMSE: 0.0414 | Consistency: 0.0066 | SSIM: 0.0288 | Grad: 126334.867\n",
      "[Epoch 46, Batch 82/100] Loss: 0.0454 | RMSE: 0.0424 | Consistency: 0.0086 | SSIM: 0.0291 | Grad: 93682.516\n",
      "[Epoch 46, Batch 83/100] Loss: 0.0462 | RMSE: 0.0431 | Consistency: 0.0093 | SSIM: 0.0308 | Grad: 76694.500\n",
      "[Epoch 46, Batch 84/100] Loss: 0.0495 | RMSE: 0.0469 | Consistency: 0.0101 | SSIM: 0.0249 | Grad: 117603.750\n",
      "[Epoch 46, Batch 85/100] Loss: 0.0515 | RMSE: 0.0486 | Consistency: 0.0118 | SSIM: 0.0275 | Grad: 61285.812\n",
      "[Epoch 46, Batch 86/100] Loss: 0.0436 | RMSE: 0.0408 | Consistency: 0.0085 | SSIM: 0.0275 | Grad: 54653.676\n",
      "[Epoch 46, Batch 87/100] Loss: 0.0391 | RMSE: 0.0362 | Consistency: 0.0072 | SSIM: 0.0283 | Grad: 52643.977\n",
      "[Epoch 46, Batch 88/100] Loss: 0.0516 | RMSE: 0.0482 | Consistency: 0.0149 | SSIM: 0.0327 | Grad: 58744.082\n",
      "[Epoch 46, Batch 89/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0077 | SSIM: 0.0249 | Grad: 45152.117\n",
      "[Epoch 46, Batch 90/100] Loss: 0.0477 | RMSE: 0.0449 | Consistency: 0.0115 | SSIM: 0.0271 | Grad: 61558.188\n",
      "[Epoch 46, Batch 91/100] Loss: 0.0413 | RMSE: 0.0390 | Consistency: 0.0082 | SSIM: 0.0224 | Grad: 64285.301\n",
      "[Epoch 46, Batch 92/100] Loss: 0.0415 | RMSE: 0.0383 | Consistency: 0.0086 | SSIM: 0.0316 | Grad: 60543.973\n",
      "[Epoch 46, Batch 93/100] Loss: 0.0365 | RMSE: 0.0337 | Consistency: 0.0055 | SSIM: 0.0273 | Grad: 95293.844\n",
      "[Epoch 46, Batch 94/100] Loss: 0.0435 | RMSE: 0.0403 | Consistency: 0.0091 | SSIM: 0.0305 | Grad: 39603.551\n",
      "[Epoch 46, Batch 95/100] Loss: 0.0446 | RMSE: 0.0414 | Consistency: 0.0080 | SSIM: 0.0314 | Grad: 29318.752\n",
      "[Epoch 46, Batch 96/100] Loss: 0.0436 | RMSE: 0.0400 | Consistency: 0.0105 | SSIM: 0.0348 | Grad: 89034.641\n",
      "[Epoch 46, Batch 97/100] Loss: 0.0538 | RMSE: 0.0498 | Consistency: 0.0170 | SSIM: 0.0378 | Grad: 106347.781\n",
      "[Epoch 46, Batch 98/100] Loss: 0.0423 | RMSE: 0.0398 | Consistency: 0.0091 | SSIM: 0.0239 | Grad: 65638.531\n",
      "[Epoch 46, Batch 99/100] Loss: 0.0479 | RMSE: 0.0450 | Consistency: 0.0091 | SSIM: 0.0281 | Grad: 136905.016\n",
      "[Epoch 46, Batch 100/100] Loss: 0.0425 | RMSE: 0.0394 | Consistency: 0.0079 | SSIM: 0.0305 | Grad: 100256.625\n",
      "✅ Epoch 46 완료!\n",
      "   📈 평균 Loss: 0.043717\n",
      "   📊 평균 RMSE: 0.040871\n",
      "   ⚙️  학습률: 0.000456\n",
      "   🏆 NEW BEST! RMSE: 0.040871\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 47/80 시작...\n",
      "[Epoch 47, Batch 1/100] Loss: 0.0426 | RMSE: 0.0395 | Consistency: 0.0083 | SSIM: 0.0302 | Grad: 57896.465\n",
      "[Epoch 47, Batch 2/100] Loss: 0.0421 | RMSE: 0.0391 | Consistency: 0.0095 | SSIM: 0.0291 | Grad: 83650.797\n",
      "[Epoch 47, Batch 3/100] Loss: 0.0494 | RMSE: 0.0463 | Consistency: 0.0108 | SSIM: 0.0299 | Grad: 55215.590\n",
      "[Epoch 47, Batch 4/100] Loss: 0.0409 | RMSE: 0.0382 | Consistency: 0.0062 | SSIM: 0.0265 | Grad: 137546.734\n",
      "[Epoch 47, Batch 5/100] Loss: 0.0403 | RMSE: 0.0377 | Consistency: 0.0071 | SSIM: 0.0249 | Grad: 91687.109\n",
      "[Epoch 47, Batch 6/100] Loss: 0.0375 | RMSE: 0.0351 | Consistency: 0.0074 | SSIM: 0.0230 | Grad: 47928.121\n",
      "[Epoch 47, Batch 7/100] Loss: 0.0491 | RMSE: 0.0457 | Consistency: 0.0108 | SSIM: 0.0331 | Grad: 87093.180\n",
      "[Epoch 47, Batch 8/100] Loss: 0.0479 | RMSE: 0.0450 | Consistency: 0.0107 | SSIM: 0.0277 | Grad: 120743.414\n",
      "[Epoch 47, Batch 9/100] Loss: 0.0429 | RMSE: 0.0404 | Consistency: 0.0064 | SSIM: 0.0251 | Grad: 139029.594\n",
      "[Epoch 47, Batch 10/100] Loss: 0.0381 | RMSE: 0.0357 | Consistency: 0.0068 | SSIM: 0.0229 | Grad: 87026.031\n",
      "[Epoch 47, Batch 11/100] Loss: 0.0421 | RMSE: 0.0397 | Consistency: 0.0083 | SSIM: 0.0236 | Grad: 50473.137\n",
      "[Epoch 47, Batch 12/100] Loss: 0.0384 | RMSE: 0.0356 | Consistency: 0.0063 | SSIM: 0.0277 | Grad: 99483.469\n",
      "[Epoch 47, Batch 13/100] Loss: 0.0433 | RMSE: 0.0410 | Consistency: 0.0071 | SSIM: 0.0223 | Grad: 117849.781\n",
      "[Epoch 47, Batch 14/100] Loss: 0.0477 | RMSE: 0.0449 | Consistency: 0.0089 | SSIM: 0.0274 | Grad: 148152.750\n",
      "[Epoch 47, Batch 15/100] Loss: 0.0404 | RMSE: 0.0381 | Consistency: 0.0069 | SSIM: 0.0226 | Grad: 103887.305\n",
      "[Epoch 47, Batch 16/100] Loss: 0.0409 | RMSE: 0.0384 | Consistency: 0.0069 | SSIM: 0.0237 | Grad: 112225.781\n",
      "[Epoch 47, Batch 17/100] Loss: 0.0415 | RMSE: 0.0386 | Consistency: 0.0085 | SSIM: 0.0287 | Grad: 68347.484\n",
      "[Epoch 47, Batch 18/100] Loss: 0.0455 | RMSE: 0.0428 | Consistency: 0.0080 | SSIM: 0.0264 | Grad: 68585.016\n",
      "[Epoch 47, Batch 19/100] Loss: 0.0405 | RMSE: 0.0377 | Consistency: 0.0072 | SSIM: 0.0269 | Grad: 123314.242\n",
      "[Epoch 47, Batch 20/100] Loss: 0.0488 | RMSE: 0.0458 | Consistency: 0.0097 | SSIM: 0.0291 | Grad: 125309.031\n",
      "[Epoch 47, Batch 21/100] Loss: 0.0414 | RMSE: 0.0387 | Consistency: 0.0083 | SSIM: 0.0265 | Grad: 39849.664\n",
      "[Epoch 47, Batch 22/100] Loss: 0.0449 | RMSE: 0.0421 | Consistency: 0.0083 | SSIM: 0.0272 | Grad: 116483.016\n",
      "[Epoch 47, Batch 23/100] Loss: 0.0437 | RMSE: 0.0412 | Consistency: 0.0087 | SSIM: 0.0249 | Grad: 147848.391\n",
      "[Epoch 47, Batch 24/100] Loss: 0.0435 | RMSE: 0.0406 | Consistency: 0.0093 | SSIM: 0.0282 | Grad: 67315.703\n",
      "[Epoch 47, Batch 25/100] Loss: 0.0386 | RMSE: 0.0357 | Consistency: 0.0075 | SSIM: 0.0288 | Grad: 59661.035\n",
      "[Epoch 47, Batch 26/100] Loss: 0.0401 | RMSE: 0.0375 | Consistency: 0.0081 | SSIM: 0.0251 | Grad: 37723.715\n",
      "[Epoch 47, Batch 27/100] Loss: 0.0467 | RMSE: 0.0437 | Consistency: 0.0084 | SSIM: 0.0288 | Grad: 73194.188\n",
      "[Epoch 47, Batch 28/100] Loss: 0.0377 | RMSE: 0.0356 | Consistency: 0.0064 | SSIM: 0.0211 | Grad: 82373.039\n",
      "[Epoch 47, Batch 29/100] Loss: 0.0389 | RMSE: 0.0364 | Consistency: 0.0067 | SSIM: 0.0236 | Grad: 74594.414\n",
      "[Epoch 47, Batch 30/100] Loss: 0.0371 | RMSE: 0.0351 | Consistency: 0.0057 | SSIM: 0.0194 | Grad: 53899.375\n",
      "[Epoch 47, Batch 31/100] Loss: 0.0415 | RMSE: 0.0390 | Consistency: 0.0081 | SSIM: 0.0244 | Grad: 70836.914\n",
      "[Epoch 47, Batch 32/100] Loss: 0.0451 | RMSE: 0.0425 | Consistency: 0.0074 | SSIM: 0.0257 | Grad: 74008.859\n",
      "[Epoch 47, Batch 33/100] Loss: 0.0486 | RMSE: 0.0461 | Consistency: 0.0078 | SSIM: 0.0241 | Grad: 135774.547\n",
      "[Epoch 47, Batch 34/100] Loss: 0.0349 | RMSE: 0.0323 | Consistency: 0.0063 | SSIM: 0.0247 | Grad: 58746.281\n",
      "[Epoch 47, Batch 35/100] Loss: 0.0525 | RMSE: 0.0489 | Consistency: 0.0146 | SSIM: 0.0345 | Grad: 65742.883\n",
      "[Epoch 47, Batch 36/100] Loss: 0.0363 | RMSE: 0.0339 | Consistency: 0.0072 | SSIM: 0.0234 | Grad: 57428.617\n",
      "[Epoch 47, Batch 37/100] Loss: 0.0399 | RMSE: 0.0370 | Consistency: 0.0070 | SSIM: 0.0280 | Grad: 44622.953\n",
      "[Epoch 47, Batch 38/100] Loss: 0.0376 | RMSE: 0.0351 | Consistency: 0.0067 | SSIM: 0.0248 | Grad: 65114.930\n",
      "[Epoch 47, Batch 39/100] Loss: 0.0467 | RMSE: 0.0436 | Consistency: 0.0090 | SSIM: 0.0300 | Grad: 129493.297\n",
      "[Epoch 47, Batch 40/100] Loss: 0.0444 | RMSE: 0.0414 | Consistency: 0.0092 | SSIM: 0.0290 | Grad: 121416.844\n",
      "[Epoch 47, Batch 41/100] Loss: 0.0465 | RMSE: 0.0437 | Consistency: 0.0080 | SSIM: 0.0268 | Grad: 61199.195\n",
      "[Epoch 47, Batch 42/100] Loss: 0.0436 | RMSE: 0.0411 | Consistency: 0.0093 | SSIM: 0.0246 | Grad: 97837.352\n",
      "[Epoch 47, Batch 43/100] Loss: 0.0374 | RMSE: 0.0351 | Consistency: 0.0081 | SSIM: 0.0216 | Grad: 86736.953\n",
      "[Epoch 47, Batch 44/100] Loss: 0.0412 | RMSE: 0.0384 | Consistency: 0.0095 | SSIM: 0.0277 | Grad: 60907.914\n",
      "[Epoch 47, Batch 45/100] Loss: 0.0457 | RMSE: 0.0429 | Consistency: 0.0086 | SSIM: 0.0271 | Grad: 96687.906\n",
      "[Epoch 47, Batch 46/100] Loss: 0.0410 | RMSE: 0.0383 | Consistency: 0.0088 | SSIM: 0.0257 | Grad: 69477.109\n",
      "[Epoch 47, Batch 47/100] Loss: 0.0419 | RMSE: 0.0393 | Consistency: 0.0079 | SSIM: 0.0259 | Grad: 71643.266\n",
      "[Epoch 47, Batch 48/100] Loss: 0.0414 | RMSE: 0.0388 | Consistency: 0.0085 | SSIM: 0.0247 | Grad: 62906.633\n",
      "[Epoch 47, Batch 49/100] Loss: 0.0433 | RMSE: 0.0406 | Consistency: 0.0101 | SSIM: 0.0262 | Grad: 25207.547\n",
      "[Epoch 47, Batch 50/100] Loss: 0.0450 | RMSE: 0.0424 | Consistency: 0.0089 | SSIM: 0.0252 | Grad: 86372.852\n",
      "[Epoch 47, Batch 51/100] Loss: 0.0396 | RMSE: 0.0370 | Consistency: 0.0067 | SSIM: 0.0249 | Grad: 97417.727\n",
      "[Epoch 47, Batch 52/100] Loss: 0.0389 | RMSE: 0.0362 | Consistency: 0.0079 | SSIM: 0.0264 | Grad: 73911.703\n",
      "[Epoch 47, Batch 53/100] Loss: 0.0405 | RMSE: 0.0381 | Consistency: 0.0092 | SSIM: 0.0225 | Grad: 85944.086\n",
      "[Epoch 47, Batch 54/100] Loss: 0.0539 | RMSE: 0.0509 | Consistency: 0.0144 | SSIM: 0.0282 | Grad: 63492.051\n",
      "[Epoch 47, Batch 55/100] Loss: 0.0487 | RMSE: 0.0452 | Consistency: 0.0130 | SSIM: 0.0337 | Grad: 100411.195\n",
      "[Epoch 47, Batch 56/100] Loss: 0.0496 | RMSE: 0.0461 | Consistency: 0.0136 | SSIM: 0.0337 | Grad: 107174.695\n",
      "[Epoch 47, Batch 57/100] Loss: 0.0525 | RMSE: 0.0492 | Consistency: 0.0137 | SSIM: 0.0312 | Grad: 109575.531\n",
      "[Epoch 47, Batch 58/100] Loss: 0.0463 | RMSE: 0.0428 | Consistency: 0.0093 | SSIM: 0.0343 | Grad: 99858.875\n",
      "[Epoch 47, Batch 59/100] Loss: 0.0424 | RMSE: 0.0397 | Consistency: 0.0068 | SSIM: 0.0262 | Grad: 63761.840\n",
      "[Epoch 47, Batch 60/100] Loss: 0.0382 | RMSE: 0.0352 | Consistency: 0.0078 | SSIM: 0.0294 | Grad: 56338.500\n",
      "[Epoch 47, Batch 61/100] Loss: 0.0393 | RMSE: 0.0370 | Consistency: 0.0087 | SSIM: 0.0221 | Grad: 109006.648\n",
      "[Epoch 47, Batch 62/100] Loss: 0.0429 | RMSE: 0.0395 | Consistency: 0.0070 | SSIM: 0.0331 | Grad: 110100.977\n",
      "[Epoch 47, Batch 63/100] Loss: 0.0424 | RMSE: 0.0398 | Consistency: 0.0089 | SSIM: 0.0245 | Grad: 69269.000\n",
      "[Epoch 47, Batch 64/100] Loss: 0.0418 | RMSE: 0.0395 | Consistency: 0.0079 | SSIM: 0.0223 | Grad: 85321.367\n",
      "[Epoch 47, Batch 65/100] Loss: 0.0413 | RMSE: 0.0385 | Consistency: 0.0087 | SSIM: 0.0266 | Grad: 76971.984\n",
      "[Epoch 47, Batch 66/100] Loss: 0.0473 | RMSE: 0.0443 | Consistency: 0.0097 | SSIM: 0.0291 | Grad: 120312.992\n",
      "[Epoch 47, Batch 67/100] Loss: 0.0408 | RMSE: 0.0379 | Consistency: 0.0079 | SSIM: 0.0286 | Grad: 100630.383\n",
      "[Epoch 47, Batch 68/100] Loss: 0.0393 | RMSE: 0.0368 | Consistency: 0.0063 | SSIM: 0.0241 | Grad: 70066.641\n",
      "[Epoch 47, Batch 69/100] Loss: 0.0492 | RMSE: 0.0464 | Consistency: 0.0087 | SSIM: 0.0271 | Grad: 68675.750\n",
      "[Epoch 47, Batch 70/100] Loss: 0.0379 | RMSE: 0.0351 | Consistency: 0.0078 | SSIM: 0.0274 | Grad: 27601.066\n",
      "[Epoch 47, Batch 71/100] Loss: 0.0410 | RMSE: 0.0384 | Consistency: 0.0077 | SSIM: 0.0258 | Grad: 106014.625\n",
      "[Epoch 47, Batch 72/100] Loss: 0.0469 | RMSE: 0.0437 | Consistency: 0.0093 | SSIM: 0.0310 | Grad: 81415.984\n",
      "[Epoch 47, Batch 73/100] Loss: 0.0437 | RMSE: 0.0405 | Consistency: 0.0095 | SSIM: 0.0315 | Grad: 89896.000\n",
      "[Epoch 47, Batch 74/100] Loss: 0.0461 | RMSE: 0.0424 | Consistency: 0.0095 | SSIM: 0.0363 | Grad: 58885.562\n",
      "[Epoch 47, Batch 75/100] Loss: 0.0454 | RMSE: 0.0426 | Consistency: 0.0091 | SSIM: 0.0272 | Grad: 68491.164\n",
      "[Epoch 47, Batch 76/100] Loss: 0.0592 | RMSE: 0.0548 | Consistency: 0.0160 | SSIM: 0.0424 | Grad: 37951.863\n",
      "[Epoch 47, Batch 77/100] Loss: 0.0390 | RMSE: 0.0359 | Consistency: 0.0075 | SSIM: 0.0303 | Grad: 48575.500\n",
      "[Epoch 47, Batch 78/100] Loss: 0.0371 | RMSE: 0.0348 | Consistency: 0.0071 | SSIM: 0.0218 | Grad: 45883.234\n",
      "[Epoch 47, Batch 79/100] Loss: 0.0433 | RMSE: 0.0409 | Consistency: 0.0085 | SSIM: 0.0235 | Grad: 113157.250\n",
      "[Epoch 47, Batch 80/100] Loss: 0.0394 | RMSE: 0.0368 | Consistency: 0.0073 | SSIM: 0.0257 | Grad: 51518.051\n",
      "[Epoch 47, Batch 81/100] Loss: 0.0477 | RMSE: 0.0447 | Consistency: 0.0108 | SSIM: 0.0290 | Grad: 94852.672\n",
      "[Epoch 47, Batch 82/100] Loss: 0.0420 | RMSE: 0.0395 | Consistency: 0.0087 | SSIM: 0.0248 | Grad: 111980.398\n",
      "[Epoch 47, Batch 83/100] Loss: 0.0493 | RMSE: 0.0461 | Consistency: 0.0141 | SSIM: 0.0310 | Grad: 166043.641\n",
      "[Epoch 47, Batch 84/100] Loss: 0.0455 | RMSE: 0.0427 | Consistency: 0.0114 | SSIM: 0.0274 | Grad: 121377.281\n",
      "[Epoch 47, Batch 85/100] Loss: 0.0440 | RMSE: 0.0414 | Consistency: 0.0103 | SSIM: 0.0252 | Grad: 91011.961\n",
      "[Epoch 47, Batch 86/100] Loss: 0.0462 | RMSE: 0.0426 | Consistency: 0.0109 | SSIM: 0.0351 | Grad: 87644.883\n",
      "[Epoch 47, Batch 87/100] Loss: 0.0463 | RMSE: 0.0433 | Consistency: 0.0113 | SSIM: 0.0289 | Grad: 121124.961\n",
      "[Epoch 47, Batch 88/100] Loss: 0.0450 | RMSE: 0.0422 | Consistency: 0.0096 | SSIM: 0.0268 | Grad: 99115.289\n",
      "[Epoch 47, Batch 89/100] Loss: 0.0487 | RMSE: 0.0459 | Consistency: 0.0112 | SSIM: 0.0269 | Grad: 84388.391\n",
      "[Epoch 47, Batch 90/100] Loss: 0.0419 | RMSE: 0.0393 | Consistency: 0.0076 | SSIM: 0.0250 | Grad: 62232.816\n",
      "[Epoch 47, Batch 91/100] Loss: 0.0458 | RMSE: 0.0428 | Consistency: 0.0088 | SSIM: 0.0291 | Grad: 104996.406\n",
      "[Epoch 47, Batch 92/100] Loss: 0.0475 | RMSE: 0.0439 | Consistency: 0.0121 | SSIM: 0.0348 | Grad: 73259.773\n",
      "[Epoch 47, Batch 93/100] Loss: 0.0464 | RMSE: 0.0435 | Consistency: 0.0097 | SSIM: 0.0275 | Grad: 80095.281\n",
      "[Epoch 47, Batch 94/100] Loss: 0.0399 | RMSE: 0.0373 | Consistency: 0.0070 | SSIM: 0.0258 | Grad: 76328.188\n",
      "[Epoch 47, Batch 95/100] Loss: 0.0483 | RMSE: 0.0452 | Consistency: 0.0102 | SSIM: 0.0299 | Grad: 38743.742\n",
      "[Epoch 47, Batch 96/100] Loss: 0.0429 | RMSE: 0.0403 | Consistency: 0.0086 | SSIM: 0.0251 | Grad: 89475.250\n",
      "[Epoch 47, Batch 97/100] Loss: 0.0632 | RMSE: 0.0587 | Consistency: 0.0226 | SSIM: 0.0432 | Grad: 96182.594\n",
      "[Epoch 47, Batch 98/100] Loss: 0.0442 | RMSE: 0.0414 | Consistency: 0.0106 | SSIM: 0.0274 | Grad: 125021.391\n",
      "[Epoch 47, Batch 99/100] Loss: 0.0569 | RMSE: 0.0539 | Consistency: 0.0114 | SSIM: 0.0284 | Grad: 148722.109\n",
      "[Epoch 47, Batch 100/100] Loss: 0.0465 | RMSE: 0.0434 | Consistency: 0.0092 | SSIM: 0.0298 | Grad: 141921.812\n",
      "✅ Epoch 47 완료!\n",
      "   📈 평균 Loss: 0.043791\n",
      "   📊 평균 RMSE: 0.040960\n",
      "   ⚙️  학습률: 0.000435\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 48/80 시작...\n",
      "[Epoch 48, Batch 1/100] Loss: 0.0490 | RMSE: 0.0457 | Consistency: 0.0099 | SSIM: 0.0314 | Grad: 126788.008\n",
      "[Epoch 48, Batch 2/100] Loss: 0.0434 | RMSE: 0.0409 | Consistency: 0.0085 | SSIM: 0.0238 | Grad: 74598.500\n",
      "[Epoch 48, Batch 3/100] Loss: 0.0413 | RMSE: 0.0384 | Consistency: 0.0077 | SSIM: 0.0284 | Grad: 79451.422\n",
      "[Epoch 48, Batch 4/100] Loss: 0.0406 | RMSE: 0.0385 | Consistency: 0.0065 | SSIM: 0.0208 | Grad: 97068.547\n",
      "[Epoch 48, Batch 5/100] Loss: 0.0437 | RMSE: 0.0405 | Consistency: 0.0087 | SSIM: 0.0306 | Grad: 110594.180\n",
      "[Epoch 48, Batch 6/100] Loss: 0.0472 | RMSE: 0.0440 | Consistency: 0.0101 | SSIM: 0.0318 | Grad: 104026.812\n",
      "[Epoch 48, Batch 7/100] Loss: 0.0404 | RMSE: 0.0376 | Consistency: 0.0078 | SSIM: 0.0281 | Grad: 92241.852\n",
      "[Epoch 48, Batch 8/100] Loss: 0.0470 | RMSE: 0.0440 | Consistency: 0.0112 | SSIM: 0.0287 | Grad: 49538.230\n",
      "[Epoch 48, Batch 9/100] Loss: 0.0374 | RMSE: 0.0352 | Consistency: 0.0064 | SSIM: 0.0213 | Grad: 113550.180\n",
      "[Epoch 48, Batch 10/100] Loss: 0.0453 | RMSE: 0.0426 | Consistency: 0.0101 | SSIM: 0.0264 | Grad: 92170.750\n",
      "[Epoch 48, Batch 11/100] Loss: 0.0378 | RMSE: 0.0358 | Consistency: 0.0063 | SSIM: 0.0189 | Grad: 106545.000\n",
      "[Epoch 48, Batch 12/100] Loss: 0.0384 | RMSE: 0.0358 | Consistency: 0.0072 | SSIM: 0.0257 | Grad: 99963.930\n",
      "[Epoch 48, Batch 13/100] Loss: 0.0341 | RMSE: 0.0322 | Consistency: 0.0053 | SSIM: 0.0184 | Grad: 48836.473\n",
      "[Epoch 48, Batch 14/100] Loss: 0.0380 | RMSE: 0.0360 | Consistency: 0.0055 | SSIM: 0.0193 | Grad: 37457.367\n",
      "[Epoch 48, Batch 15/100] Loss: 0.0397 | RMSE: 0.0375 | Consistency: 0.0062 | SSIM: 0.0210 | Grad: 127748.391\n",
      "[Epoch 48, Batch 16/100] Loss: 0.0482 | RMSE: 0.0453 | Consistency: 0.0089 | SSIM: 0.0278 | Grad: 107764.867\n",
      "[Epoch 48, Batch 17/100] Loss: 0.0473 | RMSE: 0.0436 | Consistency: 0.0113 | SSIM: 0.0362 | Grad: 76404.188\n",
      "[Epoch 48, Batch 18/100] Loss: 0.0482 | RMSE: 0.0443 | Consistency: 0.0094 | SSIM: 0.0383 | Grad: 46453.598\n",
      "[Epoch 48, Batch 19/100] Loss: 0.0464 | RMSE: 0.0438 | Consistency: 0.0090 | SSIM: 0.0257 | Grad: 84257.719\n",
      "[Epoch 48, Batch 20/100] Loss: 0.0439 | RMSE: 0.0410 | Consistency: 0.0093 | SSIM: 0.0283 | Grad: 59605.125\n",
      "[Epoch 48, Batch 21/100] Loss: 0.0511 | RMSE: 0.0486 | Consistency: 0.0088 | SSIM: 0.0241 | Grad: 117124.234\n",
      "[Epoch 48, Batch 22/100] Loss: 0.0495 | RMSE: 0.0464 | Consistency: 0.0115 | SSIM: 0.0299 | Grad: 92354.688\n",
      "[Epoch 48, Batch 23/100] Loss: 0.0396 | RMSE: 0.0368 | Consistency: 0.0082 | SSIM: 0.0265 | Grad: 86670.773\n",
      "[Epoch 48, Batch 24/100] Loss: 0.0385 | RMSE: 0.0362 | Consistency: 0.0072 | SSIM: 0.0224 | Grad: 35262.008\n",
      "[Epoch 48, Batch 25/100] Loss: 0.0433 | RMSE: 0.0404 | Consistency: 0.0093 | SSIM: 0.0279 | Grad: 98367.961\n",
      "[Epoch 48, Batch 26/100] Loss: 0.0449 | RMSE: 0.0423 | Consistency: 0.0103 | SSIM: 0.0257 | Grad: 130177.266\n",
      "[Epoch 48, Batch 27/100] Loss: 0.0482 | RMSE: 0.0452 | Consistency: 0.0082 | SSIM: 0.0287 | Grad: 112660.922\n",
      "[Epoch 48, Batch 28/100] Loss: 0.0457 | RMSE: 0.0424 | Consistency: 0.0102 | SSIM: 0.0325 | Grad: 92461.133\n",
      "[Epoch 48, Batch 29/100] Loss: 0.0392 | RMSE: 0.0360 | Consistency: 0.0061 | SSIM: 0.0316 | Grad: 61853.375\n",
      "[Epoch 48, Batch 30/100] Loss: 0.0449 | RMSE: 0.0416 | Consistency: 0.0103 | SSIM: 0.0326 | Grad: 82078.797\n",
      "[Epoch 48, Batch 31/100] Loss: 0.0386 | RMSE: 0.0356 | Consistency: 0.0065 | SSIM: 0.0291 | Grad: 72498.250\n",
      "[Epoch 48, Batch 32/100] Loss: 0.0470 | RMSE: 0.0438 | Consistency: 0.0103 | SSIM: 0.0311 | Grad: 118396.492\n",
      "[Epoch 48, Batch 33/100] Loss: 0.0398 | RMSE: 0.0368 | Consistency: 0.0068 | SSIM: 0.0292 | Grad: 36025.398\n",
      "[Epoch 48, Batch 34/100] Loss: 0.0448 | RMSE: 0.0417 | Consistency: 0.0090 | SSIM: 0.0307 | Grad: 39172.852\n",
      "[Epoch 48, Batch 35/100] Loss: 0.0438 | RMSE: 0.0410 | Consistency: 0.0091 | SSIM: 0.0273 | Grad: 34905.543\n",
      "[Epoch 48, Batch 36/100] Loss: 0.0505 | RMSE: 0.0471 | Consistency: 0.0106 | SSIM: 0.0332 | Grad: 121450.375\n",
      "[Epoch 48, Batch 37/100] Loss: 0.0414 | RMSE: 0.0385 | Consistency: 0.0072 | SSIM: 0.0285 | Grad: 99888.953\n",
      "[Epoch 48, Batch 38/100] Loss: 0.0451 | RMSE: 0.0426 | Consistency: 0.0075 | SSIM: 0.0242 | Grad: 119865.344\n",
      "[Epoch 48, Batch 39/100] Loss: 0.0433 | RMSE: 0.0398 | Consistency: 0.0090 | SSIM: 0.0337 | Grad: 35778.180\n",
      "[Epoch 48, Batch 40/100] Loss: 0.0395 | RMSE: 0.0370 | Consistency: 0.0067 | SSIM: 0.0245 | Grad: 43361.887\n",
      "[Epoch 48, Batch 41/100] Loss: 0.0368 | RMSE: 0.0343 | Consistency: 0.0067 | SSIM: 0.0235 | Grad: 66027.984\n",
      "[Epoch 48, Batch 42/100] Loss: 0.0332 | RMSE: 0.0314 | Consistency: 0.0053 | SSIM: 0.0175 | Grad: 82073.328\n",
      "[Epoch 48, Batch 43/100] Loss: 0.0432 | RMSE: 0.0407 | Consistency: 0.0081 | SSIM: 0.0243 | Grad: 63245.043\n",
      "[Epoch 48, Batch 44/100] Loss: 0.0404 | RMSE: 0.0378 | Consistency: 0.0077 | SSIM: 0.0252 | Grad: 99450.109\n",
      "[Epoch 48, Batch 45/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0084 | SSIM: 0.0244 | Grad: 101775.875\n",
      "[Epoch 48, Batch 46/100] Loss: 0.0406 | RMSE: 0.0381 | Consistency: 0.0072 | SSIM: 0.0242 | Grad: 79740.086\n",
      "[Epoch 48, Batch 47/100] Loss: 0.0446 | RMSE: 0.0422 | Consistency: 0.0096 | SSIM: 0.0231 | Grad: 79415.281\n",
      "[Epoch 48, Batch 48/100] Loss: 0.0392 | RMSE: 0.0368 | Consistency: 0.0067 | SSIM: 0.0236 | Grad: 75367.336\n",
      "[Epoch 48, Batch 49/100] Loss: 0.0398 | RMSE: 0.0370 | Consistency: 0.0068 | SSIM: 0.0274 | Grad: 88437.281\n",
      "[Epoch 48, Batch 50/100] Loss: 0.0425 | RMSE: 0.0393 | Consistency: 0.0077 | SSIM: 0.0308 | Grad: 75007.891\n",
      "[Epoch 48, Batch 51/100] Loss: 0.0348 | RMSE: 0.0327 | Consistency: 0.0059 | SSIM: 0.0210 | Grad: 59640.797\n",
      "[Epoch 48, Batch 52/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0067 | SSIM: 0.0234 | Grad: 49331.910\n",
      "[Epoch 48, Batch 53/100] Loss: 0.0434 | RMSE: 0.0406 | Consistency: 0.0092 | SSIM: 0.0262 | Grad: 79145.352\n",
      "[Epoch 48, Batch 54/100] Loss: 0.0518 | RMSE: 0.0486 | Consistency: 0.0146 | SSIM: 0.0301 | Grad: 82012.578\n",
      "[Epoch 48, Batch 55/100] Loss: 0.0349 | RMSE: 0.0328 | Consistency: 0.0055 | SSIM: 0.0200 | Grad: 36421.570\n",
      "[Epoch 48, Batch 56/100] Loss: 0.0435 | RMSE: 0.0407 | Consistency: 0.0071 | SSIM: 0.0270 | Grad: 125218.875\n",
      "[Epoch 48, Batch 57/100] Loss: 0.0542 | RMSE: 0.0507 | Consistency: 0.0122 | SSIM: 0.0336 | Grad: 113084.570\n",
      "[Epoch 48, Batch 58/100] Loss: 0.0426 | RMSE: 0.0393 | Consistency: 0.0089 | SSIM: 0.0323 | Grad: 108260.109\n",
      "[Epoch 48, Batch 59/100] Loss: 0.0484 | RMSE: 0.0453 | Consistency: 0.0101 | SSIM: 0.0300 | Grad: 75632.562\n",
      "[Epoch 48, Batch 60/100] Loss: 0.0413 | RMSE: 0.0386 | Consistency: 0.0075 | SSIM: 0.0263 | Grad: 86334.484\n",
      "[Epoch 48, Batch 61/100] Loss: 0.0451 | RMSE: 0.0417 | Consistency: 0.0094 | SSIM: 0.0326 | Grad: 73602.094\n",
      "[Epoch 48, Batch 62/100] Loss: 0.0528 | RMSE: 0.0495 | Consistency: 0.0107 | SSIM: 0.0323 | Grad: 55160.691\n",
      "[Epoch 48, Batch 63/100] Loss: 0.0402 | RMSE: 0.0381 | Consistency: 0.0075 | SSIM: 0.0204 | Grad: 80382.180\n",
      "[Epoch 48, Batch 64/100] Loss: 0.0397 | RMSE: 0.0373 | Consistency: 0.0070 | SSIM: 0.0233 | Grad: 80480.039\n",
      "[Epoch 48, Batch 65/100] Loss: 0.0424 | RMSE: 0.0396 | Consistency: 0.0075 | SSIM: 0.0278 | Grad: 65161.102\n",
      "[Epoch 48, Batch 66/100] Loss: 0.0406 | RMSE: 0.0379 | Consistency: 0.0079 | SSIM: 0.0258 | Grad: 63121.926\n",
      "[Epoch 48, Batch 67/100] Loss: 0.0428 | RMSE: 0.0400 | Consistency: 0.0080 | SSIM: 0.0268 | Grad: 133013.734\n",
      "[Epoch 48, Batch 68/100] Loss: 0.0510 | RMSE: 0.0478 | Consistency: 0.0129 | SSIM: 0.0306 | Grad: 107212.672\n",
      "[Epoch 48, Batch 69/100] Loss: 0.0490 | RMSE: 0.0460 | Consistency: 0.0119 | SSIM: 0.0291 | Grad: 141161.938\n",
      "[Epoch 48, Batch 70/100] Loss: 0.0359 | RMSE: 0.0332 | Consistency: 0.0062 | SSIM: 0.0267 | Grad: 106032.805\n",
      "[Epoch 48, Batch 71/100] Loss: 0.0436 | RMSE: 0.0406 | Consistency: 0.0099 | SSIM: 0.0288 | Grad: 48506.387\n",
      "[Epoch 48, Batch 72/100] Loss: 0.0408 | RMSE: 0.0381 | Consistency: 0.0089 | SSIM: 0.0264 | Grad: 72840.562\n",
      "[Epoch 48, Batch 73/100] Loss: 0.0386 | RMSE: 0.0358 | Consistency: 0.0066 | SSIM: 0.0271 | Grad: 105056.227\n",
      "[Epoch 48, Batch 74/100] Loss: 0.0395 | RMSE: 0.0368 | Consistency: 0.0066 | SSIM: 0.0260 | Grad: 57781.871\n",
      "[Epoch 48, Batch 75/100] Loss: 0.0422 | RMSE: 0.0397 | Consistency: 0.0087 | SSIM: 0.0242 | Grad: 101371.766\n",
      "[Epoch 48, Batch 76/100] Loss: 0.0477 | RMSE: 0.0445 | Consistency: 0.0125 | SSIM: 0.0303 | Grad: 127581.602\n",
      "[Epoch 48, Batch 77/100] Loss: 0.0412 | RMSE: 0.0383 | Consistency: 0.0092 | SSIM: 0.0281 | Grad: 101928.227\n",
      "[Epoch 48, Batch 78/100] Loss: 0.0438 | RMSE: 0.0405 | Consistency: 0.0102 | SSIM: 0.0322 | Grad: 62971.172\n",
      "[Epoch 48, Batch 79/100] Loss: 0.0400 | RMSE: 0.0369 | Consistency: 0.0068 | SSIM: 0.0304 | Grad: 23457.391\n",
      "[Epoch 48, Batch 80/100] Loss: 0.0448 | RMSE: 0.0421 | Consistency: 0.0099 | SSIM: 0.0265 | Grad: 84229.641\n",
      "[Epoch 48, Batch 81/100] Loss: 0.0465 | RMSE: 0.0436 | Consistency: 0.0122 | SSIM: 0.0274 | Grad: 127565.188\n",
      "[Epoch 48, Batch 82/100] Loss: 0.0462 | RMSE: 0.0429 | Consistency: 0.0131 | SSIM: 0.0321 | Grad: 120636.422\n",
      "[Epoch 48, Batch 83/100] Loss: 0.0504 | RMSE: 0.0472 | Consistency: 0.0142 | SSIM: 0.0303 | Grad: 102763.273\n",
      "[Epoch 48, Batch 84/100] Loss: 0.0393 | RMSE: 0.0361 | Consistency: 0.0077 | SSIM: 0.0307 | Grad: 88118.352\n",
      "[Epoch 48, Batch 85/100] Loss: 0.0454 | RMSE: 0.0430 | Consistency: 0.0076 | SSIM: 0.0232 | Grad: 78287.914\n",
      "[Epoch 48, Batch 86/100] Loss: 0.0457 | RMSE: 0.0430 | Consistency: 0.0117 | SSIM: 0.0261 | Grad: 102762.789\n",
      "[Epoch 48, Batch 87/100] Loss: 0.0572 | RMSE: 0.0532 | Consistency: 0.0159 | SSIM: 0.0377 | Grad: 112440.391\n",
      "[Epoch 48, Batch 88/100] Loss: 0.0414 | RMSE: 0.0387 | Consistency: 0.0081 | SSIM: 0.0266 | Grad: 76424.086\n",
      "[Epoch 48, Batch 89/100] Loss: 0.0454 | RMSE: 0.0422 | Consistency: 0.0090 | SSIM: 0.0304 | Grad: 36996.012\n",
      "[Epoch 48, Batch 90/100] Loss: 0.0451 | RMSE: 0.0422 | Consistency: 0.0094 | SSIM: 0.0279 | Grad: 100963.109\n",
      "[Epoch 48, Batch 91/100] Loss: 0.0416 | RMSE: 0.0385 | Consistency: 0.0076 | SSIM: 0.0301 | Grad: 99062.906\n",
      "[Epoch 48, Batch 92/100] Loss: 0.0416 | RMSE: 0.0391 | Consistency: 0.0089 | SSIM: 0.0241 | Grad: 74691.305\n",
      "[Epoch 48, Batch 93/100] Loss: 0.0476 | RMSE: 0.0442 | Consistency: 0.0098 | SSIM: 0.0335 | Grad: 95039.773\n",
      "[Epoch 48, Batch 94/100] Loss: 0.0408 | RMSE: 0.0385 | Consistency: 0.0071 | SSIM: 0.0217 | Grad: 123251.273\n",
      "[Epoch 48, Batch 95/100] Loss: 0.0412 | RMSE: 0.0387 | Consistency: 0.0084 | SSIM: 0.0240 | Grad: 117425.250\n",
      "[Epoch 48, Batch 96/100] Loss: 0.0473 | RMSE: 0.0433 | Consistency: 0.0101 | SSIM: 0.0382 | Grad: 76029.719\n",
      "[Epoch 48, Batch 97/100] Loss: 0.0359 | RMSE: 0.0339 | Consistency: 0.0072 | SSIM: 0.0197 | Grad: 80882.578\n",
      "[Epoch 48, Batch 98/100] Loss: 0.0467 | RMSE: 0.0436 | Consistency: 0.0105 | SSIM: 0.0302 | Grad: 85778.453\n",
      "[Epoch 48, Batch 99/100] Loss: 0.0443 | RMSE: 0.0417 | Consistency: 0.0089 | SSIM: 0.0246 | Grad: 92855.836\n",
      "[Epoch 48, Batch 100/100] Loss: 0.0383 | RMSE: 0.0354 | Consistency: 0.0056 | SSIM: 0.0277 | Grad: 121223.250\n",
      "✅ Epoch 48 완료!\n",
      "   📈 평균 Loss: 0.043166\n",
      "   📊 평균 RMSE: 0.040339\n",
      "   ⚙️  학습률: 0.000413\n",
      "   🏆 NEW BEST! RMSE: 0.040339\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 49/80 시작...\n",
      "[Epoch 49, Batch 1/100] Loss: 0.0471 | RMSE: 0.0441 | Consistency: 0.0098 | SSIM: 0.0292 | Grad: 120423.711\n",
      "[Epoch 49, Batch 2/100] Loss: 0.0395 | RMSE: 0.0369 | Consistency: 0.0080 | SSIM: 0.0258 | Grad: 71585.164\n",
      "[Epoch 49, Batch 3/100] Loss: 0.0452 | RMSE: 0.0425 | Consistency: 0.0120 | SSIM: 0.0266 | Grad: 92898.938\n",
      "[Epoch 49, Batch 4/100] Loss: 0.0424 | RMSE: 0.0396 | Consistency: 0.0079 | SSIM: 0.0271 | Grad: 134087.016\n",
      "[Epoch 49, Batch 5/100] Loss: 0.0423 | RMSE: 0.0401 | Consistency: 0.0082 | SSIM: 0.0210 | Grad: 111069.039\n",
      "[Epoch 49, Batch 6/100] Loss: 0.0437 | RMSE: 0.0406 | Consistency: 0.0082 | SSIM: 0.0296 | Grad: 55357.844\n",
      "[Epoch 49, Batch 7/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0072 | SSIM: 0.0220 | Grad: 119565.945\n",
      "[Epoch 49, Batch 8/100] Loss: 0.0467 | RMSE: 0.0434 | Consistency: 0.0112 | SSIM: 0.0323 | Grad: 110861.438\n",
      "[Epoch 49, Batch 9/100] Loss: 0.0435 | RMSE: 0.0403 | Consistency: 0.0087 | SSIM: 0.0311 | Grad: 114713.125\n",
      "[Epoch 49, Batch 10/100] Loss: 0.0606 | RMSE: 0.0574 | Consistency: 0.0201 | SSIM: 0.0297 | Grad: 102211.398\n",
      "[Epoch 49, Batch 11/100] Loss: 0.0474 | RMSE: 0.0449 | Consistency: 0.0074 | SSIM: 0.0245 | Grad: 100347.961\n",
      "[Epoch 49, Batch 12/100] Loss: 0.0424 | RMSE: 0.0399 | Consistency: 0.0094 | SSIM: 0.0246 | Grad: 97953.906\n",
      "[Epoch 49, Batch 13/100] Loss: 0.0432 | RMSE: 0.0405 | Consistency: 0.0096 | SSIM: 0.0266 | Grad: 89686.109\n",
      "[Epoch 49, Batch 14/100] Loss: 0.0430 | RMSE: 0.0403 | Consistency: 0.0084 | SSIM: 0.0263 | Grad: 79672.617\n",
      "[Epoch 49, Batch 15/100] Loss: 0.0387 | RMSE: 0.0362 | Consistency: 0.0071 | SSIM: 0.0242 | Grad: 69455.984\n",
      "[Epoch 49, Batch 16/100] Loss: 0.0358 | RMSE: 0.0337 | Consistency: 0.0054 | SSIM: 0.0209 | Grad: 72085.242\n",
      "[Epoch 49, Batch 17/100] Loss: 0.0455 | RMSE: 0.0428 | Consistency: 0.0102 | SSIM: 0.0258 | Grad: 105515.070\n",
      "[Epoch 49, Batch 18/100] Loss: 0.0430 | RMSE: 0.0403 | Consistency: 0.0097 | SSIM: 0.0257 | Grad: 116437.578\n",
      "[Epoch 49, Batch 19/100] Loss: 0.0416 | RMSE: 0.0385 | Consistency: 0.0087 | SSIM: 0.0298 | Grad: 66342.094\n",
      "[Epoch 49, Batch 20/100] Loss: 0.0456 | RMSE: 0.0426 | Consistency: 0.0096 | SSIM: 0.0294 | Grad: 72612.758\n",
      "[Epoch 49, Batch 21/100] Loss: 0.0426 | RMSE: 0.0397 | Consistency: 0.0080 | SSIM: 0.0279 | Grad: 57161.949\n",
      "[Epoch 49, Batch 22/100] Loss: 0.0433 | RMSE: 0.0407 | Consistency: 0.0090 | SSIM: 0.0258 | Grad: 100200.078\n",
      "[Epoch 49, Batch 23/100] Loss: 0.0464 | RMSE: 0.0438 | Consistency: 0.0110 | SSIM: 0.0255 | Grad: 128073.773\n",
      "[Epoch 49, Batch 24/100] Loss: 0.0386 | RMSE: 0.0363 | Consistency: 0.0084 | SSIM: 0.0220 | Grad: 80921.703\n",
      "[Epoch 49, Batch 25/100] Loss: 0.0425 | RMSE: 0.0396 | Consistency: 0.0084 | SSIM: 0.0285 | Grad: 71716.094\n",
      "[Epoch 49, Batch 26/100] Loss: 0.0394 | RMSE: 0.0366 | Consistency: 0.0070 | SSIM: 0.0275 | Grad: 17921.379\n",
      "[Epoch 49, Batch 27/100] Loss: 0.0466 | RMSE: 0.0437 | Consistency: 0.0097 | SSIM: 0.0275 | Grad: 70312.891\n",
      "[Epoch 49, Batch 28/100] Loss: 0.0451 | RMSE: 0.0423 | Consistency: 0.0091 | SSIM: 0.0270 | Grad: 109428.867\n",
      "[Epoch 49, Batch 29/100] Loss: 0.0436 | RMSE: 0.0411 | Consistency: 0.0100 | SSIM: 0.0240 | Grad: 115951.312\n",
      "[Epoch 49, Batch 30/100] Loss: 0.0408 | RMSE: 0.0385 | Consistency: 0.0073 | SSIM: 0.0224 | Grad: 119743.977\n",
      "[Epoch 49, Batch 31/100] Loss: 0.0460 | RMSE: 0.0435 | Consistency: 0.0075 | SSIM: 0.0238 | Grad: 91896.133\n",
      "[Epoch 49, Batch 32/100] Loss: 0.0394 | RMSE: 0.0367 | Consistency: 0.0061 | SSIM: 0.0256 | Grad: 63598.125\n",
      "[Epoch 49, Batch 33/100] Loss: 0.0412 | RMSE: 0.0387 | Consistency: 0.0080 | SSIM: 0.0251 | Grad: 73568.281\n",
      "[Epoch 49, Batch 34/100] Loss: 0.0472 | RMSE: 0.0442 | Consistency: 0.0099 | SSIM: 0.0287 | Grad: 42300.273\n",
      "[Epoch 49, Batch 35/100] Loss: 0.0471 | RMSE: 0.0442 | Consistency: 0.0090 | SSIM: 0.0280 | Grad: 95219.359\n",
      "[Epoch 49, Batch 36/100] Loss: 0.0388 | RMSE: 0.0365 | Consistency: 0.0077 | SSIM: 0.0221 | Grad: 47045.875\n",
      "[Epoch 49, Batch 37/100] Loss: 0.0406 | RMSE: 0.0372 | Consistency: 0.0065 | SSIM: 0.0335 | Grad: 24321.398\n",
      "[Epoch 49, Batch 38/100] Loss: 0.0481 | RMSE: 0.0451 | Consistency: 0.0119 | SSIM: 0.0292 | Grad: 96298.234\n",
      "[Epoch 49, Batch 39/100] Loss: 0.0411 | RMSE: 0.0382 | Consistency: 0.0075 | SSIM: 0.0276 | Grad: 73244.367\n",
      "[Epoch 49, Batch 40/100] Loss: 0.0407 | RMSE: 0.0383 | Consistency: 0.0089 | SSIM: 0.0230 | Grad: 38918.207\n",
      "[Epoch 49, Batch 41/100] Loss: 0.0402 | RMSE: 0.0380 | Consistency: 0.0069 | SSIM: 0.0217 | Grad: 92968.633\n",
      "[Epoch 49, Batch 42/100] Loss: 0.0445 | RMSE: 0.0414 | Consistency: 0.0092 | SSIM: 0.0303 | Grad: 78697.867\n",
      "[Epoch 49, Batch 43/100] Loss: 0.0471 | RMSE: 0.0444 | Consistency: 0.0098 | SSIM: 0.0260 | Grad: 106607.391\n",
      "[Epoch 49, Batch 44/100] Loss: 0.0388 | RMSE: 0.0364 | Consistency: 0.0066 | SSIM: 0.0239 | Grad: 38502.004\n",
      "[Epoch 49, Batch 45/100] Loss: 0.0417 | RMSE: 0.0387 | Consistency: 0.0079 | SSIM: 0.0292 | Grad: 70434.320\n",
      "[Epoch 49, Batch 46/100] Loss: 0.0400 | RMSE: 0.0376 | Consistency: 0.0073 | SSIM: 0.0237 | Grad: 87989.250\n",
      "[Epoch 49, Batch 47/100] Loss: 0.0434 | RMSE: 0.0409 | Consistency: 0.0088 | SSIM: 0.0242 | Grad: 100910.781\n",
      "[Epoch 49, Batch 48/100] Loss: 0.0495 | RMSE: 0.0461 | Consistency: 0.0119 | SSIM: 0.0326 | Grad: 88920.828\n",
      "[Epoch 49, Batch 49/100] Loss: 0.0407 | RMSE: 0.0378 | Consistency: 0.0072 | SSIM: 0.0287 | Grad: 88493.719\n",
      "[Epoch 49, Batch 50/100] Loss: 0.0480 | RMSE: 0.0444 | Consistency: 0.0106 | SSIM: 0.0340 | Grad: 60343.820\n",
      "[Epoch 49, Batch 51/100] Loss: 0.0416 | RMSE: 0.0391 | Consistency: 0.0084 | SSIM: 0.0242 | Grad: 88085.609\n",
      "[Epoch 49, Batch 52/100] Loss: 0.0401 | RMSE: 0.0379 | Consistency: 0.0082 | SSIM: 0.0209 | Grad: 115753.922\n",
      "[Epoch 49, Batch 53/100] Loss: 0.0490 | RMSE: 0.0457 | Consistency: 0.0092 | SSIM: 0.0320 | Grad: 112933.375\n",
      "[Epoch 49, Batch 54/100] Loss: 0.0433 | RMSE: 0.0409 | Consistency: 0.0097 | SSIM: 0.0234 | Grad: 99599.586\n",
      "[Epoch 49, Batch 55/100] Loss: 0.0423 | RMSE: 0.0397 | Consistency: 0.0078 | SSIM: 0.0249 | Grad: 47811.355\n",
      "[Epoch 49, Batch 56/100] Loss: 0.0409 | RMSE: 0.0380 | Consistency: 0.0073 | SSIM: 0.0284 | Grad: 48497.254\n",
      "[Epoch 49, Batch 57/100] Loss: 0.0417 | RMSE: 0.0390 | Consistency: 0.0073 | SSIM: 0.0259 | Grad: 111478.047\n",
      "[Epoch 49, Batch 58/100] Loss: 0.0463 | RMSE: 0.0436 | Consistency: 0.0099 | SSIM: 0.0256 | Grad: 106287.758\n",
      "[Epoch 49, Batch 59/100] Loss: 0.0394 | RMSE: 0.0372 | Consistency: 0.0064 | SSIM: 0.0211 | Grad: 103994.164\n",
      "[Epoch 49, Batch 60/100] Loss: 0.0421 | RMSE: 0.0398 | Consistency: 0.0066 | SSIM: 0.0224 | Grad: 82785.766\n",
      "[Epoch 49, Batch 61/100] Loss: 0.0465 | RMSE: 0.0434 | Consistency: 0.0091 | SSIM: 0.0306 | Grad: 52531.164\n",
      "[Epoch 49, Batch 62/100] Loss: 0.0429 | RMSE: 0.0395 | Consistency: 0.0088 | SSIM: 0.0337 | Grad: 88863.805\n",
      "[Epoch 49, Batch 63/100] Loss: 0.0478 | RMSE: 0.0443 | Consistency: 0.0094 | SSIM: 0.0339 | Grad: 113414.555\n",
      "[Epoch 49, Batch 64/100] Loss: 0.0456 | RMSE: 0.0427 | Consistency: 0.0087 | SSIM: 0.0284 | Grad: 104320.758\n",
      "[Epoch 49, Batch 65/100] Loss: 0.0485 | RMSE: 0.0450 | Consistency: 0.0117 | SSIM: 0.0339 | Grad: 124332.773\n",
      "[Epoch 49, Batch 66/100] Loss: 0.0435 | RMSE: 0.0404 | Consistency: 0.0115 | SSIM: 0.0300 | Grad: 67234.688\n",
      "[Epoch 49, Batch 67/100] Loss: 0.0440 | RMSE: 0.0415 | Consistency: 0.0087 | SSIM: 0.0244 | Grad: 120213.281\n",
      "[Epoch 49, Batch 68/100] Loss: 0.0463 | RMSE: 0.0430 | Consistency: 0.0095 | SSIM: 0.0319 | Grad: 114583.359\n",
      "[Epoch 49, Batch 69/100] Loss: 0.0419 | RMSE: 0.0395 | Consistency: 0.0086 | SSIM: 0.0232 | Grad: 123711.414\n",
      "[Epoch 49, Batch 70/100] Loss: 0.0489 | RMSE: 0.0461 | Consistency: 0.0119 | SSIM: 0.0271 | Grad: 138196.703\n",
      "[Epoch 49, Batch 71/100] Loss: 0.0416 | RMSE: 0.0387 | Consistency: 0.0083 | SSIM: 0.0282 | Grad: 74447.141\n",
      "[Epoch 49, Batch 72/100] Loss: 0.0381 | RMSE: 0.0358 | Consistency: 0.0071 | SSIM: 0.0228 | Grad: 67784.906\n",
      "[Epoch 49, Batch 73/100] Loss: 0.0433 | RMSE: 0.0404 | Consistency: 0.0074 | SSIM: 0.0289 | Grad: 95610.234\n",
      "[Epoch 49, Batch 74/100] Loss: 0.0417 | RMSE: 0.0395 | Consistency: 0.0084 | SSIM: 0.0207 | Grad: 123030.258\n",
      "[Epoch 49, Batch 75/100] Loss: 0.0368 | RMSE: 0.0343 | Consistency: 0.0066 | SSIM: 0.0247 | Grad: 111433.078\n",
      "[Epoch 49, Batch 76/100] Loss: 0.0378 | RMSE: 0.0355 | Consistency: 0.0054 | SSIM: 0.0229 | Grad: 86450.039\n",
      "[Epoch 49, Batch 77/100] Loss: 0.0365 | RMSE: 0.0338 | Consistency: 0.0062 | SSIM: 0.0265 | Grad: 47470.332\n",
      "[Epoch 49, Batch 78/100] Loss: 0.0427 | RMSE: 0.0401 | Consistency: 0.0087 | SSIM: 0.0250 | Grad: 110252.773\n",
      "[Epoch 49, Batch 79/100] Loss: 0.0397 | RMSE: 0.0372 | Consistency: 0.0070 | SSIM: 0.0237 | Grad: 62803.980\n",
      "[Epoch 49, Batch 80/100] Loss: 0.0379 | RMSE: 0.0350 | Consistency: 0.0058 | SSIM: 0.0289 | Grad: 16602.049\n",
      "[Epoch 49, Batch 81/100] Loss: 0.0417 | RMSE: 0.0390 | Consistency: 0.0065 | SSIM: 0.0260 | Grad: 84077.820\n",
      "[Epoch 49, Batch 82/100] Loss: 0.0445 | RMSE: 0.0419 | Consistency: 0.0089 | SSIM: 0.0260 | Grad: 66605.352\n",
      "[Epoch 49, Batch 83/100] Loss: 0.0419 | RMSE: 0.0395 | Consistency: 0.0088 | SSIM: 0.0234 | Grad: 113010.680\n",
      "[Epoch 49, Batch 84/100] Loss: 0.0419 | RMSE: 0.0392 | Consistency: 0.0084 | SSIM: 0.0260 | Grad: 59590.246\n",
      "[Epoch 49, Batch 85/100] Loss: 0.0434 | RMSE: 0.0408 | Consistency: 0.0080 | SSIM: 0.0250 | Grad: 79826.016\n",
      "[Epoch 49, Batch 86/100] Loss: 0.0452 | RMSE: 0.0417 | Consistency: 0.0101 | SSIM: 0.0337 | Grad: 84061.500\n",
      "[Epoch 49, Batch 87/100] Loss: 0.0453 | RMSE: 0.0423 | Consistency: 0.0091 | SSIM: 0.0289 | Grad: 53878.266\n",
      "[Epoch 49, Batch 88/100] Loss: 0.0410 | RMSE: 0.0387 | Consistency: 0.0067 | SSIM: 0.0227 | Grad: 92014.914\n",
      "[Epoch 49, Batch 89/100] Loss: 0.0423 | RMSE: 0.0395 | Consistency: 0.0066 | SSIM: 0.0266 | Grad: 120314.547\n",
      "[Epoch 49, Batch 90/100] Loss: 0.0408 | RMSE: 0.0378 | Consistency: 0.0063 | SSIM: 0.0285 | Grad: 135563.516\n",
      "[Epoch 49, Batch 91/100] Loss: 0.0391 | RMSE: 0.0367 | Consistency: 0.0065 | SSIM: 0.0234 | Grad: 105251.508\n",
      "[Epoch 49, Batch 92/100] Loss: 0.0454 | RMSE: 0.0425 | Consistency: 0.0093 | SSIM: 0.0276 | Grad: 108680.992\n",
      "[Epoch 49, Batch 93/100] Loss: 0.0351 | RMSE: 0.0331 | Consistency: 0.0049 | SSIM: 0.0192 | Grad: 95498.453\n",
      "[Epoch 49, Batch 94/100] Loss: 0.0420 | RMSE: 0.0388 | Consistency: 0.0077 | SSIM: 0.0311 | Grad: 102307.016\n",
      "[Epoch 49, Batch 95/100] Loss: 0.0481 | RMSE: 0.0448 | Consistency: 0.0087 | SSIM: 0.0325 | Grad: 120053.570\n",
      "[Epoch 49, Batch 96/100] Loss: 0.0402 | RMSE: 0.0380 | Consistency: 0.0066 | SSIM: 0.0215 | Grad: 116233.516\n",
      "[Epoch 49, Batch 97/100] Loss: 0.0541 | RMSE: 0.0510 | Consistency: 0.0099 | SSIM: 0.0300 | Grad: 104172.469\n",
      "[Epoch 49, Batch 98/100] Loss: 0.0425 | RMSE: 0.0396 | Consistency: 0.0081 | SSIM: 0.0287 | Grad: 36041.199\n",
      "[Epoch 49, Batch 99/100] Loss: 0.0386 | RMSE: 0.0359 | Consistency: 0.0084 | SSIM: 0.0257 | Grad: 65487.586\n",
      "[Epoch 49, Batch 100/100] Loss: 0.0379 | RMSE: 0.0358 | Consistency: 0.0062 | SSIM: 0.0206 | Grad: 76270.906\n",
      "✅ Epoch 49 완료!\n",
      "   📈 평균 Loss: 0.042982\n",
      "   📊 평균 RMSE: 0.040241\n",
      "   ⚙️  학습률: 0.000392\n",
      "   🏆 NEW BEST! RMSE: 0.040241\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 50/80 시작...\n",
      "[Epoch 50, Batch 1/100] Loss: 0.0456 | RMSE: 0.0425 | Consistency: 0.0093 | SSIM: 0.0296 | Grad: 141793.469\n",
      "[Epoch 50, Batch 2/100] Loss: 0.0480 | RMSE: 0.0451 | Consistency: 0.0114 | SSIM: 0.0285 | Grad: 77984.125\n",
      "[Epoch 50, Batch 3/100] Loss: 0.0424 | RMSE: 0.0402 | Consistency: 0.0088 | SSIM: 0.0219 | Grad: 79127.602\n",
      "[Epoch 50, Batch 4/100] Loss: 0.0386 | RMSE: 0.0363 | Consistency: 0.0074 | SSIM: 0.0226 | Grad: 36035.117\n",
      "[Epoch 50, Batch 5/100] Loss: 0.0511 | RMSE: 0.0479 | Consistency: 0.0131 | SSIM: 0.0302 | Grad: 62369.434\n",
      "[Epoch 50, Batch 6/100] Loss: 0.0489 | RMSE: 0.0456 | Consistency: 0.0101 | SSIM: 0.0319 | Grad: 119837.445\n",
      "[Epoch 50, Batch 7/100] Loss: 0.0439 | RMSE: 0.0411 | Consistency: 0.0082 | SSIM: 0.0268 | Grad: 106867.352\n",
      "[Epoch 50, Batch 8/100] Loss: 0.0420 | RMSE: 0.0388 | Consistency: 0.0087 | SSIM: 0.0308 | Grad: 62775.293\n",
      "[Epoch 50, Batch 9/100] Loss: 0.0421 | RMSE: 0.0392 | Consistency: 0.0072 | SSIM: 0.0280 | Grad: 75127.367\n",
      "[Epoch 50, Batch 10/100] Loss: 0.0445 | RMSE: 0.0418 | Consistency: 0.0081 | SSIM: 0.0261 | Grad: 120635.555\n",
      "[Epoch 50, Batch 11/100] Loss: 0.0506 | RMSE: 0.0469 | Consistency: 0.0107 | SSIM: 0.0360 | Grad: 118807.164\n",
      "[Epoch 50, Batch 12/100] Loss: 0.0477 | RMSE: 0.0446 | Consistency: 0.0108 | SSIM: 0.0301 | Grad: 139376.234\n",
      "[Epoch 50, Batch 13/100] Loss: 0.0407 | RMSE: 0.0381 | Consistency: 0.0072 | SSIM: 0.0250 | Grad: 114950.117\n",
      "[Epoch 50, Batch 14/100] Loss: 0.0393 | RMSE: 0.0368 | Consistency: 0.0072 | SSIM: 0.0245 | Grad: 74472.773\n",
      "[Epoch 50, Batch 15/100] Loss: 0.0409 | RMSE: 0.0383 | Consistency: 0.0065 | SSIM: 0.0260 | Grad: 143659.141\n",
      "[Epoch 50, Batch 16/100] Loss: 0.0428 | RMSE: 0.0398 | Consistency: 0.0084 | SSIM: 0.0286 | Grad: 85173.305\n",
      "[Epoch 50, Batch 17/100] Loss: 0.0397 | RMSE: 0.0376 | Consistency: 0.0071 | SSIM: 0.0201 | Grad: 104132.680\n",
      "[Epoch 50, Batch 18/100] Loss: 0.0411 | RMSE: 0.0382 | Consistency: 0.0087 | SSIM: 0.0279 | Grad: 100490.906\n",
      "[Epoch 50, Batch 19/100] Loss: 0.0442 | RMSE: 0.0419 | Consistency: 0.0068 | SSIM: 0.0224 | Grad: 64989.234\n",
      "[Epoch 50, Batch 20/100] Loss: 0.0330 | RMSE: 0.0313 | Consistency: 0.0054 | SSIM: 0.0161 | Grad: 45928.031\n",
      "[Epoch 50, Batch 21/100] Loss: 0.0385 | RMSE: 0.0358 | Consistency: 0.0084 | SSIM: 0.0267 | Grad: 46357.855\n",
      "[Epoch 50, Batch 22/100] Loss: 0.0390 | RMSE: 0.0368 | Consistency: 0.0075 | SSIM: 0.0213 | Grad: 53559.723\n",
      "[Epoch 50, Batch 23/100] Loss: 0.0404 | RMSE: 0.0376 | Consistency: 0.0086 | SSIM: 0.0273 | Grad: 66572.758\n",
      "[Epoch 50, Batch 24/100] Loss: 0.0454 | RMSE: 0.0420 | Consistency: 0.0095 | SSIM: 0.0330 | Grad: 39201.363\n",
      "[Epoch 50, Batch 25/100] Loss: 0.0383 | RMSE: 0.0351 | Consistency: 0.0072 | SSIM: 0.0305 | Grad: 51195.273\n",
      "[Epoch 50, Batch 26/100] Loss: 0.0327 | RMSE: 0.0304 | Consistency: 0.0051 | SSIM: 0.0219 | Grad: 63259.664\n",
      "[Epoch 50, Batch 27/100] Loss: 0.0425 | RMSE: 0.0395 | Consistency: 0.0083 | SSIM: 0.0284 | Grad: 43621.078\n",
      "[Epoch 50, Batch 28/100] Loss: 0.0387 | RMSE: 0.0360 | Consistency: 0.0080 | SSIM: 0.0263 | Grad: 69825.625\n",
      "[Epoch 50, Batch 29/100] Loss: 0.0395 | RMSE: 0.0370 | Consistency: 0.0077 | SSIM: 0.0243 | Grad: 102590.695\n",
      "[Epoch 50, Batch 30/100] Loss: 0.0410 | RMSE: 0.0383 | Consistency: 0.0082 | SSIM: 0.0266 | Grad: 38426.789\n",
      "[Epoch 50, Batch 31/100] Loss: 0.0430 | RMSE: 0.0406 | Consistency: 0.0090 | SSIM: 0.0235 | Grad: 23551.783\n",
      "[Epoch 50, Batch 32/100] Loss: 0.0404 | RMSE: 0.0377 | Consistency: 0.0086 | SSIM: 0.0262 | Grad: 44934.992\n",
      "[Epoch 50, Batch 33/100] Loss: 0.0402 | RMSE: 0.0374 | Consistency: 0.0079 | SSIM: 0.0268 | Grad: 74460.469\n",
      "[Epoch 50, Batch 34/100] Loss: 0.0431 | RMSE: 0.0406 | Consistency: 0.0094 | SSIM: 0.0237 | Grad: 95539.617\n",
      "[Epoch 50, Batch 35/100] Loss: 0.0482 | RMSE: 0.0447 | Consistency: 0.0114 | SSIM: 0.0335 | Grad: 136183.500\n",
      "[Epoch 50, Batch 36/100] Loss: 0.0512 | RMSE: 0.0480 | Consistency: 0.0107 | SSIM: 0.0309 | Grad: 97012.766\n",
      "[Epoch 50, Batch 37/100] Loss: 0.0381 | RMSE: 0.0354 | Consistency: 0.0071 | SSIM: 0.0256 | Grad: 58017.965\n",
      "[Epoch 50, Batch 38/100] Loss: 0.0526 | RMSE: 0.0489 | Consistency: 0.0120 | SSIM: 0.0357 | Grad: 94313.117\n",
      "[Epoch 50, Batch 39/100] Loss: 0.0422 | RMSE: 0.0394 | Consistency: 0.0080 | SSIM: 0.0271 | Grad: 98602.367\n",
      "[Epoch 50, Batch 40/100] Loss: 0.0482 | RMSE: 0.0458 | Consistency: 0.0083 | SSIM: 0.0232 | Grad: 126807.594\n",
      "[Epoch 50, Batch 41/100] Loss: 0.0403 | RMSE: 0.0380 | Consistency: 0.0071 | SSIM: 0.0225 | Grad: 61793.297\n",
      "[Epoch 50, Batch 42/100] Loss: 0.0393 | RMSE: 0.0360 | Consistency: 0.0075 | SSIM: 0.0328 | Grad: 37276.820\n",
      "[Epoch 50, Batch 43/100] Loss: 0.0430 | RMSE: 0.0400 | Consistency: 0.0107 | SSIM: 0.0294 | Grad: 54977.027\n",
      "[Epoch 50, Batch 44/100] Loss: 0.0420 | RMSE: 0.0396 | Consistency: 0.0083 | SSIM: 0.0224 | Grad: 89908.227\n",
      "[Epoch 50, Batch 45/100] Loss: 0.0460 | RMSE: 0.0430 | Consistency: 0.0099 | SSIM: 0.0283 | Grad: 79588.164\n",
      "[Epoch 50, Batch 46/100] Loss: 0.0487 | RMSE: 0.0456 | Consistency: 0.0108 | SSIM: 0.0293 | Grad: 88354.555\n",
      "[Epoch 50, Batch 47/100] Loss: 0.0443 | RMSE: 0.0415 | Consistency: 0.0091 | SSIM: 0.0272 | Grad: 73827.977\n",
      "[Epoch 50, Batch 48/100] Loss: 0.0392 | RMSE: 0.0367 | Consistency: 0.0077 | SSIM: 0.0242 | Grad: 74889.633\n",
      "[Epoch 50, Batch 49/100] Loss: 0.0384 | RMSE: 0.0356 | Consistency: 0.0068 | SSIM: 0.0276 | Grad: 40014.293\n",
      "[Epoch 50, Batch 50/100] Loss: 0.0430 | RMSE: 0.0398 | Consistency: 0.0093 | SSIM: 0.0310 | Grad: 63826.953\n",
      "[Epoch 50, Batch 51/100] Loss: 0.0351 | RMSE: 0.0332 | Consistency: 0.0057 | SSIM: 0.0186 | Grad: 80555.664\n",
      "[Epoch 50, Batch 52/100] Loss: 0.0371 | RMSE: 0.0350 | Consistency: 0.0070 | SSIM: 0.0198 | Grad: 19518.275\n",
      "[Epoch 50, Batch 53/100] Loss: 0.0388 | RMSE: 0.0363 | Consistency: 0.0064 | SSIM: 0.0252 | Grad: 70798.219\n",
      "[Epoch 50, Batch 54/100] Loss: 0.0377 | RMSE: 0.0351 | Consistency: 0.0068 | SSIM: 0.0250 | Grad: 26917.568\n",
      "[Epoch 50, Batch 55/100] Loss: 0.0406 | RMSE: 0.0379 | Consistency: 0.0081 | SSIM: 0.0258 | Grad: 59691.199\n",
      "[Epoch 50, Batch 56/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0069 | SSIM: 0.0237 | Grad: 37662.469\n",
      "[Epoch 50, Batch 57/100] Loss: 0.0475 | RMSE: 0.0443 | Consistency: 0.0092 | SSIM: 0.0311 | Grad: 118213.758\n",
      "[Epoch 50, Batch 58/100] Loss: 0.0390 | RMSE: 0.0367 | Consistency: 0.0078 | SSIM: 0.0220 | Grad: 99332.867\n",
      "[Epoch 50, Batch 59/100] Loss: 0.0382 | RMSE: 0.0356 | Consistency: 0.0069 | SSIM: 0.0257 | Grad: 82391.109\n",
      "[Epoch 50, Batch 60/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0080 | SSIM: 0.0239 | Grad: 76965.164\n",
      "[Epoch 50, Batch 61/100] Loss: 0.0377 | RMSE: 0.0348 | Consistency: 0.0076 | SSIM: 0.0288 | Grad: 59290.449\n",
      "[Epoch 50, Batch 62/100] Loss: 0.0425 | RMSE: 0.0398 | Consistency: 0.0070 | SSIM: 0.0264 | Grad: 61353.426\n",
      "[Epoch 50, Batch 63/100] Loss: 0.0417 | RMSE: 0.0396 | Consistency: 0.0059 | SSIM: 0.0213 | Grad: 100040.219\n",
      "[Epoch 50, Batch 64/100] Loss: 0.0406 | RMSE: 0.0383 | Consistency: 0.0070 | SSIM: 0.0229 | Grad: 131829.641\n",
      "[Epoch 50, Batch 65/100] Loss: 0.0353 | RMSE: 0.0331 | Consistency: 0.0058 | SSIM: 0.0216 | Grad: 101779.469\n",
      "[Epoch 50, Batch 66/100] Loss: 0.0432 | RMSE: 0.0402 | Consistency: 0.0080 | SSIM: 0.0289 | Grad: 72322.000\n",
      "[Epoch 50, Batch 67/100] Loss: 0.0372 | RMSE: 0.0351 | Consistency: 0.0067 | SSIM: 0.0206 | Grad: 73021.141\n",
      "[Epoch 50, Batch 68/100] Loss: 0.0464 | RMSE: 0.0434 | Consistency: 0.0075 | SSIM: 0.0289 | Grad: 138244.938\n",
      "[Epoch 50, Batch 69/100] Loss: 0.0408 | RMSE: 0.0386 | Consistency: 0.0070 | SSIM: 0.0216 | Grad: 128544.570\n",
      "[Epoch 50, Batch 70/100] Loss: 0.0400 | RMSE: 0.0373 | Consistency: 0.0078 | SSIM: 0.0266 | Grad: 90927.766\n",
      "[Epoch 50, Batch 71/100] Loss: 0.0442 | RMSE: 0.0413 | Consistency: 0.0121 | SSIM: 0.0274 | Grad: 96533.203\n",
      "[Epoch 50, Batch 72/100] Loss: 0.0451 | RMSE: 0.0416 | Consistency: 0.0112 | SSIM: 0.0339 | Grad: 89757.727\n",
      "[Epoch 50, Batch 73/100] Loss: 0.0353 | RMSE: 0.0331 | Consistency: 0.0063 | SSIM: 0.0214 | Grad: 69219.930\n",
      "[Epoch 50, Batch 74/100] Loss: 0.0397 | RMSE: 0.0370 | Consistency: 0.0062 | SSIM: 0.0266 | Grad: 108676.852\n",
      "[Epoch 50, Batch 75/100] Loss: 0.0400 | RMSE: 0.0367 | Consistency: 0.0080 | SSIM: 0.0328 | Grad: 82161.242\n",
      "[Epoch 50, Batch 76/100] Loss: 0.0386 | RMSE: 0.0360 | Consistency: 0.0077 | SSIM: 0.0253 | Grad: 85008.227\n",
      "[Epoch 50, Batch 77/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0075 | SSIM: 0.0248 | Grad: 99863.562\n",
      "[Epoch 50, Batch 78/100] Loss: 0.0564 | RMSE: 0.0528 | Consistency: 0.0162 | SSIM: 0.0343 | Grad: 55279.074\n",
      "[Epoch 50, Batch 79/100] Loss: 0.0389 | RMSE: 0.0364 | Consistency: 0.0073 | SSIM: 0.0242 | Grad: 81710.750\n",
      "[Epoch 50, Batch 80/100] Loss: 0.0436 | RMSE: 0.0413 | Consistency: 0.0079 | SSIM: 0.0224 | Grad: 61462.164\n",
      "[Epoch 50, Batch 81/100] Loss: 0.0424 | RMSE: 0.0398 | Consistency: 0.0067 | SSIM: 0.0251 | Grad: 57448.449\n",
      "[Epoch 50, Batch 82/100] Loss: 0.0367 | RMSE: 0.0346 | Consistency: 0.0064 | SSIM: 0.0208 | Grad: 53264.703\n",
      "[Epoch 50, Batch 83/100] Loss: 0.0376 | RMSE: 0.0351 | Consistency: 0.0075 | SSIM: 0.0242 | Grad: 49473.883\n",
      "[Epoch 50, Batch 84/100] Loss: 0.0397 | RMSE: 0.0368 | Consistency: 0.0076 | SSIM: 0.0279 | Grad: 57568.445\n",
      "[Epoch 50, Batch 85/100] Loss: 0.0381 | RMSE: 0.0355 | Consistency: 0.0066 | SSIM: 0.0255 | Grad: 117210.750\n",
      "[Epoch 50, Batch 86/100] Loss: 0.0463 | RMSE: 0.0432 | Consistency: 0.0113 | SSIM: 0.0298 | Grad: 119363.094\n",
      "[Epoch 50, Batch 87/100] Loss: 0.0387 | RMSE: 0.0365 | Consistency: 0.0067 | SSIM: 0.0215 | Grad: 96870.555\n",
      "[Epoch 50, Batch 88/100] Loss: 0.0417 | RMSE: 0.0388 | Consistency: 0.0082 | SSIM: 0.0286 | Grad: 74702.742\n",
      "[Epoch 50, Batch 89/100] Loss: 0.0403 | RMSE: 0.0376 | Consistency: 0.0065 | SSIM: 0.0266 | Grad: 53936.918\n",
      "[Epoch 50, Batch 90/100] Loss: 0.0429 | RMSE: 0.0397 | Consistency: 0.0083 | SSIM: 0.0305 | Grad: 121514.758\n",
      "[Epoch 50, Batch 91/100] Loss: 0.0446 | RMSE: 0.0419 | Consistency: 0.0085 | SSIM: 0.0259 | Grad: 130764.062\n",
      "[Epoch 50, Batch 92/100] Loss: 0.0462 | RMSE: 0.0434 | Consistency: 0.0079 | SSIM: 0.0271 | Grad: 133735.484\n",
      "[Epoch 50, Batch 93/100] Loss: 0.0430 | RMSE: 0.0404 | Consistency: 0.0074 | SSIM: 0.0253 | Grad: 123258.383\n",
      "[Epoch 50, Batch 94/100] Loss: 0.0459 | RMSE: 0.0429 | Consistency: 0.0107 | SSIM: 0.0282 | Grad: 124173.039\n",
      "[Epoch 50, Batch 95/100] Loss: 0.0376 | RMSE: 0.0352 | Consistency: 0.0076 | SSIM: 0.0238 | Grad: 39282.996\n",
      "[Epoch 50, Batch 96/100] Loss: 0.0408 | RMSE: 0.0385 | Consistency: 0.0071 | SSIM: 0.0229 | Grad: 106924.086\n",
      "[Epoch 50, Batch 97/100] Loss: 0.0497 | RMSE: 0.0466 | Consistency: 0.0117 | SSIM: 0.0293 | Grad: 152747.656\n",
      "[Epoch 50, Batch 98/100] Loss: 0.0453 | RMSE: 0.0426 | Consistency: 0.0086 | SSIM: 0.0252 | Grad: 150383.484\n",
      "[Epoch 50, Batch 99/100] Loss: 0.0460 | RMSE: 0.0432 | Consistency: 0.0097 | SSIM: 0.0275 | Grad: 118293.703\n",
      "[Epoch 50, Batch 100/100] Loss: 0.0374 | RMSE: 0.0352 | Consistency: 0.0062 | SSIM: 0.0219 | Grad: 132620.938\n",
      "✅ Epoch 50 완료!\n",
      "   📈 평균 Loss: 0.041952\n",
      "   📊 평균 RMSE: 0.039240\n",
      "   ⚙️  학습률: 0.000370\n",
      "   🏆 NEW BEST! RMSE: 0.039240\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 51/80 시작...\n",
      "[Epoch 51, Batch 1/100] Loss: 0.0533 | RMSE: 0.0499 | Consistency: 0.0165 | SSIM: 0.0325 | Grad: 37915.684\n",
      "[Epoch 51, Batch 2/100] Loss: 0.0467 | RMSE: 0.0437 | Consistency: 0.0110 | SSIM: 0.0289 | Grad: 82690.539\n",
      "[Epoch 51, Batch 3/100] Loss: 0.0417 | RMSE: 0.0393 | Consistency: 0.0079 | SSIM: 0.0225 | Grad: 81432.188\n",
      "[Epoch 51, Batch 4/100] Loss: 0.0452 | RMSE: 0.0423 | Consistency: 0.0089 | SSIM: 0.0276 | Grad: 92547.719\n",
      "[Epoch 51, Batch 5/100] Loss: 0.0414 | RMSE: 0.0385 | Consistency: 0.0077 | SSIM: 0.0277 | Grad: 64224.930\n",
      "[Epoch 51, Batch 6/100] Loss: 0.0423 | RMSE: 0.0391 | Consistency: 0.0090 | SSIM: 0.0310 | Grad: 83373.938\n",
      "[Epoch 51, Batch 7/100] Loss: 0.0391 | RMSE: 0.0369 | Consistency: 0.0083 | SSIM: 0.0215 | Grad: 41856.863\n",
      "[Epoch 51, Batch 8/100] Loss: 0.0355 | RMSE: 0.0330 | Consistency: 0.0059 | SSIM: 0.0241 | Grad: 74354.109\n",
      "[Epoch 51, Batch 9/100] Loss: 0.0427 | RMSE: 0.0404 | Consistency: 0.0064 | SSIM: 0.0228 | Grad: 77701.055\n",
      "[Epoch 51, Batch 10/100] Loss: 0.0417 | RMSE: 0.0388 | Consistency: 0.0078 | SSIM: 0.0274 | Grad: 104522.344\n",
      "[Epoch 51, Batch 11/100] Loss: 0.0405 | RMSE: 0.0380 | Consistency: 0.0063 | SSIM: 0.0236 | Grad: 65826.977\n",
      "[Epoch 51, Batch 12/100] Loss: 0.0409 | RMSE: 0.0377 | Consistency: 0.0069 | SSIM: 0.0308 | Grad: 70059.648\n",
      "[Epoch 51, Batch 13/100] Loss: 0.0366 | RMSE: 0.0341 | Consistency: 0.0056 | SSIM: 0.0245 | Grad: 44281.363\n",
      "[Epoch 51, Batch 14/100] Loss: 0.0405 | RMSE: 0.0378 | Consistency: 0.0076 | SSIM: 0.0266 | Grad: 41424.801\n",
      "[Epoch 51, Batch 15/100] Loss: 0.0497 | RMSE: 0.0466 | Consistency: 0.0122 | SSIM: 0.0299 | Grad: 68328.188\n",
      "[Epoch 51, Batch 16/100] Loss: 0.0375 | RMSE: 0.0351 | Consistency: 0.0066 | SSIM: 0.0236 | Grad: 101429.352\n",
      "[Epoch 51, Batch 17/100] Loss: 0.0421 | RMSE: 0.0390 | Consistency: 0.0082 | SSIM: 0.0306 | Grad: 82494.203\n",
      "[Epoch 51, Batch 18/100] Loss: 0.0461 | RMSE: 0.0425 | Consistency: 0.0088 | SSIM: 0.0344 | Grad: 73914.422\n",
      "[Epoch 51, Batch 19/100] Loss: 0.0438 | RMSE: 0.0406 | Consistency: 0.0092 | SSIM: 0.0314 | Grad: 20951.643\n",
      "[Epoch 51, Batch 20/100] Loss: 0.0398 | RMSE: 0.0375 | Consistency: 0.0061 | SSIM: 0.0221 | Grad: 78044.602\n",
      "[Epoch 51, Batch 21/100] Loss: 0.0406 | RMSE: 0.0379 | Consistency: 0.0078 | SSIM: 0.0266 | Grad: 141441.734\n",
      "[Epoch 51, Batch 22/100] Loss: 0.0436 | RMSE: 0.0412 | Consistency: 0.0076 | SSIM: 0.0229 | Grad: 48665.582\n",
      "[Epoch 51, Batch 23/100] Loss: 0.0424 | RMSE: 0.0397 | Consistency: 0.0073 | SSIM: 0.0259 | Grad: 60802.941\n",
      "[Epoch 51, Batch 24/100] Loss: 0.0444 | RMSE: 0.0409 | Consistency: 0.0095 | SSIM: 0.0342 | Grad: 61102.266\n",
      "[Epoch 51, Batch 25/100] Loss: 0.0412 | RMSE: 0.0390 | Consistency: 0.0083 | SSIM: 0.0207 | Grad: 87446.797\n",
      "[Epoch 51, Batch 26/100] Loss: 0.0383 | RMSE: 0.0358 | Consistency: 0.0070 | SSIM: 0.0238 | Grad: 90048.086\n",
      "[Epoch 51, Batch 27/100] Loss: 0.0439 | RMSE: 0.0414 | Consistency: 0.0082 | SSIM: 0.0246 | Grad: 125630.797\n",
      "[Epoch 51, Batch 28/100] Loss: 0.0393 | RMSE: 0.0369 | Consistency: 0.0062 | SSIM: 0.0234 | Grad: 116158.531\n",
      "[Epoch 51, Batch 29/100] Loss: 0.0466 | RMSE: 0.0435 | Consistency: 0.0085 | SSIM: 0.0295 | Grad: 68439.430\n",
      "[Epoch 51, Batch 30/100] Loss: 0.0566 | RMSE: 0.0531 | Consistency: 0.0127 | SSIM: 0.0346 | Grad: 68157.445\n",
      "[Epoch 51, Batch 31/100] Loss: 0.0373 | RMSE: 0.0349 | Consistency: 0.0061 | SSIM: 0.0238 | Grad: 115449.984\n",
      "[Epoch 51, Batch 32/100] Loss: 0.0407 | RMSE: 0.0383 | Consistency: 0.0075 | SSIM: 0.0239 | Grad: 87927.711\n",
      "[Epoch 51, Batch 33/100] Loss: 0.0441 | RMSE: 0.0408 | Consistency: 0.0090 | SSIM: 0.0318 | Grad: 90440.609\n",
      "[Epoch 51, Batch 34/100] Loss: 0.0375 | RMSE: 0.0351 | Consistency: 0.0063 | SSIM: 0.0236 | Grad: 59031.070\n",
      "[Epoch 51, Batch 35/100] Loss: 0.0398 | RMSE: 0.0370 | Consistency: 0.0085 | SSIM: 0.0268 | Grad: 71880.148\n",
      "[Epoch 51, Batch 36/100] Loss: 0.0453 | RMSE: 0.0423 | Consistency: 0.0099 | SSIM: 0.0297 | Grad: 103481.086\n",
      "[Epoch 51, Batch 37/100] Loss: 0.0425 | RMSE: 0.0398 | Consistency: 0.0095 | SSIM: 0.0269 | Grad: 71708.602\n",
      "[Epoch 51, Batch 38/100] Loss: 0.0410 | RMSE: 0.0380 | Consistency: 0.0066 | SSIM: 0.0293 | Grad: 59681.160\n",
      "[Epoch 51, Batch 39/100] Loss: 0.0408 | RMSE: 0.0380 | Consistency: 0.0082 | SSIM: 0.0268 | Grad: 37770.309\n",
      "[Epoch 51, Batch 40/100] Loss: 0.0414 | RMSE: 0.0383 | Consistency: 0.0074 | SSIM: 0.0300 | Grad: 113335.500\n",
      "[Epoch 51, Batch 41/100] Loss: 0.0550 | RMSE: 0.0519 | Consistency: 0.0148 | SSIM: 0.0289 | Grad: 138246.688\n",
      "[Epoch 51, Batch 42/100] Loss: 0.0435 | RMSE: 0.0408 | Consistency: 0.0093 | SSIM: 0.0263 | Grad: 121110.422\n",
      "[Epoch 51, Batch 43/100] Loss: 0.0381 | RMSE: 0.0358 | Consistency: 0.0070 | SSIM: 0.0218 | Grad: 103378.031\n",
      "[Epoch 51, Batch 44/100] Loss: 0.0401 | RMSE: 0.0378 | Consistency: 0.0068 | SSIM: 0.0223 | Grad: 98850.031\n",
      "[Epoch 51, Batch 45/100] Loss: 0.0435 | RMSE: 0.0409 | Consistency: 0.0087 | SSIM: 0.0258 | Grad: 123124.070\n",
      "[Epoch 51, Batch 46/100] Loss: 0.0528 | RMSE: 0.0495 | Consistency: 0.0119 | SSIM: 0.0326 | Grad: 47154.844\n",
      "[Epoch 51, Batch 47/100] Loss: 0.0507 | RMSE: 0.0474 | Consistency: 0.0094 | SSIM: 0.0324 | Grad: 119148.781\n",
      "[Epoch 51, Batch 48/100] Loss: 0.0381 | RMSE: 0.0357 | Consistency: 0.0060 | SSIM: 0.0232 | Grad: 106547.086\n",
      "[Epoch 51, Batch 49/100] Loss: 0.0464 | RMSE: 0.0432 | Consistency: 0.0087 | SSIM: 0.0311 | Grad: 103477.891\n",
      "[Epoch 51, Batch 50/100] Loss: 0.0457 | RMSE: 0.0429 | Consistency: 0.0098 | SSIM: 0.0271 | Grad: 84438.539\n",
      "[Epoch 51, Batch 51/100] Loss: 0.0406 | RMSE: 0.0383 | Consistency: 0.0066 | SSIM: 0.0227 | Grad: 121910.445\n",
      "[Epoch 51, Batch 52/100] Loss: 0.0407 | RMSE: 0.0383 | Consistency: 0.0075 | SSIM: 0.0241 | Grad: 84101.398\n",
      "[Epoch 51, Batch 53/100] Loss: 0.0462 | RMSE: 0.0431 | Consistency: 0.0103 | SSIM: 0.0304 | Grad: 116437.508\n",
      "[Epoch 51, Batch 54/100] Loss: 0.0458 | RMSE: 0.0426 | Consistency: 0.0093 | SSIM: 0.0314 | Grad: 141444.656\n",
      "[Epoch 51, Batch 55/100] Loss: 0.0455 | RMSE: 0.0427 | Consistency: 0.0091 | SSIM: 0.0269 | Grad: 112775.000\n",
      "[Epoch 51, Batch 56/100] Loss: 0.0400 | RMSE: 0.0378 | Consistency: 0.0056 | SSIM: 0.0213 | Grad: 91307.477\n",
      "[Epoch 51, Batch 57/100] Loss: 0.0438 | RMSE: 0.0408 | Consistency: 0.0086 | SSIM: 0.0290 | Grad: 83511.227\n",
      "[Epoch 51, Batch 58/100] Loss: 0.0353 | RMSE: 0.0329 | Consistency: 0.0056 | SSIM: 0.0230 | Grad: 51684.660\n",
      "[Epoch 51, Batch 59/100] Loss: 0.0374 | RMSE: 0.0350 | Consistency: 0.0070 | SSIM: 0.0232 | Grad: 88797.148\n",
      "[Epoch 51, Batch 60/100] Loss: 0.0452 | RMSE: 0.0429 | Consistency: 0.0084 | SSIM: 0.0225 | Grad: 137531.344\n",
      "[Epoch 51, Batch 61/100] Loss: 0.0380 | RMSE: 0.0351 | Consistency: 0.0061 | SSIM: 0.0284 | Grad: 68800.148\n",
      "[Epoch 51, Batch 62/100] Loss: 0.0446 | RMSE: 0.0419 | Consistency: 0.0092 | SSIM: 0.0263 | Grad: 108027.883\n",
      "[Epoch 51, Batch 63/100] Loss: 0.0398 | RMSE: 0.0373 | Consistency: 0.0075 | SSIM: 0.0241 | Grad: 70262.781\n",
      "[Epoch 51, Batch 64/100] Loss: 0.0397 | RMSE: 0.0368 | Consistency: 0.0063 | SSIM: 0.0291 | Grad: 80151.547\n",
      "[Epoch 51, Batch 65/100] Loss: 0.0387 | RMSE: 0.0356 | Consistency: 0.0077 | SSIM: 0.0302 | Grad: 42294.301\n",
      "[Epoch 51, Batch 66/100] Loss: 0.0391 | RMSE: 0.0367 | Consistency: 0.0067 | SSIM: 0.0231 | Grad: 22859.992\n",
      "[Epoch 51, Batch 67/100] Loss: 0.0354 | RMSE: 0.0329 | Consistency: 0.0058 | SSIM: 0.0236 | Grad: 57857.312\n",
      "[Epoch 51, Batch 68/100] Loss: 0.0348 | RMSE: 0.0328 | Consistency: 0.0063 | SSIM: 0.0192 | Grad: 97439.672\n",
      "[Epoch 51, Batch 69/100] Loss: 0.0504 | RMSE: 0.0471 | Consistency: 0.0142 | SSIM: 0.0316 | Grad: 49348.781\n",
      "[Epoch 51, Batch 70/100] Loss: 0.0470 | RMSE: 0.0437 | Consistency: 0.0104 | SSIM: 0.0316 | Grad: 90910.656\n",
      "[Epoch 51, Batch 71/100] Loss: 0.0380 | RMSE: 0.0356 | Consistency: 0.0063 | SSIM: 0.0234 | Grad: 76874.422\n",
      "[Epoch 51, Batch 72/100] Loss: 0.0434 | RMSE: 0.0399 | Consistency: 0.0086 | SSIM: 0.0346 | Grad: 74297.602\n",
      "[Epoch 51, Batch 73/100] Loss: 0.0415 | RMSE: 0.0386 | Consistency: 0.0085 | SSIM: 0.0286 | Grad: 62759.957\n",
      "[Epoch 51, Batch 74/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0080 | SSIM: 0.0241 | Grad: 38805.031\n",
      "[Epoch 51, Batch 75/100] Loss: 0.0383 | RMSE: 0.0358 | Consistency: 0.0066 | SSIM: 0.0243 | Grad: 97113.477\n",
      "[Epoch 51, Batch 76/100] Loss: 0.0462 | RMSE: 0.0432 | Consistency: 0.0102 | SSIM: 0.0295 | Grad: 90805.844\n",
      "[Epoch 51, Batch 77/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0062 | SSIM: 0.0228 | Grad: 67067.102\n",
      "[Epoch 51, Batch 78/100] Loss: 0.0477 | RMSE: 0.0446 | Consistency: 0.0078 | SSIM: 0.0307 | Grad: 127555.039\n",
      "[Epoch 51, Batch 79/100] Loss: 0.0424 | RMSE: 0.0399 | Consistency: 0.0067 | SSIM: 0.0248 | Grad: 104114.914\n",
      "[Epoch 51, Batch 80/100] Loss: 0.0416 | RMSE: 0.0388 | Consistency: 0.0070 | SSIM: 0.0271 | Grad: 85004.102\n",
      "[Epoch 51, Batch 81/100] Loss: 0.0423 | RMSE: 0.0391 | Consistency: 0.0064 | SSIM: 0.0312 | Grad: 96837.648\n",
      "[Epoch 51, Batch 82/100] Loss: 0.0375 | RMSE: 0.0346 | Consistency: 0.0056 | SSIM: 0.0280 | Grad: 86708.164\n",
      "[Epoch 51, Batch 83/100] Loss: 0.0424 | RMSE: 0.0398 | Consistency: 0.0069 | SSIM: 0.0259 | Grad: 130092.141\n",
      "[Epoch 51, Batch 84/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0081 | SSIM: 0.0251 | Grad: 55808.527\n",
      "[Epoch 51, Batch 85/100] Loss: 0.0384 | RMSE: 0.0362 | Consistency: 0.0071 | SSIM: 0.0212 | Grad: 42395.449\n",
      "[Epoch 51, Batch 86/100] Loss: 0.0472 | RMSE: 0.0444 | Consistency: 0.0129 | SSIM: 0.0271 | Grad: 117650.844\n",
      "[Epoch 51, Batch 87/100] Loss: 0.0407 | RMSE: 0.0382 | Consistency: 0.0068 | SSIM: 0.0247 | Grad: 124286.727\n",
      "[Epoch 51, Batch 88/100] Loss: 0.0371 | RMSE: 0.0350 | Consistency: 0.0060 | SSIM: 0.0199 | Grad: 80941.344\n",
      "[Epoch 51, Batch 89/100] Loss: 0.0447 | RMSE: 0.0422 | Consistency: 0.0094 | SSIM: 0.0243 | Grad: 94047.156\n",
      "[Epoch 51, Batch 90/100] Loss: 0.0414 | RMSE: 0.0382 | Consistency: 0.0095 | SSIM: 0.0315 | Grad: 73436.531\n",
      "[Epoch 51, Batch 91/100] Loss: 0.0419 | RMSE: 0.0390 | Consistency: 0.0091 | SSIM: 0.0290 | Grad: 72834.562\n",
      "[Epoch 51, Batch 92/100] Loss: 0.0455 | RMSE: 0.0427 | Consistency: 0.0084 | SSIM: 0.0266 | Grad: 94711.312\n",
      "[Epoch 51, Batch 93/100] Loss: 0.0432 | RMSE: 0.0401 | Consistency: 0.0075 | SSIM: 0.0297 | Grad: 108657.656\n",
      "[Epoch 51, Batch 94/100] Loss: 0.0447 | RMSE: 0.0423 | Consistency: 0.0085 | SSIM: 0.0234 | Grad: 94811.406\n",
      "[Epoch 51, Batch 95/100] Loss: 0.0368 | RMSE: 0.0347 | Consistency: 0.0069 | SSIM: 0.0205 | Grad: 103158.211\n",
      "[Epoch 51, Batch 96/100] Loss: 0.0412 | RMSE: 0.0386 | Consistency: 0.0087 | SSIM: 0.0242 | Grad: 94713.164\n",
      "[Epoch 51, Batch 97/100] Loss: 0.0423 | RMSE: 0.0400 | Consistency: 0.0089 | SSIM: 0.0222 | Grad: 71291.109\n",
      "[Epoch 51, Batch 98/100] Loss: 0.0420 | RMSE: 0.0395 | Consistency: 0.0076 | SSIM: 0.0249 | Grad: 94931.711\n",
      "[Epoch 51, Batch 99/100] Loss: 0.0366 | RMSE: 0.0346 | Consistency: 0.0055 | SSIM: 0.0196 | Grad: 87664.703\n",
      "[Epoch 51, Batch 100/100] Loss: 0.0445 | RMSE: 0.0420 | Consistency: 0.0092 | SSIM: 0.0242 | Grad: 89421.359\n",
      "✅ Epoch 51 완료!\n",
      "   📈 평균 Loss: 0.042201\n",
      "   📊 평균 RMSE: 0.039470\n",
      "   ⚙️  학습률: 0.000349\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 52/80 시작...\n",
      "[Epoch 52, Batch 1/100] Loss: 0.0391 | RMSE: 0.0363 | Consistency: 0.0074 | SSIM: 0.0278 | Grad: 74928.234\n",
      "[Epoch 52, Batch 2/100] Loss: 0.0344 | RMSE: 0.0321 | Consistency: 0.0059 | SSIM: 0.0227 | Grad: 92138.594\n",
      "[Epoch 52, Batch 3/100] Loss: 0.0341 | RMSE: 0.0319 | Consistency: 0.0053 | SSIM: 0.0207 | Grad: 109543.484\n",
      "[Epoch 52, Batch 4/100] Loss: 0.0385 | RMSE: 0.0356 | Consistency: 0.0054 | SSIM: 0.0279 | Grad: 53255.352\n",
      "[Epoch 52, Batch 5/100] Loss: 0.0447 | RMSE: 0.0419 | Consistency: 0.0076 | SSIM: 0.0275 | Grad: 38819.652\n",
      "[Epoch 52, Batch 6/100] Loss: 0.0439 | RMSE: 0.0409 | Consistency: 0.0098 | SSIM: 0.0288 | Grad: 109376.797\n",
      "[Epoch 52, Batch 7/100] Loss: 0.0449 | RMSE: 0.0422 | Consistency: 0.0091 | SSIM: 0.0256 | Grad: 100924.359\n",
      "[Epoch 52, Batch 8/100] Loss: 0.0431 | RMSE: 0.0410 | Consistency: 0.0079 | SSIM: 0.0203 | Grad: 133090.141\n",
      "[Epoch 52, Batch 9/100] Loss: 0.0378 | RMSE: 0.0351 | Consistency: 0.0064 | SSIM: 0.0266 | Grad: 80709.148\n",
      "[Epoch 52, Batch 10/100] Loss: 0.0328 | RMSE: 0.0309 | Consistency: 0.0057 | SSIM: 0.0187 | Grad: 79227.125\n",
      "[Epoch 52, Batch 11/100] Loss: 0.0411 | RMSE: 0.0384 | Consistency: 0.0095 | SSIM: 0.0261 | Grad: 64326.477\n",
      "[Epoch 52, Batch 12/100] Loss: 0.0458 | RMSE: 0.0430 | Consistency: 0.0107 | SSIM: 0.0267 | Grad: 77191.227\n",
      "[Epoch 52, Batch 13/100] Loss: 0.0541 | RMSE: 0.0507 | Consistency: 0.0136 | SSIM: 0.0324 | Grad: 93158.367\n",
      "[Epoch 52, Batch 14/100] Loss: 0.0382 | RMSE: 0.0358 | Consistency: 0.0057 | SSIM: 0.0239 | Grad: 103866.875\n",
      "[Epoch 52, Batch 15/100] Loss: 0.0460 | RMSE: 0.0425 | Consistency: 0.0087 | SSIM: 0.0348 | Grad: 107985.750\n",
      "[Epoch 52, Batch 16/100] Loss: 0.0433 | RMSE: 0.0406 | Consistency: 0.0077 | SSIM: 0.0263 | Grad: 112432.602\n",
      "[Epoch 52, Batch 17/100] Loss: 0.0384 | RMSE: 0.0363 | Consistency: 0.0063 | SSIM: 0.0207 | Grad: 50714.953\n",
      "[Epoch 52, Batch 18/100] Loss: 0.0450 | RMSE: 0.0419 | Consistency: 0.0077 | SSIM: 0.0304 | Grad: 49105.562\n",
      "[Epoch 52, Batch 19/100] Loss: 0.0398 | RMSE: 0.0374 | Consistency: 0.0074 | SSIM: 0.0230 | Grad: 70561.570\n",
      "[Epoch 52, Batch 20/100] Loss: 0.0418 | RMSE: 0.0391 | Consistency: 0.0066 | SSIM: 0.0261 | Grad: 37446.348\n",
      "[Epoch 52, Batch 21/100] Loss: 0.0429 | RMSE: 0.0404 | Consistency: 0.0078 | SSIM: 0.0244 | Grad: 42969.648\n",
      "[Epoch 52, Batch 22/100] Loss: 0.0400 | RMSE: 0.0376 | Consistency: 0.0078 | SSIM: 0.0225 | Grad: 109696.047\n",
      "[Epoch 52, Batch 23/100] Loss: 0.0444 | RMSE: 0.0413 | Consistency: 0.0116 | SSIM: 0.0298 | Grad: 87909.484\n",
      "[Epoch 52, Batch 24/100] Loss: 0.0375 | RMSE: 0.0351 | Consistency: 0.0076 | SSIM: 0.0233 | Grad: 92041.023\n",
      "[Epoch 52, Batch 25/100] Loss: 0.0449 | RMSE: 0.0416 | Consistency: 0.0089 | SSIM: 0.0321 | Grad: 88771.250\n",
      "[Epoch 52, Batch 26/100] Loss: 0.0406 | RMSE: 0.0380 | Consistency: 0.0085 | SSIM: 0.0249 | Grad: 65338.051\n",
      "[Epoch 52, Batch 27/100] Loss: 0.0437 | RMSE: 0.0406 | Consistency: 0.0100 | SSIM: 0.0302 | Grad: 64637.570\n",
      "[Epoch 52, Batch 28/100] Loss: 0.0414 | RMSE: 0.0380 | Consistency: 0.0086 | SSIM: 0.0336 | Grad: 43025.023\n",
      "[Epoch 52, Batch 29/100] Loss: 0.0414 | RMSE: 0.0384 | Consistency: 0.0081 | SSIM: 0.0292 | Grad: 82499.547\n",
      "[Epoch 52, Batch 30/100] Loss: 0.0339 | RMSE: 0.0320 | Consistency: 0.0057 | SSIM: 0.0187 | Grad: 65225.988\n",
      "[Epoch 52, Batch 31/100] Loss: 0.0351 | RMSE: 0.0328 | Consistency: 0.0057 | SSIM: 0.0227 | Grad: 57362.777\n",
      "[Epoch 52, Batch 32/100] Loss: 0.0402 | RMSE: 0.0373 | Consistency: 0.0078 | SSIM: 0.0280 | Grad: 19902.656\n",
      "[Epoch 52, Batch 33/100] Loss: 0.0416 | RMSE: 0.0396 | Consistency: 0.0062 | SSIM: 0.0193 | Grad: 29990.463\n",
      "[Epoch 52, Batch 34/100] Loss: 0.0376 | RMSE: 0.0349 | Consistency: 0.0062 | SSIM: 0.0260 | Grad: 76241.773\n",
      "[Epoch 52, Batch 35/100] Loss: 0.0455 | RMSE: 0.0428 | Consistency: 0.0116 | SSIM: 0.0264 | Grad: 111683.820\n",
      "[Epoch 52, Batch 36/100] Loss: 0.0435 | RMSE: 0.0405 | Consistency: 0.0087 | SSIM: 0.0286 | Grad: 37463.832\n",
      "[Epoch 52, Batch 37/100] Loss: 0.0392 | RMSE: 0.0367 | Consistency: 0.0069 | SSIM: 0.0243 | Grad: 82161.289\n",
      "[Epoch 52, Batch 38/100] Loss: 0.0396 | RMSE: 0.0371 | Consistency: 0.0070 | SSIM: 0.0241 | Grad: 69792.453\n",
      "[Epoch 52, Batch 39/100] Loss: 0.0464 | RMSE: 0.0430 | Consistency: 0.0101 | SSIM: 0.0328 | Grad: 106024.141\n",
      "[Epoch 52, Batch 40/100] Loss: 0.0435 | RMSE: 0.0403 | Consistency: 0.0091 | SSIM: 0.0308 | Grad: 58091.445\n",
      "[Epoch 52, Batch 41/100] Loss: 0.0432 | RMSE: 0.0402 | Consistency: 0.0102 | SSIM: 0.0286 | Grad: 87813.180\n",
      "[Epoch 52, Batch 42/100] Loss: 0.0385 | RMSE: 0.0360 | Consistency: 0.0065 | SSIM: 0.0243 | Grad: 30236.225\n",
      "[Epoch 52, Batch 43/100] Loss: 0.0351 | RMSE: 0.0331 | Consistency: 0.0058 | SSIM: 0.0195 | Grad: 49504.785\n",
      "[Epoch 52, Batch 44/100] Loss: 0.0451 | RMSE: 0.0420 | Consistency: 0.0097 | SSIM: 0.0300 | Grad: 72659.055\n",
      "[Epoch 52, Batch 45/100] Loss: 0.0395 | RMSE: 0.0367 | Consistency: 0.0079 | SSIM: 0.0266 | Grad: 48159.730\n",
      "[Epoch 52, Batch 46/100] Loss: 0.0446 | RMSE: 0.0416 | Consistency: 0.0096 | SSIM: 0.0294 | Grad: 38855.617\n",
      "[Epoch 52, Batch 47/100] Loss: 0.0430 | RMSE: 0.0404 | Consistency: 0.0081 | SSIM: 0.0251 | Grad: 47987.457\n",
      "[Epoch 52, Batch 48/100] Loss: 0.0439 | RMSE: 0.0409 | Consistency: 0.0092 | SSIM: 0.0292 | Grad: 72171.641\n",
      "[Epoch 52, Batch 49/100] Loss: 0.0456 | RMSE: 0.0431 | Consistency: 0.0087 | SSIM: 0.0242 | Grad: 88584.320\n",
      "[Epoch 52, Batch 50/100] Loss: 0.0430 | RMSE: 0.0398 | Consistency: 0.0068 | SSIM: 0.0307 | Grad: 87329.031\n",
      "[Epoch 52, Batch 51/100] Loss: 0.0349 | RMSE: 0.0326 | Consistency: 0.0062 | SSIM: 0.0219 | Grad: 100042.250\n",
      "[Epoch 52, Batch 52/100] Loss: 0.0377 | RMSE: 0.0343 | Consistency: 0.0069 | SSIM: 0.0335 | Grad: 80137.547\n",
      "[Epoch 52, Batch 53/100] Loss: 0.0378 | RMSE: 0.0355 | Consistency: 0.0076 | SSIM: 0.0222 | Grad: 36338.242\n",
      "[Epoch 52, Batch 54/100] Loss: 0.0395 | RMSE: 0.0370 | Consistency: 0.0065 | SSIM: 0.0241 | Grad: 97293.297\n",
      "[Epoch 52, Batch 55/100] Loss: 0.0508 | RMSE: 0.0478 | Consistency: 0.0119 | SSIM: 0.0294 | Grad: 88707.766\n",
      "[Epoch 52, Batch 56/100] Loss: 0.0405 | RMSE: 0.0379 | Consistency: 0.0069 | SSIM: 0.0256 | Grad: 32519.293\n",
      "[Epoch 52, Batch 57/100] Loss: 0.0559 | RMSE: 0.0521 | Consistency: 0.0177 | SSIM: 0.0357 | Grad: 68007.547\n",
      "[Epoch 52, Batch 58/100] Loss: 0.0430 | RMSE: 0.0406 | Consistency: 0.0081 | SSIM: 0.0228 | Grad: 65300.812\n",
      "[Epoch 52, Batch 59/100] Loss: 0.0419 | RMSE: 0.0390 | Consistency: 0.0072 | SSIM: 0.0281 | Grad: 63694.426\n",
      "[Epoch 52, Batch 60/100] Loss: 0.0422 | RMSE: 0.0395 | Consistency: 0.0084 | SSIM: 0.0266 | Grad: 67190.781\n",
      "[Epoch 52, Batch 61/100] Loss: 0.0429 | RMSE: 0.0397 | Consistency: 0.0094 | SSIM: 0.0316 | Grad: 84143.688\n",
      "[Epoch 52, Batch 62/100] Loss: 0.0439 | RMSE: 0.0409 | Consistency: 0.0092 | SSIM: 0.0288 | Grad: 112108.977\n",
      "[Epoch 52, Batch 63/100] Loss: 0.0418 | RMSE: 0.0394 | Consistency: 0.0088 | SSIM: 0.0232 | Grad: 108307.586\n",
      "[Epoch 52, Batch 64/100] Loss: 0.0329 | RMSE: 0.0307 | Consistency: 0.0055 | SSIM: 0.0215 | Grad: 32823.578\n",
      "[Epoch 52, Batch 65/100] Loss: 0.0394 | RMSE: 0.0373 | Consistency: 0.0063 | SSIM: 0.0197 | Grad: 114223.094\n",
      "[Epoch 52, Batch 66/100] Loss: 0.0425 | RMSE: 0.0402 | Consistency: 0.0077 | SSIM: 0.0219 | Grad: 125373.094\n",
      "[Epoch 52, Batch 67/100] Loss: 0.0497 | RMSE: 0.0471 | Consistency: 0.0071 | SSIM: 0.0248 | Grad: 135199.500\n",
      "[Epoch 52, Batch 68/100] Loss: 0.0465 | RMSE: 0.0435 | Consistency: 0.0097 | SSIM: 0.0289 | Grad: 133043.547\n",
      "[Epoch 52, Batch 69/100] Loss: 0.0441 | RMSE: 0.0411 | Consistency: 0.0067 | SSIM: 0.0292 | Grad: 101524.383\n",
      "[Epoch 52, Batch 70/100] Loss: 0.0407 | RMSE: 0.0386 | Consistency: 0.0073 | SSIM: 0.0208 | Grad: 58016.672\n",
      "[Epoch 52, Batch 71/100] Loss: 0.0353 | RMSE: 0.0327 | Consistency: 0.0057 | SSIM: 0.0251 | Grad: 50430.273\n",
      "[Epoch 52, Batch 72/100] Loss: 0.0400 | RMSE: 0.0372 | Consistency: 0.0066 | SSIM: 0.0278 | Grad: 70852.445\n",
      "[Epoch 52, Batch 73/100] Loss: 0.0403 | RMSE: 0.0373 | Consistency: 0.0078 | SSIM: 0.0291 | Grad: 96897.117\n",
      "[Epoch 52, Batch 74/100] Loss: 0.0458 | RMSE: 0.0429 | Consistency: 0.0098 | SSIM: 0.0275 | Grad: 98439.305\n",
      "[Epoch 52, Batch 75/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0057 | SSIM: 0.0237 | Grad: 89791.336\n",
      "[Epoch 52, Batch 76/100] Loss: 0.0402 | RMSE: 0.0379 | Consistency: 0.0076 | SSIM: 0.0228 | Grad: 62907.570\n",
      "[Epoch 52, Batch 77/100] Loss: 0.0363 | RMSE: 0.0340 | Consistency: 0.0066 | SSIM: 0.0225 | Grad: 45924.746\n",
      "[Epoch 52, Batch 78/100] Loss: 0.0438 | RMSE: 0.0411 | Consistency: 0.0082 | SSIM: 0.0260 | Grad: 97632.164\n",
      "[Epoch 52, Batch 79/100] Loss: 0.0415 | RMSE: 0.0392 | Consistency: 0.0086 | SSIM: 0.0225 | Grad: 80204.852\n",
      "[Epoch 52, Batch 80/100] Loss: 0.0391 | RMSE: 0.0360 | Consistency: 0.0085 | SSIM: 0.0304 | Grad: 113036.195\n",
      "[Epoch 52, Batch 81/100] Loss: 0.0421 | RMSE: 0.0391 | Consistency: 0.0087 | SSIM: 0.0283 | Grad: 62634.344\n",
      "[Epoch 52, Batch 82/100] Loss: 0.0415 | RMSE: 0.0392 | Consistency: 0.0087 | SSIM: 0.0225 | Grad: 78773.172\n",
      "[Epoch 52, Batch 83/100] Loss: 0.0431 | RMSE: 0.0403 | Consistency: 0.0077 | SSIM: 0.0269 | Grad: 59007.109\n",
      "[Epoch 52, Batch 84/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0076 | SSIM: 0.0230 | Grad: 105625.836\n",
      "[Epoch 52, Batch 85/100] Loss: 0.0513 | RMSE: 0.0484 | Consistency: 0.0115 | SSIM: 0.0278 | Grad: 93634.266\n",
      "[Epoch 52, Batch 86/100] Loss: 0.0403 | RMSE: 0.0378 | Consistency: 0.0088 | SSIM: 0.0240 | Grad: 80185.625\n",
      "[Epoch 52, Batch 87/100] Loss: 0.0388 | RMSE: 0.0366 | Consistency: 0.0058 | SSIM: 0.0209 | Grad: 170334.922\n",
      "[Epoch 52, Batch 88/100] Loss: 0.0389 | RMSE: 0.0361 | Consistency: 0.0085 | SSIM: 0.0263 | Grad: 88220.297\n",
      "[Epoch 52, Batch 89/100] Loss: 0.0434 | RMSE: 0.0408 | Consistency: 0.0080 | SSIM: 0.0250 | Grad: 99662.047\n",
      "[Epoch 52, Batch 90/100] Loss: 0.0443 | RMSE: 0.0420 | Consistency: 0.0082 | SSIM: 0.0219 | Grad: 83418.125\n",
      "[Epoch 52, Batch 91/100] Loss: 0.0376 | RMSE: 0.0355 | Consistency: 0.0063 | SSIM: 0.0204 | Grad: 78719.148\n",
      "[Epoch 52, Batch 92/100] Loss: 0.0388 | RMSE: 0.0366 | Consistency: 0.0059 | SSIM: 0.0213 | Grad: 98709.836\n",
      "[Epoch 52, Batch 93/100] Loss: 0.0432 | RMSE: 0.0404 | Consistency: 0.0083 | SSIM: 0.0269 | Grad: 75902.359\n",
      "[Epoch 52, Batch 94/100] Loss: 0.0432 | RMSE: 0.0406 | Consistency: 0.0088 | SSIM: 0.0250 | Grad: 98098.242\n",
      "[Epoch 52, Batch 95/100] Loss: 0.0387 | RMSE: 0.0363 | Consistency: 0.0076 | SSIM: 0.0233 | Grad: 57164.387\n",
      "[Epoch 52, Batch 96/100] Loss: 0.0343 | RMSE: 0.0317 | Consistency: 0.0064 | SSIM: 0.0248 | Grad: 44998.445\n",
      "[Epoch 52, Batch 97/100] Loss: 0.0358 | RMSE: 0.0336 | Consistency: 0.0066 | SSIM: 0.0211 | Grad: 60413.902\n",
      "[Epoch 52, Batch 98/100] Loss: 0.0481 | RMSE: 0.0451 | Consistency: 0.0086 | SSIM: 0.0284 | Grad: 137614.078\n",
      "[Epoch 52, Batch 99/100] Loss: 0.0481 | RMSE: 0.0457 | Consistency: 0.0102 | SSIM: 0.0237 | Grad: 133787.281\n",
      "[Epoch 52, Batch 100/100] Loss: 0.0430 | RMSE: 0.0402 | Consistency: 0.0086 | SSIM: 0.0270 | Grad: 69594.203\n",
      "✅ Epoch 52 완료!\n",
      "   📈 평균 Loss: 0.041501\n",
      "   📊 평균 RMSE: 0.038838\n",
      "   ⚙️  학습률: 0.000329\n",
      "   🏆 NEW BEST! RMSE: 0.038838\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 53/80 시작...\n",
      "[Epoch 53, Batch 1/100] Loss: 0.0438 | RMSE: 0.0411 | Consistency: 0.0093 | SSIM: 0.0266 | Grad: 67132.641\n",
      "[Epoch 53, Batch 2/100] Loss: 0.0483 | RMSE: 0.0456 | Consistency: 0.0082 | SSIM: 0.0261 | Grad: 106059.180\n",
      "[Epoch 53, Batch 3/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0080 | SSIM: 0.0241 | Grad: 96974.477\n",
      "[Epoch 53, Batch 4/100] Loss: 0.0395 | RMSE: 0.0369 | Consistency: 0.0074 | SSIM: 0.0257 | Grad: 69876.469\n",
      "[Epoch 53, Batch 5/100] Loss: 0.0507 | RMSE: 0.0477 | Consistency: 0.0103 | SSIM: 0.0292 | Grad: 77968.523\n",
      "[Epoch 53, Batch 6/100] Loss: 0.0416 | RMSE: 0.0390 | Consistency: 0.0087 | SSIM: 0.0250 | Grad: 103496.016\n",
      "[Epoch 53, Batch 7/100] Loss: 0.0411 | RMSE: 0.0382 | Consistency: 0.0080 | SSIM: 0.0283 | Grad: 102871.148\n",
      "[Epoch 53, Batch 8/100] Loss: 0.0373 | RMSE: 0.0349 | Consistency: 0.0074 | SSIM: 0.0229 | Grad: 72586.484\n",
      "[Epoch 53, Batch 9/100] Loss: 0.0390 | RMSE: 0.0365 | Consistency: 0.0073 | SSIM: 0.0235 | Grad: 102750.945\n",
      "[Epoch 53, Batch 10/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0085 | SSIM: 0.0237 | Grad: 56901.891\n",
      "[Epoch 53, Batch 11/100] Loss: 0.0372 | RMSE: 0.0347 | Consistency: 0.0076 | SSIM: 0.0242 | Grad: 107538.914\n",
      "[Epoch 53, Batch 12/100] Loss: 0.0360 | RMSE: 0.0335 | Consistency: 0.0064 | SSIM: 0.0245 | Grad: 100533.531\n",
      "[Epoch 53, Batch 13/100] Loss: 0.0378 | RMSE: 0.0358 | Consistency: 0.0056 | SSIM: 0.0201 | Grad: 26608.963\n",
      "[Epoch 53, Batch 14/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0052 | SSIM: 0.0191 | Grad: 53150.219\n",
      "[Epoch 53, Batch 15/100] Loss: 0.0451 | RMSE: 0.0419 | Consistency: 0.0121 | SSIM: 0.0301 | Grad: 63213.453\n",
      "[Epoch 53, Batch 16/100] Loss: 0.0360 | RMSE: 0.0340 | Consistency: 0.0060 | SSIM: 0.0198 | Grad: 38992.723\n",
      "[Epoch 53, Batch 17/100] Loss: 0.0396 | RMSE: 0.0365 | Consistency: 0.0079 | SSIM: 0.0303 | Grad: 62066.504\n",
      "[Epoch 53, Batch 18/100] Loss: 0.0442 | RMSE: 0.0413 | Consistency: 0.0091 | SSIM: 0.0278 | Grad: 53992.074\n",
      "[Epoch 53, Batch 19/100] Loss: 0.0353 | RMSE: 0.0330 | Consistency: 0.0053 | SSIM: 0.0225 | Grad: 46054.723\n",
      "[Epoch 53, Batch 20/100] Loss: 0.0366 | RMSE: 0.0344 | Consistency: 0.0065 | SSIM: 0.0214 | Grad: 63180.250\n",
      "[Epoch 53, Batch 21/100] Loss: 0.0373 | RMSE: 0.0345 | Consistency: 0.0069 | SSIM: 0.0275 | Grad: 42967.988\n",
      "[Epoch 53, Batch 22/100] Loss: 0.0427 | RMSE: 0.0401 | Consistency: 0.0092 | SSIM: 0.0251 | Grad: 52288.477\n",
      "[Epoch 53, Batch 23/100] Loss: 0.0367 | RMSE: 0.0344 | Consistency: 0.0056 | SSIM: 0.0230 | Grad: 21611.779\n",
      "[Epoch 53, Batch 24/100] Loss: 0.0346 | RMSE: 0.0325 | Consistency: 0.0072 | SSIM: 0.0204 | Grad: 39468.070\n",
      "[Epoch 53, Batch 25/100] Loss: 0.0360 | RMSE: 0.0339 | Consistency: 0.0066 | SSIM: 0.0200 | Grad: 69855.094\n",
      "[Epoch 53, Batch 26/100] Loss: 0.0404 | RMSE: 0.0379 | Consistency: 0.0087 | SSIM: 0.0233 | Grad: 83513.125\n",
      "[Epoch 53, Batch 27/100] Loss: 0.0468 | RMSE: 0.0439 | Consistency: 0.0079 | SSIM: 0.0278 | Grad: 72472.250\n",
      "[Epoch 53, Batch 28/100] Loss: 0.0395 | RMSE: 0.0369 | Consistency: 0.0075 | SSIM: 0.0253 | Grad: 60751.844\n",
      "[Epoch 53, Batch 29/100] Loss: 0.0414 | RMSE: 0.0383 | Consistency: 0.0081 | SSIM: 0.0303 | Grad: 39955.562\n",
      "[Epoch 53, Batch 30/100] Loss: 0.0430 | RMSE: 0.0404 | Consistency: 0.0093 | SSIM: 0.0249 | Grad: 27156.373\n",
      "[Epoch 53, Batch 31/100] Loss: 0.0410 | RMSE: 0.0381 | Consistency: 0.0081 | SSIM: 0.0284 | Grad: 44313.375\n",
      "[Epoch 53, Batch 32/100] Loss: 0.0411 | RMSE: 0.0383 | Consistency: 0.0081 | SSIM: 0.0275 | Grad: 66704.648\n",
      "[Epoch 53, Batch 33/100] Loss: 0.0419 | RMSE: 0.0396 | Consistency: 0.0082 | SSIM: 0.0224 | Grad: 114089.070\n",
      "[Epoch 53, Batch 34/100] Loss: 0.0427 | RMSE: 0.0401 | Consistency: 0.0097 | SSIM: 0.0248 | Grad: 91413.281\n",
      "[Epoch 53, Batch 35/100] Loss: 0.0421 | RMSE: 0.0394 | Consistency: 0.0072 | SSIM: 0.0266 | Grad: 80532.719\n",
      "[Epoch 53, Batch 36/100] Loss: 0.0413 | RMSE: 0.0386 | Consistency: 0.0088 | SSIM: 0.0266 | Grad: 43154.074\n",
      "[Epoch 53, Batch 37/100] Loss: 0.0380 | RMSE: 0.0361 | Consistency: 0.0069 | SSIM: 0.0187 | Grad: 81597.336\n",
      "[Epoch 53, Batch 38/100] Loss: 0.0389 | RMSE: 0.0360 | Consistency: 0.0061 | SSIM: 0.0282 | Grad: 97158.039\n",
      "[Epoch 53, Batch 39/100] Loss: 0.0396 | RMSE: 0.0369 | Consistency: 0.0055 | SSIM: 0.0258 | Grad: 74019.594\n",
      "[Epoch 53, Batch 40/100] Loss: 0.0485 | RMSE: 0.0452 | Consistency: 0.0141 | SSIM: 0.0316 | Grad: 143165.797\n",
      "[Epoch 53, Batch 41/100] Loss: 0.0443 | RMSE: 0.0413 | Consistency: 0.0108 | SSIM: 0.0284 | Grad: 123775.719\n",
      "[Epoch 53, Batch 42/100] Loss: 0.0448 | RMSE: 0.0415 | Consistency: 0.0123 | SSIM: 0.0319 | Grad: 101068.117\n",
      "[Epoch 53, Batch 43/100] Loss: 0.0454 | RMSE: 0.0422 | Consistency: 0.0103 | SSIM: 0.0301 | Grad: 62590.867\n",
      "[Epoch 53, Batch 44/100] Loss: 0.0375 | RMSE: 0.0353 | Consistency: 0.0061 | SSIM: 0.0212 | Grad: 63055.457\n",
      "[Epoch 53, Batch 45/100] Loss: 0.0405 | RMSE: 0.0380 | Consistency: 0.0086 | SSIM: 0.0240 | Grad: 66712.109\n",
      "[Epoch 53, Batch 46/100] Loss: 0.0401 | RMSE: 0.0377 | Consistency: 0.0073 | SSIM: 0.0229 | Grad: 77255.234\n",
      "[Epoch 53, Batch 47/100] Loss: 0.0381 | RMSE: 0.0357 | Consistency: 0.0068 | SSIM: 0.0230 | Grad: 63671.395\n",
      "[Epoch 53, Batch 48/100] Loss: 0.0429 | RMSE: 0.0400 | Consistency: 0.0095 | SSIM: 0.0279 | Grad: 61414.871\n",
      "[Epoch 53, Batch 49/100] Loss: 0.0376 | RMSE: 0.0347 | Consistency: 0.0064 | SSIM: 0.0283 | Grad: 72463.844\n",
      "[Epoch 53, Batch 50/100] Loss: 0.0463 | RMSE: 0.0424 | Consistency: 0.0123 | SSIM: 0.0371 | Grad: 78818.703\n",
      "[Epoch 53, Batch 51/100] Loss: 0.0429 | RMSE: 0.0398 | Consistency: 0.0086 | SSIM: 0.0303 | Grad: 61065.445\n",
      "[Epoch 53, Batch 52/100] Loss: 0.0366 | RMSE: 0.0347 | Consistency: 0.0059 | SSIM: 0.0190 | Grad: 79840.125\n",
      "[Epoch 53, Batch 53/100] Loss: 0.0360 | RMSE: 0.0335 | Consistency: 0.0064 | SSIM: 0.0237 | Grad: 43147.902\n",
      "[Epoch 53, Batch 54/100] Loss: 0.0404 | RMSE: 0.0381 | Consistency: 0.0091 | SSIM: 0.0224 | Grad: 59410.957\n",
      "[Epoch 53, Batch 55/100] Loss: 0.0406 | RMSE: 0.0382 | Consistency: 0.0071 | SSIM: 0.0233 | Grad: 59472.801\n",
      "[Epoch 53, Batch 56/100] Loss: 0.0379 | RMSE: 0.0358 | Consistency: 0.0072 | SSIM: 0.0202 | Grad: 84100.555\n",
      "[Epoch 53, Batch 57/100] Loss: 0.0415 | RMSE: 0.0391 | Consistency: 0.0092 | SSIM: 0.0227 | Grad: 104184.672\n",
      "[Epoch 53, Batch 58/100] Loss: 0.0396 | RMSE: 0.0371 | Consistency: 0.0070 | SSIM: 0.0245 | Grad: 115541.008\n",
      "[Epoch 53, Batch 59/100] Loss: 0.0375 | RMSE: 0.0348 | Consistency: 0.0065 | SSIM: 0.0257 | Grad: 35298.379\n",
      "[Epoch 53, Batch 60/100] Loss: 0.0474 | RMSE: 0.0443 | Consistency: 0.0113 | SSIM: 0.0307 | Grad: 44867.117\n",
      "[Epoch 53, Batch 61/100] Loss: 0.0410 | RMSE: 0.0384 | Consistency: 0.0071 | SSIM: 0.0250 | Grad: 93737.305\n",
      "[Epoch 53, Batch 62/100] Loss: 0.0399 | RMSE: 0.0368 | Consistency: 0.0064 | SSIM: 0.0298 | Grad: 125032.805\n",
      "[Epoch 53, Batch 63/100] Loss: 0.0570 | RMSE: 0.0541 | Consistency: 0.0187 | SSIM: 0.0269 | Grad: 121776.789\n",
      "[Epoch 53, Batch 64/100] Loss: 0.0624 | RMSE: 0.0580 | Consistency: 0.0221 | SSIM: 0.0411 | Grad: 108502.602\n",
      "[Epoch 53, Batch 65/100] Loss: 0.0401 | RMSE: 0.0379 | Consistency: 0.0056 | SSIM: 0.0216 | Grad: 101520.945\n",
      "[Epoch 53, Batch 66/100] Loss: 0.0417 | RMSE: 0.0391 | Consistency: 0.0073 | SSIM: 0.0262 | Grad: 49930.988\n",
      "[Epoch 53, Batch 67/100] Loss: 0.0398 | RMSE: 0.0372 | Consistency: 0.0069 | SSIM: 0.0251 | Grad: 94523.406\n",
      "[Epoch 53, Batch 68/100] Loss: 0.0462 | RMSE: 0.0438 | Consistency: 0.0115 | SSIM: 0.0230 | Grad: 57201.559\n",
      "[Epoch 53, Batch 69/100] Loss: 0.0340 | RMSE: 0.0316 | Consistency: 0.0054 | SSIM: 0.0240 | Grad: 78573.938\n",
      "[Epoch 53, Batch 70/100] Loss: 0.0421 | RMSE: 0.0394 | Consistency: 0.0073 | SSIM: 0.0264 | Grad: 100551.633\n",
      "[Epoch 53, Batch 71/100] Loss: 0.0428 | RMSE: 0.0404 | Consistency: 0.0066 | SSIM: 0.0235 | Grad: 95877.375\n",
      "[Epoch 53, Batch 72/100] Loss: 0.0422 | RMSE: 0.0399 | Consistency: 0.0071 | SSIM: 0.0223 | Grad: 81699.375\n",
      "[Epoch 53, Batch 73/100] Loss: 0.0382 | RMSE: 0.0355 | Consistency: 0.0083 | SSIM: 0.0268 | Grad: 47321.719\n",
      "[Epoch 53, Batch 74/100] Loss: 0.0479 | RMSE: 0.0450 | Consistency: 0.0107 | SSIM: 0.0288 | Grad: 75411.383\n",
      "[Epoch 53, Batch 75/100] Loss: 0.0404 | RMSE: 0.0380 | Consistency: 0.0067 | SSIM: 0.0227 | Grad: 38679.809\n",
      "[Epoch 53, Batch 76/100] Loss: 0.0382 | RMSE: 0.0354 | Consistency: 0.0060 | SSIM: 0.0273 | Grad: 108725.789\n",
      "[Epoch 53, Batch 77/100] Loss: 0.0402 | RMSE: 0.0373 | Consistency: 0.0074 | SSIM: 0.0279 | Grad: 82516.758\n",
      "[Epoch 53, Batch 78/100] Loss: 0.0417 | RMSE: 0.0390 | Consistency: 0.0076 | SSIM: 0.0264 | Grad: 35067.910\n",
      "[Epoch 53, Batch 79/100] Loss: 0.0372 | RMSE: 0.0349 | Consistency: 0.0063 | SSIM: 0.0227 | Grad: 49639.547\n",
      "[Epoch 53, Batch 80/100] Loss: 0.0401 | RMSE: 0.0374 | Consistency: 0.0084 | SSIM: 0.0260 | Grad: 74910.898\n",
      "[Epoch 53, Batch 81/100] Loss: 0.0428 | RMSE: 0.0403 | Consistency: 0.0085 | SSIM: 0.0246 | Grad: 100690.766\n",
      "[Epoch 53, Batch 82/100] Loss: 0.0417 | RMSE: 0.0391 | Consistency: 0.0081 | SSIM: 0.0250 | Grad: 76045.281\n",
      "[Epoch 53, Batch 83/100] Loss: 0.0389 | RMSE: 0.0359 | Consistency: 0.0072 | SSIM: 0.0292 | Grad: 38524.871\n",
      "[Epoch 53, Batch 84/100] Loss: 0.0367 | RMSE: 0.0340 | Consistency: 0.0063 | SSIM: 0.0263 | Grad: 53725.188\n",
      "[Epoch 53, Batch 85/100] Loss: 0.0390 | RMSE: 0.0364 | Consistency: 0.0070 | SSIM: 0.0260 | Grad: 38397.125\n",
      "[Epoch 53, Batch 86/100] Loss: 0.0416 | RMSE: 0.0390 | Consistency: 0.0084 | SSIM: 0.0251 | Grad: 27141.424\n",
      "[Epoch 53, Batch 87/100] Loss: 0.0412 | RMSE: 0.0382 | Consistency: 0.0070 | SSIM: 0.0290 | Grad: 106801.992\n",
      "[Epoch 53, Batch 88/100] Loss: 0.0377 | RMSE: 0.0355 | Consistency: 0.0063 | SSIM: 0.0214 | Grad: 113349.320\n",
      "[Epoch 53, Batch 89/100] Loss: 0.0377 | RMSE: 0.0353 | Consistency: 0.0066 | SSIM: 0.0229 | Grad: 124130.094\n",
      "[Epoch 53, Batch 90/100] Loss: 0.0424 | RMSE: 0.0395 | Consistency: 0.0090 | SSIM: 0.0273 | Grad: 118661.547\n",
      "[Epoch 53, Batch 91/100] Loss: 0.0414 | RMSE: 0.0386 | Consistency: 0.0069 | SSIM: 0.0270 | Grad: 104057.477\n",
      "[Epoch 53, Batch 92/100] Loss: 0.0391 | RMSE: 0.0360 | Consistency: 0.0064 | SSIM: 0.0304 | Grad: 41527.562\n",
      "[Epoch 53, Batch 93/100] Loss: 0.0419 | RMSE: 0.0394 | Consistency: 0.0081 | SSIM: 0.0239 | Grad: 110187.641\n",
      "[Epoch 53, Batch 94/100] Loss: 0.0370 | RMSE: 0.0344 | Consistency: 0.0063 | SSIM: 0.0251 | Grad: 60514.348\n",
      "[Epoch 53, Batch 95/100] Loss: 0.0370 | RMSE: 0.0340 | Consistency: 0.0069 | SSIM: 0.0287 | Grad: 63057.527\n",
      "[Epoch 53, Batch 96/100] Loss: 0.0374 | RMSE: 0.0348 | Consistency: 0.0063 | SSIM: 0.0254 | Grad: 48422.965\n",
      "[Epoch 53, Batch 97/100] Loss: 0.0362 | RMSE: 0.0334 | Consistency: 0.0056 | SSIM: 0.0277 | Grad: 67193.445\n",
      "[Epoch 53, Batch 98/100] Loss: 0.0338 | RMSE: 0.0313 | Consistency: 0.0055 | SSIM: 0.0243 | Grad: 66289.742\n",
      "[Epoch 53, Batch 99/100] Loss: 0.0356 | RMSE: 0.0334 | Consistency: 0.0059 | SSIM: 0.0219 | Grad: 57848.949\n",
      "[Epoch 53, Batch 100/100] Loss: 0.0378 | RMSE: 0.0356 | Consistency: 0.0060 | SSIM: 0.0214 | Grad: 87485.938\n",
      "✅ Epoch 53 완료!\n",
      "   📈 평균 Loss: 0.040642\n",
      "   📊 평균 RMSE: 0.038006\n",
      "   ⚙️  학습률: 0.000308\n",
      "   🏆 NEW BEST! RMSE: 0.038006\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 54/80 시작...\n",
      "[Epoch 54, Batch 1/100] Loss: 0.0422 | RMSE: 0.0394 | Consistency: 0.0084 | SSIM: 0.0276 | Grad: 51818.012\n",
      "[Epoch 54, Batch 2/100] Loss: 0.0405 | RMSE: 0.0375 | Consistency: 0.0079 | SSIM: 0.0293 | Grad: 28456.207\n",
      "[Epoch 54, Batch 3/100] Loss: 0.0398 | RMSE: 0.0371 | Consistency: 0.0076 | SSIM: 0.0257 | Grad: 97337.000\n",
      "[Epoch 54, Batch 4/100] Loss: 0.0407 | RMSE: 0.0381 | Consistency: 0.0084 | SSIM: 0.0253 | Grad: 90676.461\n",
      "[Epoch 54, Batch 5/100] Loss: 0.0446 | RMSE: 0.0419 | Consistency: 0.0083 | SSIM: 0.0259 | Grad: 49957.605\n",
      "[Epoch 54, Batch 6/100] Loss: 0.0359 | RMSE: 0.0336 | Consistency: 0.0062 | SSIM: 0.0217 | Grad: 109964.070\n",
      "[Epoch 54, Batch 7/100] Loss: 0.0409 | RMSE: 0.0379 | Consistency: 0.0085 | SSIM: 0.0295 | Grad: 98962.969\n",
      "[Epoch 54, Batch 8/100] Loss: 0.0366 | RMSE: 0.0340 | Consistency: 0.0063 | SSIM: 0.0254 | Grad: 66934.117\n",
      "[Epoch 54, Batch 9/100] Loss: 0.0385 | RMSE: 0.0363 | Consistency: 0.0063 | SSIM: 0.0210 | Grad: 57462.516\n",
      "[Epoch 54, Batch 10/100] Loss: 0.0430 | RMSE: 0.0399 | Consistency: 0.0083 | SSIM: 0.0295 | Grad: 104541.648\n",
      "[Epoch 54, Batch 11/100] Loss: 0.0386 | RMSE: 0.0361 | Consistency: 0.0075 | SSIM: 0.0248 | Grad: 120681.172\n",
      "[Epoch 54, Batch 12/100] Loss: 0.0384 | RMSE: 0.0359 | Consistency: 0.0073 | SSIM: 0.0244 | Grad: 109306.781\n",
      "[Epoch 54, Batch 13/100] Loss: 0.0472 | RMSE: 0.0449 | Consistency: 0.0091 | SSIM: 0.0214 | Grad: 82074.109\n",
      "[Epoch 54, Batch 14/100] Loss: 0.0430 | RMSE: 0.0403 | Consistency: 0.0086 | SSIM: 0.0258 | Grad: 77761.820\n",
      "[Epoch 54, Batch 15/100] Loss: 0.0379 | RMSE: 0.0348 | Consistency: 0.0065 | SSIM: 0.0299 | Grad: 60941.410\n",
      "[Epoch 54, Batch 16/100] Loss: 0.0423 | RMSE: 0.0397 | Consistency: 0.0066 | SSIM: 0.0252 | Grad: 76111.672\n",
      "[Epoch 54, Batch 17/100] Loss: 0.0453 | RMSE: 0.0426 | Consistency: 0.0086 | SSIM: 0.0256 | Grad: 100559.352\n",
      "[Epoch 54, Batch 18/100] Loss: 0.0351 | RMSE: 0.0332 | Consistency: 0.0071 | SSIM: 0.0183 | Grad: 66949.094\n",
      "[Epoch 54, Batch 19/100] Loss: 0.0395 | RMSE: 0.0365 | Consistency: 0.0081 | SSIM: 0.0298 | Grad: 77521.492\n",
      "[Epoch 54, Batch 20/100] Loss: 0.0382 | RMSE: 0.0357 | Consistency: 0.0072 | SSIM: 0.0243 | Grad: 53316.496\n",
      "[Epoch 54, Batch 21/100] Loss: 0.0400 | RMSE: 0.0374 | Consistency: 0.0067 | SSIM: 0.0256 | Grad: 77662.508\n",
      "[Epoch 54, Batch 22/100] Loss: 0.0389 | RMSE: 0.0365 | Consistency: 0.0077 | SSIM: 0.0230 | Grad: 56628.352\n",
      "[Epoch 54, Batch 23/100] Loss: 0.0406 | RMSE: 0.0380 | Consistency: 0.0083 | SSIM: 0.0253 | Grad: 88137.555\n",
      "[Epoch 54, Batch 24/100] Loss: 0.0390 | RMSE: 0.0362 | Consistency: 0.0070 | SSIM: 0.0273 | Grad: 40350.750\n",
      "[Epoch 54, Batch 25/100] Loss: 0.0374 | RMSE: 0.0348 | Consistency: 0.0060 | SSIM: 0.0247 | Grad: 41395.012\n",
      "[Epoch 54, Batch 26/100] Loss: 0.0386 | RMSE: 0.0364 | Consistency: 0.0070 | SSIM: 0.0219 | Grad: 101275.031\n",
      "[Epoch 54, Batch 27/100] Loss: 0.0449 | RMSE: 0.0423 | Consistency: 0.0088 | SSIM: 0.0252 | Grad: 88551.766\n",
      "[Epoch 54, Batch 28/100] Loss: 0.0405 | RMSE: 0.0380 | Consistency: 0.0076 | SSIM: 0.0238 | Grad: 79999.891\n",
      "[Epoch 54, Batch 29/100] Loss: 0.0384 | RMSE: 0.0356 | Consistency: 0.0074 | SSIM: 0.0272 | Grad: 72984.680\n",
      "[Epoch 54, Batch 30/100] Loss: 0.0359 | RMSE: 0.0331 | Consistency: 0.0067 | SSIM: 0.0273 | Grad: 60909.434\n",
      "[Epoch 54, Batch 31/100] Loss: 0.0407 | RMSE: 0.0376 | Consistency: 0.0072 | SSIM: 0.0307 | Grad: 100245.266\n",
      "[Epoch 54, Batch 32/100] Loss: 0.0408 | RMSE: 0.0380 | Consistency: 0.0067 | SSIM: 0.0278 | Grad: 104762.328\n",
      "[Epoch 54, Batch 33/100] Loss: 0.0406 | RMSE: 0.0375 | Consistency: 0.0078 | SSIM: 0.0298 | Grad: 70366.969\n",
      "[Epoch 54, Batch 34/100] Loss: 0.0374 | RMSE: 0.0351 | Consistency: 0.0070 | SSIM: 0.0231 | Grad: 68452.109\n",
      "[Epoch 54, Batch 35/100] Loss: 0.0375 | RMSE: 0.0352 | Consistency: 0.0073 | SSIM: 0.0222 | Grad: 77652.672\n",
      "[Epoch 54, Batch 36/100] Loss: 0.0450 | RMSE: 0.0422 | Consistency: 0.0097 | SSIM: 0.0269 | Grad: 77539.336\n",
      "[Epoch 54, Batch 37/100] Loss: 0.0376 | RMSE: 0.0356 | Consistency: 0.0061 | SSIM: 0.0196 | Grad: 99337.070\n",
      "[Epoch 54, Batch 38/100] Loss: 0.0371 | RMSE: 0.0351 | Consistency: 0.0071 | SSIM: 0.0202 | Grad: 100276.570\n",
      "[Epoch 54, Batch 39/100] Loss: 0.0355 | RMSE: 0.0332 | Consistency: 0.0065 | SSIM: 0.0222 | Grad: 86762.383\n",
      "[Epoch 54, Batch 40/100] Loss: 0.0393 | RMSE: 0.0365 | Consistency: 0.0067 | SSIM: 0.0273 | Grad: 87941.516\n",
      "[Epoch 54, Batch 41/100] Loss: 0.0422 | RMSE: 0.0392 | Consistency: 0.0084 | SSIM: 0.0288 | Grad: 51679.871\n",
      "[Epoch 54, Batch 42/100] Loss: 0.0410 | RMSE: 0.0381 | Consistency: 0.0086 | SSIM: 0.0284 | Grad: 40671.766\n",
      "[Epoch 54, Batch 43/100] Loss: 0.0371 | RMSE: 0.0352 | Consistency: 0.0064 | SSIM: 0.0185 | Grad: 61623.473\n",
      "[Epoch 54, Batch 44/100] Loss: 0.0335 | RMSE: 0.0317 | Consistency: 0.0048 | SSIM: 0.0172 | Grad: 55410.211\n",
      "[Epoch 54, Batch 45/100] Loss: 0.0373 | RMSE: 0.0349 | Consistency: 0.0070 | SSIM: 0.0234 | Grad: 55568.816\n",
      "[Epoch 54, Batch 46/100] Loss: 0.0381 | RMSE: 0.0362 | Consistency: 0.0068 | SSIM: 0.0185 | Grad: 64986.758\n",
      "[Epoch 54, Batch 47/100] Loss: 0.0415 | RMSE: 0.0393 | Consistency: 0.0073 | SSIM: 0.0213 | Grad: 57190.742\n",
      "[Epoch 54, Batch 48/100] Loss: 0.0434 | RMSE: 0.0406 | Consistency: 0.0098 | SSIM: 0.0265 | Grad: 98661.883\n",
      "[Epoch 54, Batch 49/100] Loss: 0.0453 | RMSE: 0.0422 | Consistency: 0.0088 | SSIM: 0.0294 | Grad: 67809.219\n",
      "[Epoch 54, Batch 50/100] Loss: 0.0390 | RMSE: 0.0369 | Consistency: 0.0070 | SSIM: 0.0205 | Grad: 85483.250\n",
      "[Epoch 54, Batch 51/100] Loss: 0.0380 | RMSE: 0.0352 | Consistency: 0.0068 | SSIM: 0.0281 | Grad: 41411.969\n",
      "[Epoch 54, Batch 52/100] Loss: 0.0406 | RMSE: 0.0378 | Consistency: 0.0071 | SSIM: 0.0277 | Grad: 69498.953\n",
      "[Epoch 54, Batch 53/100] Loss: 0.0395 | RMSE: 0.0363 | Consistency: 0.0056 | SSIM: 0.0315 | Grad: 119226.180\n",
      "[Epoch 54, Batch 54/100] Loss: 0.0461 | RMSE: 0.0428 | Consistency: 0.0113 | SSIM: 0.0322 | Grad: 74678.531\n",
      "[Epoch 54, Batch 55/100] Loss: 0.0423 | RMSE: 0.0398 | Consistency: 0.0087 | SSIM: 0.0251 | Grad: 54747.023\n",
      "[Epoch 54, Batch 56/100] Loss: 0.0359 | RMSE: 0.0337 | Consistency: 0.0066 | SSIM: 0.0211 | Grad: 30039.232\n",
      "[Epoch 54, Batch 57/100] Loss: 0.0399 | RMSE: 0.0373 | Consistency: 0.0076 | SSIM: 0.0259 | Grad: 31985.385\n",
      "[Epoch 54, Batch 58/100] Loss: 0.0359 | RMSE: 0.0336 | Consistency: 0.0064 | SSIM: 0.0223 | Grad: 67977.641\n",
      "[Epoch 54, Batch 59/100] Loss: 0.0396 | RMSE: 0.0374 | Consistency: 0.0091 | SSIM: 0.0213 | Grad: 76142.492\n",
      "[Epoch 54, Batch 60/100] Loss: 0.0412 | RMSE: 0.0386 | Consistency: 0.0098 | SSIM: 0.0244 | Grad: 93259.477\n",
      "[Epoch 54, Batch 61/100] Loss: 0.0390 | RMSE: 0.0365 | Consistency: 0.0080 | SSIM: 0.0245 | Grad: 87141.742\n",
      "[Epoch 54, Batch 62/100] Loss: 0.0391 | RMSE: 0.0366 | Consistency: 0.0070 | SSIM: 0.0244 | Grad: 68608.305\n",
      "[Epoch 54, Batch 63/100] Loss: 0.0403 | RMSE: 0.0376 | Consistency: 0.0079 | SSIM: 0.0269 | Grad: 56407.715\n",
      "[Epoch 54, Batch 64/100] Loss: 0.0438 | RMSE: 0.0414 | Consistency: 0.0105 | SSIM: 0.0228 | Grad: 106953.477\n",
      "[Epoch 54, Batch 65/100] Loss: 0.0456 | RMSE: 0.0424 | Consistency: 0.0111 | SSIM: 0.0311 | Grad: 171520.906\n",
      "[Epoch 54, Batch 66/100] Loss: 0.0498 | RMSE: 0.0467 | Consistency: 0.0150 | SSIM: 0.0298 | Grad: 137601.609\n",
      "[Epoch 54, Batch 67/100] Loss: 0.0388 | RMSE: 0.0364 | Consistency: 0.0083 | SSIM: 0.0233 | Grad: 121268.977\n",
      "[Epoch 54, Batch 68/100] Loss: 0.0401 | RMSE: 0.0374 | Consistency: 0.0088 | SSIM: 0.0264 | Grad: 92096.242\n",
      "[Epoch 54, Batch 69/100] Loss: 0.0364 | RMSE: 0.0341 | Consistency: 0.0065 | SSIM: 0.0222 | Grad: 33434.152\n",
      "[Epoch 54, Batch 70/100] Loss: 0.0461 | RMSE: 0.0430 | Consistency: 0.0099 | SSIM: 0.0297 | Grad: 73096.734\n",
      "[Epoch 54, Batch 71/100] Loss: 0.0408 | RMSE: 0.0375 | Consistency: 0.0078 | SSIM: 0.0326 | Grad: 66145.055\n",
      "[Epoch 54, Batch 72/100] Loss: 0.0420 | RMSE: 0.0393 | Consistency: 0.0078 | SSIM: 0.0264 | Grad: 101220.008\n",
      "[Epoch 54, Batch 73/100] Loss: 0.0387 | RMSE: 0.0364 | Consistency: 0.0071 | SSIM: 0.0220 | Grad: 89603.844\n",
      "[Epoch 54, Batch 74/100] Loss: 0.0401 | RMSE: 0.0374 | Consistency: 0.0077 | SSIM: 0.0266 | Grad: 30286.914\n",
      "[Epoch 54, Batch 75/100] Loss: 0.0390 | RMSE: 0.0361 | Consistency: 0.0072 | SSIM: 0.0279 | Grad: 67707.922\n",
      "[Epoch 54, Batch 76/100] Loss: 0.0327 | RMSE: 0.0309 | Consistency: 0.0048 | SSIM: 0.0180 | Grad: 60481.391\n",
      "[Epoch 54, Batch 77/100] Loss: 0.0401 | RMSE: 0.0375 | Consistency: 0.0073 | SSIM: 0.0254 | Grad: 64078.699\n",
      "[Epoch 54, Batch 78/100] Loss: 0.0392 | RMSE: 0.0359 | Consistency: 0.0068 | SSIM: 0.0319 | Grad: 62210.477\n",
      "[Epoch 54, Batch 79/100] Loss: 0.0429 | RMSE: 0.0405 | Consistency: 0.0086 | SSIM: 0.0233 | Grad: 66193.312\n",
      "[Epoch 54, Batch 80/100] Loss: 0.0402 | RMSE: 0.0373 | Consistency: 0.0064 | SSIM: 0.0278 | Grad: 80875.391\n",
      "[Epoch 54, Batch 81/100] Loss: 0.0361 | RMSE: 0.0339 | Consistency: 0.0057 | SSIM: 0.0218 | Grad: 44885.227\n",
      "[Epoch 54, Batch 82/100] Loss: 0.0415 | RMSE: 0.0388 | Consistency: 0.0073 | SSIM: 0.0266 | Grad: 49903.758\n",
      "[Epoch 54, Batch 83/100] Loss: 0.0308 | RMSE: 0.0290 | Consistency: 0.0049 | SSIM: 0.0176 | Grad: 42233.312\n",
      "[Epoch 54, Batch 84/100] Loss: 0.0353 | RMSE: 0.0328 | Consistency: 0.0058 | SSIM: 0.0248 | Grad: 86226.367\n",
      "[Epoch 54, Batch 85/100] Loss: 0.0307 | RMSE: 0.0290 | Consistency: 0.0044 | SSIM: 0.0166 | Grad: 25179.900\n",
      "[Epoch 54, Batch 86/100] Loss: 0.0443 | RMSE: 0.0417 | Consistency: 0.0086 | SSIM: 0.0251 | Grad: 84075.922\n",
      "[Epoch 54, Batch 87/100] Loss: 0.0427 | RMSE: 0.0400 | Consistency: 0.0078 | SSIM: 0.0265 | Grad: 76040.938\n",
      "[Epoch 54, Batch 88/100] Loss: 0.0441 | RMSE: 0.0412 | Consistency: 0.0092 | SSIM: 0.0281 | Grad: 77711.602\n",
      "[Epoch 54, Batch 89/100] Loss: 0.0381 | RMSE: 0.0359 | Consistency: 0.0073 | SSIM: 0.0204 | Grad: 43444.957\n",
      "[Epoch 54, Batch 90/100] Loss: 0.0473 | RMSE: 0.0445 | Consistency: 0.0118 | SSIM: 0.0269 | Grad: 87379.641\n",
      "[Epoch 54, Batch 91/100] Loss: 0.0344 | RMSE: 0.0321 | Consistency: 0.0055 | SSIM: 0.0229 | Grad: 93200.273\n",
      "[Epoch 54, Batch 92/100] Loss: 0.0354 | RMSE: 0.0335 | Consistency: 0.0051 | SSIM: 0.0189 | Grad: 69139.070\n",
      "[Epoch 54, Batch 93/100] Loss: 0.0433 | RMSE: 0.0404 | Consistency: 0.0088 | SSIM: 0.0286 | Grad: 82101.492\n",
      "[Epoch 54, Batch 94/100] Loss: 0.0400 | RMSE: 0.0376 | Consistency: 0.0075 | SSIM: 0.0226 | Grad: 72763.422\n",
      "[Epoch 54, Batch 95/100] Loss: 0.0450 | RMSE: 0.0422 | Consistency: 0.0093 | SSIM: 0.0279 | Grad: 77785.297\n",
      "[Epoch 54, Batch 96/100] Loss: 0.0389 | RMSE: 0.0362 | Consistency: 0.0066 | SSIM: 0.0258 | Grad: 48214.742\n",
      "[Epoch 54, Batch 97/100] Loss: 0.0485 | RMSE: 0.0451 | Consistency: 0.0139 | SSIM: 0.0328 | Grad: 28191.105\n",
      "[Epoch 54, Batch 98/100] Loss: 0.0361 | RMSE: 0.0342 | Consistency: 0.0069 | SSIM: 0.0180 | Grad: 54621.816\n",
      "[Epoch 54, Batch 99/100] Loss: 0.0358 | RMSE: 0.0331 | Consistency: 0.0065 | SSIM: 0.0257 | Grad: 19288.221\n",
      "[Epoch 54, Batch 100/100] Loss: 0.0367 | RMSE: 0.0346 | Consistency: 0.0058 | SSIM: 0.0206 | Grad: 21934.939\n",
      "✅ Epoch 54 완료!\n",
      "   📈 평균 Loss: 0.039912\n",
      "   📊 평균 RMSE: 0.037331\n",
      "   ⚙️  학습률: 0.000288\n",
      "   🏆 NEW BEST! RMSE: 0.037331\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 55/80 시작...\n",
      "[Epoch 55, Batch 1/100] Loss: 0.0388 | RMSE: 0.0366 | Consistency: 0.0075 | SSIM: 0.0210 | Grad: 94317.500\n",
      "[Epoch 55, Batch 2/100] Loss: 0.0446 | RMSE: 0.0421 | Consistency: 0.0084 | SSIM: 0.0241 | Grad: 41134.113\n",
      "[Epoch 55, Batch 3/100] Loss: 0.0368 | RMSE: 0.0348 | Consistency: 0.0066 | SSIM: 0.0190 | Grad: 98705.273\n",
      "[Epoch 55, Batch 4/100] Loss: 0.0437 | RMSE: 0.0409 | Consistency: 0.0091 | SSIM: 0.0271 | Grad: 45035.020\n",
      "[Epoch 55, Batch 5/100] Loss: 0.0375 | RMSE: 0.0349 | Consistency: 0.0069 | SSIM: 0.0245 | Grad: 102379.156\n",
      "[Epoch 55, Batch 6/100] Loss: 0.0340 | RMSE: 0.0315 | Consistency: 0.0053 | SSIM: 0.0243 | Grad: 57565.402\n",
      "[Epoch 55, Batch 7/100] Loss: 0.0418 | RMSE: 0.0390 | Consistency: 0.0078 | SSIM: 0.0270 | Grad: 53911.199\n",
      "[Epoch 55, Batch 8/100] Loss: 0.0440 | RMSE: 0.0411 | Consistency: 0.0105 | SSIM: 0.0280 | Grad: 24313.439\n",
      "[Epoch 55, Batch 9/100] Loss: 0.0508 | RMSE: 0.0473 | Consistency: 0.0149 | SSIM: 0.0335 | Grad: 38355.926\n",
      "[Epoch 55, Batch 10/100] Loss: 0.0401 | RMSE: 0.0372 | Consistency: 0.0072 | SSIM: 0.0283 | Grad: 77671.555\n",
      "[Epoch 55, Batch 11/100] Loss: 0.0438 | RMSE: 0.0410 | Consistency: 0.0104 | SSIM: 0.0277 | Grad: 76169.852\n",
      "[Epoch 55, Batch 12/100] Loss: 0.0363 | RMSE: 0.0341 | Consistency: 0.0059 | SSIM: 0.0214 | Grad: 88798.180\n",
      "[Epoch 55, Batch 13/100] Loss: 0.0397 | RMSE: 0.0367 | Consistency: 0.0078 | SSIM: 0.0291 | Grad: 73866.586\n",
      "[Epoch 55, Batch 14/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0064 | SSIM: 0.0234 | Grad: 26392.422\n",
      "[Epoch 55, Batch 15/100] Loss: 0.0353 | RMSE: 0.0332 | Consistency: 0.0056 | SSIM: 0.0201 | Grad: 47473.383\n",
      "[Epoch 55, Batch 16/100] Loss: 0.0409 | RMSE: 0.0380 | Consistency: 0.0069 | SSIM: 0.0289 | Grad: 20730.904\n",
      "[Epoch 55, Batch 17/100] Loss: 0.0425 | RMSE: 0.0400 | Consistency: 0.0079 | SSIM: 0.0238 | Grad: 55178.195\n",
      "[Epoch 55, Batch 18/100] Loss: 0.0349 | RMSE: 0.0329 | Consistency: 0.0056 | SSIM: 0.0195 | Grad: 20836.086\n",
      "[Epoch 55, Batch 19/100] Loss: 0.0414 | RMSE: 0.0389 | Consistency: 0.0070 | SSIM: 0.0247 | Grad: 92152.188\n",
      "[Epoch 55, Batch 20/100] Loss: 0.0399 | RMSE: 0.0370 | Consistency: 0.0061 | SSIM: 0.0279 | Grad: 62370.707\n",
      "[Epoch 55, Batch 21/100] Loss: 0.0352 | RMSE: 0.0331 | Consistency: 0.0067 | SSIM: 0.0203 | Grad: 39618.883\n",
      "[Epoch 55, Batch 22/100] Loss: 0.0413 | RMSE: 0.0387 | Consistency: 0.0076 | SSIM: 0.0254 | Grad: 54310.445\n",
      "[Epoch 55, Batch 23/100] Loss: 0.0355 | RMSE: 0.0335 | Consistency: 0.0060 | SSIM: 0.0189 | Grad: 25913.729\n",
      "[Epoch 55, Batch 24/100] Loss: 0.0378 | RMSE: 0.0354 | Consistency: 0.0059 | SSIM: 0.0235 | Grad: 119423.727\n",
      "[Epoch 55, Batch 25/100] Loss: 0.0398 | RMSE: 0.0365 | Consistency: 0.0082 | SSIM: 0.0314 | Grad: 48439.566\n",
      "[Epoch 55, Batch 26/100] Loss: 0.0400 | RMSE: 0.0374 | Consistency: 0.0069 | SSIM: 0.0244 | Grad: 75710.250\n",
      "[Epoch 55, Batch 27/100] Loss: 0.0327 | RMSE: 0.0305 | Consistency: 0.0053 | SSIM: 0.0210 | Grad: 82089.180\n",
      "[Epoch 55, Batch 28/100] Loss: 0.0389 | RMSE: 0.0358 | Consistency: 0.0072 | SSIM: 0.0308 | Grad: 15117.139\n",
      "[Epoch 55, Batch 29/100] Loss: 0.0380 | RMSE: 0.0358 | Consistency: 0.0069 | SSIM: 0.0210 | Grad: 49697.895\n",
      "[Epoch 55, Batch 30/100] Loss: 0.0371 | RMSE: 0.0342 | Consistency: 0.0059 | SSIM: 0.0286 | Grad: 84549.766\n",
      "[Epoch 55, Batch 31/100] Loss: 0.0403 | RMSE: 0.0379 | Consistency: 0.0070 | SSIM: 0.0225 | Grad: 106123.477\n",
      "[Epoch 55, Batch 32/100] Loss: 0.0377 | RMSE: 0.0354 | Consistency: 0.0065 | SSIM: 0.0219 | Grad: 77776.531\n",
      "[Epoch 55, Batch 33/100] Loss: 0.0454 | RMSE: 0.0420 | Consistency: 0.0099 | SSIM: 0.0332 | Grad: 59364.848\n",
      "[Epoch 55, Batch 34/100] Loss: 0.0425 | RMSE: 0.0404 | Consistency: 0.0081 | SSIM: 0.0204 | Grad: 78529.859\n",
      "[Epoch 55, Batch 35/100] Loss: 0.0421 | RMSE: 0.0398 | Consistency: 0.0078 | SSIM: 0.0226 | Grad: 43121.484\n",
      "[Epoch 55, Batch 36/100] Loss: 0.0431 | RMSE: 0.0399 | Consistency: 0.0087 | SSIM: 0.0312 | Grad: 78148.305\n",
      "[Epoch 55, Batch 37/100] Loss: 0.0426 | RMSE: 0.0394 | Consistency: 0.0083 | SSIM: 0.0310 | Grad: 54331.285\n",
      "[Epoch 55, Batch 38/100] Loss: 0.0369 | RMSE: 0.0344 | Consistency: 0.0058 | SSIM: 0.0246 | Grad: 13805.681\n",
      "[Epoch 55, Batch 39/100] Loss: 0.0399 | RMSE: 0.0369 | Consistency: 0.0073 | SSIM: 0.0294 | Grad: 70934.211\n",
      "[Epoch 55, Batch 40/100] Loss: 0.0361 | RMSE: 0.0341 | Consistency: 0.0055 | SSIM: 0.0191 | Grad: 110039.492\n",
      "[Epoch 55, Batch 41/100] Loss: 0.0370 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0250 | Grad: 18401.025\n",
      "[Epoch 55, Batch 42/100] Loss: 0.0367 | RMSE: 0.0348 | Consistency: 0.0060 | SSIM: 0.0192 | Grad: 96246.125\n",
      "[Epoch 55, Batch 43/100] Loss: 0.0393 | RMSE: 0.0361 | Consistency: 0.0068 | SSIM: 0.0311 | Grad: 71541.914\n",
      "[Epoch 55, Batch 44/100] Loss: 0.0365 | RMSE: 0.0339 | Consistency: 0.0060 | SSIM: 0.0256 | Grad: 54304.816\n",
      "[Epoch 55, Batch 45/100] Loss: 0.0396 | RMSE: 0.0368 | Consistency: 0.0079 | SSIM: 0.0270 | Grad: 85013.914\n",
      "[Epoch 55, Batch 46/100] Loss: 0.0446 | RMSE: 0.0420 | Consistency: 0.0078 | SSIM: 0.0256 | Grad: 72250.125\n",
      "[Epoch 55, Batch 47/100] Loss: 0.0647 | RMSE: 0.0612 | Consistency: 0.0183 | SSIM: 0.0326 | Grad: 42965.906\n",
      "[Epoch 55, Batch 48/100] Loss: 0.0421 | RMSE: 0.0391 | Consistency: 0.0079 | SSIM: 0.0291 | Grad: 67101.891\n",
      "[Epoch 55, Batch 49/100] Loss: 0.0377 | RMSE: 0.0352 | Consistency: 0.0070 | SSIM: 0.0244 | Grad: 70730.891\n",
      "[Epoch 55, Batch 50/100] Loss: 0.0441 | RMSE: 0.0414 | Consistency: 0.0086 | SSIM: 0.0257 | Grad: 78340.391\n",
      "[Epoch 55, Batch 51/100] Loss: 0.0415 | RMSE: 0.0385 | Consistency: 0.0087 | SSIM: 0.0291 | Grad: 93282.750\n",
      "[Epoch 55, Batch 52/100] Loss: 0.0451 | RMSE: 0.0419 | Consistency: 0.0085 | SSIM: 0.0308 | Grad: 52458.082\n",
      "[Epoch 55, Batch 53/100] Loss: 0.0344 | RMSE: 0.0325 | Consistency: 0.0055 | SSIM: 0.0185 | Grad: 46347.406\n",
      "[Epoch 55, Batch 54/100] Loss: 0.0420 | RMSE: 0.0390 | Consistency: 0.0076 | SSIM: 0.0294 | Grad: 66682.539\n",
      "[Epoch 55, Batch 55/100] Loss: 0.0394 | RMSE: 0.0365 | Consistency: 0.0073 | SSIM: 0.0278 | Grad: 77418.195\n",
      "[Epoch 55, Batch 56/100] Loss: 0.0394 | RMSE: 0.0370 | Consistency: 0.0068 | SSIM: 0.0230 | Grad: 67374.500\n",
      "[Epoch 55, Batch 57/100] Loss: 0.0363 | RMSE: 0.0338 | Consistency: 0.0067 | SSIM: 0.0245 | Grad: 95149.164\n",
      "[Epoch 55, Batch 58/100] Loss: 0.0377 | RMSE: 0.0353 | Consistency: 0.0069 | SSIM: 0.0235 | Grad: 66090.656\n",
      "[Epoch 55, Batch 59/100] Loss: 0.0409 | RMSE: 0.0379 | Consistency: 0.0077 | SSIM: 0.0286 | Grad: 72361.445\n",
      "[Epoch 55, Batch 60/100] Loss: 0.0360 | RMSE: 0.0339 | Consistency: 0.0064 | SSIM: 0.0207 | Grad: 96950.758\n",
      "[Epoch 55, Batch 61/100] Loss: 0.0404 | RMSE: 0.0373 | Consistency: 0.0078 | SSIM: 0.0301 | Grad: 34928.250\n",
      "[Epoch 55, Batch 62/100] Loss: 0.0383 | RMSE: 0.0360 | Consistency: 0.0062 | SSIM: 0.0218 | Grad: 30523.748\n",
      "[Epoch 55, Batch 63/100] Loss: 0.0427 | RMSE: 0.0404 | Consistency: 0.0077 | SSIM: 0.0229 | Grad: 26368.580\n",
      "[Epoch 55, Batch 64/100] Loss: 0.0373 | RMSE: 0.0352 | Consistency: 0.0065 | SSIM: 0.0206 | Grad: 61186.527\n",
      "[Epoch 55, Batch 65/100] Loss: 0.0357 | RMSE: 0.0334 | Consistency: 0.0065 | SSIM: 0.0219 | Grad: 57052.918\n",
      "[Epoch 55, Batch 66/100] Loss: 0.0344 | RMSE: 0.0323 | Consistency: 0.0061 | SSIM: 0.0209 | Grad: 64924.160\n",
      "[Epoch 55, Batch 67/100] Loss: 0.0415 | RMSE: 0.0389 | Consistency: 0.0084 | SSIM: 0.0255 | Grad: 83128.016\n",
      "[Epoch 55, Batch 68/100] Loss: 0.0374 | RMSE: 0.0350 | Consistency: 0.0067 | SSIM: 0.0231 | Grad: 36398.633\n",
      "[Epoch 55, Batch 69/100] Loss: 0.0365 | RMSE: 0.0342 | Consistency: 0.0074 | SSIM: 0.0221 | Grad: 36794.035\n",
      "[Epoch 55, Batch 70/100] Loss: 0.0401 | RMSE: 0.0375 | Consistency: 0.0078 | SSIM: 0.0248 | Grad: 35118.855\n",
      "[Epoch 55, Batch 71/100] Loss: 0.0351 | RMSE: 0.0330 | Consistency: 0.0065 | SSIM: 0.0204 | Grad: 75286.742\n",
      "[Epoch 55, Batch 72/100] Loss: 0.0453 | RMSE: 0.0423 | Consistency: 0.0104 | SSIM: 0.0287 | Grad: 71436.469\n",
      "[Epoch 55, Batch 73/100] Loss: 0.0388 | RMSE: 0.0363 | Consistency: 0.0068 | SSIM: 0.0237 | Grad: 67523.742\n",
      "[Epoch 55, Batch 74/100] Loss: 0.0403 | RMSE: 0.0379 | Consistency: 0.0083 | SSIM: 0.0226 | Grad: 71472.578\n",
      "[Epoch 55, Batch 75/100] Loss: 0.0406 | RMSE: 0.0374 | Consistency: 0.0073 | SSIM: 0.0317 | Grad: 66583.148\n",
      "[Epoch 55, Batch 76/100] Loss: 0.0351 | RMSE: 0.0330 | Consistency: 0.0051 | SSIM: 0.0199 | Grad: 40545.363\n",
      "[Epoch 55, Batch 77/100] Loss: 0.0390 | RMSE: 0.0365 | Consistency: 0.0068 | SSIM: 0.0248 | Grad: 47998.230\n",
      "[Epoch 55, Batch 78/100] Loss: 0.0357 | RMSE: 0.0330 | Consistency: 0.0063 | SSIM: 0.0266 | Grad: 44467.809\n",
      "[Epoch 55, Batch 79/100] Loss: 0.0366 | RMSE: 0.0343 | Consistency: 0.0065 | SSIM: 0.0219 | Grad: 93303.094\n",
      "[Epoch 55, Batch 80/100] Loss: 0.0374 | RMSE: 0.0354 | Consistency: 0.0061 | SSIM: 0.0199 | Grad: 66807.133\n",
      "[Epoch 55, Batch 81/100] Loss: 0.0354 | RMSE: 0.0331 | Consistency: 0.0055 | SSIM: 0.0220 | Grad: 35788.695\n",
      "[Epoch 55, Batch 82/100] Loss: 0.0333 | RMSE: 0.0310 | Consistency: 0.0051 | SSIM: 0.0227 | Grad: 57136.352\n",
      "[Epoch 55, Batch 83/100] Loss: 0.0371 | RMSE: 0.0346 | Consistency: 0.0066 | SSIM: 0.0246 | Grad: 42399.652\n",
      "[Epoch 55, Batch 84/100] Loss: 0.0385 | RMSE: 0.0364 | Consistency: 0.0066 | SSIM: 0.0203 | Grad: 75957.938\n",
      "[Epoch 55, Batch 85/100] Loss: 0.0441 | RMSE: 0.0409 | Consistency: 0.0106 | SSIM: 0.0311 | Grad: 74446.367\n",
      "[Epoch 55, Batch 86/100] Loss: 0.0377 | RMSE: 0.0345 | Consistency: 0.0062 | SSIM: 0.0307 | Grad: 82969.312\n",
      "[Epoch 55, Batch 87/100] Loss: 0.0373 | RMSE: 0.0351 | Consistency: 0.0069 | SSIM: 0.0216 | Grad: 73302.016\n",
      "[Epoch 55, Batch 88/100] Loss: 0.0416 | RMSE: 0.0385 | Consistency: 0.0088 | SSIM: 0.0305 | Grad: 109534.508\n",
      "[Epoch 55, Batch 89/100] Loss: 0.0440 | RMSE: 0.0416 | Consistency: 0.0102 | SSIM: 0.0224 | Grad: 109804.484\n",
      "[Epoch 55, Batch 90/100] Loss: 0.0402 | RMSE: 0.0377 | Consistency: 0.0078 | SSIM: 0.0240 | Grad: 88262.656\n",
      "[Epoch 55, Batch 91/100] Loss: 0.0442 | RMSE: 0.0412 | Consistency: 0.0084 | SSIM: 0.0294 | Grad: 48081.910\n",
      "[Epoch 55, Batch 92/100] Loss: 0.0438 | RMSE: 0.0407 | Consistency: 0.0073 | SSIM: 0.0304 | Grad: 77985.094\n",
      "[Epoch 55, Batch 93/100] Loss: 0.0388 | RMSE: 0.0361 | Consistency: 0.0064 | SSIM: 0.0256 | Grad: 74123.281\n",
      "[Epoch 55, Batch 94/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0077 | SSIM: 0.0243 | Grad: 82653.266\n",
      "[Epoch 55, Batch 95/100] Loss: 0.0381 | RMSE: 0.0360 | Consistency: 0.0070 | SSIM: 0.0198 | Grad: 110746.852\n",
      "[Epoch 55, Batch 96/100] Loss: 0.0357 | RMSE: 0.0338 | Consistency: 0.0048 | SSIM: 0.0192 | Grad: 97241.344\n",
      "[Epoch 55, Batch 97/100] Loss: 0.0435 | RMSE: 0.0413 | Consistency: 0.0077 | SSIM: 0.0218 | Grad: 84819.641\n",
      "[Epoch 55, Batch 98/100] Loss: 0.0426 | RMSE: 0.0397 | Consistency: 0.0083 | SSIM: 0.0279 | Grad: 89528.758\n",
      "[Epoch 55, Batch 99/100] Loss: 0.0371 | RMSE: 0.0348 | Consistency: 0.0060 | SSIM: 0.0220 | Grad: 41252.180\n",
      "[Epoch 55, Batch 100/100] Loss: 0.0340 | RMSE: 0.0316 | Consistency: 0.0053 | SSIM: 0.0232 | Grad: 71979.031\n",
      "✅ Epoch 55 완료!\n",
      "   📈 평균 Loss: 0.039563\n",
      "   📊 평균 RMSE: 0.036996\n",
      "   ⚙️  학습률: 0.000269\n",
      "   🏆 NEW BEST! RMSE: 0.036996\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 56/80 시작...\n",
      "[Epoch 56, Batch 1/100] Loss: 0.0371 | RMSE: 0.0344 | Consistency: 0.0066 | SSIM: 0.0263 | Grad: 46327.316\n",
      "[Epoch 56, Batch 2/100] Loss: 0.0471 | RMSE: 0.0444 | Consistency: 0.0085 | SSIM: 0.0266 | Grad: 139086.156\n",
      "[Epoch 56, Batch 3/100] Loss: 0.0394 | RMSE: 0.0364 | Consistency: 0.0073 | SSIM: 0.0291 | Grad: 76823.914\n",
      "[Epoch 56, Batch 4/100] Loss: 0.0405 | RMSE: 0.0376 | Consistency: 0.0067 | SSIM: 0.0283 | Grad: 137772.172\n",
      "[Epoch 56, Batch 5/100] Loss: 0.0407 | RMSE: 0.0379 | Consistency: 0.0073 | SSIM: 0.0272 | Grad: 109980.258\n",
      "[Epoch 56, Batch 6/100] Loss: 0.0398 | RMSE: 0.0371 | Consistency: 0.0088 | SSIM: 0.0258 | Grad: 38050.410\n",
      "[Epoch 56, Batch 7/100] Loss: 0.0399 | RMSE: 0.0376 | Consistency: 0.0065 | SSIM: 0.0224 | Grad: 94545.805\n",
      "[Epoch 56, Batch 8/100] Loss: 0.0368 | RMSE: 0.0344 | Consistency: 0.0069 | SSIM: 0.0235 | Grad: 76290.734\n",
      "[Epoch 56, Batch 9/100] Loss: 0.0442 | RMSE: 0.0414 | Consistency: 0.0083 | SSIM: 0.0273 | Grad: 91976.109\n",
      "[Epoch 56, Batch 10/100] Loss: 0.0376 | RMSE: 0.0349 | Consistency: 0.0070 | SSIM: 0.0255 | Grad: 103376.984\n",
      "[Epoch 56, Batch 11/100] Loss: 0.0413 | RMSE: 0.0385 | Consistency: 0.0078 | SSIM: 0.0275 | Grad: 61071.164\n",
      "[Epoch 56, Batch 12/100] Loss: 0.0367 | RMSE: 0.0341 | Consistency: 0.0065 | SSIM: 0.0258 | Grad: 45221.031\n",
      "[Epoch 56, Batch 13/100] Loss: 0.0361 | RMSE: 0.0337 | Consistency: 0.0054 | SSIM: 0.0227 | Grad: 103118.906\n",
      "[Epoch 56, Batch 14/100] Loss: 0.0353 | RMSE: 0.0333 | Consistency: 0.0065 | SSIM: 0.0188 | Grad: 115397.312\n",
      "[Epoch 56, Batch 15/100] Loss: 0.0484 | RMSE: 0.0457 | Consistency: 0.0103 | SSIM: 0.0261 | Grad: 143257.234\n",
      "[Epoch 56, Batch 16/100] Loss: 0.0513 | RMSE: 0.0483 | Consistency: 0.0123 | SSIM: 0.0284 | Grad: 133664.609\n",
      "[Epoch 56, Batch 17/100] Loss: 0.0489 | RMSE: 0.0457 | Consistency: 0.0134 | SSIM: 0.0310 | Grad: 81204.008\n",
      "[Epoch 56, Batch 18/100] Loss: 0.0413 | RMSE: 0.0390 | Consistency: 0.0079 | SSIM: 0.0219 | Grad: 90242.141\n",
      "[Epoch 56, Batch 19/100] Loss: 0.0319 | RMSE: 0.0301 | Consistency: 0.0046 | SSIM: 0.0168 | Grad: 73971.414\n",
      "[Epoch 56, Batch 20/100] Loss: 0.0387 | RMSE: 0.0362 | Consistency: 0.0084 | SSIM: 0.0233 | Grad: 62529.879\n",
      "[Epoch 56, Batch 21/100] Loss: 0.0425 | RMSE: 0.0399 | Consistency: 0.0083 | SSIM: 0.0253 | Grad: 88848.766\n",
      "[Epoch 56, Batch 22/100] Loss: 0.0460 | RMSE: 0.0434 | Consistency: 0.0103 | SSIM: 0.0249 | Grad: 79558.695\n",
      "[Epoch 56, Batch 23/100] Loss: 0.0493 | RMSE: 0.0451 | Consistency: 0.0116 | SSIM: 0.0404 | Grad: 130981.016\n",
      "[Epoch 56, Batch 24/100] Loss: 0.0424 | RMSE: 0.0399 | Consistency: 0.0093 | SSIM: 0.0242 | Grad: 101062.070\n",
      "[Epoch 56, Batch 25/100] Loss: 0.0357 | RMSE: 0.0335 | Consistency: 0.0061 | SSIM: 0.0213 | Grad: 111114.523\n",
      "[Epoch 56, Batch 26/100] Loss: 0.0457 | RMSE: 0.0424 | Consistency: 0.0100 | SSIM: 0.0317 | Grad: 84567.180\n",
      "[Epoch 56, Batch 27/100] Loss: 0.0409 | RMSE: 0.0380 | Consistency: 0.0079 | SSIM: 0.0276 | Grad: 25486.363\n",
      "[Epoch 56, Batch 28/100] Loss: 0.0380 | RMSE: 0.0358 | Consistency: 0.0083 | SSIM: 0.0215 | Grad: 82528.781\n",
      "[Epoch 56, Batch 29/100] Loss: 0.0418 | RMSE: 0.0384 | Consistency: 0.0078 | SSIM: 0.0333 | Grad: 102553.781\n",
      "[Epoch 56, Batch 30/100] Loss: 0.0401 | RMSE: 0.0372 | Consistency: 0.0073 | SSIM: 0.0281 | Grad: 60850.699\n",
      "[Epoch 56, Batch 31/100] Loss: 0.0404 | RMSE: 0.0378 | Consistency: 0.0078 | SSIM: 0.0259 | Grad: 108076.938\n",
      "[Epoch 56, Batch 32/100] Loss: 0.0413 | RMSE: 0.0383 | Consistency: 0.0086 | SSIM: 0.0299 | Grad: 19280.391\n",
      "[Epoch 56, Batch 33/100] Loss: 0.0402 | RMSE: 0.0375 | Consistency: 0.0070 | SSIM: 0.0270 | Grad: 61934.000\n",
      "[Epoch 56, Batch 34/100] Loss: 0.0375 | RMSE: 0.0351 | Consistency: 0.0064 | SSIM: 0.0239 | Grad: 60912.723\n",
      "[Epoch 56, Batch 35/100] Loss: 0.0431 | RMSE: 0.0400 | Consistency: 0.0077 | SSIM: 0.0300 | Grad: 75684.859\n",
      "[Epoch 56, Batch 36/100] Loss: 0.0358 | RMSE: 0.0338 | Consistency: 0.0057 | SSIM: 0.0193 | Grad: 47711.637\n",
      "[Epoch 56, Batch 37/100] Loss: 0.0410 | RMSE: 0.0382 | Consistency: 0.0077 | SSIM: 0.0271 | Grad: 86585.117\n",
      "[Epoch 56, Batch 38/100] Loss: 0.0424 | RMSE: 0.0390 | Consistency: 0.0075 | SSIM: 0.0333 | Grad: 74917.047\n",
      "[Epoch 56, Batch 39/100] Loss: 0.0405 | RMSE: 0.0376 | Consistency: 0.0062 | SSIM: 0.0275 | Grad: 139532.828\n",
      "[Epoch 56, Batch 40/100] Loss: 0.0575 | RMSE: 0.0543 | Consistency: 0.0139 | SSIM: 0.0305 | Grad: 63730.055\n",
      "[Epoch 56, Batch 41/100] Loss: 0.0381 | RMSE: 0.0359 | Consistency: 0.0062 | SSIM: 0.0217 | Grad: 109576.750\n",
      "[Epoch 56, Batch 42/100] Loss: 0.0419 | RMSE: 0.0392 | Consistency: 0.0071 | SSIM: 0.0255 | Grad: 103188.766\n",
      "[Epoch 56, Batch 43/100] Loss: 0.0453 | RMSE: 0.0424 | Consistency: 0.0102 | SSIM: 0.0282 | Grad: 65873.008\n",
      "[Epoch 56, Batch 44/100] Loss: 0.0360 | RMSE: 0.0333 | Consistency: 0.0063 | SSIM: 0.0261 | Grad: 74751.641\n",
      "[Epoch 56, Batch 45/100] Loss: 0.0409 | RMSE: 0.0381 | Consistency: 0.0075 | SSIM: 0.0266 | Grad: 55346.770\n",
      "[Epoch 56, Batch 46/100] Loss: 0.0344 | RMSE: 0.0322 | Consistency: 0.0059 | SSIM: 0.0213 | Grad: 76928.133\n",
      "[Epoch 56, Batch 47/100] Loss: 0.0387 | RMSE: 0.0362 | Consistency: 0.0071 | SSIM: 0.0234 | Grad: 78546.258\n",
      "[Epoch 56, Batch 48/100] Loss: 0.0330 | RMSE: 0.0310 | Consistency: 0.0045 | SSIM: 0.0191 | Grad: 83739.648\n",
      "[Epoch 56, Batch 49/100] Loss: 0.0377 | RMSE: 0.0350 | Consistency: 0.0058 | SSIM: 0.0259 | Grad: 24859.830\n",
      "[Epoch 56, Batch 50/100] Loss: 0.0370 | RMSE: 0.0350 | Consistency: 0.0070 | SSIM: 0.0189 | Grad: 87704.164\n",
      "[Epoch 56, Batch 51/100] Loss: 0.0403 | RMSE: 0.0377 | Consistency: 0.0070 | SSIM: 0.0255 | Grad: 41555.816\n",
      "[Epoch 56, Batch 52/100] Loss: 0.0334 | RMSE: 0.0312 | Consistency: 0.0060 | SSIM: 0.0215 | Grad: 57725.715\n",
      "[Epoch 56, Batch 53/100] Loss: 0.0393 | RMSE: 0.0369 | Consistency: 0.0071 | SSIM: 0.0227 | Grad: 105336.672\n",
      "[Epoch 56, Batch 54/100] Loss: 0.0410 | RMSE: 0.0388 | Consistency: 0.0074 | SSIM: 0.0213 | Grad: 130550.688\n",
      "[Epoch 56, Batch 55/100] Loss: 0.0412 | RMSE: 0.0385 | Consistency: 0.0077 | SSIM: 0.0258 | Grad: 94348.266\n",
      "[Epoch 56, Batch 56/100] Loss: 0.0352 | RMSE: 0.0330 | Consistency: 0.0053 | SSIM: 0.0224 | Grad: 59877.012\n",
      "[Epoch 56, Batch 57/100] Loss: 0.0365 | RMSE: 0.0343 | Consistency: 0.0060 | SSIM: 0.0208 | Grad: 37685.285\n",
      "[Epoch 56, Batch 58/100] Loss: 0.0433 | RMSE: 0.0404 | Consistency: 0.0076 | SSIM: 0.0280 | Grad: 87923.906\n",
      "[Epoch 56, Batch 59/100] Loss: 0.0439 | RMSE: 0.0412 | Consistency: 0.0104 | SSIM: 0.0259 | Grad: 61578.934\n",
      "[Epoch 56, Batch 60/100] Loss: 0.0331 | RMSE: 0.0313 | Consistency: 0.0057 | SSIM: 0.0166 | Grad: 75104.758\n",
      "[Epoch 56, Batch 61/100] Loss: 0.0357 | RMSE: 0.0329 | Consistency: 0.0055 | SSIM: 0.0268 | Grad: 33017.145\n",
      "[Epoch 56, Batch 62/100] Loss: 0.0411 | RMSE: 0.0381 | Consistency: 0.0077 | SSIM: 0.0289 | Grad: 65179.180\n",
      "[Epoch 56, Batch 63/100] Loss: 0.0374 | RMSE: 0.0347 | Consistency: 0.0071 | SSIM: 0.0264 | Grad: 45974.359\n",
      "[Epoch 56, Batch 64/100] Loss: 0.0422 | RMSE: 0.0392 | Consistency: 0.0090 | SSIM: 0.0292 | Grad: 42074.035\n",
      "[Epoch 56, Batch 65/100] Loss: 0.0490 | RMSE: 0.0465 | Consistency: 0.0110 | SSIM: 0.0244 | Grad: 23029.625\n",
      "[Epoch 56, Batch 66/100] Loss: 0.0409 | RMSE: 0.0384 | Consistency: 0.0078 | SSIM: 0.0233 | Grad: 78912.695\n",
      "[Epoch 56, Batch 67/100] Loss: 0.0443 | RMSE: 0.0411 | Consistency: 0.0086 | SSIM: 0.0311 | Grad: 100818.539\n",
      "[Epoch 56, Batch 68/100] Loss: 0.0396 | RMSE: 0.0371 | Consistency: 0.0074 | SSIM: 0.0246 | Grad: 79834.320\n",
      "[Epoch 56, Batch 69/100] Loss: 0.0371 | RMSE: 0.0348 | Consistency: 0.0064 | SSIM: 0.0230 | Grad: 36343.688\n",
      "[Epoch 56, Batch 70/100] Loss: 0.0425 | RMSE: 0.0397 | Consistency: 0.0084 | SSIM: 0.0271 | Grad: 98134.750\n",
      "[Epoch 56, Batch 71/100] Loss: 0.0420 | RMSE: 0.0393 | Consistency: 0.0083 | SSIM: 0.0262 | Grad: 77213.914\n",
      "[Epoch 56, Batch 72/100] Loss: 0.0415 | RMSE: 0.0392 | Consistency: 0.0078 | SSIM: 0.0222 | Grad: 88146.031\n",
      "[Epoch 56, Batch 73/100] Loss: 0.0412 | RMSE: 0.0387 | Consistency: 0.0061 | SSIM: 0.0244 | Grad: 136942.938\n",
      "[Epoch 56, Batch 74/100] Loss: 0.0357 | RMSE: 0.0335 | Consistency: 0.0054 | SSIM: 0.0217 | Grad: 39973.086\n",
      "[Epoch 56, Batch 75/100] Loss: 0.0348 | RMSE: 0.0327 | Consistency: 0.0060 | SSIM: 0.0206 | Grad: 72271.602\n",
      "[Epoch 56, Batch 76/100] Loss: 0.0531 | RMSE: 0.0498 | Consistency: 0.0150 | SSIM: 0.0316 | Grad: 50794.566\n",
      "[Epoch 56, Batch 77/100] Loss: 0.0446 | RMSE: 0.0419 | Consistency: 0.0095 | SSIM: 0.0265 | Grad: 90111.586\n",
      "[Epoch 56, Batch 78/100] Loss: 0.0399 | RMSE: 0.0375 | Consistency: 0.0070 | SSIM: 0.0232 | Grad: 108971.414\n",
      "[Epoch 56, Batch 79/100] Loss: 0.0424 | RMSE: 0.0398 | Consistency: 0.0085 | SSIM: 0.0259 | Grad: 37731.586\n",
      "[Epoch 56, Batch 80/100] Loss: 0.0390 | RMSE: 0.0363 | Consistency: 0.0075 | SSIM: 0.0269 | Grad: 91113.680\n",
      "[Epoch 56, Batch 81/100] Loss: 0.0399 | RMSE: 0.0367 | Consistency: 0.0080 | SSIM: 0.0310 | Grad: 95109.906\n",
      "[Epoch 56, Batch 82/100] Loss: 0.0440 | RMSE: 0.0412 | Consistency: 0.0087 | SSIM: 0.0276 | Grad: 102759.656\n",
      "[Epoch 56, Batch 83/100] Loss: 0.0454 | RMSE: 0.0430 | Consistency: 0.0085 | SSIM: 0.0240 | Grad: 109231.234\n",
      "[Epoch 56, Batch 84/100] Loss: 0.0487 | RMSE: 0.0449 | Consistency: 0.0119 | SSIM: 0.0368 | Grad: 42077.559\n",
      "[Epoch 56, Batch 85/100] Loss: 0.0367 | RMSE: 0.0344 | Consistency: 0.0056 | SSIM: 0.0231 | Grad: 72478.312\n",
      "[Epoch 56, Batch 86/100] Loss: 0.0394 | RMSE: 0.0372 | Consistency: 0.0068 | SSIM: 0.0214 | Grad: 54420.105\n",
      "[Epoch 56, Batch 87/100] Loss: 0.0399 | RMSE: 0.0374 | Consistency: 0.0080 | SSIM: 0.0239 | Grad: 62804.078\n",
      "[Epoch 56, Batch 88/100] Loss: 0.0397 | RMSE: 0.0372 | Consistency: 0.0088 | SSIM: 0.0240 | Grad: 69309.414\n",
      "[Epoch 56, Batch 89/100] Loss: 0.0339 | RMSE: 0.0314 | Consistency: 0.0057 | SSIM: 0.0252 | Grad: 52659.602\n",
      "[Epoch 56, Batch 90/100] Loss: 0.0362 | RMSE: 0.0340 | Consistency: 0.0072 | SSIM: 0.0216 | Grad: 40891.793\n",
      "[Epoch 56, Batch 91/100] Loss: 0.0349 | RMSE: 0.0327 | Consistency: 0.0063 | SSIM: 0.0211 | Grad: 68802.641\n",
      "[Epoch 56, Batch 92/100] Loss: 0.0419 | RMSE: 0.0392 | Consistency: 0.0100 | SSIM: 0.0257 | Grad: 54600.309\n",
      "[Epoch 56, Batch 93/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0076 | SSIM: 0.0241 | Grad: 92865.953\n",
      "[Epoch 56, Batch 94/100] Loss: 0.0489 | RMSE: 0.0456 | Consistency: 0.0123 | SSIM: 0.0310 | Grad: 79824.195\n",
      "[Epoch 56, Batch 95/100] Loss: 0.0503 | RMSE: 0.0474 | Consistency: 0.0096 | SSIM: 0.0285 | Grad: 105138.539\n",
      "[Epoch 56, Batch 96/100] Loss: 0.0412 | RMSE: 0.0384 | Consistency: 0.0074 | SSIM: 0.0272 | Grad: 118197.766\n",
      "[Epoch 56, Batch 97/100] Loss: 0.0377 | RMSE: 0.0349 | Consistency: 0.0066 | SSIM: 0.0273 | Grad: 113440.445\n",
      "[Epoch 56, Batch 98/100] Loss: 0.0383 | RMSE: 0.0359 | Consistency: 0.0066 | SSIM: 0.0227 | Grad: 96796.586\n",
      "[Epoch 56, Batch 99/100] Loss: 0.0380 | RMSE: 0.0353 | Consistency: 0.0066 | SSIM: 0.0258 | Grad: 50485.172\n",
      "[Epoch 56, Batch 100/100] Loss: 0.0406 | RMSE: 0.0378 | Consistency: 0.0071 | SSIM: 0.0271 | Grad: 45161.023\n",
      "✅ Epoch 56 완료!\n",
      "   📈 평균 Loss: 0.040651\n",
      "   📊 평균 RMSE: 0.038016\n",
      "   ⚙️  학습률: 0.000250\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 57/80 시작...\n",
      "[Epoch 57, Batch 1/100] Loss: 0.0345 | RMSE: 0.0326 | Consistency: 0.0068 | SSIM: 0.0179 | Grad: 96629.133\n",
      "[Epoch 57, Batch 2/100] Loss: 0.0365 | RMSE: 0.0346 | Consistency: 0.0049 | SSIM: 0.0189 | Grad: 94498.273\n",
      "[Epoch 57, Batch 3/100] Loss: 0.0379 | RMSE: 0.0356 | Consistency: 0.0052 | SSIM: 0.0226 | Grad: 92746.961\n",
      "[Epoch 57, Batch 4/100] Loss: 0.0433 | RMSE: 0.0401 | Consistency: 0.0073 | SSIM: 0.0320 | Grad: 101252.023\n",
      "[Epoch 57, Batch 5/100] Loss: 0.0375 | RMSE: 0.0348 | Consistency: 0.0064 | SSIM: 0.0270 | Grad: 78521.797\n",
      "[Epoch 57, Batch 6/100] Loss: 0.0385 | RMSE: 0.0361 | Consistency: 0.0066 | SSIM: 0.0235 | Grad: 101747.227\n",
      "[Epoch 57, Batch 7/100] Loss: 0.0313 | RMSE: 0.0293 | Consistency: 0.0042 | SSIM: 0.0196 | Grad: 37824.855\n",
      "[Epoch 57, Batch 8/100] Loss: 0.0398 | RMSE: 0.0374 | Consistency: 0.0072 | SSIM: 0.0230 | Grad: 88329.750\n",
      "[Epoch 57, Batch 9/100] Loss: 0.0355 | RMSE: 0.0325 | Consistency: 0.0062 | SSIM: 0.0295 | Grad: 70001.047\n",
      "[Epoch 57, Batch 10/100] Loss: 0.0363 | RMSE: 0.0332 | Consistency: 0.0063 | SSIM: 0.0302 | Grad: 40138.965\n",
      "[Epoch 57, Batch 11/100] Loss: 0.0411 | RMSE: 0.0389 | Consistency: 0.0076 | SSIM: 0.0209 | Grad: 116268.227\n",
      "[Epoch 57, Batch 12/100] Loss: 0.0392 | RMSE: 0.0361 | Consistency: 0.0064 | SSIM: 0.0297 | Grad: 84399.148\n",
      "[Epoch 57, Batch 13/100] Loss: 0.0401 | RMSE: 0.0374 | Consistency: 0.0076 | SSIM: 0.0261 | Grad: 85679.797\n",
      "[Epoch 57, Batch 14/100] Loss: 0.0384 | RMSE: 0.0358 | Consistency: 0.0067 | SSIM: 0.0249 | Grad: 103948.352\n",
      "[Epoch 57, Batch 15/100] Loss: 0.0344 | RMSE: 0.0326 | Consistency: 0.0055 | SSIM: 0.0176 | Grad: 60750.809\n",
      "[Epoch 57, Batch 16/100] Loss: 0.0318 | RMSE: 0.0298 | Consistency: 0.0045 | SSIM: 0.0200 | Grad: 34544.609\n",
      "[Epoch 57, Batch 17/100] Loss: 0.0442 | RMSE: 0.0415 | Consistency: 0.0084 | SSIM: 0.0257 | Grad: 75613.805\n",
      "[Epoch 57, Batch 18/100] Loss: 0.0362 | RMSE: 0.0338 | Consistency: 0.0061 | SSIM: 0.0225 | Grad: 109001.062\n",
      "[Epoch 57, Batch 19/100] Loss: 0.0435 | RMSE: 0.0405 | Consistency: 0.0071 | SSIM: 0.0297 | Grad: 124925.781\n",
      "[Epoch 57, Batch 20/100] Loss: 0.0456 | RMSE: 0.0425 | Consistency: 0.0106 | SSIM: 0.0305 | Grad: 68481.227\n",
      "[Epoch 57, Batch 21/100] Loss: 0.0340 | RMSE: 0.0319 | Consistency: 0.0054 | SSIM: 0.0198 | Grad: 55039.559\n",
      "[Epoch 57, Batch 22/100] Loss: 0.0364 | RMSE: 0.0340 | Consistency: 0.0070 | SSIM: 0.0229 | Grad: 41663.246\n",
      "[Epoch 57, Batch 23/100] Loss: 0.0396 | RMSE: 0.0370 | Consistency: 0.0075 | SSIM: 0.0245 | Grad: 55547.141\n",
      "[Epoch 57, Batch 24/100] Loss: 0.0364 | RMSE: 0.0339 | Consistency: 0.0060 | SSIM: 0.0247 | Grad: 78775.617\n",
      "[Epoch 57, Batch 25/100] Loss: 0.0393 | RMSE: 0.0370 | Consistency: 0.0065 | SSIM: 0.0229 | Grad: 130519.656\n",
      "[Epoch 57, Batch 26/100] Loss: 0.0408 | RMSE: 0.0378 | Consistency: 0.0072 | SSIM: 0.0291 | Grad: 120659.586\n",
      "[Epoch 57, Batch 27/100] Loss: 0.0386 | RMSE: 0.0360 | Consistency: 0.0081 | SSIM: 0.0258 | Grad: 96441.430\n",
      "[Epoch 57, Batch 28/100] Loss: 0.0424 | RMSE: 0.0397 | Consistency: 0.0077 | SSIM: 0.0255 | Grad: 79766.328\n",
      "[Epoch 57, Batch 29/100] Loss: 0.0395 | RMSE: 0.0370 | Consistency: 0.0081 | SSIM: 0.0246 | Grad: 39957.094\n",
      "[Epoch 57, Batch 30/100] Loss: 0.0355 | RMSE: 0.0334 | Consistency: 0.0058 | SSIM: 0.0207 | Grad: 75468.641\n",
      "[Epoch 57, Batch 31/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0087 | SSIM: 0.0238 | Grad: 64010.227\n",
      "[Epoch 57, Batch 32/100] Loss: 0.0355 | RMSE: 0.0331 | Consistency: 0.0059 | SSIM: 0.0232 | Grad: 18468.971\n",
      "[Epoch 57, Batch 33/100] Loss: 0.0408 | RMSE: 0.0382 | Consistency: 0.0098 | SSIM: 0.0251 | Grad: 90013.320\n",
      "[Epoch 57, Batch 34/100] Loss: 0.0369 | RMSE: 0.0348 | Consistency: 0.0069 | SSIM: 0.0204 | Grad: 101209.930\n",
      "[Epoch 57, Batch 35/100] Loss: 0.0429 | RMSE: 0.0402 | Consistency: 0.0111 | SSIM: 0.0253 | Grad: 100940.797\n",
      "[Epoch 57, Batch 36/100] Loss: 0.0402 | RMSE: 0.0380 | Consistency: 0.0079 | SSIM: 0.0213 | Grad: 73526.266\n",
      "[Epoch 57, Batch 37/100] Loss: 0.0385 | RMSE: 0.0361 | Consistency: 0.0065 | SSIM: 0.0232 | Grad: 22526.525\n",
      "[Epoch 57, Batch 38/100] Loss: 0.0351 | RMSE: 0.0329 | Consistency: 0.0055 | SSIM: 0.0212 | Grad: 58025.660\n",
      "[Epoch 57, Batch 39/100] Loss: 0.0325 | RMSE: 0.0304 | Consistency: 0.0047 | SSIM: 0.0207 | Grad: 57620.637\n",
      "[Epoch 57, Batch 40/100] Loss: 0.0361 | RMSE: 0.0336 | Consistency: 0.0064 | SSIM: 0.0244 | Grad: 79953.273\n",
      "[Epoch 57, Batch 41/100] Loss: 0.0438 | RMSE: 0.0413 | Consistency: 0.0076 | SSIM: 0.0244 | Grad: 53802.512\n",
      "[Epoch 57, Batch 42/100] Loss: 0.0358 | RMSE: 0.0336 | Consistency: 0.0060 | SSIM: 0.0216 | Grad: 105166.625\n",
      "[Epoch 57, Batch 43/100] Loss: 0.0379 | RMSE: 0.0351 | Consistency: 0.0072 | SSIM: 0.0272 | Grad: 77862.969\n",
      "[Epoch 57, Batch 44/100] Loss: 0.0375 | RMSE: 0.0353 | Consistency: 0.0070 | SSIM: 0.0214 | Grad: 66130.469\n",
      "[Epoch 57, Batch 45/100] Loss: 0.0345 | RMSE: 0.0324 | Consistency: 0.0056 | SSIM: 0.0214 | Grad: 38541.219\n",
      "[Epoch 57, Batch 46/100] Loss: 0.0341 | RMSE: 0.0320 | Consistency: 0.0058 | SSIM: 0.0206 | Grad: 85389.266\n",
      "[Epoch 57, Batch 47/100] Loss: 0.0410 | RMSE: 0.0384 | Consistency: 0.0073 | SSIM: 0.0258 | Grad: 20336.457\n",
      "[Epoch 57, Batch 48/100] Loss: 0.0356 | RMSE: 0.0336 | Consistency: 0.0056 | SSIM: 0.0200 | Grad: 53691.582\n",
      "[Epoch 57, Batch 49/100] Loss: 0.0377 | RMSE: 0.0353 | Consistency: 0.0058 | SSIM: 0.0235 | Grad: 21485.035\n",
      "[Epoch 57, Batch 50/100] Loss: 0.0350 | RMSE: 0.0330 | Consistency: 0.0056 | SSIM: 0.0190 | Grad: 59854.559\n",
      "[Epoch 57, Batch 51/100] Loss: 0.0441 | RMSE: 0.0407 | Consistency: 0.0087 | SSIM: 0.0327 | Grad: 60610.328\n",
      "[Epoch 57, Batch 52/100] Loss: 0.0444 | RMSE: 0.0412 | Consistency: 0.0085 | SSIM: 0.0306 | Grad: 71350.430\n",
      "[Epoch 57, Batch 53/100] Loss: 0.0491 | RMSE: 0.0462 | Consistency: 0.0112 | SSIM: 0.0275 | Grad: 100604.461\n",
      "[Epoch 57, Batch 54/100] Loss: 0.0423 | RMSE: 0.0395 | Consistency: 0.0085 | SSIM: 0.0271 | Grad: 90901.273\n",
      "[Epoch 57, Batch 55/100] Loss: 0.0444 | RMSE: 0.0419 | Consistency: 0.0078 | SSIM: 0.0249 | Grad: 57598.766\n",
      "[Epoch 57, Batch 56/100] Loss: 0.0441 | RMSE: 0.0410 | Consistency: 0.0099 | SSIM: 0.0301 | Grad: 80765.828\n",
      "[Epoch 57, Batch 57/100] Loss: 0.0477 | RMSE: 0.0444 | Consistency: 0.0123 | SSIM: 0.0319 | Grad: 113855.305\n",
      "[Epoch 57, Batch 58/100] Loss: 0.0407 | RMSE: 0.0385 | Consistency: 0.0089 | SSIM: 0.0210 | Grad: 121148.117\n",
      "[Epoch 57, Batch 59/100] Loss: 0.0403 | RMSE: 0.0381 | Consistency: 0.0081 | SSIM: 0.0216 | Grad: 146691.625\n",
      "[Epoch 57, Batch 60/100] Loss: 0.0359 | RMSE: 0.0337 | Consistency: 0.0056 | SSIM: 0.0212 | Grad: 57435.496\n",
      "[Epoch 57, Batch 61/100] Loss: 0.0332 | RMSE: 0.0312 | Consistency: 0.0052 | SSIM: 0.0203 | Grad: 73342.570\n",
      "[Epoch 57, Batch 62/100] Loss: 0.0399 | RMSE: 0.0377 | Consistency: 0.0065 | SSIM: 0.0213 | Grad: 56027.230\n",
      "[Epoch 57, Batch 63/100] Loss: 0.0346 | RMSE: 0.0326 | Consistency: 0.0063 | SSIM: 0.0187 | Grad: 75847.125\n",
      "[Epoch 57, Batch 64/100] Loss: 0.0365 | RMSE: 0.0343 | Consistency: 0.0068 | SSIM: 0.0215 | Grad: 83358.086\n",
      "[Epoch 57, Batch 65/100] Loss: 0.0438 | RMSE: 0.0400 | Consistency: 0.0101 | SSIM: 0.0362 | Grad: 81013.250\n",
      "[Epoch 57, Batch 66/100] Loss: 0.0352 | RMSE: 0.0330 | Consistency: 0.0062 | SSIM: 0.0219 | Grad: 77016.422\n",
      "[Epoch 57, Batch 67/100] Loss: 0.0439 | RMSE: 0.0410 | Consistency: 0.0089 | SSIM: 0.0278 | Grad: 67649.758\n",
      "[Epoch 57, Batch 68/100] Loss: 0.0397 | RMSE: 0.0372 | Consistency: 0.0069 | SSIM: 0.0248 | Grad: 53467.441\n",
      "[Epoch 57, Batch 69/100] Loss: 0.0412 | RMSE: 0.0384 | Consistency: 0.0087 | SSIM: 0.0272 | Grad: 80998.727\n",
      "[Epoch 57, Batch 70/100] Loss: 0.0342 | RMSE: 0.0323 | Consistency: 0.0055 | SSIM: 0.0192 | Grad: 82692.641\n",
      "[Epoch 57, Batch 71/100] Loss: 0.0385 | RMSE: 0.0357 | Consistency: 0.0073 | SSIM: 0.0278 | Grad: 59286.422\n",
      "[Epoch 57, Batch 72/100] Loss: 0.0379 | RMSE: 0.0352 | Consistency: 0.0065 | SSIM: 0.0257 | Grad: 50009.383\n",
      "[Epoch 57, Batch 73/100] Loss: 0.0391 | RMSE: 0.0363 | Consistency: 0.0065 | SSIM: 0.0273 | Grad: 99019.383\n",
      "[Epoch 57, Batch 74/100] Loss: 0.0359 | RMSE: 0.0335 | Consistency: 0.0067 | SSIM: 0.0235 | Grad: 74946.461\n",
      "[Epoch 57, Batch 75/100] Loss: 0.0380 | RMSE: 0.0353 | Consistency: 0.0061 | SSIM: 0.0257 | Grad: 72241.320\n",
      "[Epoch 57, Batch 76/100] Loss: 0.0393 | RMSE: 0.0368 | Consistency: 0.0087 | SSIM: 0.0241 | Grad: 55911.508\n",
      "[Epoch 57, Batch 77/100] Loss: 0.0391 | RMSE: 0.0368 | Consistency: 0.0070 | SSIM: 0.0221 | Grad: 40362.184\n",
      "[Epoch 57, Batch 78/100] Loss: 0.0403 | RMSE: 0.0381 | Consistency: 0.0066 | SSIM: 0.0214 | Grad: 118687.820\n",
      "[Epoch 57, Batch 79/100] Loss: 0.0376 | RMSE: 0.0352 | Consistency: 0.0081 | SSIM: 0.0234 | Grad: 66367.430\n",
      "[Epoch 57, Batch 80/100] Loss: 0.0368 | RMSE: 0.0342 | Consistency: 0.0058 | SSIM: 0.0246 | Grad: 46268.027\n",
      "[Epoch 57, Batch 81/100] Loss: 0.0444 | RMSE: 0.0417 | Consistency: 0.0093 | SSIM: 0.0260 | Grad: 90345.812\n",
      "[Epoch 57, Batch 82/100] Loss: 0.0418 | RMSE: 0.0390 | Consistency: 0.0093 | SSIM: 0.0272 | Grad: 90091.492\n",
      "[Epoch 57, Batch 83/100] Loss: 0.0457 | RMSE: 0.0434 | Consistency: 0.0093 | SSIM: 0.0221 | Grad: 126485.016\n",
      "[Epoch 57, Batch 84/100] Loss: 0.0357 | RMSE: 0.0334 | Consistency: 0.0073 | SSIM: 0.0221 | Grad: 70360.008\n",
      "[Epoch 57, Batch 85/100] Loss: 0.0394 | RMSE: 0.0367 | Consistency: 0.0069 | SSIM: 0.0255 | Grad: 84648.508\n",
      "[Epoch 57, Batch 86/100] Loss: 0.0351 | RMSE: 0.0331 | Consistency: 0.0064 | SSIM: 0.0195 | Grad: 57556.352\n",
      "[Epoch 57, Batch 87/100] Loss: 0.0367 | RMSE: 0.0343 | Consistency: 0.0059 | SSIM: 0.0235 | Grad: 40550.613\n",
      "[Epoch 57, Batch 88/100] Loss: 0.0361 | RMSE: 0.0339 | Consistency: 0.0063 | SSIM: 0.0212 | Grad: 70430.523\n",
      "[Epoch 57, Batch 89/100] Loss: 0.0368 | RMSE: 0.0347 | Consistency: 0.0075 | SSIM: 0.0200 | Grad: 101263.414\n",
      "[Epoch 57, Batch 90/100] Loss: 0.0430 | RMSE: 0.0399 | Consistency: 0.0097 | SSIM: 0.0295 | Grad: 80189.883\n",
      "[Epoch 57, Batch 91/100] Loss: 0.0387 | RMSE: 0.0356 | Consistency: 0.0071 | SSIM: 0.0305 | Grad: 72993.734\n",
      "[Epoch 57, Batch 92/100] Loss: 0.0352 | RMSE: 0.0329 | Consistency: 0.0052 | SSIM: 0.0229 | Grad: 82401.953\n",
      "[Epoch 57, Batch 93/100] Loss: 0.0406 | RMSE: 0.0381 | Consistency: 0.0068 | SSIM: 0.0241 | Grad: 106372.297\n",
      "[Epoch 57, Batch 94/100] Loss: 0.0397 | RMSE: 0.0368 | Consistency: 0.0077 | SSIM: 0.0286 | Grad: 121167.375\n",
      "[Epoch 57, Batch 95/100] Loss: 0.0468 | RMSE: 0.0441 | Consistency: 0.0105 | SSIM: 0.0262 | Grad: 99586.219\n",
      "[Epoch 57, Batch 96/100] Loss: 0.0373 | RMSE: 0.0347 | Consistency: 0.0072 | SSIM: 0.0245 | Grad: 39853.719\n",
      "[Epoch 57, Batch 97/100] Loss: 0.0385 | RMSE: 0.0361 | Consistency: 0.0075 | SSIM: 0.0229 | Grad: 72191.250\n",
      "[Epoch 57, Batch 98/100] Loss: 0.0398 | RMSE: 0.0368 | Consistency: 0.0072 | SSIM: 0.0298 | Grad: 118653.281\n",
      "[Epoch 57, Batch 99/100] Loss: 0.0387 | RMSE: 0.0364 | Consistency: 0.0076 | SSIM: 0.0223 | Grad: 109224.844\n",
      "[Epoch 57, Batch 100/100] Loss: 0.0453 | RMSE: 0.0427 | Consistency: 0.0094 | SSIM: 0.0255 | Grad: 111373.156\n",
      "✅ Epoch 57 완료!\n",
      "   📈 평균 Loss: 0.038926\n",
      "   📊 평균 RMSE: 0.036421\n",
      "   ⚙️  학습률: 0.000231\n",
      "   🏆 NEW BEST! RMSE: 0.036421\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 58/80 시작...\n",
      "[Epoch 58, Batch 1/100] Loss: 0.0342 | RMSE: 0.0321 | Consistency: 0.0053 | SSIM: 0.0207 | Grad: 99703.844\n",
      "[Epoch 58, Batch 2/100] Loss: 0.0395 | RMSE: 0.0371 | Consistency: 0.0069 | SSIM: 0.0229 | Grad: 52488.891\n",
      "[Epoch 58, Batch 3/100] Loss: 0.0388 | RMSE: 0.0361 | Consistency: 0.0070 | SSIM: 0.0266 | Grad: 64768.289\n",
      "[Epoch 58, Batch 4/100] Loss: 0.0380 | RMSE: 0.0353 | Consistency: 0.0064 | SSIM: 0.0263 | Grad: 44051.145\n",
      "[Epoch 58, Batch 5/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0092 | SSIM: 0.0239 | Grad: 70513.703\n",
      "[Epoch 58, Batch 6/100] Loss: 0.0422 | RMSE: 0.0398 | Consistency: 0.0090 | SSIM: 0.0239 | Grad: 114763.625\n",
      "[Epoch 58, Batch 7/100] Loss: 0.0393 | RMSE: 0.0367 | Consistency: 0.0073 | SSIM: 0.0251 | Grad: 93602.273\n",
      "[Epoch 58, Batch 8/100] Loss: 0.0401 | RMSE: 0.0376 | Consistency: 0.0072 | SSIM: 0.0240 | Grad: 98433.914\n",
      "[Epoch 58, Batch 9/100] Loss: 0.0393 | RMSE: 0.0368 | Consistency: 0.0071 | SSIM: 0.0244 | Grad: 29805.340\n",
      "[Epoch 58, Batch 10/100] Loss: 0.0367 | RMSE: 0.0340 | Consistency: 0.0067 | SSIM: 0.0269 | Grad: 48989.836\n",
      "[Epoch 58, Batch 11/100] Loss: 0.0453 | RMSE: 0.0427 | Consistency: 0.0078 | SSIM: 0.0258 | Grad: 99830.586\n",
      "[Epoch 58, Batch 12/100] Loss: 0.0351 | RMSE: 0.0325 | Consistency: 0.0054 | SSIM: 0.0255 | Grad: 45324.867\n",
      "[Epoch 58, Batch 13/100] Loss: 0.0406 | RMSE: 0.0382 | Consistency: 0.0082 | SSIM: 0.0237 | Grad: 44569.445\n",
      "[Epoch 58, Batch 14/100] Loss: 0.0372 | RMSE: 0.0345 | Consistency: 0.0061 | SSIM: 0.0261 | Grad: 43258.355\n",
      "[Epoch 58, Batch 15/100] Loss: 0.0373 | RMSE: 0.0346 | Consistency: 0.0068 | SSIM: 0.0256 | Grad: 56387.707\n",
      "[Epoch 58, Batch 16/100] Loss: 0.0315 | RMSE: 0.0296 | Consistency: 0.0047 | SSIM: 0.0188 | Grad: 27731.439\n",
      "[Epoch 58, Batch 17/100] Loss: 0.0387 | RMSE: 0.0361 | Consistency: 0.0078 | SSIM: 0.0259 | Grad: 55064.047\n",
      "[Epoch 58, Batch 18/100] Loss: 0.0373 | RMSE: 0.0346 | Consistency: 0.0078 | SSIM: 0.0261 | Grad: 85199.023\n",
      "[Epoch 58, Batch 19/100] Loss: 0.0370 | RMSE: 0.0347 | Consistency: 0.0060 | SSIM: 0.0229 | Grad: 114231.469\n",
      "[Epoch 58, Batch 20/100] Loss: 0.0343 | RMSE: 0.0322 | Consistency: 0.0060 | SSIM: 0.0208 | Grad: 74617.820\n",
      "[Epoch 58, Batch 21/100] Loss: 0.0457 | RMSE: 0.0427 | Consistency: 0.0083 | SSIM: 0.0293 | Grad: 96670.578\n",
      "[Epoch 58, Batch 22/100] Loss: 0.0392 | RMSE: 0.0369 | Consistency: 0.0078 | SSIM: 0.0220 | Grad: 98968.422\n",
      "[Epoch 58, Batch 23/100] Loss: 0.0389 | RMSE: 0.0365 | Consistency: 0.0086 | SSIM: 0.0232 | Grad: 90045.672\n",
      "[Epoch 58, Batch 24/100] Loss: 0.0478 | RMSE: 0.0451 | Consistency: 0.0102 | SSIM: 0.0260 | Grad: 124945.164\n",
      "[Epoch 58, Batch 25/100] Loss: 0.0371 | RMSE: 0.0340 | Consistency: 0.0066 | SSIM: 0.0299 | Grad: 55259.492\n",
      "[Epoch 58, Batch 26/100] Loss: 0.0371 | RMSE: 0.0339 | Consistency: 0.0068 | SSIM: 0.0316 | Grad: 48307.031\n",
      "[Epoch 58, Batch 27/100] Loss: 0.0408 | RMSE: 0.0385 | Consistency: 0.0068 | SSIM: 0.0221 | Grad: 66599.055\n",
      "[Epoch 58, Batch 28/100] Loss: 0.0468 | RMSE: 0.0441 | Consistency: 0.0085 | SSIM: 0.0253 | Grad: 92743.992\n",
      "[Epoch 58, Batch 29/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0068 | SSIM: 0.0238 | Grad: 96285.164\n",
      "[Epoch 58, Batch 30/100] Loss: 0.0401 | RMSE: 0.0368 | Consistency: 0.0084 | SSIM: 0.0326 | Grad: 96380.156\n",
      "[Epoch 58, Batch 31/100] Loss: 0.0379 | RMSE: 0.0357 | Consistency: 0.0074 | SSIM: 0.0218 | Grad: 76304.531\n",
      "[Epoch 58, Batch 32/100] Loss: 0.0402 | RMSE: 0.0380 | Consistency: 0.0074 | SSIM: 0.0209 | Grad: 105595.430\n",
      "[Epoch 58, Batch 33/100] Loss: 0.0423 | RMSE: 0.0399 | Consistency: 0.0073 | SSIM: 0.0229 | Grad: 53988.117\n",
      "[Epoch 58, Batch 34/100] Loss: 0.0329 | RMSE: 0.0305 | Consistency: 0.0051 | SSIM: 0.0236 | Grad: 46481.402\n",
      "[Epoch 58, Batch 35/100] Loss: 0.0420 | RMSE: 0.0396 | Consistency: 0.0081 | SSIM: 0.0234 | Grad: 41281.961\n",
      "[Epoch 58, Batch 36/100] Loss: 0.0354 | RMSE: 0.0327 | Consistency: 0.0064 | SSIM: 0.0261 | Grad: 17106.568\n",
      "[Epoch 58, Batch 37/100] Loss: 0.0416 | RMSE: 0.0390 | Consistency: 0.0094 | SSIM: 0.0254 | Grad: 92972.398\n",
      "[Epoch 58, Batch 38/100] Loss: 0.0467 | RMSE: 0.0442 | Consistency: 0.0111 | SSIM: 0.0241 | Grad: 117509.711\n",
      "[Epoch 58, Batch 39/100] Loss: 0.0397 | RMSE: 0.0371 | Consistency: 0.0078 | SSIM: 0.0254 | Grad: 85006.281\n",
      "[Epoch 58, Batch 40/100] Loss: 0.0389 | RMSE: 0.0368 | Consistency: 0.0074 | SSIM: 0.0206 | Grad: 90721.375\n",
      "[Epoch 58, Batch 41/100] Loss: 0.0403 | RMSE: 0.0377 | Consistency: 0.0080 | SSIM: 0.0258 | Grad: 101642.727\n",
      "[Epoch 58, Batch 42/100] Loss: 0.0360 | RMSE: 0.0337 | Consistency: 0.0063 | SSIM: 0.0231 | Grad: 60732.234\n",
      "[Epoch 58, Batch 43/100] Loss: 0.0379 | RMSE: 0.0351 | Consistency: 0.0069 | SSIM: 0.0273 | Grad: 40000.797\n",
      "[Epoch 58, Batch 44/100] Loss: 0.0470 | RMSE: 0.0441 | Consistency: 0.0112 | SSIM: 0.0279 | Grad: 74580.812\n",
      "[Epoch 58, Batch 45/100] Loss: 0.0500 | RMSE: 0.0468 | Consistency: 0.0101 | SSIM: 0.0312 | Grad: 108797.000\n",
      "[Epoch 58, Batch 46/100] Loss: 0.0402 | RMSE: 0.0379 | Consistency: 0.0069 | SSIM: 0.0227 | Grad: 117257.398\n",
      "[Epoch 58, Batch 47/100] Loss: 0.0414 | RMSE: 0.0387 | Consistency: 0.0080 | SSIM: 0.0258 | Grad: 172537.156\n",
      "[Epoch 58, Batch 48/100] Loss: 0.0391 | RMSE: 0.0366 | Consistency: 0.0081 | SSIM: 0.0233 | Grad: 120485.375\n",
      "[Epoch 58, Batch 49/100] Loss: 0.0369 | RMSE: 0.0346 | Consistency: 0.0069 | SSIM: 0.0222 | Grad: 74450.820\n",
      "[Epoch 58, Batch 50/100] Loss: 0.0385 | RMSE: 0.0362 | Consistency: 0.0074 | SSIM: 0.0227 | Grad: 41551.059\n",
      "[Epoch 58, Batch 51/100] Loss: 0.0370 | RMSE: 0.0345 | Consistency: 0.0065 | SSIM: 0.0251 | Grad: 64468.074\n",
      "[Epoch 58, Batch 52/100] Loss: 0.0378 | RMSE: 0.0356 | Consistency: 0.0074 | SSIM: 0.0213 | Grad: 98852.328\n",
      "[Epoch 58, Batch 53/100] Loss: 0.0374 | RMSE: 0.0345 | Consistency: 0.0070 | SSIM: 0.0288 | Grad: 79721.625\n",
      "[Epoch 58, Batch 54/100] Loss: 0.0447 | RMSE: 0.0422 | Consistency: 0.0104 | SSIM: 0.0236 | Grad: 143422.625\n",
      "[Epoch 58, Batch 55/100] Loss: 0.0404 | RMSE: 0.0375 | Consistency: 0.0080 | SSIM: 0.0284 | Grad: 102995.492\n",
      "[Epoch 58, Batch 56/100] Loss: 0.0389 | RMSE: 0.0367 | Consistency: 0.0066 | SSIM: 0.0209 | Grad: 98175.633\n",
      "[Epoch 58, Batch 57/100] Loss: 0.0449 | RMSE: 0.0415 | Consistency: 0.0087 | SSIM: 0.0322 | Grad: 82536.523\n",
      "[Epoch 58, Batch 58/100] Loss: 0.0422 | RMSE: 0.0401 | Consistency: 0.0072 | SSIM: 0.0205 | Grad: 93574.398\n",
      "[Epoch 58, Batch 59/100] Loss: 0.0463 | RMSE: 0.0428 | Consistency: 0.0114 | SSIM: 0.0336 | Grad: 116793.266\n",
      "[Epoch 58, Batch 60/100] Loss: 0.0378 | RMSE: 0.0351 | Consistency: 0.0074 | SSIM: 0.0257 | Grad: 95995.641\n",
      "[Epoch 58, Batch 61/100] Loss: 0.0382 | RMSE: 0.0359 | Consistency: 0.0074 | SSIM: 0.0228 | Grad: 88447.773\n",
      "[Epoch 58, Batch 62/100] Loss: 0.0419 | RMSE: 0.0392 | Consistency: 0.0090 | SSIM: 0.0254 | Grad: 94143.641\n",
      "[Epoch 58, Batch 63/100] Loss: 0.0380 | RMSE: 0.0350 | Consistency: 0.0065 | SSIM: 0.0296 | Grad: 80977.602\n",
      "[Epoch 58, Batch 64/100] Loss: 0.0373 | RMSE: 0.0348 | Consistency: 0.0060 | SSIM: 0.0244 | Grad: 109840.148\n",
      "[Epoch 58, Batch 65/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0054 | SSIM: 0.0211 | Grad: 89009.766\n",
      "[Epoch 58, Batch 66/100] Loss: 0.0382 | RMSE: 0.0359 | Consistency: 0.0071 | SSIM: 0.0227 | Grad: 87292.695\n",
      "[Epoch 58, Batch 67/100] Loss: 0.0388 | RMSE: 0.0361 | Consistency: 0.0063 | SSIM: 0.0258 | Grad: 85170.742\n",
      "[Epoch 58, Batch 68/100] Loss: 0.0429 | RMSE: 0.0398 | Consistency: 0.0093 | SSIM: 0.0298 | Grad: 82526.883\n",
      "[Epoch 58, Batch 69/100] Loss: 0.0403 | RMSE: 0.0375 | Consistency: 0.0074 | SSIM: 0.0274 | Grad: 125366.125\n",
      "[Epoch 58, Batch 70/100] Loss: 0.0401 | RMSE: 0.0372 | Consistency: 0.0075 | SSIM: 0.0282 | Grad: 108609.094\n",
      "[Epoch 58, Batch 71/100] Loss: 0.0353 | RMSE: 0.0330 | Consistency: 0.0055 | SSIM: 0.0227 | Grad: 90872.297\n",
      "[Epoch 58, Batch 72/100] Loss: 0.0443 | RMSE: 0.0413 | Consistency: 0.0086 | SSIM: 0.0290 | Grad: 64225.059\n",
      "[Epoch 58, Batch 73/100] Loss: 0.0347 | RMSE: 0.0325 | Consistency: 0.0057 | SSIM: 0.0219 | Grad: 62641.031\n",
      "[Epoch 58, Batch 74/100] Loss: 0.0391 | RMSE: 0.0366 | Consistency: 0.0068 | SSIM: 0.0242 | Grad: 106286.266\n",
      "[Epoch 58, Batch 75/100] Loss: 0.0420 | RMSE: 0.0388 | Consistency: 0.0083 | SSIM: 0.0305 | Grad: 73368.234\n",
      "[Epoch 58, Batch 76/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0067 | SSIM: 0.0227 | Grad: 41630.500\n",
      "[Epoch 58, Batch 77/100] Loss: 0.0394 | RMSE: 0.0367 | Consistency: 0.0073 | SSIM: 0.0258 | Grad: 90705.383\n",
      "[Epoch 58, Batch 78/100] Loss: 0.0350 | RMSE: 0.0325 | Consistency: 0.0061 | SSIM: 0.0246 | Grad: 29611.160\n",
      "[Epoch 58, Batch 79/100] Loss: 0.0367 | RMSE: 0.0337 | Consistency: 0.0060 | SSIM: 0.0298 | Grad: 99081.430\n",
      "[Epoch 58, Batch 80/100] Loss: 0.0400 | RMSE: 0.0372 | Consistency: 0.0066 | SSIM: 0.0268 | Grad: 112079.305\n",
      "[Epoch 58, Batch 81/100] Loss: 0.0371 | RMSE: 0.0349 | Consistency: 0.0067 | SSIM: 0.0220 | Grad: 83328.977\n",
      "[Epoch 58, Batch 82/100] Loss: 0.0389 | RMSE: 0.0369 | Consistency: 0.0062 | SSIM: 0.0198 | Grad: 65570.031\n",
      "[Epoch 58, Batch 83/100] Loss: 0.0372 | RMSE: 0.0346 | Consistency: 0.0058 | SSIM: 0.0258 | Grad: 71438.594\n",
      "[Epoch 58, Batch 84/100] Loss: 0.0316 | RMSE: 0.0295 | Consistency: 0.0047 | SSIM: 0.0202 | Grad: 58645.957\n",
      "[Epoch 58, Batch 85/100] Loss: 0.0376 | RMSE: 0.0355 | Consistency: 0.0066 | SSIM: 0.0201 | Grad: 56334.977\n",
      "[Epoch 58, Batch 86/100] Loss: 0.0375 | RMSE: 0.0349 | Consistency: 0.0068 | SSIM: 0.0257 | Grad: 85857.953\n",
      "[Epoch 58, Batch 87/100] Loss: 0.0514 | RMSE: 0.0481 | Consistency: 0.0152 | SSIM: 0.0316 | Grad: 49962.387\n",
      "[Epoch 58, Batch 88/100] Loss: 0.0373 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0269 | Grad: 57990.309\n",
      "[Epoch 58, Batch 89/100] Loss: 0.0360 | RMSE: 0.0334 | Consistency: 0.0065 | SSIM: 0.0248 | Grad: 42435.648\n",
      "[Epoch 58, Batch 90/100] Loss: 0.0372 | RMSE: 0.0346 | Consistency: 0.0057 | SSIM: 0.0252 | Grad: 17730.330\n",
      "[Epoch 58, Batch 91/100] Loss: 0.0389 | RMSE: 0.0367 | Consistency: 0.0067 | SSIM: 0.0222 | Grad: 79906.961\n",
      "[Epoch 58, Batch 92/100] Loss: 0.0377 | RMSE: 0.0350 | Consistency: 0.0065 | SSIM: 0.0267 | Grad: 45398.863\n",
      "[Epoch 58, Batch 93/100] Loss: 0.0328 | RMSE: 0.0306 | Consistency: 0.0048 | SSIM: 0.0215 | Grad: 57860.480\n",
      "[Epoch 58, Batch 94/100] Loss: 0.0344 | RMSE: 0.0322 | Consistency: 0.0058 | SSIM: 0.0214 | Grad: 83129.953\n",
      "[Epoch 58, Batch 95/100] Loss: 0.0396 | RMSE: 0.0368 | Consistency: 0.0075 | SSIM: 0.0278 | Grad: 90339.555\n",
      "[Epoch 58, Batch 96/100] Loss: 0.0358 | RMSE: 0.0335 | Consistency: 0.0059 | SSIM: 0.0224 | Grad: 109602.414\n",
      "[Epoch 58, Batch 97/100] Loss: 0.0365 | RMSE: 0.0333 | Consistency: 0.0068 | SSIM: 0.0307 | Grad: 63216.449\n",
      "[Epoch 58, Batch 98/100] Loss: 0.0352 | RMSE: 0.0327 | Consistency: 0.0051 | SSIM: 0.0244 | Grad: 80420.703\n",
      "[Epoch 58, Batch 99/100] Loss: 0.0394 | RMSE: 0.0371 | Consistency: 0.0085 | SSIM: 0.0229 | Grad: 73012.125\n",
      "[Epoch 58, Batch 100/100] Loss: 0.0358 | RMSE: 0.0338 | Consistency: 0.0061 | SSIM: 0.0197 | Grad: 23524.453\n",
      "✅ Epoch 58 완료!\n",
      "   📈 평균 Loss: 0.039121\n",
      "   📊 평균 RMSE: 0.036553\n",
      "   ⚙️  학습률: 0.000213\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 59/80 시작...\n",
      "[Epoch 59, Batch 1/100] Loss: 0.0508 | RMSE: 0.0480 | Consistency: 0.0146 | SSIM: 0.0263 | Grad: 45977.012\n",
      "[Epoch 59, Batch 2/100] Loss: 0.0357 | RMSE: 0.0335 | Consistency: 0.0055 | SSIM: 0.0214 | Grad: 29188.447\n",
      "[Epoch 59, Batch 3/100] Loss: 0.0356 | RMSE: 0.0334 | Consistency: 0.0054 | SSIM: 0.0212 | Grad: 62984.504\n",
      "[Epoch 59, Batch 4/100] Loss: 0.0357 | RMSE: 0.0331 | Consistency: 0.0065 | SSIM: 0.0250 | Grad: 43938.645\n",
      "[Epoch 59, Batch 5/100] Loss: 0.0383 | RMSE: 0.0357 | Consistency: 0.0069 | SSIM: 0.0249 | Grad: 65073.594\n",
      "[Epoch 59, Batch 6/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0056 | SSIM: 0.0217 | Grad: 45209.180\n",
      "[Epoch 59, Batch 7/100] Loss: 0.0380 | RMSE: 0.0358 | Consistency: 0.0067 | SSIM: 0.0216 | Grad: 60673.348\n",
      "[Epoch 59, Batch 8/100] Loss: 0.0368 | RMSE: 0.0345 | Consistency: 0.0068 | SSIM: 0.0225 | Grad: 72811.672\n",
      "[Epoch 59, Batch 9/100] Loss: 0.0406 | RMSE: 0.0379 | Consistency: 0.0087 | SSIM: 0.0268 | Grad: 47415.930\n",
      "[Epoch 59, Batch 10/100] Loss: 0.0394 | RMSE: 0.0371 | Consistency: 0.0081 | SSIM: 0.0225 | Grad: 46994.922\n",
      "[Epoch 59, Batch 11/100] Loss: 0.0346 | RMSE: 0.0323 | Consistency: 0.0059 | SSIM: 0.0226 | Grad: 55359.922\n",
      "[Epoch 59, Batch 12/100] Loss: 0.0351 | RMSE: 0.0330 | Consistency: 0.0058 | SSIM: 0.0209 | Grad: 69164.352\n",
      "[Epoch 59, Batch 13/100] Loss: 0.0355 | RMSE: 0.0330 | Consistency: 0.0055 | SSIM: 0.0245 | Grad: 72022.273\n",
      "[Epoch 59, Batch 14/100] Loss: 0.0329 | RMSE: 0.0309 | Consistency: 0.0056 | SSIM: 0.0196 | Grad: 83906.922\n",
      "[Epoch 59, Batch 15/100] Loss: 0.0446 | RMSE: 0.0418 | Consistency: 0.0111 | SSIM: 0.0263 | Grad: 94360.570\n",
      "[Epoch 59, Batch 16/100] Loss: 0.0354 | RMSE: 0.0327 | Consistency: 0.0061 | SSIM: 0.0267 | Grad: 55465.836\n",
      "[Epoch 59, Batch 17/100] Loss: 0.0339 | RMSE: 0.0316 | Consistency: 0.0064 | SSIM: 0.0224 | Grad: 90266.812\n",
      "[Epoch 59, Batch 18/100] Loss: 0.0437 | RMSE: 0.0410 | Consistency: 0.0085 | SSIM: 0.0260 | Grad: 57906.535\n",
      "[Epoch 59, Batch 19/100] Loss: 0.0394 | RMSE: 0.0371 | Consistency: 0.0069 | SSIM: 0.0219 | Grad: 74093.961\n",
      "[Epoch 59, Batch 20/100] Loss: 0.0385 | RMSE: 0.0364 | Consistency: 0.0067 | SSIM: 0.0209 | Grad: 101828.023\n",
      "[Epoch 59, Batch 21/100] Loss: 0.0353 | RMSE: 0.0330 | Consistency: 0.0068 | SSIM: 0.0229 | Grad: 60398.992\n",
      "[Epoch 59, Batch 22/100] Loss: 0.0345 | RMSE: 0.0322 | Consistency: 0.0054 | SSIM: 0.0222 | Grad: 75528.562\n",
      "[Epoch 59, Batch 23/100] Loss: 0.0361 | RMSE: 0.0331 | Consistency: 0.0065 | SSIM: 0.0301 | Grad: 32434.562\n",
      "[Epoch 59, Batch 24/100] Loss: 0.0416 | RMSE: 0.0394 | Consistency: 0.0072 | SSIM: 0.0215 | Grad: 116831.117\n",
      "[Epoch 59, Batch 25/100] Loss: 0.0419 | RMSE: 0.0390 | Consistency: 0.0075 | SSIM: 0.0286 | Grad: 46170.723\n",
      "[Epoch 59, Batch 26/100] Loss: 0.0397 | RMSE: 0.0365 | Consistency: 0.0065 | SSIM: 0.0316 | Grad: 92097.320\n",
      "[Epoch 59, Batch 27/100] Loss: 0.0340 | RMSE: 0.0321 | Consistency: 0.0057 | SSIM: 0.0179 | Grad: 53299.340\n",
      "[Epoch 59, Batch 28/100] Loss: 0.0365 | RMSE: 0.0343 | Consistency: 0.0062 | SSIM: 0.0219 | Grad: 99596.625\n",
      "[Epoch 59, Batch 29/100] Loss: 0.0345 | RMSE: 0.0323 | Consistency: 0.0055 | SSIM: 0.0211 | Grad: 49648.148\n",
      "[Epoch 59, Batch 30/100] Loss: 0.0404 | RMSE: 0.0380 | Consistency: 0.0071 | SSIM: 0.0233 | Grad: 119255.430\n",
      "[Epoch 59, Batch 31/100] Loss: 0.0377 | RMSE: 0.0354 | Consistency: 0.0060 | SSIM: 0.0217 | Grad: 64636.094\n",
      "[Epoch 59, Batch 32/100] Loss: 0.0370 | RMSE: 0.0347 | Consistency: 0.0065 | SSIM: 0.0225 | Grad: 70212.883\n",
      "[Epoch 59, Batch 33/100] Loss: 0.0394 | RMSE: 0.0364 | Consistency: 0.0071 | SSIM: 0.0296 | Grad: 67330.773\n",
      "[Epoch 59, Batch 34/100] Loss: 0.0381 | RMSE: 0.0356 | Consistency: 0.0066 | SSIM: 0.0236 | Grad: 78877.547\n",
      "[Epoch 59, Batch 35/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0053 | SSIM: 0.0207 | Grad: 73774.234\n",
      "[Epoch 59, Batch 36/100] Loss: 0.0345 | RMSE: 0.0321 | Consistency: 0.0053 | SSIM: 0.0236 | Grad: 94847.539\n",
      "[Epoch 59, Batch 37/100] Loss: 0.0329 | RMSE: 0.0310 | Consistency: 0.0056 | SSIM: 0.0183 | Grad: 36948.422\n",
      "[Epoch 59, Batch 38/100] Loss: 0.0450 | RMSE: 0.0413 | Consistency: 0.0091 | SSIM: 0.0370 | Grad: 80237.453\n",
      "[Epoch 59, Batch 39/100] Loss: 0.0324 | RMSE: 0.0301 | Consistency: 0.0052 | SSIM: 0.0224 | Grad: 55190.637\n",
      "[Epoch 59, Batch 40/100] Loss: 0.0338 | RMSE: 0.0316 | Consistency: 0.0056 | SSIM: 0.0208 | Grad: 86590.312\n",
      "[Epoch 59, Batch 41/100] Loss: 0.0376 | RMSE: 0.0351 | Consistency: 0.0066 | SSIM: 0.0235 | Grad: 90911.469\n",
      "[Epoch 59, Batch 42/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0067 | SSIM: 0.0245 | Grad: 81179.359\n",
      "[Epoch 59, Batch 43/100] Loss: 0.0349 | RMSE: 0.0324 | Consistency: 0.0049 | SSIM: 0.0244 | Grad: 36283.469\n",
      "[Epoch 59, Batch 44/100] Loss: 0.0425 | RMSE: 0.0394 | Consistency: 0.0091 | SSIM: 0.0309 | Grad: 93445.016\n",
      "[Epoch 59, Batch 45/100] Loss: 0.0354 | RMSE: 0.0332 | Consistency: 0.0058 | SSIM: 0.0209 | Grad: 106523.555\n",
      "[Epoch 59, Batch 46/100] Loss: 0.0363 | RMSE: 0.0340 | Consistency: 0.0058 | SSIM: 0.0226 | Grad: 98021.773\n",
      "[Epoch 59, Batch 47/100] Loss: 0.0352 | RMSE: 0.0331 | Consistency: 0.0050 | SSIM: 0.0205 | Grad: 118827.773\n",
      "[Epoch 59, Batch 48/100] Loss: 0.0374 | RMSE: 0.0350 | Consistency: 0.0072 | SSIM: 0.0225 | Grad: 37008.359\n",
      "[Epoch 59, Batch 49/100] Loss: 0.0405 | RMSE: 0.0373 | Consistency: 0.0076 | SSIM: 0.0316 | Grad: 38097.031\n",
      "[Epoch 59, Batch 50/100] Loss: 0.0357 | RMSE: 0.0330 | Consistency: 0.0061 | SSIM: 0.0265 | Grad: 91990.891\n",
      "[Epoch 59, Batch 51/100] Loss: 0.0313 | RMSE: 0.0291 | Consistency: 0.0043 | SSIM: 0.0219 | Grad: 61707.148\n",
      "[Epoch 59, Batch 52/100] Loss: 0.0421 | RMSE: 0.0395 | Consistency: 0.0069 | SSIM: 0.0253 | Grad: 103412.742\n",
      "[Epoch 59, Batch 53/100] Loss: 0.0428 | RMSE: 0.0403 | Consistency: 0.0087 | SSIM: 0.0245 | Grad: 100761.250\n",
      "[Epoch 59, Batch 54/100] Loss: 0.0319 | RMSE: 0.0302 | Consistency: 0.0050 | SSIM: 0.0167 | Grad: 72119.578\n",
      "[Epoch 59, Batch 55/100] Loss: 0.0365 | RMSE: 0.0346 | Consistency: 0.0062 | SSIM: 0.0191 | Grad: 65634.570\n",
      "[Epoch 59, Batch 56/100] Loss: 0.0300 | RMSE: 0.0280 | Consistency: 0.0040 | SSIM: 0.0194 | Grad: 58980.504\n",
      "[Epoch 59, Batch 57/100] Loss: 0.0338 | RMSE: 0.0314 | Consistency: 0.0055 | SSIM: 0.0234 | Grad: 49076.156\n",
      "[Epoch 59, Batch 58/100] Loss: 0.0433 | RMSE: 0.0402 | Consistency: 0.0080 | SSIM: 0.0306 | Grad: 65550.438\n",
      "[Epoch 59, Batch 59/100] Loss: 0.0388 | RMSE: 0.0365 | Consistency: 0.0083 | SSIM: 0.0220 | Grad: 110853.055\n",
      "[Epoch 59, Batch 60/100] Loss: 0.0368 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0226 | Grad: 59730.875\n",
      "[Epoch 59, Batch 61/100] Loss: 0.0354 | RMSE: 0.0334 | Consistency: 0.0059 | SSIM: 0.0191 | Grad: 55865.660\n",
      "[Epoch 59, Batch 62/100] Loss: 0.0428 | RMSE: 0.0401 | Consistency: 0.0088 | SSIM: 0.0267 | Grad: 47466.570\n",
      "[Epoch 59, Batch 63/100] Loss: 0.0360 | RMSE: 0.0332 | Consistency: 0.0067 | SSIM: 0.0268 | Grad: 23474.574\n",
      "[Epoch 59, Batch 64/100] Loss: 0.0362 | RMSE: 0.0336 | Consistency: 0.0062 | SSIM: 0.0255 | Grad: 59989.340\n",
      "[Epoch 59, Batch 65/100] Loss: 0.0347 | RMSE: 0.0319 | Consistency: 0.0057 | SSIM: 0.0276 | Grad: 86079.805\n",
      "[Epoch 59, Batch 66/100] Loss: 0.0376 | RMSE: 0.0350 | Consistency: 0.0069 | SSIM: 0.0246 | Grad: 18552.545\n",
      "[Epoch 59, Batch 67/100] Loss: 0.0359 | RMSE: 0.0336 | Consistency: 0.0055 | SSIM: 0.0227 | Grad: 101525.883\n",
      "[Epoch 59, Batch 68/100] Loss: 0.0372 | RMSE: 0.0349 | Consistency: 0.0076 | SSIM: 0.0221 | Grad: 30262.316\n",
      "[Epoch 59, Batch 69/100] Loss: 0.0334 | RMSE: 0.0309 | Consistency: 0.0059 | SSIM: 0.0236 | Grad: 14702.361\n",
      "[Epoch 59, Batch 70/100] Loss: 0.0365 | RMSE: 0.0346 | Consistency: 0.0065 | SSIM: 0.0184 | Grad: 87063.500\n",
      "[Epoch 59, Batch 71/100] Loss: 0.0368 | RMSE: 0.0342 | Consistency: 0.0066 | SSIM: 0.0248 | Grad: 105471.094\n",
      "[Epoch 59, Batch 72/100] Loss: 0.0379 | RMSE: 0.0357 | Consistency: 0.0066 | SSIM: 0.0208 | Grad: 73971.289\n",
      "[Epoch 59, Batch 73/100] Loss: 0.0409 | RMSE: 0.0383 | Consistency: 0.0068 | SSIM: 0.0253 | Grad: 87953.492\n",
      "[Epoch 59, Batch 74/100] Loss: 0.0418 | RMSE: 0.0391 | Consistency: 0.0078 | SSIM: 0.0261 | Grad: 71588.781\n",
      "[Epoch 59, Batch 75/100] Loss: 0.0390 | RMSE: 0.0362 | Consistency: 0.0068 | SSIM: 0.0272 | Grad: 92833.703\n",
      "[Epoch 59, Batch 76/100] Loss: 0.0373 | RMSE: 0.0352 | Consistency: 0.0061 | SSIM: 0.0203 | Grad: 33870.484\n",
      "[Epoch 59, Batch 77/100] Loss: 0.0396 | RMSE: 0.0371 | Consistency: 0.0078 | SSIM: 0.0237 | Grad: 50742.438\n",
      "[Epoch 59, Batch 78/100] Loss: 0.0402 | RMSE: 0.0376 | Consistency: 0.0081 | SSIM: 0.0248 | Grad: 27477.582\n",
      "[Epoch 59, Batch 79/100] Loss: 0.0340 | RMSE: 0.0317 | Consistency: 0.0050 | SSIM: 0.0219 | Grad: 62979.125\n",
      "[Epoch 59, Batch 80/100] Loss: 0.0388 | RMSE: 0.0362 | Consistency: 0.0072 | SSIM: 0.0246 | Grad: 33823.832\n",
      "[Epoch 59, Batch 81/100] Loss: 0.0373 | RMSE: 0.0351 | Consistency: 0.0061 | SSIM: 0.0218 | Grad: 75724.844\n",
      "[Epoch 59, Batch 82/100] Loss: 0.0413 | RMSE: 0.0385 | Consistency: 0.0081 | SSIM: 0.0275 | Grad: 46876.254\n",
      "[Epoch 59, Batch 83/100] Loss: 0.0391 | RMSE: 0.0363 | Consistency: 0.0064 | SSIM: 0.0273 | Grad: 67840.992\n",
      "[Epoch 59, Batch 84/100] Loss: 0.0363 | RMSE: 0.0340 | Consistency: 0.0077 | SSIM: 0.0223 | Grad: 86802.039\n",
      "[Epoch 59, Batch 85/100] Loss: 0.0378 | RMSE: 0.0354 | Consistency: 0.0075 | SSIM: 0.0224 | Grad: 57651.465\n",
      "[Epoch 59, Batch 86/100] Loss: 0.0441 | RMSE: 0.0413 | Consistency: 0.0096 | SSIM: 0.0271 | Grad: 122445.414\n",
      "[Epoch 59, Batch 87/100] Loss: 0.0411 | RMSE: 0.0388 | Consistency: 0.0079 | SSIM: 0.0217 | Grad: 69011.688\n",
      "[Epoch 59, Batch 88/100] Loss: 0.0377 | RMSE: 0.0352 | Consistency: 0.0065 | SSIM: 0.0241 | Grad: 94520.539\n",
      "[Epoch 59, Batch 89/100] Loss: 0.0352 | RMSE: 0.0331 | Consistency: 0.0056 | SSIM: 0.0209 | Grad: 43049.824\n",
      "[Epoch 59, Batch 90/100] Loss: 0.0376 | RMSE: 0.0351 | Consistency: 0.0085 | SSIM: 0.0240 | Grad: 90046.266\n",
      "[Epoch 59, Batch 91/100] Loss: 0.0463 | RMSE: 0.0433 | Consistency: 0.0110 | SSIM: 0.0287 | Grad: 65550.789\n",
      "[Epoch 59, Batch 92/100] Loss: 0.0454 | RMSE: 0.0421 | Consistency: 0.0104 | SSIM: 0.0315 | Grad: 123275.133\n",
      "[Epoch 59, Batch 93/100] Loss: 0.0448 | RMSE: 0.0420 | Consistency: 0.0081 | SSIM: 0.0279 | Grad: 81408.906\n",
      "[Epoch 59, Batch 94/100] Loss: 0.0306 | RMSE: 0.0287 | Consistency: 0.0046 | SSIM: 0.0181 | Grad: 22126.871\n",
      "[Epoch 59, Batch 95/100] Loss: 0.0365 | RMSE: 0.0339 | Consistency: 0.0071 | SSIM: 0.0256 | Grad: 70488.523\n",
      "[Epoch 59, Batch 96/100] Loss: 0.0537 | RMSE: 0.0507 | Consistency: 0.0119 | SSIM: 0.0291 | Grad: 64216.238\n",
      "[Epoch 59, Batch 97/100] Loss: 0.0409 | RMSE: 0.0374 | Consistency: 0.0068 | SSIM: 0.0341 | Grad: 125737.727\n",
      "[Epoch 59, Batch 98/100] Loss: 0.0379 | RMSE: 0.0353 | Consistency: 0.0068 | SSIM: 0.0256 | Grad: 105310.961\n",
      "[Epoch 59, Batch 99/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0073 | SSIM: 0.0225 | Grad: 86582.086\n",
      "[Epoch 59, Batch 100/100] Loss: 0.0434 | RMSE: 0.0401 | Consistency: 0.0086 | SSIM: 0.0326 | Grad: 18583.322\n",
      "✅ Epoch 59 완료!\n",
      "   📈 평균 Loss: 0.037987\n",
      "   📊 평균 RMSE: 0.035506\n",
      "   ⚙️  학습률: 0.000195\n",
      "   🏆 NEW BEST! RMSE: 0.035506\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 60/80 시작...\n",
      "[Epoch 60, Batch 1/100] Loss: 0.0346 | RMSE: 0.0324 | Consistency: 0.0061 | SSIM: 0.0208 | Grad: 81521.211\n",
      "[Epoch 60, Batch 2/100] Loss: 0.0358 | RMSE: 0.0333 | Consistency: 0.0060 | SSIM: 0.0239 | Grad: 63070.527\n",
      "[Epoch 60, Batch 3/100] Loss: 0.0343 | RMSE: 0.0321 | Consistency: 0.0063 | SSIM: 0.0215 | Grad: 63070.848\n",
      "[Epoch 60, Batch 4/100] Loss: 0.0381 | RMSE: 0.0353 | Consistency: 0.0083 | SSIM: 0.0275 | Grad: 32103.629\n",
      "[Epoch 60, Batch 5/100] Loss: 0.0360 | RMSE: 0.0338 | Consistency: 0.0065 | SSIM: 0.0214 | Grad: 41421.648\n",
      "[Epoch 60, Batch 6/100] Loss: 0.0395 | RMSE: 0.0369 | Consistency: 0.0073 | SSIM: 0.0256 | Grad: 44923.422\n",
      "[Epoch 60, Batch 7/100] Loss: 0.0433 | RMSE: 0.0408 | Consistency: 0.0069 | SSIM: 0.0242 | Grad: 104722.688\n",
      "[Epoch 60, Batch 8/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0066 | SSIM: 0.0222 | Grad: 124859.406\n",
      "[Epoch 60, Batch 9/100] Loss: 0.0519 | RMSE: 0.0493 | Consistency: 0.0115 | SSIM: 0.0255 | Grad: 127523.023\n",
      "[Epoch 60, Batch 10/100] Loss: 0.0381 | RMSE: 0.0354 | Consistency: 0.0076 | SSIM: 0.0264 | Grad: 141079.359\n",
      "[Epoch 60, Batch 11/100] Loss: 0.0426 | RMSE: 0.0389 | Consistency: 0.0074 | SSIM: 0.0371 | Grad: 122760.219\n",
      "[Epoch 60, Batch 12/100] Loss: 0.0459 | RMSE: 0.0434 | Consistency: 0.0085 | SSIM: 0.0234 | Grad: 95125.281\n",
      "[Epoch 60, Batch 13/100] Loss: 0.0337 | RMSE: 0.0314 | Consistency: 0.0056 | SSIM: 0.0232 | Grad: 55270.684\n",
      "[Epoch 60, Batch 14/100] Loss: 0.0369 | RMSE: 0.0348 | Consistency: 0.0064 | SSIM: 0.0202 | Grad: 81153.523\n",
      "[Epoch 60, Batch 15/100] Loss: 0.0360 | RMSE: 0.0336 | Consistency: 0.0060 | SSIM: 0.0233 | Grad: 69927.297\n",
      "[Epoch 60, Batch 16/100] Loss: 0.0347 | RMSE: 0.0328 | Consistency: 0.0060 | SSIM: 0.0183 | Grad: 101730.664\n",
      "[Epoch 60, Batch 17/100] Loss: 0.0412 | RMSE: 0.0388 | Consistency: 0.0077 | SSIM: 0.0236 | Grad: 63796.227\n",
      "[Epoch 60, Batch 18/100] Loss: 0.0340 | RMSE: 0.0321 | Consistency: 0.0056 | SSIM: 0.0185 | Grad: 59403.414\n",
      "[Epoch 60, Batch 19/100] Loss: 0.0352 | RMSE: 0.0324 | Consistency: 0.0062 | SSIM: 0.0272 | Grad: 65360.867\n",
      "[Epoch 60, Batch 20/100] Loss: 0.0449 | RMSE: 0.0416 | Consistency: 0.0105 | SSIM: 0.0326 | Grad: 65684.922\n",
      "[Epoch 60, Batch 21/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0056 | SSIM: 0.0210 | Grad: 68148.367\n",
      "[Epoch 60, Batch 22/100] Loss: 0.0344 | RMSE: 0.0324 | Consistency: 0.0050 | SSIM: 0.0204 | Grad: 94380.477\n",
      "[Epoch 60, Batch 23/100] Loss: 0.0472 | RMSE: 0.0447 | Consistency: 0.0117 | SSIM: 0.0245 | Grad: 75880.641\n",
      "[Epoch 60, Batch 24/100] Loss: 0.0399 | RMSE: 0.0371 | Consistency: 0.0098 | SSIM: 0.0274 | Grad: 112009.625\n",
      "[Epoch 60, Batch 25/100] Loss: 0.0432 | RMSE: 0.0399 | Consistency: 0.0088 | SSIM: 0.0327 | Grad: 103979.812\n",
      "[Epoch 60, Batch 26/100] Loss: 0.0402 | RMSE: 0.0382 | Consistency: 0.0084 | SSIM: 0.0199 | Grad: 89376.609\n",
      "[Epoch 60, Batch 27/100] Loss: 0.0380 | RMSE: 0.0358 | Consistency: 0.0073 | SSIM: 0.0212 | Grad: 92594.445\n",
      "[Epoch 60, Batch 28/100] Loss: 0.0374 | RMSE: 0.0348 | Consistency: 0.0069 | SSIM: 0.0252 | Grad: 54461.020\n",
      "[Epoch 60, Batch 29/100] Loss: 0.0344 | RMSE: 0.0322 | Consistency: 0.0056 | SSIM: 0.0214 | Grad: 54108.262\n",
      "[Epoch 60, Batch 30/100] Loss: 0.0356 | RMSE: 0.0336 | Consistency: 0.0061 | SSIM: 0.0187 | Grad: 64448.922\n",
      "[Epoch 60, Batch 31/100] Loss: 0.0362 | RMSE: 0.0340 | Consistency: 0.0065 | SSIM: 0.0216 | Grad: 54229.754\n",
      "[Epoch 60, Batch 32/100] Loss: 0.0386 | RMSE: 0.0359 | Consistency: 0.0073 | SSIM: 0.0257 | Grad: 78485.125\n",
      "[Epoch 60, Batch 33/100] Loss: 0.0472 | RMSE: 0.0444 | Consistency: 0.0104 | SSIM: 0.0273 | Grad: 54822.727\n",
      "[Epoch 60, Batch 34/100] Loss: 0.0413 | RMSE: 0.0382 | Consistency: 0.0096 | SSIM: 0.0301 | Grad: 110811.414\n",
      "[Epoch 60, Batch 35/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0068 | SSIM: 0.0212 | Grad: 90531.234\n",
      "[Epoch 60, Batch 36/100] Loss: 0.0388 | RMSE: 0.0362 | Consistency: 0.0078 | SSIM: 0.0249 | Grad: 79438.680\n",
      "[Epoch 60, Batch 37/100] Loss: 0.0485 | RMSE: 0.0452 | Consistency: 0.0137 | SSIM: 0.0316 | Grad: 77165.438\n",
      "[Epoch 60, Batch 38/100] Loss: 0.0382 | RMSE: 0.0360 | Consistency: 0.0062 | SSIM: 0.0220 | Grad: 66060.367\n",
      "[Epoch 60, Batch 39/100] Loss: 0.0384 | RMSE: 0.0358 | Consistency: 0.0077 | SSIM: 0.0251 | Grad: 59158.273\n",
      "[Epoch 60, Batch 40/100] Loss: 0.0363 | RMSE: 0.0340 | Consistency: 0.0059 | SSIM: 0.0216 | Grad: 52987.641\n",
      "[Epoch 60, Batch 41/100] Loss: 0.0381 | RMSE: 0.0352 | Consistency: 0.0068 | SSIM: 0.0279 | Grad: 51183.418\n",
      "[Epoch 60, Batch 42/100] Loss: 0.0377 | RMSE: 0.0353 | Consistency: 0.0062 | SSIM: 0.0233 | Grad: 61281.816\n",
      "[Epoch 60, Batch 43/100] Loss: 0.0379 | RMSE: 0.0353 | Consistency: 0.0063 | SSIM: 0.0249 | Grad: 60646.371\n",
      "[Epoch 60, Batch 44/100] Loss: 0.0370 | RMSE: 0.0345 | Consistency: 0.0067 | SSIM: 0.0239 | Grad: 40160.555\n",
      "[Epoch 60, Batch 45/100] Loss: 0.0325 | RMSE: 0.0305 | Consistency: 0.0059 | SSIM: 0.0194 | Grad: 49623.605\n",
      "[Epoch 60, Batch 46/100] Loss: 0.0391 | RMSE: 0.0360 | Consistency: 0.0067 | SSIM: 0.0303 | Grad: 67183.547\n",
      "[Epoch 60, Batch 47/100] Loss: 0.0299 | RMSE: 0.0276 | Consistency: 0.0043 | SSIM: 0.0222 | Grad: 28182.582\n",
      "[Epoch 60, Batch 48/100] Loss: 0.0375 | RMSE: 0.0348 | Consistency: 0.0067 | SSIM: 0.0260 | Grad: 53886.281\n",
      "[Epoch 60, Batch 49/100] Loss: 0.0333 | RMSE: 0.0313 | Consistency: 0.0055 | SSIM: 0.0196 | Grad: 100820.406\n",
      "[Epoch 60, Batch 50/100] Loss: 0.0389 | RMSE: 0.0368 | Consistency: 0.0081 | SSIM: 0.0203 | Grad: 85605.320\n",
      "[Epoch 60, Batch 51/100] Loss: 0.0403 | RMSE: 0.0381 | Consistency: 0.0061 | SSIM: 0.0211 | Grad: 121947.672\n",
      "[Epoch 60, Batch 52/100] Loss: 0.0427 | RMSE: 0.0392 | Consistency: 0.0084 | SSIM: 0.0342 | Grad: 64531.598\n",
      "[Epoch 60, Batch 53/100] Loss: 0.0315 | RMSE: 0.0298 | Consistency: 0.0044 | SSIM: 0.0167 | Grad: 52761.422\n",
      "[Epoch 60, Batch 54/100] Loss: 0.0375 | RMSE: 0.0347 | Consistency: 0.0051 | SSIM: 0.0266 | Grad: 112911.008\n",
      "[Epoch 60, Batch 55/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0059 | SSIM: 0.0224 | Grad: 70236.297\n",
      "[Epoch 60, Batch 56/100] Loss: 0.0432 | RMSE: 0.0398 | Consistency: 0.0087 | SSIM: 0.0336 | Grad: 91793.203\n",
      "[Epoch 60, Batch 57/100] Loss: 0.0379 | RMSE: 0.0350 | Consistency: 0.0065 | SSIM: 0.0279 | Grad: 31621.941\n",
      "[Epoch 60, Batch 58/100] Loss: 0.0325 | RMSE: 0.0303 | Consistency: 0.0054 | SSIM: 0.0220 | Grad: 54317.051\n",
      "[Epoch 60, Batch 59/100] Loss: 0.0392 | RMSE: 0.0370 | Consistency: 0.0063 | SSIM: 0.0218 | Grad: 80435.695\n",
      "[Epoch 60, Batch 60/100] Loss: 0.0369 | RMSE: 0.0346 | Consistency: 0.0071 | SSIM: 0.0222 | Grad: 54346.781\n",
      "[Epoch 60, Batch 61/100] Loss: 0.0358 | RMSE: 0.0340 | Consistency: 0.0065 | SSIM: 0.0178 | Grad: 62522.730\n",
      "[Epoch 60, Batch 62/100] Loss: 0.0456 | RMSE: 0.0429 | Consistency: 0.0113 | SSIM: 0.0261 | Grad: 97419.516\n",
      "[Epoch 60, Batch 63/100] Loss: 0.0311 | RMSE: 0.0292 | Consistency: 0.0041 | SSIM: 0.0189 | Grad: 88795.695\n",
      "[Epoch 60, Batch 64/100] Loss: 0.0323 | RMSE: 0.0301 | Consistency: 0.0051 | SSIM: 0.0212 | Grad: 23354.877\n",
      "[Epoch 60, Batch 65/100] Loss: 0.0360 | RMSE: 0.0340 | Consistency: 0.0055 | SSIM: 0.0194 | Grad: 61155.414\n",
      "[Epoch 60, Batch 66/100] Loss: 0.0344 | RMSE: 0.0320 | Consistency: 0.0061 | SSIM: 0.0234 | Grad: 44911.008\n",
      "[Epoch 60, Batch 67/100] Loss: 0.0377 | RMSE: 0.0353 | Consistency: 0.0056 | SSIM: 0.0230 | Grad: 92663.727\n",
      "[Epoch 60, Batch 68/100] Loss: 0.0369 | RMSE: 0.0348 | Consistency: 0.0054 | SSIM: 0.0200 | Grad: 72347.375\n",
      "[Epoch 60, Batch 69/100] Loss: 0.0366 | RMSE: 0.0340 | Consistency: 0.0057 | SSIM: 0.0260 | Grad: 24568.354\n",
      "[Epoch 60, Batch 70/100] Loss: 0.0468 | RMSE: 0.0439 | Consistency: 0.0095 | SSIM: 0.0284 | Grad: 90960.789\n",
      "[Epoch 60, Batch 71/100] Loss: 0.0399 | RMSE: 0.0371 | Consistency: 0.0079 | SSIM: 0.0267 | Grad: 59476.840\n",
      "[Epoch 60, Batch 72/100] Loss: 0.0479 | RMSE: 0.0447 | Consistency: 0.0123 | SSIM: 0.0310 | Grad: 57719.492\n",
      "[Epoch 60, Batch 73/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0059 | SSIM: 0.0230 | Grad: 66032.953\n",
      "[Epoch 60, Batch 74/100] Loss: 0.0409 | RMSE: 0.0380 | Consistency: 0.0074 | SSIM: 0.0279 | Grad: 47074.625\n",
      "[Epoch 60, Batch 75/100] Loss: 0.0341 | RMSE: 0.0320 | Consistency: 0.0056 | SSIM: 0.0211 | Grad: 61848.133\n",
      "[Epoch 60, Batch 76/100] Loss: 0.0449 | RMSE: 0.0420 | Consistency: 0.0079 | SSIM: 0.0283 | Grad: 111316.320\n",
      "[Epoch 60, Batch 77/100] Loss: 0.0373 | RMSE: 0.0351 | Consistency: 0.0067 | SSIM: 0.0216 | Grad: 92924.383\n",
      "[Epoch 60, Batch 78/100] Loss: 0.0382 | RMSE: 0.0354 | Consistency: 0.0063 | SSIM: 0.0274 | Grad: 70500.078\n",
      "[Epoch 60, Batch 79/100] Loss: 0.0376 | RMSE: 0.0353 | Consistency: 0.0072 | SSIM: 0.0218 | Grad: 38797.391\n",
      "[Epoch 60, Batch 80/100] Loss: 0.0384 | RMSE: 0.0363 | Consistency: 0.0060 | SSIM: 0.0200 | Grad: 75718.688\n",
      "[Epoch 60, Batch 81/100] Loss: 0.0414 | RMSE: 0.0389 | Consistency: 0.0062 | SSIM: 0.0238 | Grad: 118385.578\n",
      "[Epoch 60, Batch 82/100] Loss: 0.0424 | RMSE: 0.0396 | Consistency: 0.0069 | SSIM: 0.0278 | Grad: 78212.602\n",
      "[Epoch 60, Batch 83/100] Loss: 0.0314 | RMSE: 0.0294 | Consistency: 0.0045 | SSIM: 0.0196 | Grad: 99016.984\n",
      "[Epoch 60, Batch 84/100] Loss: 0.0412 | RMSE: 0.0385 | Consistency: 0.0071 | SSIM: 0.0271 | Grad: 114425.781\n",
      "[Epoch 60, Batch 85/100] Loss: 0.0404 | RMSE: 0.0378 | Consistency: 0.0062 | SSIM: 0.0257 | Grad: 72973.281\n",
      "[Epoch 60, Batch 86/100] Loss: 0.0407 | RMSE: 0.0378 | Consistency: 0.0078 | SSIM: 0.0280 | Grad: 57590.531\n",
      "[Epoch 60, Batch 87/100] Loss: 0.0356 | RMSE: 0.0334 | Consistency: 0.0055 | SSIM: 0.0210 | Grad: 59348.359\n",
      "[Epoch 60, Batch 88/100] Loss: 0.0350 | RMSE: 0.0328 | Consistency: 0.0055 | SSIM: 0.0211 | Grad: 47074.832\n",
      "[Epoch 60, Batch 89/100] Loss: 0.0340 | RMSE: 0.0317 | Consistency: 0.0052 | SSIM: 0.0215 | Grad: 39693.930\n",
      "[Epoch 60, Batch 90/100] Loss: 0.0388 | RMSE: 0.0362 | Consistency: 0.0066 | SSIM: 0.0260 | Grad: 56669.484\n",
      "[Epoch 60, Batch 91/100] Loss: 0.0354 | RMSE: 0.0333 | Consistency: 0.0061 | SSIM: 0.0213 | Grad: 54708.945\n",
      "[Epoch 60, Batch 92/100] Loss: 0.0404 | RMSE: 0.0372 | Consistency: 0.0084 | SSIM: 0.0313 | Grad: 25395.695\n",
      "[Epoch 60, Batch 93/100] Loss: 0.0538 | RMSE: 0.0507 | Consistency: 0.0169 | SSIM: 0.0293 | Grad: 67359.398\n",
      "[Epoch 60, Batch 94/100] Loss: 0.0352 | RMSE: 0.0331 | Consistency: 0.0049 | SSIM: 0.0196 | Grad: 64843.270\n",
      "[Epoch 60, Batch 95/100] Loss: 0.0383 | RMSE: 0.0357 | Consistency: 0.0063 | SSIM: 0.0252 | Grad: 32430.424\n",
      "[Epoch 60, Batch 96/100] Loss: 0.0311 | RMSE: 0.0291 | Consistency: 0.0044 | SSIM: 0.0191 | Grad: 52988.258\n",
      "[Epoch 60, Batch 97/100] Loss: 0.0346 | RMSE: 0.0324 | Consistency: 0.0053 | SSIM: 0.0220 | Grad: 74742.156\n",
      "[Epoch 60, Batch 98/100] Loss: 0.0394 | RMSE: 0.0371 | Consistency: 0.0079 | SSIM: 0.0228 | Grad: 53609.082\n",
      "[Epoch 60, Batch 99/100] Loss: 0.0388 | RMSE: 0.0362 | Consistency: 0.0066 | SSIM: 0.0255 | Grad: 105002.922\n",
      "[Epoch 60, Batch 100/100] Loss: 0.0368 | RMSE: 0.0344 | Consistency: 0.0070 | SSIM: 0.0225 | Grad: 120773.328\n",
      "✅ Epoch 60 완료!\n",
      "   📈 평균 Loss: 0.038317\n",
      "   📊 평균 RMSE: 0.035837\n",
      "   ⚙️  학습률: 0.000178\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 61/80 시작...\n",
      "[Epoch 61, Batch 1/100] Loss: 0.0416 | RMSE: 0.0382 | Consistency: 0.0077 | SSIM: 0.0335 | Grad: 77048.984\n",
      "[Epoch 61, Batch 2/100] Loss: 0.0350 | RMSE: 0.0327 | Consistency: 0.0050 | SSIM: 0.0226 | Grad: 84365.617\n",
      "[Epoch 61, Batch 3/100] Loss: 0.0355 | RMSE: 0.0329 | Consistency: 0.0058 | SSIM: 0.0255 | Grad: 99854.484\n",
      "[Epoch 61, Batch 4/100] Loss: 0.0412 | RMSE: 0.0383 | Consistency: 0.0081 | SSIM: 0.0280 | Grad: 97879.477\n",
      "[Epoch 61, Batch 5/100] Loss: 0.0391 | RMSE: 0.0367 | Consistency: 0.0073 | SSIM: 0.0239 | Grad: 86800.695\n",
      "[Epoch 61, Batch 6/100] Loss: 0.0368 | RMSE: 0.0344 | Consistency: 0.0069 | SSIM: 0.0237 | Grad: 92242.672\n",
      "[Epoch 61, Batch 7/100] Loss: 0.0383 | RMSE: 0.0361 | Consistency: 0.0058 | SSIM: 0.0216 | Grad: 66706.664\n",
      "[Epoch 61, Batch 8/100] Loss: 0.0392 | RMSE: 0.0368 | Consistency: 0.0080 | SSIM: 0.0232 | Grad: 46535.621\n",
      "[Epoch 61, Batch 9/100] Loss: 0.0364 | RMSE: 0.0341 | Consistency: 0.0064 | SSIM: 0.0221 | Grad: 39501.156\n",
      "[Epoch 61, Batch 10/100] Loss: 0.0367 | RMSE: 0.0342 | Consistency: 0.0065 | SSIM: 0.0244 | Grad: 60039.965\n",
      "[Epoch 61, Batch 11/100] Loss: 0.0347 | RMSE: 0.0321 | Consistency: 0.0067 | SSIM: 0.0252 | Grad: 60226.184\n",
      "[Epoch 61, Batch 12/100] Loss: 0.0370 | RMSE: 0.0343 | Consistency: 0.0061 | SSIM: 0.0256 | Grad: 86372.953\n",
      "[Epoch 61, Batch 13/100] Loss: 0.0358 | RMSE: 0.0338 | Consistency: 0.0059 | SSIM: 0.0190 | Grad: 99970.602\n",
      "[Epoch 61, Batch 14/100] Loss: 0.0505 | RMSE: 0.0464 | Consistency: 0.0107 | SSIM: 0.0403 | Grad: 120184.164\n",
      "[Epoch 61, Batch 15/100] Loss: 0.0397 | RMSE: 0.0375 | Consistency: 0.0072 | SSIM: 0.0214 | Grad: 112029.430\n",
      "[Epoch 61, Batch 16/100] Loss: 0.0450 | RMSE: 0.0409 | Consistency: 0.0075 | SSIM: 0.0395 | Grad: 63246.055\n",
      "[Epoch 61, Batch 17/100] Loss: 0.0405 | RMSE: 0.0380 | Consistency: 0.0083 | SSIM: 0.0241 | Grad: 48018.742\n",
      "[Epoch 61, Batch 18/100] Loss: 0.0358 | RMSE: 0.0332 | Consistency: 0.0062 | SSIM: 0.0252 | Grad: 61697.539\n",
      "[Epoch 61, Batch 19/100] Loss: 0.0372 | RMSE: 0.0344 | Consistency: 0.0064 | SSIM: 0.0272 | Grad: 73948.469\n",
      "[Epoch 61, Batch 20/100] Loss: 0.0322 | RMSE: 0.0302 | Consistency: 0.0043 | SSIM: 0.0197 | Grad: 53852.043\n",
      "[Epoch 61, Batch 21/100] Loss: 0.0350 | RMSE: 0.0327 | Consistency: 0.0057 | SSIM: 0.0231 | Grad: 108807.734\n",
      "[Epoch 61, Batch 22/100] Loss: 0.0367 | RMSE: 0.0344 | Consistency: 0.0056 | SSIM: 0.0225 | Grad: 85766.641\n",
      "[Epoch 61, Batch 23/100] Loss: 0.0352 | RMSE: 0.0329 | Consistency: 0.0049 | SSIM: 0.0219 | Grad: 113985.305\n",
      "[Epoch 61, Batch 24/100] Loss: 0.0412 | RMSE: 0.0389 | Consistency: 0.0057 | SSIM: 0.0231 | Grad: 94782.602\n",
      "[Epoch 61, Batch 25/100] Loss: 0.0491 | RMSE: 0.0464 | Consistency: 0.0084 | SSIM: 0.0260 | Grad: 118361.922\n",
      "[Epoch 61, Batch 26/100] Loss: 0.0424 | RMSE: 0.0400 | Consistency: 0.0079 | SSIM: 0.0237 | Grad: 97873.633\n",
      "[Epoch 61, Batch 27/100] Loss: 0.0393 | RMSE: 0.0366 | Consistency: 0.0075 | SSIM: 0.0261 | Grad: 34962.109\n",
      "[Epoch 61, Batch 28/100] Loss: 0.0345 | RMSE: 0.0325 | Consistency: 0.0054 | SSIM: 0.0199 | Grad: 120354.961\n",
      "[Epoch 61, Batch 29/100] Loss: 0.0460 | RMSE: 0.0430 | Consistency: 0.0102 | SSIM: 0.0288 | Grad: 16711.945\n",
      "[Epoch 61, Batch 30/100] Loss: 0.0369 | RMSE: 0.0353 | Consistency: 0.0054 | SSIM: 0.0160 | Grad: 120534.125\n",
      "[Epoch 61, Batch 31/100] Loss: 0.0378 | RMSE: 0.0350 | Consistency: 0.0065 | SSIM: 0.0274 | Grad: 98496.258\n",
      "[Epoch 61, Batch 32/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0058 | SSIM: 0.0216 | Grad: 112509.945\n",
      "[Epoch 61, Batch 33/100] Loss: 0.0480 | RMSE: 0.0455 | Consistency: 0.0080 | SSIM: 0.0239 | Grad: 125444.227\n",
      "[Epoch 61, Batch 34/100] Loss: 0.0415 | RMSE: 0.0389 | Consistency: 0.0099 | SSIM: 0.0253 | Grad: 21462.594\n",
      "[Epoch 61, Batch 35/100] Loss: 0.0302 | RMSE: 0.0285 | Consistency: 0.0045 | SSIM: 0.0165 | Grad: 99520.922\n",
      "[Epoch 61, Batch 36/100] Loss: 0.0372 | RMSE: 0.0349 | Consistency: 0.0060 | SSIM: 0.0223 | Grad: 66624.469\n",
      "[Epoch 61, Batch 37/100] Loss: 0.0387 | RMSE: 0.0360 | Consistency: 0.0064 | SSIM: 0.0262 | Grad: 76553.234\n",
      "[Epoch 61, Batch 38/100] Loss: 0.0361 | RMSE: 0.0339 | Consistency: 0.0068 | SSIM: 0.0205 | Grad: 98087.055\n",
      "[Epoch 61, Batch 39/100] Loss: 0.0417 | RMSE: 0.0386 | Consistency: 0.0074 | SSIM: 0.0304 | Grad: 63909.832\n",
      "[Epoch 61, Batch 40/100] Loss: 0.0359 | RMSE: 0.0336 | Consistency: 0.0055 | SSIM: 0.0231 | Grad: 56933.195\n",
      "[Epoch 61, Batch 41/100] Loss: 0.0381 | RMSE: 0.0356 | Consistency: 0.0068 | SSIM: 0.0241 | Grad: 84159.742\n",
      "[Epoch 61, Batch 42/100] Loss: 0.0371 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0247 | Grad: 57999.867\n",
      "[Epoch 61, Batch 43/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0073 | SSIM: 0.0248 | Grad: 36524.934\n",
      "[Epoch 61, Batch 44/100] Loss: 0.0353 | RMSE: 0.0330 | Consistency: 0.0062 | SSIM: 0.0223 | Grad: 37933.234\n",
      "[Epoch 61, Batch 45/100] Loss: 0.0359 | RMSE: 0.0337 | Consistency: 0.0062 | SSIM: 0.0214 | Grad: 33053.785\n",
      "[Epoch 61, Batch 46/100] Loss: 0.0332 | RMSE: 0.0310 | Consistency: 0.0054 | SSIM: 0.0211 | Grad: 40985.496\n",
      "[Epoch 61, Batch 47/100] Loss: 0.0405 | RMSE: 0.0374 | Consistency: 0.0081 | SSIM: 0.0302 | Grad: 52822.598\n",
      "[Epoch 61, Batch 48/100] Loss: 0.0333 | RMSE: 0.0313 | Consistency: 0.0055 | SSIM: 0.0193 | Grad: 52018.652\n",
      "[Epoch 61, Batch 49/100] Loss: 0.0379 | RMSE: 0.0356 | Consistency: 0.0062 | SSIM: 0.0229 | Grad: 80148.867\n",
      "[Epoch 61, Batch 50/100] Loss: 0.0543 | RMSE: 0.0510 | Consistency: 0.0174 | SSIM: 0.0314 | Grad: 109382.406\n",
      "[Epoch 61, Batch 51/100] Loss: 0.0361 | RMSE: 0.0332 | Consistency: 0.0064 | SSIM: 0.0286 | Grad: 48199.574\n",
      "[Epoch 61, Batch 52/100] Loss: 0.0332 | RMSE: 0.0313 | Consistency: 0.0053 | SSIM: 0.0192 | Grad: 83452.867\n",
      "[Epoch 61, Batch 53/100] Loss: 0.0348 | RMSE: 0.0329 | Consistency: 0.0059 | SSIM: 0.0189 | Grad: 84287.234\n",
      "[Epoch 61, Batch 54/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0065 | SSIM: 0.0223 | Grad: 51389.598\n",
      "[Epoch 61, Batch 55/100] Loss: 0.0385 | RMSE: 0.0365 | Consistency: 0.0056 | SSIM: 0.0202 | Grad: 25458.598\n",
      "[Epoch 61, Batch 56/100] Loss: 0.0368 | RMSE: 0.0346 | Consistency: 0.0067 | SSIM: 0.0213 | Grad: 56109.371\n",
      "[Epoch 61, Batch 57/100] Loss: 0.0390 | RMSE: 0.0366 | Consistency: 0.0078 | SSIM: 0.0230 | Grad: 64933.734\n",
      "[Epoch 61, Batch 58/100] Loss: 0.0462 | RMSE: 0.0432 | Consistency: 0.0092 | SSIM: 0.0291 | Grad: 45088.102\n",
      "[Epoch 61, Batch 59/100] Loss: 0.0350 | RMSE: 0.0324 | Consistency: 0.0059 | SSIM: 0.0249 | Grad: 30230.340\n",
      "[Epoch 61, Batch 60/100] Loss: 0.0350 | RMSE: 0.0331 | Consistency: 0.0051 | SSIM: 0.0185 | Grad: 74076.555\n",
      "[Epoch 61, Batch 61/100] Loss: 0.0357 | RMSE: 0.0334 | Consistency: 0.0065 | SSIM: 0.0218 | Grad: 56113.402\n",
      "[Epoch 61, Batch 62/100] Loss: 0.0360 | RMSE: 0.0336 | Consistency: 0.0069 | SSIM: 0.0240 | Grad: 61228.746\n",
      "[Epoch 61, Batch 63/100] Loss: 0.0378 | RMSE: 0.0352 | Consistency: 0.0067 | SSIM: 0.0257 | Grad: 61543.039\n",
      "[Epoch 61, Batch 64/100] Loss: 0.0375 | RMSE: 0.0347 | Consistency: 0.0058 | SSIM: 0.0271 | Grad: 52136.352\n",
      "[Epoch 61, Batch 65/100] Loss: 0.0331 | RMSE: 0.0307 | Consistency: 0.0050 | SSIM: 0.0239 | Grad: 55057.977\n",
      "[Epoch 61, Batch 66/100] Loss: 0.0385 | RMSE: 0.0366 | Consistency: 0.0064 | SSIM: 0.0191 | Grad: 65941.383\n",
      "[Epoch 61, Batch 67/100] Loss: 0.0370 | RMSE: 0.0344 | Consistency: 0.0061 | SSIM: 0.0252 | Grad: 47698.004\n",
      "[Epoch 61, Batch 68/100] Loss: 0.0369 | RMSE: 0.0342 | Consistency: 0.0069 | SSIM: 0.0257 | Grad: 55131.223\n",
      "[Epoch 61, Batch 69/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0069 | SSIM: 0.0246 | Grad: 40543.547\n",
      "[Epoch 61, Batch 70/100] Loss: 0.0346 | RMSE: 0.0326 | Consistency: 0.0065 | SSIM: 0.0190 | Grad: 53911.355\n",
      "[Epoch 61, Batch 71/100] Loss: 0.0383 | RMSE: 0.0358 | Consistency: 0.0065 | SSIM: 0.0245 | Grad: 26439.367\n",
      "[Epoch 61, Batch 72/100] Loss: 0.0388 | RMSE: 0.0368 | Consistency: 0.0061 | SSIM: 0.0197 | Grad: 65414.895\n",
      "[Epoch 61, Batch 73/100] Loss: 0.0363 | RMSE: 0.0337 | Consistency: 0.0065 | SSIM: 0.0252 | Grad: 84678.070\n",
      "[Epoch 61, Batch 74/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0057 | SSIM: 0.0250 | Grad: 56867.555\n",
      "[Epoch 61, Batch 75/100] Loss: 0.0382 | RMSE: 0.0354 | Consistency: 0.0061 | SSIM: 0.0276 | Grad: 93947.289\n",
      "[Epoch 61, Batch 76/100] Loss: 0.0397 | RMSE: 0.0367 | Consistency: 0.0069 | SSIM: 0.0290 | Grad: 65925.234\n",
      "[Epoch 61, Batch 77/100] Loss: 0.0413 | RMSE: 0.0393 | Consistency: 0.0072 | SSIM: 0.0197 | Grad: 49321.891\n",
      "[Epoch 61, Batch 78/100] Loss: 0.0383 | RMSE: 0.0362 | Consistency: 0.0067 | SSIM: 0.0200 | Grad: 80305.586\n",
      "[Epoch 61, Batch 79/100] Loss: 0.0356 | RMSE: 0.0334 | Consistency: 0.0063 | SSIM: 0.0210 | Grad: 50567.566\n",
      "[Epoch 61, Batch 80/100] Loss: 0.0350 | RMSE: 0.0331 | Consistency: 0.0052 | SSIM: 0.0189 | Grad: 87744.273\n",
      "[Epoch 61, Batch 81/100] Loss: 0.0325 | RMSE: 0.0301 | Consistency: 0.0056 | SSIM: 0.0238 | Grad: 44507.062\n",
      "[Epoch 61, Batch 82/100] Loss: 0.0461 | RMSE: 0.0427 | Consistency: 0.0102 | SSIM: 0.0322 | Grad: 75218.352\n",
      "[Epoch 61, Batch 83/100] Loss: 0.0418 | RMSE: 0.0385 | Consistency: 0.0082 | SSIM: 0.0314 | Grad: 51381.980\n",
      "[Epoch 61, Batch 84/100] Loss: 0.0401 | RMSE: 0.0376 | Consistency: 0.0074 | SSIM: 0.0236 | Grad: 56622.051\n",
      "[Epoch 61, Batch 85/100] Loss: 0.0285 | RMSE: 0.0267 | Consistency: 0.0039 | SSIM: 0.0170 | Grad: 75220.875\n",
      "[Epoch 61, Batch 86/100] Loss: 0.0425 | RMSE: 0.0401 | Consistency: 0.0074 | SSIM: 0.0226 | Grad: 74616.812\n",
      "[Epoch 61, Batch 87/100] Loss: 0.0397 | RMSE: 0.0365 | Consistency: 0.0081 | SSIM: 0.0303 | Grad: 86876.445\n",
      "[Epoch 61, Batch 88/100] Loss: 0.0386 | RMSE: 0.0361 | Consistency: 0.0064 | SSIM: 0.0247 | Grad: 71481.859\n",
      "[Epoch 61, Batch 89/100] Loss: 0.0402 | RMSE: 0.0371 | Consistency: 0.0085 | SSIM: 0.0301 | Grad: 79133.898\n",
      "[Epoch 61, Batch 90/100] Loss: 0.0391 | RMSE: 0.0364 | Consistency: 0.0072 | SSIM: 0.0262 | Grad: 59532.555\n",
      "[Epoch 61, Batch 91/100] Loss: 0.0391 | RMSE: 0.0363 | Consistency: 0.0065 | SSIM: 0.0274 | Grad: 84069.820\n",
      "[Epoch 61, Batch 92/100] Loss: 0.0361 | RMSE: 0.0340 | Consistency: 0.0058 | SSIM: 0.0209 | Grad: 47181.758\n",
      "[Epoch 61, Batch 93/100] Loss: 0.0359 | RMSE: 0.0333 | Consistency: 0.0064 | SSIM: 0.0253 | Grad: 38381.395\n",
      "[Epoch 61, Batch 94/100] Loss: 0.0420 | RMSE: 0.0394 | Consistency: 0.0076 | SSIM: 0.0257 | Grad: 55196.242\n",
      "[Epoch 61, Batch 95/100] Loss: 0.0356 | RMSE: 0.0335 | Consistency: 0.0065 | SSIM: 0.0203 | Grad: 94494.055\n",
      "[Epoch 61, Batch 96/100] Loss: 0.0368 | RMSE: 0.0347 | Consistency: 0.0064 | SSIM: 0.0207 | Grad: 88413.703\n",
      "[Epoch 61, Batch 97/100] Loss: 0.0451 | RMSE: 0.0426 | Consistency: 0.0080 | SSIM: 0.0246 | Grad: 89918.766\n",
      "[Epoch 61, Batch 98/100] Loss: 0.0418 | RMSE: 0.0386 | Consistency: 0.0083 | SSIM: 0.0314 | Grad: 100726.000\n",
      "[Epoch 61, Batch 99/100] Loss: 0.0389 | RMSE: 0.0365 | Consistency: 0.0082 | SSIM: 0.0227 | Grad: 73110.539\n",
      "[Epoch 61, Batch 100/100] Loss: 0.0370 | RMSE: 0.0346 | Consistency: 0.0062 | SSIM: 0.0232 | Grad: 29542.600\n",
      "✅ Epoch 61 완료!\n",
      "   📈 평균 Loss: 0.038248\n",
      "   📊 평균 RMSE: 0.035757\n",
      "   ⚙️  학습률: 0.000162\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 62/80 시작...\n",
      "[Epoch 62, Batch 1/100] Loss: 0.0440 | RMSE: 0.0414 | Consistency: 0.0072 | SSIM: 0.0254 | Grad: 84268.758\n",
      "[Epoch 62, Batch 2/100] Loss: 0.0327 | RMSE: 0.0308 | Consistency: 0.0050 | SSIM: 0.0181 | Grad: 31267.396\n",
      "[Epoch 62, Batch 3/100] Loss: 0.0358 | RMSE: 0.0337 | Consistency: 0.0070 | SSIM: 0.0199 | Grad: 76007.297\n",
      "[Epoch 62, Batch 4/100] Loss: 0.0379 | RMSE: 0.0353 | Consistency: 0.0068 | SSIM: 0.0255 | Grad: 34095.262\n",
      "[Epoch 62, Batch 5/100] Loss: 0.0421 | RMSE: 0.0392 | Consistency: 0.0083 | SSIM: 0.0273 | Grad: 66322.281\n",
      "[Epoch 62, Batch 6/100] Loss: 0.0363 | RMSE: 0.0340 | Consistency: 0.0066 | SSIM: 0.0231 | Grad: 60242.855\n",
      "[Epoch 62, Batch 7/100] Loss: 0.0368 | RMSE: 0.0342 | Consistency: 0.0067 | SSIM: 0.0259 | Grad: 24806.240\n",
      "[Epoch 62, Batch 8/100] Loss: 0.0363 | RMSE: 0.0339 | Consistency: 0.0060 | SSIM: 0.0229 | Grad: 51585.363\n",
      "[Epoch 62, Batch 9/100] Loss: 0.0415 | RMSE: 0.0391 | Consistency: 0.0079 | SSIM: 0.0233 | Grad: 16325.049\n",
      "[Epoch 62, Batch 10/100] Loss: 0.0436 | RMSE: 0.0406 | Consistency: 0.0083 | SSIM: 0.0296 | Grad: 110658.945\n",
      "[Epoch 62, Batch 11/100] Loss: 0.0347 | RMSE: 0.0319 | Consistency: 0.0066 | SSIM: 0.0273 | Grad: 51311.430\n",
      "[Epoch 62, Batch 12/100] Loss: 0.0323 | RMSE: 0.0306 | Consistency: 0.0046 | SSIM: 0.0165 | Grad: 90262.562\n",
      "[Epoch 62, Batch 13/100] Loss: 0.0370 | RMSE: 0.0346 | Consistency: 0.0079 | SSIM: 0.0230 | Grad: 49883.918\n",
      "[Epoch 62, Batch 14/100] Loss: 0.0432 | RMSE: 0.0405 | Consistency: 0.0106 | SSIM: 0.0265 | Grad: 38638.605\n",
      "[Epoch 62, Batch 15/100] Loss: 0.0353 | RMSE: 0.0332 | Consistency: 0.0056 | SSIM: 0.0207 | Grad: 28564.400\n",
      "[Epoch 62, Batch 16/100] Loss: 0.0433 | RMSE: 0.0406 | Consistency: 0.0081 | SSIM: 0.0258 | Grad: 98090.070\n",
      "[Epoch 62, Batch 17/100] Loss: 0.0409 | RMSE: 0.0384 | Consistency: 0.0088 | SSIM: 0.0241 | Grad: 40300.004\n",
      "[Epoch 62, Batch 18/100] Loss: 0.0371 | RMSE: 0.0347 | Consistency: 0.0070 | SSIM: 0.0235 | Grad: 68306.469\n",
      "[Epoch 62, Batch 19/100] Loss: 0.0378 | RMSE: 0.0354 | Consistency: 0.0065 | SSIM: 0.0238 | Grad: 75155.945\n",
      "[Epoch 62, Batch 20/100] Loss: 0.0478 | RMSE: 0.0447 | Consistency: 0.0106 | SSIM: 0.0301 | Grad: 27702.586\n",
      "[Epoch 62, Batch 21/100] Loss: 0.0425 | RMSE: 0.0401 | Consistency: 0.0079 | SSIM: 0.0234 | Grad: 69145.867\n",
      "[Epoch 62, Batch 22/100] Loss: 0.0470 | RMSE: 0.0433 | Consistency: 0.0124 | SSIM: 0.0354 | Grad: 115955.688\n",
      "[Epoch 62, Batch 23/100] Loss: 0.0355 | RMSE: 0.0331 | Consistency: 0.0057 | SSIM: 0.0231 | Grad: 50605.531\n",
      "[Epoch 62, Batch 24/100] Loss: 0.0303 | RMSE: 0.0286 | Consistency: 0.0043 | SSIM: 0.0171 | Grad: 42176.184\n",
      "[Epoch 62, Batch 25/100] Loss: 0.0354 | RMSE: 0.0331 | Consistency: 0.0065 | SSIM: 0.0231 | Grad: 70647.805\n",
      "[Epoch 62, Batch 26/100] Loss: 0.0407 | RMSE: 0.0378 | Consistency: 0.0086 | SSIM: 0.0281 | Grad: 20922.121\n",
      "[Epoch 62, Batch 27/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0085 | SSIM: 0.0240 | Grad: 60668.617\n",
      "[Epoch 62, Batch 28/100] Loss: 0.0397 | RMSE: 0.0371 | Consistency: 0.0081 | SSIM: 0.0249 | Grad: 86215.344\n",
      "[Epoch 62, Batch 29/100] Loss: 0.0430 | RMSE: 0.0396 | Consistency: 0.0087 | SSIM: 0.0326 | Grad: 75930.555\n",
      "[Epoch 62, Batch 30/100] Loss: 0.0418 | RMSE: 0.0389 | Consistency: 0.0089 | SSIM: 0.0282 | Grad: 32782.352\n",
      "[Epoch 62, Batch 31/100] Loss: 0.0398 | RMSE: 0.0378 | Consistency: 0.0064 | SSIM: 0.0195 | Grad: 77321.883\n",
      "[Epoch 62, Batch 32/100] Loss: 0.0363 | RMSE: 0.0340 | Consistency: 0.0064 | SSIM: 0.0224 | Grad: 72878.859\n",
      "[Epoch 62, Batch 33/100] Loss: 0.0455 | RMSE: 0.0419 | Consistency: 0.0084 | SSIM: 0.0354 | Grad: 66529.711\n",
      "[Epoch 62, Batch 34/100] Loss: 0.0376 | RMSE: 0.0350 | Consistency: 0.0067 | SSIM: 0.0252 | Grad: 51614.180\n",
      "[Epoch 62, Batch 35/100] Loss: 0.0357 | RMSE: 0.0334 | Consistency: 0.0060 | SSIM: 0.0228 | Grad: 66585.297\n",
      "[Epoch 62, Batch 36/100] Loss: 0.0360 | RMSE: 0.0337 | Consistency: 0.0069 | SSIM: 0.0230 | Grad: 63353.836\n",
      "[Epoch 62, Batch 37/100] Loss: 0.0460 | RMSE: 0.0436 | Consistency: 0.0079 | SSIM: 0.0230 | Grad: 118384.750\n",
      "[Epoch 62, Batch 38/100] Loss: 0.0391 | RMSE: 0.0364 | Consistency: 0.0072 | SSIM: 0.0271 | Grad: 85987.703\n",
      "[Epoch 62, Batch 39/100] Loss: 0.0336 | RMSE: 0.0313 | Consistency: 0.0051 | SSIM: 0.0220 | Grad: 57343.316\n",
      "[Epoch 62, Batch 40/100] Loss: 0.0384 | RMSE: 0.0362 | Consistency: 0.0072 | SSIM: 0.0221 | Grad: 72225.133\n",
      "[Epoch 62, Batch 41/100] Loss: 0.0399 | RMSE: 0.0371 | Consistency: 0.0068 | SSIM: 0.0279 | Grad: 85114.305\n",
      "[Epoch 62, Batch 42/100] Loss: 0.0383 | RMSE: 0.0360 | Consistency: 0.0067 | SSIM: 0.0227 | Grad: 79877.438\n",
      "[Epoch 62, Batch 43/100] Loss: 0.0351 | RMSE: 0.0326 | Consistency: 0.0053 | SSIM: 0.0240 | Grad: 71758.922\n",
      "[Epoch 62, Batch 44/100] Loss: 0.0309 | RMSE: 0.0292 | Consistency: 0.0043 | SSIM: 0.0172 | Grad: 80195.672\n",
      "[Epoch 62, Batch 45/100] Loss: 0.0419 | RMSE: 0.0391 | Consistency: 0.0083 | SSIM: 0.0265 | Grad: 91129.062\n",
      "[Epoch 62, Batch 46/100] Loss: 0.0326 | RMSE: 0.0305 | Consistency: 0.0053 | SSIM: 0.0201 | Grad: 56696.848\n",
      "[Epoch 62, Batch 47/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0062 | SSIM: 0.0218 | Grad: 59277.156\n",
      "[Epoch 62, Batch 48/100] Loss: 0.0345 | RMSE: 0.0324 | Consistency: 0.0058 | SSIM: 0.0213 | Grad: 62543.344\n",
      "[Epoch 62, Batch 49/100] Loss: 0.0440 | RMSE: 0.0409 | Consistency: 0.0087 | SSIM: 0.0295 | Grad: 87374.898\n",
      "[Epoch 62, Batch 50/100] Loss: 0.0393 | RMSE: 0.0369 | Consistency: 0.0082 | SSIM: 0.0228 | Grad: 56595.602\n",
      "[Epoch 62, Batch 51/100] Loss: 0.0311 | RMSE: 0.0291 | Consistency: 0.0046 | SSIM: 0.0196 | Grad: 73686.312\n",
      "[Epoch 62, Batch 52/100] Loss: 0.0380 | RMSE: 0.0358 | Consistency: 0.0076 | SSIM: 0.0211 | Grad: 48731.980\n",
      "[Epoch 62, Batch 53/100] Loss: 0.0331 | RMSE: 0.0305 | Consistency: 0.0051 | SSIM: 0.0249 | Grad: 47827.195\n",
      "[Epoch 62, Batch 54/100] Loss: 0.0388 | RMSE: 0.0358 | Consistency: 0.0079 | SSIM: 0.0290 | Grad: 66557.734\n",
      "[Epoch 62, Batch 55/100] Loss: 0.0367 | RMSE: 0.0342 | Consistency: 0.0074 | SSIM: 0.0238 | Grad: 86229.266\n",
      "[Epoch 62, Batch 56/100] Loss: 0.0390 | RMSE: 0.0363 | Consistency: 0.0078 | SSIM: 0.0259 | Grad: 43477.262\n",
      "[Epoch 62, Batch 57/100] Loss: 0.0366 | RMSE: 0.0341 | Consistency: 0.0068 | SSIM: 0.0243 | Grad: 30931.369\n",
      "[Epoch 62, Batch 58/100] Loss: 0.0419 | RMSE: 0.0388 | Consistency: 0.0098 | SSIM: 0.0304 | Grad: 26486.168\n",
      "[Epoch 62, Batch 59/100] Loss: 0.0338 | RMSE: 0.0311 | Consistency: 0.0056 | SSIM: 0.0265 | Grad: 31491.387\n",
      "[Epoch 62, Batch 60/100] Loss: 0.0379 | RMSE: 0.0358 | Consistency: 0.0060 | SSIM: 0.0204 | Grad: 77419.797\n",
      "[Epoch 62, Batch 61/100] Loss: 0.0364 | RMSE: 0.0340 | Consistency: 0.0075 | SSIM: 0.0228 | Grad: 107842.836\n",
      "[Epoch 62, Batch 62/100] Loss: 0.0404 | RMSE: 0.0380 | Consistency: 0.0082 | SSIM: 0.0227 | Grad: 70132.719\n",
      "[Epoch 62, Batch 63/100] Loss: 0.0361 | RMSE: 0.0337 | Consistency: 0.0062 | SSIM: 0.0234 | Grad: 57796.266\n",
      "[Epoch 62, Batch 64/100] Loss: 0.0326 | RMSE: 0.0303 | Consistency: 0.0046 | SSIM: 0.0221 | Grad: 31227.566\n",
      "[Epoch 62, Batch 65/100] Loss: 0.0353 | RMSE: 0.0331 | Consistency: 0.0059 | SSIM: 0.0209 | Grad: 70415.586\n",
      "[Epoch 62, Batch 66/100] Loss: 0.0425 | RMSE: 0.0397 | Consistency: 0.0068 | SSIM: 0.0269 | Grad: 73263.547\n",
      "[Epoch 62, Batch 67/100] Loss: 0.0367 | RMSE: 0.0343 | Consistency: 0.0067 | SSIM: 0.0234 | Grad: 49725.488\n",
      "[Epoch 62, Batch 68/100] Loss: 0.0390 | RMSE: 0.0368 | Consistency: 0.0076 | SSIM: 0.0218 | Grad: 47277.477\n",
      "[Epoch 62, Batch 69/100] Loss: 0.0342 | RMSE: 0.0321 | Consistency: 0.0055 | SSIM: 0.0200 | Grad: 57739.625\n",
      "[Epoch 62, Batch 70/100] Loss: 0.0391 | RMSE: 0.0367 | Consistency: 0.0070 | SSIM: 0.0231 | Grad: 46885.191\n",
      "[Epoch 62, Batch 71/100] Loss: 0.0377 | RMSE: 0.0353 | Consistency: 0.0075 | SSIM: 0.0242 | Grad: 74989.938\n",
      "[Epoch 62, Batch 72/100] Loss: 0.0430 | RMSE: 0.0403 | Consistency: 0.0087 | SSIM: 0.0265 | Grad: 72371.766\n",
      "[Epoch 62, Batch 73/100] Loss: 0.0315 | RMSE: 0.0294 | Consistency: 0.0046 | SSIM: 0.0212 | Grad: 38166.574\n",
      "[Epoch 62, Batch 74/100] Loss: 0.0362 | RMSE: 0.0340 | Consistency: 0.0063 | SSIM: 0.0205 | Grad: 44805.621\n",
      "[Epoch 62, Batch 75/100] Loss: 0.0301 | RMSE: 0.0283 | Consistency: 0.0040 | SSIM: 0.0170 | Grad: 82436.242\n",
      "[Epoch 62, Batch 76/100] Loss: 0.0356 | RMSE: 0.0336 | Consistency: 0.0066 | SSIM: 0.0195 | Grad: 55936.957\n",
      "[Epoch 62, Batch 77/100] Loss: 0.0368 | RMSE: 0.0345 | Consistency: 0.0062 | SSIM: 0.0218 | Grad: 52699.523\n",
      "[Epoch 62, Batch 78/100] Loss: 0.0383 | RMSE: 0.0350 | Consistency: 0.0061 | SSIM: 0.0322 | Grad: 55815.957\n",
      "[Epoch 62, Batch 79/100] Loss: 0.0367 | RMSE: 0.0346 | Consistency: 0.0071 | SSIM: 0.0208 | Grad: 32899.039\n",
      "[Epoch 62, Batch 80/100] Loss: 0.0367 | RMSE: 0.0343 | Consistency: 0.0065 | SSIM: 0.0232 | Grad: 62507.316\n",
      "[Epoch 62, Batch 81/100] Loss: 0.0368 | RMSE: 0.0339 | Consistency: 0.0064 | SSIM: 0.0291 | Grad: 58381.277\n",
      "[Epoch 62, Batch 82/100] Loss: 0.0343 | RMSE: 0.0322 | Consistency: 0.0059 | SSIM: 0.0206 | Grad: 24925.346\n",
      "[Epoch 62, Batch 83/100] Loss: 0.0369 | RMSE: 0.0346 | Consistency: 0.0065 | SSIM: 0.0223 | Grad: 110413.836\n",
      "[Epoch 62, Batch 84/100] Loss: 0.0390 | RMSE: 0.0362 | Consistency: 0.0072 | SSIM: 0.0266 | Grad: 93193.328\n",
      "[Epoch 62, Batch 85/100] Loss: 0.0374 | RMSE: 0.0350 | Consistency: 0.0063 | SSIM: 0.0238 | Grad: 64905.375\n",
      "[Epoch 62, Batch 86/100] Loss: 0.0357 | RMSE: 0.0334 | Consistency: 0.0063 | SSIM: 0.0230 | Grad: 91569.312\n",
      "[Epoch 62, Batch 87/100] Loss: 0.0393 | RMSE: 0.0368 | Consistency: 0.0068 | SSIM: 0.0244 | Grad: 102650.352\n",
      "[Epoch 62, Batch 88/100] Loss: 0.0329 | RMSE: 0.0304 | Consistency: 0.0049 | SSIM: 0.0244 | Grad: 67336.750\n",
      "[Epoch 62, Batch 89/100] Loss: 0.0388 | RMSE: 0.0364 | Consistency: 0.0066 | SSIM: 0.0229 | Grad: 77717.414\n",
      "[Epoch 62, Batch 90/100] Loss: 0.0407 | RMSE: 0.0385 | Consistency: 0.0074 | SSIM: 0.0213 | Grad: 102604.492\n",
      "[Epoch 62, Batch 91/100] Loss: 0.0453 | RMSE: 0.0426 | Consistency: 0.0074 | SSIM: 0.0267 | Grad: 36535.641\n",
      "[Epoch 62, Batch 92/100] Loss: 0.0316 | RMSE: 0.0295 | Consistency: 0.0042 | SSIM: 0.0205 | Grad: 96737.914\n",
      "[Epoch 62, Batch 93/100] Loss: 0.0396 | RMSE: 0.0369 | Consistency: 0.0072 | SSIM: 0.0255 | Grad: 112637.125\n",
      "[Epoch 62, Batch 94/100] Loss: 0.0341 | RMSE: 0.0322 | Consistency: 0.0053 | SSIM: 0.0191 | Grad: 72187.133\n",
      "[Epoch 62, Batch 95/100] Loss: 0.0413 | RMSE: 0.0393 | Consistency: 0.0070 | SSIM: 0.0202 | Grad: 35290.086\n",
      "[Epoch 62, Batch 96/100] Loss: 0.0444 | RMSE: 0.0409 | Consistency: 0.0088 | SSIM: 0.0339 | Grad: 103273.297\n",
      "[Epoch 62, Batch 97/100] Loss: 0.0372 | RMSE: 0.0348 | Consistency: 0.0064 | SSIM: 0.0230 | Grad: 90023.352\n",
      "[Epoch 62, Batch 98/100] Loss: 0.0404 | RMSE: 0.0373 | Consistency: 0.0073 | SSIM: 0.0303 | Grad: 50563.824\n",
      "[Epoch 62, Batch 99/100] Loss: 0.0340 | RMSE: 0.0321 | Consistency: 0.0053 | SSIM: 0.0191 | Grad: 30583.105\n",
      "[Epoch 62, Batch 100/100] Loss: 0.0366 | RMSE: 0.0343 | Consistency: 0.0069 | SSIM: 0.0222 | Grad: 33278.438\n",
      "✅ Epoch 62 완료!\n",
      "   📈 평균 Loss: 0.037895\n",
      "   📊 평균 RMSE: 0.035429\n",
      "   ⚙️  학습률: 0.000146\n",
      "   🏆 NEW BEST! RMSE: 0.035429\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 63/80 시작...\n",
      "[Epoch 63, Batch 1/100] Loss: 0.0515 | RMSE: 0.0486 | Consistency: 0.0152 | SSIM: 0.0272 | Grad: 93071.391\n",
      "[Epoch 63, Batch 2/100] Loss: 0.0425 | RMSE: 0.0397 | Consistency: 0.0082 | SSIM: 0.0275 | Grad: 94030.562\n",
      "[Epoch 63, Batch 3/100] Loss: 0.0321 | RMSE: 0.0302 | Consistency: 0.0047 | SSIM: 0.0190 | Grad: 92507.414\n",
      "[Epoch 63, Batch 4/100] Loss: 0.0404 | RMSE: 0.0373 | Consistency: 0.0071 | SSIM: 0.0304 | Grad: 102170.289\n",
      "[Epoch 63, Batch 5/100] Loss: 0.0351 | RMSE: 0.0327 | Consistency: 0.0056 | SSIM: 0.0233 | Grad: 123666.117\n",
      "[Epoch 63, Batch 6/100] Loss: 0.0375 | RMSE: 0.0355 | Consistency: 0.0062 | SSIM: 0.0197 | Grad: 92219.305\n",
      "[Epoch 63, Batch 7/100] Loss: 0.0309 | RMSE: 0.0291 | Consistency: 0.0043 | SSIM: 0.0178 | Grad: 125886.438\n",
      "[Epoch 63, Batch 8/100] Loss: 0.0371 | RMSE: 0.0349 | Consistency: 0.0066 | SSIM: 0.0215 | Grad: 30725.695\n",
      "[Epoch 63, Batch 9/100] Loss: 0.0355 | RMSE: 0.0329 | Consistency: 0.0050 | SSIM: 0.0245 | Grad: 70437.641\n",
      "[Epoch 63, Batch 10/100] Loss: 0.0369 | RMSE: 0.0349 | Consistency: 0.0063 | SSIM: 0.0198 | Grad: 71202.594\n",
      "[Epoch 63, Batch 11/100] Loss: 0.0373 | RMSE: 0.0350 | Consistency: 0.0055 | SSIM: 0.0227 | Grad: 119306.180\n",
      "[Epoch 63, Batch 12/100] Loss: 0.0412 | RMSE: 0.0385 | Consistency: 0.0075 | SSIM: 0.0259 | Grad: 85816.664\n",
      "[Epoch 63, Batch 13/100] Loss: 0.0334 | RMSE: 0.0314 | Consistency: 0.0052 | SSIM: 0.0196 | Grad: 108060.938\n",
      "[Epoch 63, Batch 14/100] Loss: 0.0408 | RMSE: 0.0378 | Consistency: 0.0077 | SSIM: 0.0294 | Grad: 78748.430\n",
      "[Epoch 63, Batch 15/100] Loss: 0.0353 | RMSE: 0.0332 | Consistency: 0.0052 | SSIM: 0.0205 | Grad: 99446.023\n",
      "[Epoch 63, Batch 16/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0060 | SSIM: 0.0216 | Grad: 87255.750\n",
      "[Epoch 63, Batch 17/100] Loss: 0.0341 | RMSE: 0.0316 | Consistency: 0.0051 | SSIM: 0.0241 | Grad: 113433.734\n",
      "[Epoch 63, Batch 18/100] Loss: 0.0377 | RMSE: 0.0351 | Consistency: 0.0072 | SSIM: 0.0251 | Grad: 34297.594\n",
      "[Epoch 63, Batch 19/100] Loss: 0.0366 | RMSE: 0.0340 | Consistency: 0.0061 | SSIM: 0.0251 | Grad: 67303.547\n",
      "[Epoch 63, Batch 20/100] Loss: 0.0347 | RMSE: 0.0322 | Consistency: 0.0060 | SSIM: 0.0243 | Grad: 28282.977\n",
      "[Epoch 63, Batch 21/100] Loss: 0.0469 | RMSE: 0.0439 | Consistency: 0.0113 | SSIM: 0.0291 | Grad: 57698.395\n",
      "[Epoch 63, Batch 22/100] Loss: 0.0374 | RMSE: 0.0348 | Consistency: 0.0061 | SSIM: 0.0259 | Grad: 108171.164\n",
      "[Epoch 63, Batch 23/100] Loss: 0.0340 | RMSE: 0.0310 | Consistency: 0.0058 | SSIM: 0.0297 | Grad: 98485.711\n",
      "[Epoch 63, Batch 24/100] Loss: 0.0378 | RMSE: 0.0358 | Consistency: 0.0053 | SSIM: 0.0198 | Grad: 131309.812\n",
      "[Epoch 63, Batch 25/100] Loss: 0.0364 | RMSE: 0.0344 | Consistency: 0.0051 | SSIM: 0.0192 | Grad: 124099.648\n",
      "[Epoch 63, Batch 26/100] Loss: 0.0386 | RMSE: 0.0361 | Consistency: 0.0067 | SSIM: 0.0239 | Grad: 78430.062\n",
      "[Epoch 63, Batch 27/100] Loss: 0.0382 | RMSE: 0.0360 | Consistency: 0.0067 | SSIM: 0.0217 | Grad: 77978.422\n",
      "[Epoch 63, Batch 28/100] Loss: 0.0323 | RMSE: 0.0304 | Consistency: 0.0050 | SSIM: 0.0189 | Grad: 30641.869\n",
      "[Epoch 63, Batch 29/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0054 | SSIM: 0.0207 | Grad: 78480.336\n",
      "[Epoch 63, Batch 30/100] Loss: 0.0381 | RMSE: 0.0353 | Consistency: 0.0066 | SSIM: 0.0269 | Grad: 56018.531\n",
      "[Epoch 63, Batch 31/100] Loss: 0.0366 | RMSE: 0.0343 | Consistency: 0.0060 | SSIM: 0.0219 | Grad: 121634.133\n",
      "[Epoch 63, Batch 32/100] Loss: 0.0342 | RMSE: 0.0323 | Consistency: 0.0051 | SSIM: 0.0180 | Grad: 103685.562\n",
      "[Epoch 63, Batch 33/100] Loss: 0.0354 | RMSE: 0.0331 | Consistency: 0.0064 | SSIM: 0.0224 | Grad: 102069.000\n",
      "[Epoch 63, Batch 34/100] Loss: 0.0423 | RMSE: 0.0394 | Consistency: 0.0085 | SSIM: 0.0280 | Grad: 76182.742\n",
      "[Epoch 63, Batch 35/100] Loss: 0.0382 | RMSE: 0.0357 | Consistency: 0.0063 | SSIM: 0.0238 | Grad: 85641.656\n",
      "[Epoch 63, Batch 36/100] Loss: 0.0376 | RMSE: 0.0348 | Consistency: 0.0061 | SSIM: 0.0271 | Grad: 94816.531\n",
      "[Epoch 63, Batch 37/100] Loss: 0.0356 | RMSE: 0.0335 | Consistency: 0.0057 | SSIM: 0.0205 | Grad: 98636.430\n",
      "[Epoch 63, Batch 38/100] Loss: 0.0363 | RMSE: 0.0341 | Consistency: 0.0069 | SSIM: 0.0214 | Grad: 81529.922\n",
      "[Epoch 63, Batch 39/100] Loss: 0.0362 | RMSE: 0.0336 | Consistency: 0.0062 | SSIM: 0.0252 | Grad: 117654.586\n",
      "[Epoch 63, Batch 40/100] Loss: 0.0350 | RMSE: 0.0328 | Consistency: 0.0061 | SSIM: 0.0209 | Grad: 79089.508\n",
      "[Epoch 63, Batch 41/100] Loss: 0.0407 | RMSE: 0.0380 | Consistency: 0.0083 | SSIM: 0.0267 | Grad: 79036.172\n",
      "[Epoch 63, Batch 42/100] Loss: 0.0462 | RMSE: 0.0427 | Consistency: 0.0100 | SSIM: 0.0338 | Grad: 83292.406\n",
      "[Epoch 63, Batch 43/100] Loss: 0.0402 | RMSE: 0.0379 | Consistency: 0.0070 | SSIM: 0.0223 | Grad: 89633.781\n",
      "[Epoch 63, Batch 44/100] Loss: 0.0424 | RMSE: 0.0399 | Consistency: 0.0082 | SSIM: 0.0240 | Grad: 94524.195\n",
      "[Epoch 63, Batch 45/100] Loss: 0.0341 | RMSE: 0.0316 | Consistency: 0.0049 | SSIM: 0.0238 | Grad: 57368.367\n",
      "[Epoch 63, Batch 46/100] Loss: 0.0344 | RMSE: 0.0319 | Consistency: 0.0056 | SSIM: 0.0239 | Grad: 69583.328\n",
      "[Epoch 63, Batch 47/100] Loss: 0.0429 | RMSE: 0.0401 | Consistency: 0.0091 | SSIM: 0.0271 | Grad: 58441.316\n",
      "[Epoch 63, Batch 48/100] Loss: 0.0367 | RMSE: 0.0341 | Consistency: 0.0062 | SSIM: 0.0263 | Grad: 75261.805\n",
      "[Epoch 63, Batch 49/100] Loss: 0.0408 | RMSE: 0.0379 | Consistency: 0.0082 | SSIM: 0.0286 | Grad: 69825.305\n",
      "[Epoch 63, Batch 50/100] Loss: 0.0358 | RMSE: 0.0336 | Consistency: 0.0060 | SSIM: 0.0209 | Grad: 30184.113\n",
      "[Epoch 63, Batch 51/100] Loss: 0.0356 | RMSE: 0.0337 | Consistency: 0.0057 | SSIM: 0.0188 | Grad: 99538.172\n",
      "[Epoch 63, Batch 52/100] Loss: 0.0337 | RMSE: 0.0317 | Consistency: 0.0056 | SSIM: 0.0202 | Grad: 99517.023\n",
      "[Epoch 63, Batch 53/100] Loss: 0.0356 | RMSE: 0.0332 | Consistency: 0.0059 | SSIM: 0.0234 | Grad: 26469.910\n",
      "[Epoch 63, Batch 54/100] Loss: 0.0404 | RMSE: 0.0377 | Consistency: 0.0070 | SSIM: 0.0261 | Grad: 31903.346\n",
      "[Epoch 63, Batch 55/100] Loss: 0.0380 | RMSE: 0.0351 | Consistency: 0.0071 | SSIM: 0.0288 | Grad: 31824.035\n",
      "[Epoch 63, Batch 56/100] Loss: 0.0318 | RMSE: 0.0295 | Consistency: 0.0052 | SSIM: 0.0224 | Grad: 46791.684\n",
      "[Epoch 63, Batch 57/100] Loss: 0.0387 | RMSE: 0.0361 | Consistency: 0.0079 | SSIM: 0.0251 | Grad: 44232.309\n",
      "[Epoch 63, Batch 58/100] Loss: 0.0356 | RMSE: 0.0332 | Consistency: 0.0064 | SSIM: 0.0234 | Grad: 57943.656\n",
      "[Epoch 63, Batch 59/100] Loss: 0.0319 | RMSE: 0.0300 | Consistency: 0.0053 | SSIM: 0.0185 | Grad: 32161.963\n",
      "[Epoch 63, Batch 60/100] Loss: 0.0320 | RMSE: 0.0298 | Consistency: 0.0054 | SSIM: 0.0220 | Grad: 30670.342\n",
      "[Epoch 63, Batch 61/100] Loss: 0.0358 | RMSE: 0.0330 | Consistency: 0.0063 | SSIM: 0.0274 | Grad: 82771.391\n",
      "[Epoch 63, Batch 62/100] Loss: 0.0362 | RMSE: 0.0337 | Consistency: 0.0064 | SSIM: 0.0244 | Grad: 78450.703\n",
      "[Epoch 63, Batch 63/100] Loss: 0.0357 | RMSE: 0.0329 | Consistency: 0.0066 | SSIM: 0.0271 | Grad: 26984.129\n",
      "[Epoch 63, Batch 64/100] Loss: 0.0428 | RMSE: 0.0404 | Consistency: 0.0084 | SSIM: 0.0227 | Grad: 72172.445\n",
      "[Epoch 63, Batch 65/100] Loss: 0.0359 | RMSE: 0.0332 | Consistency: 0.0066 | SSIM: 0.0268 | Grad: 86469.000\n",
      "[Epoch 63, Batch 66/100] Loss: 0.0412 | RMSE: 0.0382 | Consistency: 0.0080 | SSIM: 0.0287 | Grad: 93563.078\n",
      "[Epoch 63, Batch 67/100] Loss: 0.0350 | RMSE: 0.0322 | Consistency: 0.0059 | SSIM: 0.0271 | Grad: 28280.477\n",
      "[Epoch 63, Batch 68/100] Loss: 0.0498 | RMSE: 0.0471 | Consistency: 0.0138 | SSIM: 0.0258 | Grad: 24370.359\n",
      "[Epoch 63, Batch 69/100] Loss: 0.0341 | RMSE: 0.0321 | Consistency: 0.0057 | SSIM: 0.0198 | Grad: 100852.562\n",
      "[Epoch 63, Batch 70/100] Loss: 0.0463 | RMSE: 0.0435 | Consistency: 0.0091 | SSIM: 0.0274 | Grad: 81735.352\n",
      "[Epoch 63, Batch 71/100] Loss: 0.0341 | RMSE: 0.0318 | Consistency: 0.0050 | SSIM: 0.0226 | Grad: 37929.984\n",
      "[Epoch 63, Batch 72/100] Loss: 0.0351 | RMSE: 0.0331 | Consistency: 0.0063 | SSIM: 0.0199 | Grad: 32529.945\n",
      "[Epoch 63, Batch 73/100] Loss: 0.0307 | RMSE: 0.0288 | Consistency: 0.0050 | SSIM: 0.0188 | Grad: 53698.969\n",
      "[Epoch 63, Batch 74/100] Loss: 0.0355 | RMSE: 0.0333 | Consistency: 0.0056 | SSIM: 0.0215 | Grad: 37409.395\n",
      "[Epoch 63, Batch 75/100] Loss: 0.0380 | RMSE: 0.0350 | Consistency: 0.0072 | SSIM: 0.0298 | Grad: 45578.738\n",
      "[Epoch 63, Batch 76/100] Loss: 0.0400 | RMSE: 0.0370 | Consistency: 0.0084 | SSIM: 0.0283 | Grad: 56846.094\n",
      "[Epoch 63, Batch 77/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0059 | SSIM: 0.0227 | Grad: 59636.992\n",
      "[Epoch 63, Batch 78/100] Loss: 0.0373 | RMSE: 0.0351 | Consistency: 0.0060 | SSIM: 0.0216 | Grad: 55305.109\n",
      "[Epoch 63, Batch 79/100] Loss: 0.0395 | RMSE: 0.0364 | Consistency: 0.0062 | SSIM: 0.0301 | Grad: 27905.133\n",
      "[Epoch 63, Batch 80/100] Loss: 0.0378 | RMSE: 0.0350 | Consistency: 0.0062 | SSIM: 0.0271 | Grad: 33282.129\n",
      "[Epoch 63, Batch 81/100] Loss: 0.0396 | RMSE: 0.0368 | Consistency: 0.0069 | SSIM: 0.0265 | Grad: 120374.133\n",
      "[Epoch 63, Batch 82/100] Loss: 0.0328 | RMSE: 0.0306 | Consistency: 0.0056 | SSIM: 0.0218 | Grad: 89752.852\n",
      "[Epoch 63, Batch 83/100] Loss: 0.0334 | RMSE: 0.0306 | Consistency: 0.0054 | SSIM: 0.0276 | Grad: 88764.398\n",
      "[Epoch 63, Batch 84/100] Loss: 0.0438 | RMSE: 0.0409 | Consistency: 0.0076 | SSIM: 0.0277 | Grad: 96610.305\n",
      "[Epoch 63, Batch 85/100] Loss: 0.0357 | RMSE: 0.0331 | Consistency: 0.0059 | SSIM: 0.0261 | Grad: 38236.809\n",
      "[Epoch 63, Batch 86/100] Loss: 0.0433 | RMSE: 0.0402 | Consistency: 0.0085 | SSIM: 0.0301 | Grad: 62219.777\n",
      "[Epoch 63, Batch 87/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0052 | SSIM: 0.0210 | Grad: 55228.773\n",
      "[Epoch 63, Batch 88/100] Loss: 0.0341 | RMSE: 0.0322 | Consistency: 0.0057 | SSIM: 0.0185 | Grad: 57292.238\n",
      "[Epoch 63, Batch 89/100] Loss: 0.0323 | RMSE: 0.0302 | Consistency: 0.0046 | SSIM: 0.0206 | Grad: 28213.119\n",
      "[Epoch 63, Batch 90/100] Loss: 0.0328 | RMSE: 0.0305 | Consistency: 0.0055 | SSIM: 0.0229 | Grad: 28559.318\n",
      "[Epoch 63, Batch 91/100] Loss: 0.0353 | RMSE: 0.0334 | Consistency: 0.0051 | SSIM: 0.0188 | Grad: 86060.773\n",
      "[Epoch 63, Batch 92/100] Loss: 0.0339 | RMSE: 0.0318 | Consistency: 0.0058 | SSIM: 0.0202 | Grad: 54696.582\n",
      "[Epoch 63, Batch 93/100] Loss: 0.0363 | RMSE: 0.0342 | Consistency: 0.0059 | SSIM: 0.0208 | Grad: 33038.180\n",
      "[Epoch 63, Batch 94/100] Loss: 0.0353 | RMSE: 0.0327 | Consistency: 0.0060 | SSIM: 0.0254 | Grad: 52936.301\n",
      "[Epoch 63, Batch 95/100] Loss: 0.0388 | RMSE: 0.0364 | Consistency: 0.0077 | SSIM: 0.0232 | Grad: 62227.191\n",
      "[Epoch 63, Batch 96/100] Loss: 0.0408 | RMSE: 0.0378 | Consistency: 0.0084 | SSIM: 0.0286 | Grad: 51207.309\n",
      "[Epoch 63, Batch 97/100] Loss: 0.0330 | RMSE: 0.0310 | Consistency: 0.0051 | SSIM: 0.0190 | Grad: 41296.406\n",
      "[Epoch 63, Batch 98/100] Loss: 0.0336 | RMSE: 0.0317 | Consistency: 0.0051 | SSIM: 0.0189 | Grad: 78171.977\n",
      "[Epoch 63, Batch 99/100] Loss: 0.0435 | RMSE: 0.0411 | Consistency: 0.0067 | SSIM: 0.0234 | Grad: 60378.152\n",
      "[Epoch 63, Batch 100/100] Loss: 0.0349 | RMSE: 0.0322 | Consistency: 0.0064 | SSIM: 0.0264 | Grad: 47843.660\n",
      "✅ Epoch 63 완료!\n",
      "   📈 평균 Loss: 0.037169\n",
      "   📊 평균 RMSE: 0.034716\n",
      "   ⚙️  학습률: 0.000131\n",
      "   🏆 NEW BEST! RMSE: 0.034716\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 64/80 시작...\n",
      "[Epoch 64, Batch 1/100] Loss: 0.0369 | RMSE: 0.0344 | Consistency: 0.0067 | SSIM: 0.0237 | Grad: 44237.883\n",
      "[Epoch 64, Batch 2/100] Loss: 0.0306 | RMSE: 0.0286 | Consistency: 0.0049 | SSIM: 0.0191 | Grad: 84904.859\n",
      "[Epoch 64, Batch 3/100] Loss: 0.0334 | RMSE: 0.0310 | Consistency: 0.0057 | SSIM: 0.0232 | Grad: 63333.492\n",
      "[Epoch 64, Batch 4/100] Loss: 0.0382 | RMSE: 0.0357 | Consistency: 0.0057 | SSIM: 0.0248 | Grad: 65158.164\n",
      "[Epoch 64, Batch 5/100] Loss: 0.0351 | RMSE: 0.0329 | Consistency: 0.0058 | SSIM: 0.0206 | Grad: 75096.586\n",
      "[Epoch 64, Batch 6/100] Loss: 0.0332 | RMSE: 0.0311 | Consistency: 0.0049 | SSIM: 0.0206 | Grad: 46697.934\n",
      "[Epoch 64, Batch 7/100] Loss: 0.0333 | RMSE: 0.0309 | Consistency: 0.0059 | SSIM: 0.0235 | Grad: 45132.516\n",
      "[Epoch 64, Batch 8/100] Loss: 0.0396 | RMSE: 0.0374 | Consistency: 0.0063 | SSIM: 0.0218 | Grad: 45941.008\n",
      "[Epoch 64, Batch 9/100] Loss: 0.0355 | RMSE: 0.0330 | Consistency: 0.0065 | SSIM: 0.0247 | Grad: 65005.680\n",
      "[Epoch 64, Batch 10/100] Loss: 0.0375 | RMSE: 0.0350 | Consistency: 0.0066 | SSIM: 0.0248 | Grad: 56491.672\n",
      "[Epoch 64, Batch 11/100] Loss: 0.0318 | RMSE: 0.0298 | Consistency: 0.0045 | SSIM: 0.0201 | Grad: 71718.422\n",
      "[Epoch 64, Batch 12/100] Loss: 0.0349 | RMSE: 0.0326 | Consistency: 0.0052 | SSIM: 0.0216 | Grad: 30673.008\n",
      "[Epoch 64, Batch 13/100] Loss: 0.0383 | RMSE: 0.0355 | Consistency: 0.0062 | SSIM: 0.0273 | Grad: 69032.641\n",
      "[Epoch 64, Batch 14/100] Loss: 0.0353 | RMSE: 0.0332 | Consistency: 0.0054 | SSIM: 0.0208 | Grad: 39296.262\n",
      "[Epoch 64, Batch 15/100] Loss: 0.0353 | RMSE: 0.0328 | Consistency: 0.0061 | SSIM: 0.0243 | Grad: 55602.703\n",
      "[Epoch 64, Batch 16/100] Loss: 0.0420 | RMSE: 0.0393 | Consistency: 0.0084 | SSIM: 0.0258 | Grad: 83953.906\n",
      "[Epoch 64, Batch 17/100] Loss: 0.0396 | RMSE: 0.0373 | Consistency: 0.0074 | SSIM: 0.0224 | Grad: 77849.406\n",
      "[Epoch 64, Batch 18/100] Loss: 0.0356 | RMSE: 0.0335 | Consistency: 0.0058 | SSIM: 0.0207 | Grad: 87408.836\n",
      "[Epoch 64, Batch 19/100] Loss: 0.0417 | RMSE: 0.0389 | Consistency: 0.0092 | SSIM: 0.0268 | Grad: 79480.734\n",
      "[Epoch 64, Batch 20/100] Loss: 0.0402 | RMSE: 0.0377 | Consistency: 0.0086 | SSIM: 0.0234 | Grad: 74892.281\n",
      "[Epoch 64, Batch 21/100] Loss: 0.0385 | RMSE: 0.0361 | Consistency: 0.0075 | SSIM: 0.0228 | Grad: 20421.791\n",
      "[Epoch 64, Batch 22/100] Loss: 0.0352 | RMSE: 0.0333 | Consistency: 0.0056 | SSIM: 0.0184 | Grad: 63210.902\n",
      "[Epoch 64, Batch 23/100] Loss: 0.0437 | RMSE: 0.0409 | Consistency: 0.0086 | SSIM: 0.0272 | Grad: 61953.465\n",
      "[Epoch 64, Batch 24/100] Loss: 0.0429 | RMSE: 0.0406 | Consistency: 0.0067 | SSIM: 0.0227 | Grad: 102683.367\n",
      "[Epoch 64, Batch 25/100] Loss: 0.0507 | RMSE: 0.0475 | Consistency: 0.0104 | SSIM: 0.0310 | Grad: 21027.100\n",
      "[Epoch 64, Batch 26/100] Loss: 0.0367 | RMSE: 0.0346 | Consistency: 0.0067 | SSIM: 0.0202 | Grad: 85061.125\n",
      "[Epoch 64, Batch 27/100] Loss: 0.0356 | RMSE: 0.0333 | Consistency: 0.0061 | SSIM: 0.0227 | Grad: 14248.583\n",
      "[Epoch 64, Batch 28/100] Loss: 0.0343 | RMSE: 0.0324 | Consistency: 0.0060 | SSIM: 0.0183 | Grad: 25745.057\n",
      "[Epoch 64, Batch 29/100] Loss: 0.0369 | RMSE: 0.0345 | Consistency: 0.0067 | SSIM: 0.0234 | Grad: 44137.051\n",
      "[Epoch 64, Batch 30/100] Loss: 0.0317 | RMSE: 0.0297 | Consistency: 0.0053 | SSIM: 0.0198 | Grad: 49898.602\n",
      "[Epoch 64, Batch 31/100] Loss: 0.0452 | RMSE: 0.0421 | Consistency: 0.0101 | SSIM: 0.0300 | Grad: 64084.879\n",
      "[Epoch 64, Batch 32/100] Loss: 0.0375 | RMSE: 0.0347 | Consistency: 0.0060 | SSIM: 0.0272 | Grad: 82903.828\n",
      "[Epoch 64, Batch 33/100] Loss: 0.0374 | RMSE: 0.0350 | Consistency: 0.0067 | SSIM: 0.0230 | Grad: 43605.363\n",
      "[Epoch 64, Batch 34/100] Loss: 0.0319 | RMSE: 0.0298 | Consistency: 0.0043 | SSIM: 0.0212 | Grad: 50600.812\n",
      "[Epoch 64, Batch 35/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0054 | SSIM: 0.0233 | Grad: 46852.383\n",
      "[Epoch 64, Batch 36/100] Loss: 0.0382 | RMSE: 0.0362 | Consistency: 0.0066 | SSIM: 0.0197 | Grad: 65661.398\n",
      "[Epoch 64, Batch 37/100] Loss: 0.0329 | RMSE: 0.0304 | Consistency: 0.0047 | SSIM: 0.0246 | Grad: 77644.391\n",
      "[Epoch 64, Batch 38/100] Loss: 0.0359 | RMSE: 0.0335 | Consistency: 0.0057 | SSIM: 0.0228 | Grad: 71105.016\n",
      "[Epoch 64, Batch 39/100] Loss: 0.0375 | RMSE: 0.0350 | Consistency: 0.0068 | SSIM: 0.0239 | Grad: 53624.203\n",
      "[Epoch 64, Batch 40/100] Loss: 0.0406 | RMSE: 0.0375 | Consistency: 0.0081 | SSIM: 0.0304 | Grad: 16406.465\n",
      "[Epoch 64, Batch 41/100] Loss: 0.0342 | RMSE: 0.0323 | Consistency: 0.0062 | SSIM: 0.0180 | Grad: 62628.656\n",
      "[Epoch 64, Batch 42/100] Loss: 0.0323 | RMSE: 0.0305 | Consistency: 0.0052 | SSIM: 0.0181 | Grad: 67490.680\n",
      "[Epoch 64, Batch 43/100] Loss: 0.0428 | RMSE: 0.0395 | Consistency: 0.0081 | SSIM: 0.0319 | Grad: 51837.941\n",
      "[Epoch 64, Batch 44/100] Loss: 0.0362 | RMSE: 0.0335 | Consistency: 0.0051 | SSIM: 0.0264 | Grad: 74193.398\n",
      "[Epoch 64, Batch 45/100] Loss: 0.0386 | RMSE: 0.0357 | Consistency: 0.0068 | SSIM: 0.0284 | Grad: 59904.668\n",
      "[Epoch 64, Batch 46/100] Loss: 0.0412 | RMSE: 0.0388 | Consistency: 0.0086 | SSIM: 0.0230 | Grad: 77184.414\n",
      "[Epoch 64, Batch 47/100] Loss: 0.0366 | RMSE: 0.0336 | Consistency: 0.0065 | SSIM: 0.0297 | Grad: 31890.508\n",
      "[Epoch 64, Batch 48/100] Loss: 0.0345 | RMSE: 0.0323 | Consistency: 0.0061 | SSIM: 0.0218 | Grad: 35500.059\n",
      "[Epoch 64, Batch 49/100] Loss: 0.0394 | RMSE: 0.0367 | Consistency: 0.0083 | SSIM: 0.0254 | Grad: 53538.566\n",
      "[Epoch 64, Batch 50/100] Loss: 0.0382 | RMSE: 0.0354 | Consistency: 0.0064 | SSIM: 0.0276 | Grad: 57031.926\n",
      "[Epoch 64, Batch 51/100] Loss: 0.0334 | RMSE: 0.0314 | Consistency: 0.0047 | SSIM: 0.0191 | Grad: 35663.555\n",
      "[Epoch 64, Batch 52/100] Loss: 0.0350 | RMSE: 0.0328 | Consistency: 0.0056 | SSIM: 0.0210 | Grad: 60456.871\n",
      "[Epoch 64, Batch 53/100] Loss: 0.0350 | RMSE: 0.0328 | Consistency: 0.0061 | SSIM: 0.0221 | Grad: 37340.691\n",
      "[Epoch 64, Batch 54/100] Loss: 0.0405 | RMSE: 0.0378 | Consistency: 0.0074 | SSIM: 0.0262 | Grad: 41105.699\n",
      "[Epoch 64, Batch 55/100] Loss: 0.0408 | RMSE: 0.0373 | Consistency: 0.0092 | SSIM: 0.0337 | Grad: 25467.732\n",
      "[Epoch 64, Batch 56/100] Loss: 0.0276 | RMSE: 0.0260 | Consistency: 0.0032 | SSIM: 0.0153 | Grad: 56315.207\n",
      "[Epoch 64, Batch 57/100] Loss: 0.0416 | RMSE: 0.0384 | Consistency: 0.0076 | SSIM: 0.0309 | Grad: 47970.379\n",
      "[Epoch 64, Batch 58/100] Loss: 0.0346 | RMSE: 0.0320 | Consistency: 0.0056 | SSIM: 0.0259 | Grad: 16963.422\n",
      "[Epoch 64, Batch 59/100] Loss: 0.0338 | RMSE: 0.0317 | Consistency: 0.0053 | SSIM: 0.0197 | Grad: 32437.457\n",
      "[Epoch 64, Batch 60/100] Loss: 0.0428 | RMSE: 0.0403 | Consistency: 0.0081 | SSIM: 0.0236 | Grad: 44679.820\n",
      "[Epoch 64, Batch 61/100] Loss: 0.0384 | RMSE: 0.0352 | Consistency: 0.0064 | SSIM: 0.0308 | Grad: 76785.086\n",
      "[Epoch 64, Batch 62/100] Loss: 0.0334 | RMSE: 0.0313 | Consistency: 0.0063 | SSIM: 0.0202 | Grad: 101583.578\n",
      "[Epoch 64, Batch 63/100] Loss: 0.0362 | RMSE: 0.0337 | Consistency: 0.0065 | SSIM: 0.0250 | Grad: 100349.508\n",
      "[Epoch 64, Batch 64/100] Loss: 0.0405 | RMSE: 0.0380 | Consistency: 0.0077 | SSIM: 0.0251 | Grad: 78428.148\n",
      "[Epoch 64, Batch 65/100] Loss: 0.0314 | RMSE: 0.0297 | Consistency: 0.0051 | SSIM: 0.0159 | Grad: 72368.742\n",
      "[Epoch 64, Batch 66/100] Loss: 0.0381 | RMSE: 0.0354 | Consistency: 0.0065 | SSIM: 0.0257 | Grad: 77260.688\n",
      "[Epoch 64, Batch 67/100] Loss: 0.0365 | RMSE: 0.0339 | Consistency: 0.0067 | SSIM: 0.0250 | Grad: 113055.320\n",
      "[Epoch 64, Batch 68/100] Loss: 0.0336 | RMSE: 0.0314 | Consistency: 0.0061 | SSIM: 0.0212 | Grad: 23903.639\n",
      "[Epoch 64, Batch 69/100] Loss: 0.0388 | RMSE: 0.0363 | Consistency: 0.0075 | SSIM: 0.0238 | Grad: 38698.727\n",
      "[Epoch 64, Batch 70/100] Loss: 0.0353 | RMSE: 0.0333 | Consistency: 0.0065 | SSIM: 0.0189 | Grad: 51157.504\n",
      "[Epoch 64, Batch 71/100] Loss: 0.0373 | RMSE: 0.0351 | Consistency: 0.0062 | SSIM: 0.0209 | Grad: 27103.230\n",
      "[Epoch 64, Batch 72/100] Loss: 0.0376 | RMSE: 0.0346 | Consistency: 0.0069 | SSIM: 0.0288 | Grad: 89955.125\n",
      "[Epoch 64, Batch 73/100] Loss: 0.0402 | RMSE: 0.0374 | Consistency: 0.0076 | SSIM: 0.0265 | Grad: 83294.156\n",
      "[Epoch 64, Batch 74/100] Loss: 0.0352 | RMSE: 0.0328 | Consistency: 0.0052 | SSIM: 0.0235 | Grad: 49141.293\n",
      "[Epoch 64, Batch 75/100] Loss: 0.0418 | RMSE: 0.0392 | Consistency: 0.0097 | SSIM: 0.0244 | Grad: 133089.234\n",
      "[Epoch 64, Batch 76/100] Loss: 0.0320 | RMSE: 0.0297 | Consistency: 0.0051 | SSIM: 0.0231 | Grad: 100384.875\n",
      "[Epoch 64, Batch 77/100] Loss: 0.0373 | RMSE: 0.0350 | Consistency: 0.0074 | SSIM: 0.0229 | Grad: 96545.344\n",
      "[Epoch 64, Batch 78/100] Loss: 0.0354 | RMSE: 0.0323 | Consistency: 0.0058 | SSIM: 0.0295 | Grad: 66661.727\n",
      "[Epoch 64, Batch 79/100] Loss: 0.0370 | RMSE: 0.0343 | Consistency: 0.0065 | SSIM: 0.0256 | Grad: 25443.461\n",
      "[Epoch 64, Batch 80/100] Loss: 0.0335 | RMSE: 0.0311 | Consistency: 0.0052 | SSIM: 0.0233 | Grad: 53657.723\n",
      "[Epoch 64, Batch 81/100] Loss: 0.0373 | RMSE: 0.0350 | Consistency: 0.0074 | SSIM: 0.0228 | Grad: 58605.508\n",
      "[Epoch 64, Batch 82/100] Loss: 0.0416 | RMSE: 0.0382 | Consistency: 0.0096 | SSIM: 0.0331 | Grad: 85984.031\n",
      "[Epoch 64, Batch 83/100] Loss: 0.0400 | RMSE: 0.0372 | Consistency: 0.0080 | SSIM: 0.0274 | Grad: 106645.648\n",
      "[Epoch 64, Batch 84/100] Loss: 0.0368 | RMSE: 0.0336 | Consistency: 0.0068 | SSIM: 0.0310 | Grad: 51911.660\n",
      "[Epoch 64, Batch 85/100] Loss: 0.0431 | RMSE: 0.0401 | Consistency: 0.0096 | SSIM: 0.0283 | Grad: 86229.055\n",
      "[Epoch 64, Batch 86/100] Loss: 0.0376 | RMSE: 0.0352 | Consistency: 0.0077 | SSIM: 0.0229 | Grad: 83576.609\n",
      "[Epoch 64, Batch 87/100] Loss: 0.0405 | RMSE: 0.0373 | Consistency: 0.0067 | SSIM: 0.0314 | Grad: 89429.461\n",
      "[Epoch 64, Batch 88/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0076 | SSIM: 0.0229 | Grad: 85666.914\n",
      "[Epoch 64, Batch 89/100] Loss: 0.0363 | RMSE: 0.0341 | Consistency: 0.0068 | SSIM: 0.0215 | Grad: 63479.832\n",
      "[Epoch 64, Batch 90/100] Loss: 0.0344 | RMSE: 0.0324 | Consistency: 0.0062 | SSIM: 0.0200 | Grad: 70888.625\n",
      "[Epoch 64, Batch 91/100] Loss: 0.0394 | RMSE: 0.0370 | Consistency: 0.0077 | SSIM: 0.0230 | Grad: 28419.609\n",
      "[Epoch 64, Batch 92/100] Loss: 0.0442 | RMSE: 0.0410 | Consistency: 0.0091 | SSIM: 0.0312 | Grad: 104081.688\n",
      "[Epoch 64, Batch 93/100] Loss: 0.0364 | RMSE: 0.0339 | Consistency: 0.0068 | SSIM: 0.0240 | Grad: 59460.039\n",
      "[Epoch 64, Batch 94/100] Loss: 0.0310 | RMSE: 0.0294 | Consistency: 0.0043 | SSIM: 0.0157 | Grad: 106262.922\n",
      "[Epoch 64, Batch 95/100] Loss: 0.0317 | RMSE: 0.0299 | Consistency: 0.0045 | SSIM: 0.0178 | Grad: 130383.867\n",
      "[Epoch 64, Batch 96/100] Loss: 0.0358 | RMSE: 0.0333 | Consistency: 0.0059 | SSIM: 0.0244 | Grad: 118056.805\n",
      "[Epoch 64, Batch 97/100] Loss: 0.0358 | RMSE: 0.0332 | Consistency: 0.0060 | SSIM: 0.0252 | Grad: 80909.781\n",
      "[Epoch 64, Batch 98/100] Loss: 0.0390 | RMSE: 0.0366 | Consistency: 0.0074 | SSIM: 0.0232 | Grad: 56521.059\n",
      "[Epoch 64, Batch 99/100] Loss: 0.0348 | RMSE: 0.0320 | Consistency: 0.0057 | SSIM: 0.0276 | Grad: 42497.461\n",
      "[Epoch 64, Batch 100/100] Loss: 0.0372 | RMSE: 0.0348 | Consistency: 0.0075 | SSIM: 0.0237 | Grad: 28854.902\n",
      "✅ Epoch 64 완료!\n",
      "   📈 평균 Loss: 0.037062\n",
      "   📊 평균 RMSE: 0.034598\n",
      "   ⚙️  학습률: 0.000117\n",
      "   🏆 NEW BEST! RMSE: 0.034598\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 65/80 시작...\n",
      "[Epoch 65, Batch 1/100] Loss: 0.0369 | RMSE: 0.0347 | Consistency: 0.0069 | SSIM: 0.0211 | Grad: 63578.691\n",
      "[Epoch 65, Batch 2/100] Loss: 0.0373 | RMSE: 0.0347 | Consistency: 0.0066 | SSIM: 0.0256 | Grad: 74848.320\n",
      "[Epoch 65, Batch 3/100] Loss: 0.0320 | RMSE: 0.0299 | Consistency: 0.0049 | SSIM: 0.0199 | Grad: 35170.707\n",
      "[Epoch 65, Batch 4/100] Loss: 0.0342 | RMSE: 0.0319 | Consistency: 0.0055 | SSIM: 0.0226 | Grad: 57067.250\n",
      "[Epoch 65, Batch 5/100] Loss: 0.0361 | RMSE: 0.0337 | Consistency: 0.0055 | SSIM: 0.0232 | Grad: 42432.516\n",
      "[Epoch 65, Batch 6/100] Loss: 0.0308 | RMSE: 0.0289 | Consistency: 0.0042 | SSIM: 0.0190 | Grad: 65325.621\n",
      "[Epoch 65, Batch 7/100] Loss: 0.0360 | RMSE: 0.0337 | Consistency: 0.0057 | SSIM: 0.0228 | Grad: 31517.688\n",
      "[Epoch 65, Batch 8/100] Loss: 0.0384 | RMSE: 0.0359 | Consistency: 0.0061 | SSIM: 0.0244 | Grad: 83997.094\n",
      "[Epoch 65, Batch 9/100] Loss: 0.0379 | RMSE: 0.0356 | Consistency: 0.0057 | SSIM: 0.0225 | Grad: 46017.895\n",
      "[Epoch 65, Batch 10/100] Loss: 0.0359 | RMSE: 0.0330 | Consistency: 0.0061 | SSIM: 0.0281 | Grad: 70093.969\n",
      "[Epoch 65, Batch 11/100] Loss: 0.0300 | RMSE: 0.0281 | Consistency: 0.0040 | SSIM: 0.0192 | Grad: 67634.883\n",
      "[Epoch 65, Batch 12/100] Loss: 0.0334 | RMSE: 0.0314 | Consistency: 0.0050 | SSIM: 0.0201 | Grad: 55050.105\n",
      "[Epoch 65, Batch 13/100] Loss: 0.0317 | RMSE: 0.0297 | Consistency: 0.0050 | SSIM: 0.0202 | Grad: 52490.527\n",
      "[Epoch 65, Batch 14/100] Loss: 0.0426 | RMSE: 0.0395 | Consistency: 0.0088 | SSIM: 0.0302 | Grad: 69325.758\n",
      "[Epoch 65, Batch 15/100] Loss: 0.0335 | RMSE: 0.0314 | Consistency: 0.0048 | SSIM: 0.0198 | Grad: 60256.641\n",
      "[Epoch 65, Batch 16/100] Loss: 0.0426 | RMSE: 0.0398 | Consistency: 0.0078 | SSIM: 0.0268 | Grad: 48244.867\n",
      "[Epoch 65, Batch 17/100] Loss: 0.0446 | RMSE: 0.0414 | Consistency: 0.0089 | SSIM: 0.0316 | Grad: 75932.477\n",
      "[Epoch 65, Batch 18/100] Loss: 0.0367 | RMSE: 0.0342 | Consistency: 0.0064 | SSIM: 0.0243 | Grad: 36132.957\n",
      "[Epoch 65, Batch 19/100] Loss: 0.0293 | RMSE: 0.0278 | Consistency: 0.0043 | SSIM: 0.0142 | Grad: 56564.062\n",
      "[Epoch 65, Batch 20/100] Loss: 0.0357 | RMSE: 0.0324 | Consistency: 0.0061 | SSIM: 0.0322 | Grad: 90806.242\n",
      "[Epoch 65, Batch 21/100] Loss: 0.0367 | RMSE: 0.0343 | Consistency: 0.0065 | SSIM: 0.0238 | Grad: 47993.223\n",
      "[Epoch 65, Batch 22/100] Loss: 0.0434 | RMSE: 0.0399 | Consistency: 0.0098 | SSIM: 0.0335 | Grad: 97049.156\n",
      "[Epoch 65, Batch 23/100] Loss: 0.0349 | RMSE: 0.0327 | Consistency: 0.0055 | SSIM: 0.0212 | Grad: 100329.797\n",
      "[Epoch 65, Batch 24/100] Loss: 0.0374 | RMSE: 0.0351 | Consistency: 0.0063 | SSIM: 0.0224 | Grad: 106453.688\n",
      "[Epoch 65, Batch 25/100] Loss: 0.0498 | RMSE: 0.0473 | Consistency: 0.0133 | SSIM: 0.0232 | Grad: 115649.188\n",
      "[Epoch 65, Batch 26/100] Loss: 0.0338 | RMSE: 0.0314 | Consistency: 0.0056 | SSIM: 0.0233 | Grad: 56378.000\n",
      "[Epoch 65, Batch 27/100] Loss: 0.0411 | RMSE: 0.0386 | Consistency: 0.0071 | SSIM: 0.0244 | Grad: 56453.070\n",
      "[Epoch 65, Batch 28/100] Loss: 0.0316 | RMSE: 0.0297 | Consistency: 0.0048 | SSIM: 0.0186 | Grad: 45526.246\n",
      "[Epoch 65, Batch 29/100] Loss: 0.0359 | RMSE: 0.0337 | Consistency: 0.0061 | SSIM: 0.0220 | Grad: 85839.742\n",
      "[Epoch 65, Batch 30/100] Loss: 0.0346 | RMSE: 0.0325 | Consistency: 0.0056 | SSIM: 0.0212 | Grad: 51508.141\n",
      "[Epoch 65, Batch 31/100] Loss: 0.0404 | RMSE: 0.0376 | Consistency: 0.0081 | SSIM: 0.0264 | Grad: 87475.633\n",
      "[Epoch 65, Batch 32/100] Loss: 0.0416 | RMSE: 0.0392 | Consistency: 0.0073 | SSIM: 0.0237 | Grad: 52627.438\n",
      "[Epoch 65, Batch 33/100] Loss: 0.0399 | RMSE: 0.0375 | Consistency: 0.0074 | SSIM: 0.0239 | Grad: 114843.078\n",
      "[Epoch 65, Batch 34/100] Loss: 0.0353 | RMSE: 0.0335 | Consistency: 0.0058 | SSIM: 0.0178 | Grad: 91141.602\n",
      "[Epoch 65, Batch 35/100] Loss: 0.0383 | RMSE: 0.0361 | Consistency: 0.0071 | SSIM: 0.0217 | Grad: 63457.258\n",
      "[Epoch 65, Batch 36/100] Loss: 0.0385 | RMSE: 0.0357 | Consistency: 0.0063 | SSIM: 0.0273 | Grad: 83722.430\n",
      "[Epoch 65, Batch 37/100] Loss: 0.0355 | RMSE: 0.0333 | Consistency: 0.0063 | SSIM: 0.0210 | Grad: 78781.023\n",
      "[Epoch 65, Batch 38/100] Loss: 0.0430 | RMSE: 0.0403 | Consistency: 0.0074 | SSIM: 0.0262 | Grad: 85979.078\n",
      "[Epoch 65, Batch 39/100] Loss: 0.0319 | RMSE: 0.0300 | Consistency: 0.0046 | SSIM: 0.0187 | Grad: 56128.984\n",
      "[Epoch 65, Batch 40/100] Loss: 0.0294 | RMSE: 0.0272 | Consistency: 0.0041 | SSIM: 0.0212 | Grad: 67496.352\n",
      "[Epoch 65, Batch 41/100] Loss: 0.0319 | RMSE: 0.0298 | Consistency: 0.0049 | SSIM: 0.0208 | Grad: 70030.961\n",
      "[Epoch 65, Batch 42/100] Loss: 0.0391 | RMSE: 0.0367 | Consistency: 0.0082 | SSIM: 0.0232 | Grad: 71507.289\n",
      "[Epoch 65, Batch 43/100] Loss: 0.0434 | RMSE: 0.0403 | Consistency: 0.0098 | SSIM: 0.0304 | Grad: 103973.078\n",
      "[Epoch 65, Batch 44/100] Loss: 0.0351 | RMSE: 0.0329 | Consistency: 0.0060 | SSIM: 0.0221 | Grad: 42759.426\n",
      "[Epoch 65, Batch 45/100] Loss: 0.0373 | RMSE: 0.0351 | Consistency: 0.0063 | SSIM: 0.0214 | Grad: 104611.125\n",
      "[Epoch 65, Batch 46/100] Loss: 0.0375 | RMSE: 0.0351 | Consistency: 0.0062 | SSIM: 0.0235 | Grad: 112579.289\n",
      "[Epoch 65, Batch 47/100] Loss: 0.0347 | RMSE: 0.0325 | Consistency: 0.0049 | SSIM: 0.0216 | Grad: 91380.367\n",
      "[Epoch 65, Batch 48/100] Loss: 0.0406 | RMSE: 0.0379 | Consistency: 0.0064 | SSIM: 0.0261 | Grad: 73249.516\n",
      "[Epoch 65, Batch 49/100] Loss: 0.0350 | RMSE: 0.0325 | Consistency: 0.0059 | SSIM: 0.0248 | Grad: 22640.646\n",
      "[Epoch 65, Batch 50/100] Loss: 0.0356 | RMSE: 0.0332 | Consistency: 0.0057 | SSIM: 0.0229 | Grad: 29850.777\n",
      "[Epoch 65, Batch 51/100] Loss: 0.0328 | RMSE: 0.0309 | Consistency: 0.0049 | SSIM: 0.0186 | Grad: 45595.512\n",
      "[Epoch 65, Batch 52/100] Loss: 0.0360 | RMSE: 0.0336 | Consistency: 0.0065 | SSIM: 0.0233 | Grad: 79555.664\n",
      "[Epoch 65, Batch 53/100] Loss: 0.0373 | RMSE: 0.0338 | Consistency: 0.0076 | SSIM: 0.0342 | Grad: 85431.039\n",
      "[Epoch 65, Batch 54/100] Loss: 0.0338 | RMSE: 0.0314 | Consistency: 0.0055 | SSIM: 0.0235 | Grad: 108702.023\n",
      "[Epoch 65, Batch 55/100] Loss: 0.0322 | RMSE: 0.0300 | Consistency: 0.0050 | SSIM: 0.0222 | Grad: 90591.898\n",
      "[Epoch 65, Batch 56/100] Loss: 0.0338 | RMSE: 0.0315 | Consistency: 0.0057 | SSIM: 0.0229 | Grad: 61916.980\n",
      "[Epoch 65, Batch 57/100] Loss: 0.0379 | RMSE: 0.0358 | Consistency: 0.0067 | SSIM: 0.0210 | Grad: 76905.570\n",
      "[Epoch 65, Batch 58/100] Loss: 0.0324 | RMSE: 0.0307 | Consistency: 0.0048 | SSIM: 0.0164 | Grad: 48894.051\n",
      "[Epoch 65, Batch 59/100] Loss: 0.0405 | RMSE: 0.0377 | Consistency: 0.0081 | SSIM: 0.0272 | Grad: 18866.057\n",
      "[Epoch 65, Batch 60/100] Loss: 0.0396 | RMSE: 0.0374 | Consistency: 0.0069 | SSIM: 0.0213 | Grad: 23335.791\n",
      "[Epoch 65, Batch 61/100] Loss: 0.0330 | RMSE: 0.0309 | Consistency: 0.0053 | SSIM: 0.0207 | Grad: 42788.289\n",
      "[Epoch 65, Batch 62/100] Loss: 0.0320 | RMSE: 0.0301 | Consistency: 0.0052 | SSIM: 0.0187 | Grad: 53960.164\n",
      "[Epoch 65, Batch 63/100] Loss: 0.0317 | RMSE: 0.0295 | Consistency: 0.0045 | SSIM: 0.0218 | Grad: 46680.820\n",
      "[Epoch 65, Batch 64/100] Loss: 0.0364 | RMSE: 0.0341 | Consistency: 0.0060 | SSIM: 0.0225 | Grad: 46529.113\n",
      "[Epoch 65, Batch 65/100] Loss: 0.0499 | RMSE: 0.0469 | Consistency: 0.0142 | SSIM: 0.0285 | Grad: 77150.867\n",
      "[Epoch 65, Batch 66/100] Loss: 0.0328 | RMSE: 0.0309 | Consistency: 0.0050 | SSIM: 0.0187 | Grad: 70793.477\n",
      "[Epoch 65, Batch 67/100] Loss: 0.0311 | RMSE: 0.0289 | Consistency: 0.0049 | SSIM: 0.0212 | Grad: 30981.465\n",
      "[Epoch 65, Batch 68/100] Loss: 0.0310 | RMSE: 0.0289 | Consistency: 0.0048 | SSIM: 0.0204 | Grad: 36295.328\n",
      "[Epoch 65, Batch 69/100] Loss: 0.0372 | RMSE: 0.0349 | Consistency: 0.0067 | SSIM: 0.0219 | Grad: 42219.148\n",
      "[Epoch 65, Batch 70/100] Loss: 0.0350 | RMSE: 0.0330 | Consistency: 0.0060 | SSIM: 0.0199 | Grad: 70580.008\n",
      "[Epoch 65, Batch 71/100] Loss: 0.0339 | RMSE: 0.0315 | Consistency: 0.0048 | SSIM: 0.0233 | Grad: 37187.805\n",
      "[Epoch 65, Batch 72/100] Loss: 0.0331 | RMSE: 0.0309 | Consistency: 0.0048 | SSIM: 0.0218 | Grad: 23995.365\n",
      "[Epoch 65, Batch 73/100] Loss: 0.0340 | RMSE: 0.0321 | Consistency: 0.0051 | SSIM: 0.0185 | Grad: 114292.648\n",
      "[Epoch 65, Batch 74/100] Loss: 0.0364 | RMSE: 0.0340 | Consistency: 0.0061 | SSIM: 0.0234 | Grad: 72868.836\n",
      "[Epoch 65, Batch 75/100] Loss: 0.0411 | RMSE: 0.0387 | Consistency: 0.0072 | SSIM: 0.0238 | Grad: 48968.926\n",
      "[Epoch 65, Batch 76/100] Loss: 0.0347 | RMSE: 0.0322 | Consistency: 0.0068 | SSIM: 0.0244 | Grad: 72053.414\n",
      "[Epoch 65, Batch 77/100] Loss: 0.0399 | RMSE: 0.0371 | Consistency: 0.0073 | SSIM: 0.0277 | Grad: 46558.926\n",
      "[Epoch 65, Batch 78/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0071 | SSIM: 0.0224 | Grad: 112886.320\n",
      "[Epoch 65, Batch 79/100] Loss: 0.0326 | RMSE: 0.0309 | Consistency: 0.0056 | SSIM: 0.0166 | Grad: 19110.551\n",
      "[Epoch 65, Batch 80/100] Loss: 0.0409 | RMSE: 0.0385 | Consistency: 0.0073 | SSIM: 0.0231 | Grad: 62604.922\n",
      "[Epoch 65, Batch 81/100] Loss: 0.0322 | RMSE: 0.0300 | Consistency: 0.0050 | SSIM: 0.0214 | Grad: 80182.586\n",
      "[Epoch 65, Batch 82/100] Loss: 0.0319 | RMSE: 0.0300 | Consistency: 0.0057 | SSIM: 0.0179 | Grad: 44058.441\n",
      "[Epoch 65, Batch 83/100] Loss: 0.0329 | RMSE: 0.0309 | Consistency: 0.0054 | SSIM: 0.0188 | Grad: 74974.336\n",
      "[Epoch 65, Batch 84/100] Loss: 0.0428 | RMSE: 0.0396 | Consistency: 0.0091 | SSIM: 0.0308 | Grad: 20693.283\n",
      "[Epoch 65, Batch 85/100] Loss: 0.0342 | RMSE: 0.0319 | Consistency: 0.0052 | SSIM: 0.0232 | Grad: 50068.820\n",
      "[Epoch 65, Batch 86/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0050 | SSIM: 0.0189 | Grad: 95410.195\n",
      "[Epoch 65, Batch 87/100] Loss: 0.0377 | RMSE: 0.0349 | Consistency: 0.0071 | SSIM: 0.0274 | Grad: 61287.895\n",
      "[Epoch 65, Batch 88/100] Loss: 0.0342 | RMSE: 0.0320 | Consistency: 0.0049 | SSIM: 0.0219 | Grad: 88177.930\n",
      "[Epoch 65, Batch 89/100] Loss: 0.0312 | RMSE: 0.0291 | Consistency: 0.0045 | SSIM: 0.0208 | Grad: 42735.906\n",
      "[Epoch 65, Batch 90/100] Loss: 0.0403 | RMSE: 0.0374 | Consistency: 0.0083 | SSIM: 0.0281 | Grad: 37172.582\n",
      "[Epoch 65, Batch 91/100] Loss: 0.0343 | RMSE: 0.0321 | Consistency: 0.0066 | SSIM: 0.0211 | Grad: 60097.633\n",
      "[Epoch 65, Batch 92/100] Loss: 0.0339 | RMSE: 0.0316 | Consistency: 0.0062 | SSIM: 0.0217 | Grad: 49617.500\n",
      "[Epoch 65, Batch 93/100] Loss: 0.0293 | RMSE: 0.0275 | Consistency: 0.0040 | SSIM: 0.0180 | Grad: 62774.688\n",
      "[Epoch 65, Batch 94/100] Loss: 0.0330 | RMSE: 0.0312 | Consistency: 0.0047 | SSIM: 0.0174 | Grad: 37164.793\n",
      "[Epoch 65, Batch 95/100] Loss: 0.0443 | RMSE: 0.0418 | Consistency: 0.0109 | SSIM: 0.0237 | Grad: 46726.461\n",
      "[Epoch 65, Batch 96/100] Loss: 0.0408 | RMSE: 0.0385 | Consistency: 0.0078 | SSIM: 0.0222 | Grad: 85079.266\n",
      "[Epoch 65, Batch 97/100] Loss: 0.0369 | RMSE: 0.0341 | Consistency: 0.0071 | SSIM: 0.0273 | Grad: 79775.891\n",
      "[Epoch 65, Batch 98/100] Loss: 0.0464 | RMSE: 0.0433 | Consistency: 0.0104 | SSIM: 0.0297 | Grad: 64698.441\n",
      "[Epoch 65, Batch 99/100] Loss: 0.0335 | RMSE: 0.0314 | Consistency: 0.0051 | SSIM: 0.0213 | Grad: 43492.328\n",
      "[Epoch 65, Batch 100/100] Loss: 0.0401 | RMSE: 0.0373 | Consistency: 0.0081 | SSIM: 0.0265 | Grad: 99657.328\n",
      "✅ Epoch 65 완료!\n",
      "   📈 평균 Loss: 0.036301\n",
      "   📊 평균 RMSE: 0.033943\n",
      "   ⚙️  학습률: 0.000103\n",
      "   🏆 NEW BEST! RMSE: 0.033943\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 66/80 시작...\n",
      "[Epoch 66, Batch 1/100] Loss: 0.0321 | RMSE: 0.0301 | Consistency: 0.0055 | SSIM: 0.0200 | Grad: 73938.734\n",
      "[Epoch 66, Batch 2/100] Loss: 0.0380 | RMSE: 0.0352 | Consistency: 0.0067 | SSIM: 0.0277 | Grad: 39981.527\n",
      "[Epoch 66, Batch 3/100] Loss: 0.0356 | RMSE: 0.0330 | Consistency: 0.0067 | SSIM: 0.0252 | Grad: 75431.305\n",
      "[Epoch 66, Batch 4/100] Loss: 0.0321 | RMSE: 0.0300 | Consistency: 0.0051 | SSIM: 0.0209 | Grad: 23561.598\n",
      "[Epoch 66, Batch 5/100] Loss: 0.0368 | RMSE: 0.0345 | Consistency: 0.0058 | SSIM: 0.0227 | Grad: 59199.402\n",
      "[Epoch 66, Batch 6/100] Loss: 0.0339 | RMSE: 0.0313 | Consistency: 0.0062 | SSIM: 0.0258 | Grad: 47293.406\n",
      "[Epoch 66, Batch 7/100] Loss: 0.0337 | RMSE: 0.0316 | Consistency: 0.0053 | SSIM: 0.0212 | Grad: 67101.734\n",
      "[Epoch 66, Batch 8/100] Loss: 0.0362 | RMSE: 0.0336 | Consistency: 0.0070 | SSIM: 0.0257 | Grad: 84005.867\n",
      "[Epoch 66, Batch 9/100] Loss: 0.0346 | RMSE: 0.0325 | Consistency: 0.0065 | SSIM: 0.0208 | Grad: 37958.402\n",
      "[Epoch 66, Batch 10/100] Loss: 0.0363 | RMSE: 0.0341 | Consistency: 0.0067 | SSIM: 0.0210 | Grad: 73678.578\n",
      "[Epoch 66, Batch 11/100] Loss: 0.0435 | RMSE: 0.0404 | Consistency: 0.0074 | SSIM: 0.0298 | Grad: 76139.109\n",
      "[Epoch 66, Batch 12/100] Loss: 0.0343 | RMSE: 0.0320 | Consistency: 0.0061 | SSIM: 0.0215 | Grad: 48129.988\n",
      "[Epoch 66, Batch 13/100] Loss: 0.0372 | RMSE: 0.0352 | Consistency: 0.0065 | SSIM: 0.0200 | Grad: 52521.473\n",
      "[Epoch 66, Batch 14/100] Loss: 0.0392 | RMSE: 0.0369 | Consistency: 0.0072 | SSIM: 0.0221 | Grad: 65690.172\n",
      "[Epoch 66, Batch 15/100] Loss: 0.0297 | RMSE: 0.0279 | Consistency: 0.0043 | SSIM: 0.0173 | Grad: 60010.984\n",
      "[Epoch 66, Batch 16/100] Loss: 0.0372 | RMSE: 0.0347 | Consistency: 0.0058 | SSIM: 0.0248 | Grad: 38862.812\n",
      "[Epoch 66, Batch 17/100] Loss: 0.0371 | RMSE: 0.0347 | Consistency: 0.0059 | SSIM: 0.0228 | Grad: 48757.945\n",
      "[Epoch 66, Batch 18/100] Loss: 0.0366 | RMSE: 0.0344 | Consistency: 0.0073 | SSIM: 0.0210 | Grad: 73621.430\n",
      "[Epoch 66, Batch 19/100] Loss: 0.0349 | RMSE: 0.0328 | Consistency: 0.0064 | SSIM: 0.0202 | Grad: 72609.055\n",
      "[Epoch 66, Batch 20/100] Loss: 0.0397 | RMSE: 0.0377 | Consistency: 0.0076 | SSIM: 0.0195 | Grad: 78201.867\n",
      "[Epoch 66, Batch 21/100] Loss: 0.0369 | RMSE: 0.0342 | Consistency: 0.0071 | SSIM: 0.0260 | Grad: 30336.766\n",
      "[Epoch 66, Batch 22/100] Loss: 0.0296 | RMSE: 0.0279 | Consistency: 0.0042 | SSIM: 0.0164 | Grad: 69427.594\n",
      "[Epoch 66, Batch 23/100] Loss: 0.0416 | RMSE: 0.0389 | Consistency: 0.0071 | SSIM: 0.0269 | Grad: 51727.254\n",
      "[Epoch 66, Batch 24/100] Loss: 0.0368 | RMSE: 0.0348 | Consistency: 0.0068 | SSIM: 0.0188 | Grad: 25152.057\n",
      "[Epoch 66, Batch 25/100] Loss: 0.0413 | RMSE: 0.0389 | Consistency: 0.0083 | SSIM: 0.0239 | Grad: 70782.852\n",
      "[Epoch 66, Batch 26/100] Loss: 0.0353 | RMSE: 0.0329 | Consistency: 0.0062 | SSIM: 0.0228 | Grad: 99007.680\n",
      "[Epoch 66, Batch 27/100] Loss: 0.0344 | RMSE: 0.0324 | Consistency: 0.0054 | SSIM: 0.0190 | Grad: 125657.469\n",
      "[Epoch 66, Batch 28/100] Loss: 0.0316 | RMSE: 0.0294 | Consistency: 0.0052 | SSIM: 0.0217 | Grad: 27840.973\n",
      "[Epoch 66, Batch 29/100] Loss: 0.0383 | RMSE: 0.0359 | Consistency: 0.0063 | SSIM: 0.0232 | Grad: 64246.500\n",
      "[Epoch 66, Batch 30/100] Loss: 0.0383 | RMSE: 0.0361 | Consistency: 0.0062 | SSIM: 0.0215 | Grad: 37750.621\n",
      "[Epoch 66, Batch 31/100] Loss: 0.0459 | RMSE: 0.0432 | Consistency: 0.0070 | SSIM: 0.0265 | Grad: 101622.023\n",
      "[Epoch 66, Batch 32/100] Loss: 0.0334 | RMSE: 0.0317 | Consistency: 0.0052 | SSIM: 0.0167 | Grad: 52097.273\n",
      "[Epoch 66, Batch 33/100] Loss: 0.0421 | RMSE: 0.0390 | Consistency: 0.0079 | SSIM: 0.0307 | Grad: 66740.773\n",
      "[Epoch 66, Batch 34/100] Loss: 0.0358 | RMSE: 0.0331 | Consistency: 0.0061 | SSIM: 0.0266 | Grad: 42795.164\n",
      "[Epoch 66, Batch 35/100] Loss: 0.0414 | RMSE: 0.0386 | Consistency: 0.0095 | SSIM: 0.0270 | Grad: 53394.820\n",
      "[Epoch 66, Batch 36/100] Loss: 0.0348 | RMSE: 0.0321 | Consistency: 0.0050 | SSIM: 0.0265 | Grad: 21627.932\n",
      "[Epoch 66, Batch 37/100] Loss: 0.0369 | RMSE: 0.0343 | Consistency: 0.0066 | SSIM: 0.0263 | Grad: 55549.754\n",
      "[Epoch 66, Batch 38/100] Loss: 0.0307 | RMSE: 0.0286 | Consistency: 0.0043 | SSIM: 0.0203 | Grad: 43865.863\n",
      "[Epoch 66, Batch 39/100] Loss: 0.0334 | RMSE: 0.0308 | Consistency: 0.0054 | SSIM: 0.0253 | Grad: 28230.125\n",
      "[Epoch 66, Batch 40/100] Loss: 0.0365 | RMSE: 0.0344 | Consistency: 0.0069 | SSIM: 0.0196 | Grad: 49969.090\n",
      "[Epoch 66, Batch 41/100] Loss: 0.0366 | RMSE: 0.0345 | Consistency: 0.0058 | SSIM: 0.0204 | Grad: 85937.773\n",
      "[Epoch 66, Batch 42/100] Loss: 0.0401 | RMSE: 0.0368 | Consistency: 0.0081 | SSIM: 0.0315 | Grad: 51332.312\n",
      "[Epoch 66, Batch 43/100] Loss: 0.0420 | RMSE: 0.0401 | Consistency: 0.0075 | SSIM: 0.0186 | Grad: 53138.211\n",
      "[Epoch 66, Batch 44/100] Loss: 0.0347 | RMSE: 0.0321 | Consistency: 0.0053 | SSIM: 0.0255 | Grad: 54494.785\n",
      "[Epoch 66, Batch 45/100] Loss: 0.0392 | RMSE: 0.0363 | Consistency: 0.0067 | SSIM: 0.0282 | Grad: 55996.113\n",
      "[Epoch 66, Batch 46/100] Loss: 0.0351 | RMSE: 0.0324 | Consistency: 0.0059 | SSIM: 0.0265 | Grad: 71615.242\n",
      "[Epoch 66, Batch 47/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0063 | SSIM: 0.0223 | Grad: 40575.367\n",
      "[Epoch 66, Batch 48/100] Loss: 0.0375 | RMSE: 0.0349 | Consistency: 0.0065 | SSIM: 0.0255 | Grad: 83600.602\n",
      "[Epoch 66, Batch 49/100] Loss: 0.0358 | RMSE: 0.0332 | Consistency: 0.0060 | SSIM: 0.0258 | Grad: 46263.227\n",
      "[Epoch 66, Batch 50/100] Loss: 0.0356 | RMSE: 0.0333 | Consistency: 0.0070 | SSIM: 0.0222 | Grad: 68492.297\n",
      "[Epoch 66, Batch 51/100] Loss: 0.0353 | RMSE: 0.0331 | Consistency: 0.0059 | SSIM: 0.0216 | Grad: 54438.090\n",
      "[Epoch 66, Batch 52/100] Loss: 0.0394 | RMSE: 0.0370 | Consistency: 0.0070 | SSIM: 0.0231 | Grad: 49743.555\n",
      "[Epoch 66, Batch 53/100] Loss: 0.0447 | RMSE: 0.0419 | Consistency: 0.0077 | SSIM: 0.0268 | Grad: 85492.047\n",
      "[Epoch 66, Batch 54/100] Loss: 0.0349 | RMSE: 0.0331 | Consistency: 0.0051 | SSIM: 0.0182 | Grad: 64614.832\n",
      "[Epoch 66, Batch 55/100] Loss: 0.0379 | RMSE: 0.0353 | Consistency: 0.0067 | SSIM: 0.0256 | Grad: 49340.219\n",
      "[Epoch 66, Batch 56/100] Loss: 0.0415 | RMSE: 0.0388 | Consistency: 0.0081 | SSIM: 0.0260 | Grad: 64234.828\n",
      "[Epoch 66, Batch 57/100] Loss: 0.0391 | RMSE: 0.0364 | Consistency: 0.0060 | SSIM: 0.0257 | Grad: 61244.605\n",
      "[Epoch 66, Batch 58/100] Loss: 0.0346 | RMSE: 0.0325 | Consistency: 0.0057 | SSIM: 0.0201 | Grad: 69984.117\n",
      "[Epoch 66, Batch 59/100] Loss: 0.0316 | RMSE: 0.0295 | Consistency: 0.0047 | SSIM: 0.0205 | Grad: 24612.152\n",
      "[Epoch 66, Batch 60/100] Loss: 0.0402 | RMSE: 0.0376 | Consistency: 0.0078 | SSIM: 0.0256 | Grad: 62752.047\n",
      "[Epoch 66, Batch 61/100] Loss: 0.0378 | RMSE: 0.0356 | Consistency: 0.0067 | SSIM: 0.0206 | Grad: 75609.383\n",
      "[Epoch 66, Batch 62/100] Loss: 0.0382 | RMSE: 0.0359 | Consistency: 0.0062 | SSIM: 0.0232 | Grad: 91081.102\n",
      "[Epoch 66, Batch 63/100] Loss: 0.0361 | RMSE: 0.0340 | Consistency: 0.0053 | SSIM: 0.0210 | Grad: 22906.760\n",
      "[Epoch 66, Batch 64/100] Loss: 0.0328 | RMSE: 0.0308 | Consistency: 0.0046 | SSIM: 0.0191 | Grad: 25254.379\n",
      "[Epoch 66, Batch 65/100] Loss: 0.0366 | RMSE: 0.0340 | Consistency: 0.0060 | SSIM: 0.0252 | Grad: 64820.289\n",
      "[Epoch 66, Batch 66/100] Loss: 0.0348 | RMSE: 0.0322 | Consistency: 0.0055 | SSIM: 0.0248 | Grad: 71803.688\n",
      "[Epoch 66, Batch 67/100] Loss: 0.0326 | RMSE: 0.0304 | Consistency: 0.0049 | SSIM: 0.0209 | Grad: 86758.680\n",
      "[Epoch 66, Batch 68/100] Loss: 0.0351 | RMSE: 0.0330 | Consistency: 0.0061 | SSIM: 0.0206 | Grad: 54452.332\n",
      "[Epoch 66, Batch 69/100] Loss: 0.0352 | RMSE: 0.0332 | Consistency: 0.0065 | SSIM: 0.0192 | Grad: 58173.848\n",
      "[Epoch 66, Batch 70/100] Loss: 0.0349 | RMSE: 0.0325 | Consistency: 0.0065 | SSIM: 0.0229 | Grad: 66040.672\n",
      "[Epoch 66, Batch 71/100] Loss: 0.0356 | RMSE: 0.0331 | Consistency: 0.0059 | SSIM: 0.0245 | Grad: 77599.008\n",
      "[Epoch 66, Batch 72/100] Loss: 0.0366 | RMSE: 0.0343 | Consistency: 0.0059 | SSIM: 0.0218 | Grad: 31509.695\n",
      "[Epoch 66, Batch 73/100] Loss: 0.0338 | RMSE: 0.0315 | Consistency: 0.0054 | SSIM: 0.0222 | Grad: 40313.363\n",
      "[Epoch 66, Batch 74/100] Loss: 0.0338 | RMSE: 0.0317 | Consistency: 0.0059 | SSIM: 0.0205 | Grad: 42463.992\n",
      "[Epoch 66, Batch 75/100] Loss: 0.0378 | RMSE: 0.0351 | Consistency: 0.0072 | SSIM: 0.0261 | Grad: 47283.387\n",
      "[Epoch 66, Batch 76/100] Loss: 0.0364 | RMSE: 0.0343 | Consistency: 0.0070 | SSIM: 0.0201 | Grad: 30833.090\n",
      "[Epoch 66, Batch 77/100] Loss: 0.0376 | RMSE: 0.0354 | Consistency: 0.0055 | SSIM: 0.0214 | Grad: 53689.910\n",
      "[Epoch 66, Batch 78/100] Loss: 0.0343 | RMSE: 0.0322 | Consistency: 0.0045 | SSIM: 0.0213 | Grad: 83398.680\n",
      "[Epoch 66, Batch 79/100] Loss: 0.0467 | RMSE: 0.0439 | Consistency: 0.0102 | SSIM: 0.0265 | Grad: 107277.266\n",
      "[Epoch 66, Batch 80/100] Loss: 0.0336 | RMSE: 0.0311 | Consistency: 0.0055 | SSIM: 0.0246 | Grad: 60740.191\n",
      "[Epoch 66, Batch 81/100] Loss: 0.0342 | RMSE: 0.0317 | Consistency: 0.0051 | SSIM: 0.0241 | Grad: 41777.438\n",
      "[Epoch 66, Batch 82/100] Loss: 0.0340 | RMSE: 0.0314 | Consistency: 0.0052 | SSIM: 0.0254 | Grad: 68780.188\n",
      "[Epoch 66, Batch 83/100] Loss: 0.0367 | RMSE: 0.0341 | Consistency: 0.0068 | SSIM: 0.0261 | Grad: 19133.076\n",
      "[Epoch 66, Batch 84/100] Loss: 0.0327 | RMSE: 0.0309 | Consistency: 0.0049 | SSIM: 0.0173 | Grad: 63732.277\n",
      "[Epoch 66, Batch 85/100] Loss: 0.0337 | RMSE: 0.0314 | Consistency: 0.0052 | SSIM: 0.0224 | Grad: 63497.293\n",
      "[Epoch 66, Batch 86/100] Loss: 0.0456 | RMSE: 0.0431 | Consistency: 0.0122 | SSIM: 0.0241 | Grad: 24483.555\n",
      "[Epoch 66, Batch 87/100] Loss: 0.0310 | RMSE: 0.0292 | Consistency: 0.0045 | SSIM: 0.0176 | Grad: 62140.754\n",
      "[Epoch 66, Batch 88/100] Loss: 0.0406 | RMSE: 0.0377 | Consistency: 0.0091 | SSIM: 0.0284 | Grad: 86015.328\n",
      "[Epoch 66, Batch 89/100] Loss: 0.0343 | RMSE: 0.0321 | Consistency: 0.0056 | SSIM: 0.0210 | Grad: 52870.168\n",
      "[Epoch 66, Batch 90/100] Loss: 0.0345 | RMSE: 0.0327 | Consistency: 0.0050 | SSIM: 0.0170 | Grad: 50481.535\n",
      "[Epoch 66, Batch 91/100] Loss: 0.0359 | RMSE: 0.0337 | Consistency: 0.0062 | SSIM: 0.0206 | Grad: 89107.016\n",
      "[Epoch 66, Batch 92/100] Loss: 0.0419 | RMSE: 0.0389 | Consistency: 0.0086 | SSIM: 0.0290 | Grad: 53338.480\n",
      "[Epoch 66, Batch 93/100] Loss: 0.0311 | RMSE: 0.0294 | Consistency: 0.0046 | SSIM: 0.0169 | Grad: 72650.312\n",
      "[Epoch 66, Batch 94/100] Loss: 0.0345 | RMSE: 0.0322 | Consistency: 0.0057 | SSIM: 0.0222 | Grad: 76056.305\n",
      "[Epoch 66, Batch 95/100] Loss: 0.0323 | RMSE: 0.0301 | Consistency: 0.0047 | SSIM: 0.0218 | Grad: 47811.945\n",
      "[Epoch 66, Batch 96/100] Loss: 0.0339 | RMSE: 0.0317 | Consistency: 0.0059 | SSIM: 0.0219 | Grad: 54868.797\n",
      "[Epoch 66, Batch 97/100] Loss: 0.0332 | RMSE: 0.0313 | Consistency: 0.0063 | SSIM: 0.0182 | Grad: 38944.809\n",
      "[Epoch 66, Batch 98/100] Loss: 0.0395 | RMSE: 0.0366 | Consistency: 0.0079 | SSIM: 0.0280 | Grad: 57686.246\n",
      "[Epoch 66, Batch 99/100] Loss: 0.0424 | RMSE: 0.0396 | Consistency: 0.0079 | SSIM: 0.0274 | Grad: 68883.609\n",
      "[Epoch 66, Batch 100/100] Loss: 0.0330 | RMSE: 0.0312 | Consistency: 0.0051 | SSIM: 0.0178 | Grad: 35533.551\n",
      "✅ Epoch 66 완료!\n",
      "   📈 평균 Loss: 0.036390\n",
      "   📊 평균 RMSE: 0.034039\n",
      "   ⚙️  학습률: 0.000090\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 67/80 시작...\n",
      "[Epoch 67, Batch 1/100] Loss: 0.0368 | RMSE: 0.0345 | Consistency: 0.0065 | SSIM: 0.0217 | Grad: 33887.352\n",
      "[Epoch 67, Batch 2/100] Loss: 0.0409 | RMSE: 0.0384 | Consistency: 0.0063 | SSIM: 0.0242 | Grad: 114474.367\n",
      "[Epoch 67, Batch 3/100] Loss: 0.0370 | RMSE: 0.0347 | Consistency: 0.0058 | SSIM: 0.0225 | Grad: 74223.602\n",
      "[Epoch 67, Batch 4/100] Loss: 0.0366 | RMSE: 0.0343 | Consistency: 0.0064 | SSIM: 0.0227 | Grad: 87406.953\n",
      "[Epoch 67, Batch 5/100] Loss: 0.0403 | RMSE: 0.0375 | Consistency: 0.0076 | SSIM: 0.0272 | Grad: 52789.977\n",
      "[Epoch 67, Batch 6/100] Loss: 0.0305 | RMSE: 0.0289 | Consistency: 0.0044 | SSIM: 0.0155 | Grad: 41051.379\n",
      "[Epoch 67, Batch 7/100] Loss: 0.0318 | RMSE: 0.0295 | Consistency: 0.0049 | SSIM: 0.0218 | Grad: 50416.531\n",
      "[Epoch 67, Batch 8/100] Loss: 0.0363 | RMSE: 0.0339 | Consistency: 0.0057 | SSIM: 0.0239 | Grad: 58056.691\n",
      "[Epoch 67, Batch 9/100] Loss: 0.0338 | RMSE: 0.0317 | Consistency: 0.0050 | SSIM: 0.0211 | Grad: 88171.258\n",
      "[Epoch 67, Batch 10/100] Loss: 0.0371 | RMSE: 0.0347 | Consistency: 0.0069 | SSIM: 0.0230 | Grad: 23840.811\n",
      "[Epoch 67, Batch 11/100] Loss: 0.0349 | RMSE: 0.0326 | Consistency: 0.0059 | SSIM: 0.0230 | Grad: 38266.324\n",
      "[Epoch 67, Batch 12/100] Loss: 0.0312 | RMSE: 0.0291 | Consistency: 0.0042 | SSIM: 0.0203 | Grad: 108303.391\n",
      "[Epoch 67, Batch 13/100] Loss: 0.0350 | RMSE: 0.0326 | Consistency: 0.0064 | SSIM: 0.0238 | Grad: 70182.617\n",
      "[Epoch 67, Batch 14/100] Loss: 0.0336 | RMSE: 0.0312 | Consistency: 0.0056 | SSIM: 0.0234 | Grad: 67615.664\n",
      "[Epoch 67, Batch 15/100] Loss: 0.0371 | RMSE: 0.0348 | Consistency: 0.0063 | SSIM: 0.0228 | Grad: 59370.480\n",
      "[Epoch 67, Batch 16/100] Loss: 0.0409 | RMSE: 0.0382 | Consistency: 0.0077 | SSIM: 0.0265 | Grad: 58091.898\n",
      "[Epoch 67, Batch 17/100] Loss: 0.0348 | RMSE: 0.0325 | Consistency: 0.0060 | SSIM: 0.0222 | Grad: 41078.094\n",
      "[Epoch 67, Batch 18/100] Loss: 0.0374 | RMSE: 0.0348 | Consistency: 0.0065 | SSIM: 0.0256 | Grad: 87196.555\n",
      "[Epoch 67, Batch 19/100] Loss: 0.0349 | RMSE: 0.0325 | Consistency: 0.0057 | SSIM: 0.0234 | Grad: 57634.871\n",
      "[Epoch 67, Batch 20/100] Loss: 0.0389 | RMSE: 0.0366 | Consistency: 0.0074 | SSIM: 0.0219 | Grad: 66812.219\n",
      "[Epoch 67, Batch 21/100] Loss: 0.0370 | RMSE: 0.0350 | Consistency: 0.0061 | SSIM: 0.0191 | Grad: 88023.500\n",
      "[Epoch 67, Batch 22/100] Loss: 0.0362 | RMSE: 0.0338 | Consistency: 0.0049 | SSIM: 0.0239 | Grad: 83217.398\n",
      "[Epoch 67, Batch 23/100] Loss: 0.0390 | RMSE: 0.0366 | Consistency: 0.0075 | SSIM: 0.0233 | Grad: 82180.797\n",
      "[Epoch 67, Batch 24/100] Loss: 0.0388 | RMSE: 0.0360 | Consistency: 0.0062 | SSIM: 0.0274 | Grad: 100689.664\n",
      "[Epoch 67, Batch 25/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0053 | SSIM: 0.0199 | Grad: 102799.375\n",
      "[Epoch 67, Batch 26/100] Loss: 0.0370 | RMSE: 0.0346 | Consistency: 0.0069 | SSIM: 0.0234 | Grad: 109696.531\n",
      "[Epoch 67, Batch 27/100] Loss: 0.0393 | RMSE: 0.0365 | Consistency: 0.0061 | SSIM: 0.0275 | Grad: 64337.730\n",
      "[Epoch 67, Batch 28/100] Loss: 0.0397 | RMSE: 0.0368 | Consistency: 0.0076 | SSIM: 0.0277 | Grad: 39022.371\n",
      "[Epoch 67, Batch 29/100] Loss: 0.0396 | RMSE: 0.0367 | Consistency: 0.0068 | SSIM: 0.0279 | Grad: 40412.941\n",
      "[Epoch 67, Batch 30/100] Loss: 0.0380 | RMSE: 0.0349 | Consistency: 0.0072 | SSIM: 0.0300 | Grad: 96236.562\n",
      "[Epoch 67, Batch 31/100] Loss: 0.0327 | RMSE: 0.0303 | Consistency: 0.0046 | SSIM: 0.0237 | Grad: 93944.781\n",
      "[Epoch 67, Batch 32/100] Loss: 0.0323 | RMSE: 0.0300 | Consistency: 0.0053 | SSIM: 0.0219 | Grad: 80088.047\n",
      "[Epoch 67, Batch 33/100] Loss: 0.0390 | RMSE: 0.0361 | Consistency: 0.0080 | SSIM: 0.0279 | Grad: 47974.762\n",
      "[Epoch 67, Batch 34/100] Loss: 0.0379 | RMSE: 0.0357 | Consistency: 0.0073 | SSIM: 0.0215 | Grad: 64250.289\n",
      "[Epoch 67, Batch 35/100] Loss: 0.0385 | RMSE: 0.0365 | Consistency: 0.0072 | SSIM: 0.0194 | Grad: 76754.398\n",
      "[Epoch 67, Batch 36/100] Loss: 0.0449 | RMSE: 0.0425 | Consistency: 0.0110 | SSIM: 0.0234 | Grad: 101332.656\n",
      "[Epoch 67, Batch 37/100] Loss: 0.0343 | RMSE: 0.0320 | Consistency: 0.0058 | SSIM: 0.0230 | Grad: 52073.145\n",
      "[Epoch 67, Batch 38/100] Loss: 0.0365 | RMSE: 0.0336 | Consistency: 0.0064 | SSIM: 0.0281 | Grad: 65555.219\n",
      "[Epoch 67, Batch 39/100] Loss: 0.0336 | RMSE: 0.0316 | Consistency: 0.0055 | SSIM: 0.0200 | Grad: 49211.211\n",
      "[Epoch 67, Batch 40/100] Loss: 0.0352 | RMSE: 0.0328 | Consistency: 0.0056 | SSIM: 0.0233 | Grad: 37097.020\n",
      "[Epoch 67, Batch 41/100] Loss: 0.0406 | RMSE: 0.0374 | Consistency: 0.0068 | SSIM: 0.0311 | Grad: 29809.832\n",
      "[Epoch 67, Batch 42/100] Loss: 0.0360 | RMSE: 0.0334 | Consistency: 0.0059 | SSIM: 0.0254 | Grad: 54729.688\n",
      "[Epoch 67, Batch 43/100] Loss: 0.0387 | RMSE: 0.0358 | Consistency: 0.0067 | SSIM: 0.0287 | Grad: 85364.258\n",
      "[Epoch 67, Batch 44/100] Loss: 0.0335 | RMSE: 0.0313 | Consistency: 0.0052 | SSIM: 0.0217 | Grad: 71342.211\n",
      "[Epoch 67, Batch 45/100] Loss: 0.0352 | RMSE: 0.0332 | Consistency: 0.0062 | SSIM: 0.0191 | Grad: 38598.684\n",
      "[Epoch 67, Batch 46/100] Loss: 0.0366 | RMSE: 0.0334 | Consistency: 0.0068 | SSIM: 0.0312 | Grad: 50409.477\n",
      "[Epoch 67, Batch 47/100] Loss: 0.0328 | RMSE: 0.0305 | Consistency: 0.0054 | SSIM: 0.0221 | Grad: 61513.273\n",
      "[Epoch 67, Batch 48/100] Loss: 0.0348 | RMSE: 0.0324 | Consistency: 0.0061 | SSIM: 0.0236 | Grad: 64469.355\n",
      "[Epoch 67, Batch 49/100] Loss: 0.0342 | RMSE: 0.0323 | Consistency: 0.0049 | SSIM: 0.0186 | Grad: 58266.477\n",
      "[Epoch 67, Batch 50/100] Loss: 0.0318 | RMSE: 0.0298 | Consistency: 0.0048 | SSIM: 0.0197 | Grad: 38055.293\n",
      "[Epoch 67, Batch 51/100] Loss: 0.0373 | RMSE: 0.0340 | Consistency: 0.0071 | SSIM: 0.0324 | Grad: 25479.926\n",
      "[Epoch 67, Batch 52/100] Loss: 0.0325 | RMSE: 0.0306 | Consistency: 0.0049 | SSIM: 0.0188 | Grad: 43563.379\n",
      "[Epoch 67, Batch 53/100] Loss: 0.0307 | RMSE: 0.0287 | Consistency: 0.0042 | SSIM: 0.0195 | Grad: 64941.738\n",
      "[Epoch 67, Batch 54/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0056 | SSIM: 0.0224 | Grad: 46249.727\n",
      "[Epoch 67, Batch 55/100] Loss: 0.0350 | RMSE: 0.0330 | Consistency: 0.0054 | SSIM: 0.0203 | Grad: 96176.844\n",
      "[Epoch 67, Batch 56/100] Loss: 0.0369 | RMSE: 0.0344 | Consistency: 0.0058 | SSIM: 0.0244 | Grad: 60909.734\n",
      "[Epoch 67, Batch 57/100] Loss: 0.0465 | RMSE: 0.0441 | Consistency: 0.0089 | SSIM: 0.0235 | Grad: 89376.727\n",
      "[Epoch 67, Batch 58/100] Loss: 0.0389 | RMSE: 0.0364 | Consistency: 0.0073 | SSIM: 0.0246 | Grad: 58532.676\n",
      "[Epoch 67, Batch 59/100] Loss: 0.0352 | RMSE: 0.0332 | Consistency: 0.0051 | SSIM: 0.0195 | Grad: 53181.957\n",
      "[Epoch 67, Batch 60/100] Loss: 0.0340 | RMSE: 0.0322 | Consistency: 0.0054 | SSIM: 0.0177 | Grad: 43680.219\n",
      "[Epoch 67, Batch 61/100] Loss: 0.0354 | RMSE: 0.0326 | Consistency: 0.0060 | SSIM: 0.0274 | Grad: 48760.602\n",
      "[Epoch 67, Batch 62/100] Loss: 0.0291 | RMSE: 0.0273 | Consistency: 0.0045 | SSIM: 0.0172 | Grad: 32357.645\n",
      "[Epoch 67, Batch 63/100] Loss: 0.0360 | RMSE: 0.0338 | Consistency: 0.0060 | SSIM: 0.0206 | Grad: 60281.891\n",
      "[Epoch 67, Batch 64/100] Loss: 0.0315 | RMSE: 0.0289 | Consistency: 0.0047 | SSIM: 0.0254 | Grad: 17446.871\n",
      "[Epoch 67, Batch 65/100] Loss: 0.0349 | RMSE: 0.0328 | Consistency: 0.0058 | SSIM: 0.0210 | Grad: 37289.918\n",
      "[Epoch 67, Batch 66/100] Loss: 0.0320 | RMSE: 0.0297 | Consistency: 0.0048 | SSIM: 0.0225 | Grad: 75194.922\n",
      "[Epoch 67, Batch 67/100] Loss: 0.0345 | RMSE: 0.0325 | Consistency: 0.0053 | SSIM: 0.0194 | Grad: 40451.566\n",
      "[Epoch 67, Batch 68/100] Loss: 0.0389 | RMSE: 0.0361 | Consistency: 0.0080 | SSIM: 0.0269 | Grad: 31491.391\n",
      "[Epoch 67, Batch 69/100] Loss: 0.0366 | RMSE: 0.0345 | Consistency: 0.0077 | SSIM: 0.0206 | Grad: 51865.758\n",
      "[Epoch 67, Batch 70/100] Loss: 0.0342 | RMSE: 0.0321 | Consistency: 0.0057 | SSIM: 0.0212 | Grad: 45096.059\n",
      "[Epoch 67, Batch 71/100] Loss: 0.0408 | RMSE: 0.0373 | Consistency: 0.0065 | SSIM: 0.0343 | Grad: 91448.609\n",
      "[Epoch 67, Batch 72/100] Loss: 0.0326 | RMSE: 0.0304 | Consistency: 0.0052 | SSIM: 0.0207 | Grad: 49091.555\n",
      "[Epoch 67, Batch 73/100] Loss: 0.0377 | RMSE: 0.0350 | Consistency: 0.0069 | SSIM: 0.0262 | Grad: 86674.406\n",
      "[Epoch 67, Batch 74/100] Loss: 0.0328 | RMSE: 0.0307 | Consistency: 0.0052 | SSIM: 0.0202 | Grad: 60769.926\n",
      "[Epoch 67, Batch 75/100] Loss: 0.0338 | RMSE: 0.0316 | Consistency: 0.0050 | SSIM: 0.0211 | Grad: 74259.734\n",
      "[Epoch 67, Batch 76/100] Loss: 0.0319 | RMSE: 0.0298 | Consistency: 0.0052 | SSIM: 0.0208 | Grad: 65524.438\n",
      "[Epoch 67, Batch 77/100] Loss: 0.0328 | RMSE: 0.0304 | Consistency: 0.0046 | SSIM: 0.0235 | Grad: 108179.211\n",
      "[Epoch 67, Batch 78/100] Loss: 0.0320 | RMSE: 0.0302 | Consistency: 0.0056 | SSIM: 0.0173 | Grad: 52956.785\n",
      "[Epoch 67, Batch 79/100] Loss: 0.0467 | RMSE: 0.0439 | Consistency: 0.0128 | SSIM: 0.0273 | Grad: 61776.492\n",
      "[Epoch 67, Batch 80/100] Loss: 0.0349 | RMSE: 0.0326 | Consistency: 0.0061 | SSIM: 0.0229 | Grad: 24378.023\n",
      "[Epoch 67, Batch 81/100] Loss: 0.0320 | RMSE: 0.0299 | Consistency: 0.0045 | SSIM: 0.0207 | Grad: 79822.641\n",
      "[Epoch 67, Batch 82/100] Loss: 0.0306 | RMSE: 0.0286 | Consistency: 0.0045 | SSIM: 0.0189 | Grad: 39598.539\n",
      "[Epoch 67, Batch 83/100] Loss: 0.0322 | RMSE: 0.0299 | Consistency: 0.0053 | SSIM: 0.0222 | Grad: 23765.178\n",
      "[Epoch 67, Batch 84/100] Loss: 0.0389 | RMSE: 0.0367 | Consistency: 0.0061 | SSIM: 0.0212 | Grad: 67892.445\n",
      "[Epoch 67, Batch 85/100] Loss: 0.0383 | RMSE: 0.0357 | Consistency: 0.0067 | SSIM: 0.0247 | Grad: 100591.383\n",
      "[Epoch 67, Batch 86/100] Loss: 0.0386 | RMSE: 0.0360 | Consistency: 0.0066 | SSIM: 0.0252 | Grad: 24850.637\n",
      "[Epoch 67, Batch 87/100] Loss: 0.0345 | RMSE: 0.0326 | Consistency: 0.0056 | SSIM: 0.0179 | Grad: 63741.824\n",
      "[Epoch 67, Batch 88/100] Loss: 0.0367 | RMSE: 0.0344 | Consistency: 0.0063 | SSIM: 0.0224 | Grad: 40977.898\n",
      "[Epoch 67, Batch 89/100] Loss: 0.0370 | RMSE: 0.0348 | Consistency: 0.0061 | SSIM: 0.0220 | Grad: 44386.734\n",
      "[Epoch 67, Batch 90/100] Loss: 0.0397 | RMSE: 0.0373 | Consistency: 0.0073 | SSIM: 0.0232 | Grad: 45078.012\n",
      "[Epoch 67, Batch 91/100] Loss: 0.0386 | RMSE: 0.0364 | Consistency: 0.0063 | SSIM: 0.0221 | Grad: 58894.012\n",
      "[Epoch 67, Batch 92/100] Loss: 0.0328 | RMSE: 0.0305 | Consistency: 0.0058 | SSIM: 0.0226 | Grad: 42649.508\n",
      "[Epoch 67, Batch 93/100] Loss: 0.0349 | RMSE: 0.0326 | Consistency: 0.0060 | SSIM: 0.0224 | Grad: 66731.820\n",
      "[Epoch 67, Batch 94/100] Loss: 0.0327 | RMSE: 0.0304 | Consistency: 0.0046 | SSIM: 0.0231 | Grad: 74306.039\n",
      "[Epoch 67, Batch 95/100] Loss: 0.0352 | RMSE: 0.0330 | Consistency: 0.0066 | SSIM: 0.0207 | Grad: 70577.133\n",
      "[Epoch 67, Batch 96/100] Loss: 0.0414 | RMSE: 0.0386 | Consistency: 0.0087 | SSIM: 0.0272 | Grad: 48419.676\n",
      "[Epoch 67, Batch 97/100] Loss: 0.0365 | RMSE: 0.0342 | Consistency: 0.0063 | SSIM: 0.0231 | Grad: 59867.484\n",
      "[Epoch 67, Batch 98/100] Loss: 0.0337 | RMSE: 0.0318 | Consistency: 0.0049 | SSIM: 0.0188 | Grad: 57979.113\n",
      "[Epoch 67, Batch 99/100] Loss: 0.0343 | RMSE: 0.0321 | Consistency: 0.0060 | SSIM: 0.0213 | Grad: 73002.297\n",
      "[Epoch 67, Batch 100/100] Loss: 0.0382 | RMSE: 0.0357 | Consistency: 0.0065 | SSIM: 0.0240 | Grad: 94273.484\n",
      "✅ Epoch 67 완료!\n",
      "   📈 평균 Loss: 0.035958\n",
      "   📊 평균 RMSE: 0.033593\n",
      "   ⚙️  학습률: 0.000078\n",
      "   🏆 NEW BEST! RMSE: 0.033593\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 68/80 시작...\n",
      "[Epoch 68, Batch 1/100] Loss: 0.0343 | RMSE: 0.0325 | Consistency: 0.0059 | SSIM: 0.0177 | Grad: 88297.617\n",
      "[Epoch 68, Batch 2/100] Loss: 0.0316 | RMSE: 0.0290 | Consistency: 0.0052 | SSIM: 0.0248 | Grad: 48807.586\n",
      "[Epoch 68, Batch 3/100] Loss: 0.0313 | RMSE: 0.0292 | Consistency: 0.0049 | SSIM: 0.0197 | Grad: 19675.916\n",
      "[Epoch 68, Batch 4/100] Loss: 0.0335 | RMSE: 0.0313 | Consistency: 0.0051 | SSIM: 0.0208 | Grad: 52905.016\n",
      "[Epoch 68, Batch 5/100] Loss: 0.0507 | RMSE: 0.0478 | Consistency: 0.0162 | SSIM: 0.0276 | Grad: 27382.422\n",
      "[Epoch 68, Batch 6/100] Loss: 0.0380 | RMSE: 0.0352 | Consistency: 0.0071 | SSIM: 0.0274 | Grad: 39471.113\n",
      "[Epoch 68, Batch 7/100] Loss: 0.0344 | RMSE: 0.0323 | Consistency: 0.0062 | SSIM: 0.0206 | Grad: 55092.312\n",
      "[Epoch 68, Batch 8/100] Loss: 0.0392 | RMSE: 0.0358 | Consistency: 0.0072 | SSIM: 0.0334 | Grad: 83459.281\n",
      "[Epoch 68, Batch 9/100] Loss: 0.0389 | RMSE: 0.0365 | Consistency: 0.0070 | SSIM: 0.0232 | Grad: 48112.363\n",
      "[Epoch 68, Batch 10/100] Loss: 0.0385 | RMSE: 0.0357 | Consistency: 0.0067 | SSIM: 0.0274 | Grad: 46461.098\n",
      "[Epoch 68, Batch 11/100] Loss: 0.0336 | RMSE: 0.0313 | Consistency: 0.0058 | SSIM: 0.0224 | Grad: 43188.648\n",
      "[Epoch 68, Batch 12/100] Loss: 0.0389 | RMSE: 0.0364 | Consistency: 0.0070 | SSIM: 0.0244 | Grad: 14055.029\n",
      "[Epoch 68, Batch 13/100] Loss: 0.0323 | RMSE: 0.0302 | Consistency: 0.0045 | SSIM: 0.0209 | Grad: 59521.203\n",
      "[Epoch 68, Batch 14/100] Loss: 0.0327 | RMSE: 0.0305 | Consistency: 0.0051 | SSIM: 0.0216 | Grad: 49398.723\n",
      "[Epoch 68, Batch 15/100] Loss: 0.0309 | RMSE: 0.0289 | Consistency: 0.0047 | SSIM: 0.0195 | Grad: 14390.994\n",
      "[Epoch 68, Batch 16/100] Loss: 0.0352 | RMSE: 0.0329 | Consistency: 0.0051 | SSIM: 0.0232 | Grad: 52760.621\n",
      "[Epoch 68, Batch 17/100] Loss: 0.0335 | RMSE: 0.0309 | Consistency: 0.0053 | SSIM: 0.0253 | Grad: 27183.070\n",
      "[Epoch 68, Batch 18/100] Loss: 0.0362 | RMSE: 0.0340 | Consistency: 0.0070 | SSIM: 0.0218 | Grad: 34500.445\n",
      "[Epoch 68, Batch 19/100] Loss: 0.0347 | RMSE: 0.0323 | Consistency: 0.0059 | SSIM: 0.0234 | Grad: 60360.750\n",
      "[Epoch 68, Batch 20/100] Loss: 0.0315 | RMSE: 0.0293 | Consistency: 0.0052 | SSIM: 0.0213 | Grad: 33688.543\n",
      "[Epoch 68, Batch 21/100] Loss: 0.0415 | RMSE: 0.0388 | Consistency: 0.0090 | SSIM: 0.0269 | Grad: 59652.477\n",
      "[Epoch 68, Batch 22/100] Loss: 0.0437 | RMSE: 0.0408 | Consistency: 0.0103 | SSIM: 0.0278 | Grad: 106534.992\n",
      "[Epoch 68, Batch 23/100] Loss: 0.0354 | RMSE: 0.0328 | Consistency: 0.0065 | SSIM: 0.0245 | Grad: 98409.367\n",
      "[Epoch 68, Batch 24/100] Loss: 0.0365 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0196 | Grad: 19836.867\n",
      "[Epoch 68, Batch 25/100] Loss: 0.0325 | RMSE: 0.0302 | Consistency: 0.0052 | SSIM: 0.0222 | Grad: 62083.953\n",
      "[Epoch 68, Batch 26/100] Loss: 0.0348 | RMSE: 0.0327 | Consistency: 0.0055 | SSIM: 0.0206 | Grad: 23684.451\n",
      "[Epoch 68, Batch 27/100] Loss: 0.0345 | RMSE: 0.0319 | Consistency: 0.0052 | SSIM: 0.0252 | Grad: 32393.814\n",
      "[Epoch 68, Batch 28/100] Loss: 0.0356 | RMSE: 0.0328 | Consistency: 0.0060 | SSIM: 0.0275 | Grad: 45232.828\n",
      "[Epoch 68, Batch 29/100] Loss: 0.0318 | RMSE: 0.0300 | Consistency: 0.0046 | SSIM: 0.0179 | Grad: 68734.109\n",
      "[Epoch 68, Batch 30/100] Loss: 0.0334 | RMSE: 0.0313 | Consistency: 0.0054 | SSIM: 0.0202 | Grad: 39900.543\n",
      "[Epoch 68, Batch 31/100] Loss: 0.0358 | RMSE: 0.0337 | Consistency: 0.0065 | SSIM: 0.0205 | Grad: 67073.016\n",
      "[Epoch 68, Batch 32/100] Loss: 0.0366 | RMSE: 0.0341 | Consistency: 0.0064 | SSIM: 0.0245 | Grad: 66551.062\n",
      "[Epoch 68, Batch 33/100] Loss: 0.0337 | RMSE: 0.0316 | Consistency: 0.0055 | SSIM: 0.0201 | Grad: 42585.801\n",
      "[Epoch 68, Batch 34/100] Loss: 0.0395 | RMSE: 0.0368 | Consistency: 0.0075 | SSIM: 0.0257 | Grad: 77410.422\n",
      "[Epoch 68, Batch 35/100] Loss: 0.0469 | RMSE: 0.0439 | Consistency: 0.0095 | SSIM: 0.0286 | Grad: 53518.332\n",
      "[Epoch 68, Batch 36/100] Loss: 0.0337 | RMSE: 0.0312 | Consistency: 0.0058 | SSIM: 0.0241 | Grad: 41741.219\n",
      "[Epoch 68, Batch 37/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0076 | SSIM: 0.0225 | Grad: 29904.240\n",
      "[Epoch 68, Batch 38/100] Loss: 0.0398 | RMSE: 0.0365 | Consistency: 0.0079 | SSIM: 0.0321 | Grad: 67942.398\n",
      "[Epoch 68, Batch 39/100] Loss: 0.0344 | RMSE: 0.0321 | Consistency: 0.0063 | SSIM: 0.0229 | Grad: 63852.832\n",
      "[Epoch 68, Batch 40/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0065 | SSIM: 0.0241 | Grad: 59163.605\n",
      "[Epoch 68, Batch 41/100] Loss: 0.0382 | RMSE: 0.0350 | Consistency: 0.0072 | SSIM: 0.0318 | Grad: 40419.914\n",
      "[Epoch 68, Batch 42/100] Loss: 0.0394 | RMSE: 0.0366 | Consistency: 0.0079 | SSIM: 0.0268 | Grad: 66110.766\n",
      "[Epoch 68, Batch 43/100] Loss: 0.0401 | RMSE: 0.0376 | Consistency: 0.0078 | SSIM: 0.0240 | Grad: 76414.703\n",
      "[Epoch 68, Batch 44/100] Loss: 0.0401 | RMSE: 0.0376 | Consistency: 0.0086 | SSIM: 0.0247 | Grad: 38216.828\n",
      "[Epoch 68, Batch 45/100] Loss: 0.0292 | RMSE: 0.0276 | Consistency: 0.0038 | SSIM: 0.0149 | Grad: 31439.453\n",
      "[Epoch 68, Batch 46/100] Loss: 0.0346 | RMSE: 0.0322 | Consistency: 0.0056 | SSIM: 0.0236 | Grad: 43521.859\n",
      "[Epoch 68, Batch 47/100] Loss: 0.0322 | RMSE: 0.0300 | Consistency: 0.0050 | SSIM: 0.0216 | Grad: 32285.395\n",
      "[Epoch 68, Batch 48/100] Loss: 0.0349 | RMSE: 0.0330 | Consistency: 0.0063 | SSIM: 0.0187 | Grad: 62523.613\n",
      "[Epoch 68, Batch 49/100] Loss: 0.0335 | RMSE: 0.0313 | Consistency: 0.0058 | SSIM: 0.0210 | Grad: 49943.340\n",
      "[Epoch 68, Batch 50/100] Loss: 0.0331 | RMSE: 0.0309 | Consistency: 0.0054 | SSIM: 0.0213 | Grad: 81623.359\n",
      "[Epoch 68, Batch 51/100] Loss: 0.0347 | RMSE: 0.0323 | Consistency: 0.0053 | SSIM: 0.0235 | Grad: 94482.352\n",
      "[Epoch 68, Batch 52/100] Loss: 0.0369 | RMSE: 0.0341 | Consistency: 0.0060 | SSIM: 0.0279 | Grad: 66175.664\n",
      "[Epoch 68, Batch 53/100] Loss: 0.0351 | RMSE: 0.0328 | Consistency: 0.0060 | SSIM: 0.0221 | Grad: 73853.938\n",
      "[Epoch 68, Batch 54/100] Loss: 0.0397 | RMSE: 0.0370 | Consistency: 0.0075 | SSIM: 0.0261 | Grad: 105006.773\n",
      "[Epoch 68, Batch 55/100] Loss: 0.0319 | RMSE: 0.0300 | Consistency: 0.0046 | SSIM: 0.0193 | Grad: 55096.730\n",
      "[Epoch 68, Batch 56/100] Loss: 0.0303 | RMSE: 0.0281 | Consistency: 0.0046 | SSIM: 0.0216 | Grad: 67188.500\n",
      "[Epoch 68, Batch 57/100] Loss: 0.0372 | RMSE: 0.0345 | Consistency: 0.0070 | SSIM: 0.0271 | Grad: 35527.246\n",
      "[Epoch 68, Batch 58/100] Loss: 0.0325 | RMSE: 0.0300 | Consistency: 0.0049 | SSIM: 0.0246 | Grad: 41490.281\n",
      "[Epoch 68, Batch 59/100] Loss: 0.0335 | RMSE: 0.0316 | Consistency: 0.0045 | SSIM: 0.0183 | Grad: 62882.453\n",
      "[Epoch 68, Batch 60/100] Loss: 0.0347 | RMSE: 0.0325 | Consistency: 0.0055 | SSIM: 0.0217 | Grad: 56545.926\n",
      "[Epoch 68, Batch 61/100] Loss: 0.0368 | RMSE: 0.0342 | Consistency: 0.0067 | SSIM: 0.0249 | Grad: 41562.906\n",
      "[Epoch 68, Batch 62/100] Loss: 0.0390 | RMSE: 0.0363 | Consistency: 0.0067 | SSIM: 0.0260 | Grad: 25859.008\n",
      "[Epoch 68, Batch 63/100] Loss: 0.0328 | RMSE: 0.0301 | Consistency: 0.0048 | SSIM: 0.0267 | Grad: 57552.215\n",
      "[Epoch 68, Batch 64/100] Loss: 0.0373 | RMSE: 0.0353 | Consistency: 0.0053 | SSIM: 0.0192 | Grad: 91183.484\n",
      "[Epoch 68, Batch 65/100] Loss: 0.0340 | RMSE: 0.0319 | Consistency: 0.0062 | SSIM: 0.0211 | Grad: 41438.789\n",
      "[Epoch 68, Batch 66/100] Loss: 0.0371 | RMSE: 0.0348 | Consistency: 0.0068 | SSIM: 0.0223 | Grad: 43554.562\n",
      "[Epoch 68, Batch 67/100] Loss: 0.0379 | RMSE: 0.0358 | Consistency: 0.0060 | SSIM: 0.0212 | Grad: 49862.930\n",
      "[Epoch 68, Batch 68/100] Loss: 0.0365 | RMSE: 0.0343 | Consistency: 0.0067 | SSIM: 0.0216 | Grad: 78166.062\n",
      "[Epoch 68, Batch 69/100] Loss: 0.0349 | RMSE: 0.0319 | Consistency: 0.0061 | SSIM: 0.0288 | Grad: 72652.242\n",
      "[Epoch 68, Batch 70/100] Loss: 0.0360 | RMSE: 0.0340 | Consistency: 0.0054 | SSIM: 0.0194 | Grad: 91713.352\n",
      "[Epoch 68, Batch 71/100] Loss: 0.0399 | RMSE: 0.0370 | Consistency: 0.0076 | SSIM: 0.0280 | Grad: 70144.484\n",
      "[Epoch 68, Batch 72/100] Loss: 0.0287 | RMSE: 0.0265 | Consistency: 0.0037 | SSIM: 0.0216 | Grad: 43700.387\n",
      "[Epoch 68, Batch 73/100] Loss: 0.0314 | RMSE: 0.0294 | Consistency: 0.0048 | SSIM: 0.0199 | Grad: 39507.438\n",
      "[Epoch 68, Batch 74/100] Loss: 0.0316 | RMSE: 0.0298 | Consistency: 0.0044 | SSIM: 0.0179 | Grad: 34341.012\n",
      "[Epoch 68, Batch 75/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0068 | SSIM: 0.0241 | Grad: 39911.734\n",
      "[Epoch 68, Batch 76/100] Loss: 0.0311 | RMSE: 0.0291 | Consistency: 0.0044 | SSIM: 0.0192 | Grad: 59569.914\n",
      "[Epoch 68, Batch 77/100] Loss: 0.0377 | RMSE: 0.0352 | Consistency: 0.0080 | SSIM: 0.0244 | Grad: 61242.129\n",
      "[Epoch 68, Batch 78/100] Loss: 0.0329 | RMSE: 0.0307 | Consistency: 0.0061 | SSIM: 0.0215 | Grad: 42501.605\n",
      "[Epoch 68, Batch 79/100] Loss: 0.0404 | RMSE: 0.0371 | Consistency: 0.0072 | SSIM: 0.0321 | Grad: 44320.988\n",
      "[Epoch 68, Batch 80/100] Loss: 0.0318 | RMSE: 0.0298 | Consistency: 0.0040 | SSIM: 0.0191 | Grad: 64947.234\n",
      "[Epoch 68, Batch 81/100] Loss: 0.0321 | RMSE: 0.0301 | Consistency: 0.0043 | SSIM: 0.0190 | Grad: 18383.301\n",
      "[Epoch 68, Batch 82/100] Loss: 0.0352 | RMSE: 0.0324 | Consistency: 0.0062 | SSIM: 0.0273 | Grad: 39813.281\n",
      "[Epoch 68, Batch 83/100] Loss: 0.0336 | RMSE: 0.0312 | Consistency: 0.0049 | SSIM: 0.0233 | Grad: 57994.473\n",
      "[Epoch 68, Batch 84/100] Loss: 0.0330 | RMSE: 0.0309 | Consistency: 0.0053 | SSIM: 0.0210 | Grad: 28985.555\n",
      "[Epoch 68, Batch 85/100] Loss: 0.0317 | RMSE: 0.0296 | Consistency: 0.0052 | SSIM: 0.0203 | Grad: 73105.688\n",
      "[Epoch 68, Batch 86/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0057 | SSIM: 0.0241 | Grad: 49652.180\n",
      "[Epoch 68, Batch 87/100] Loss: 0.0351 | RMSE: 0.0323 | Consistency: 0.0061 | SSIM: 0.0271 | Grad: 57296.324\n",
      "[Epoch 68, Batch 88/100] Loss: 0.0357 | RMSE: 0.0334 | Consistency: 0.0065 | SSIM: 0.0222 | Grad: 96637.469\n",
      "[Epoch 68, Batch 89/100] Loss: 0.0327 | RMSE: 0.0300 | Consistency: 0.0053 | SSIM: 0.0268 | Grad: 26365.559\n",
      "[Epoch 68, Batch 90/100] Loss: 0.0306 | RMSE: 0.0289 | Consistency: 0.0047 | SSIM: 0.0161 | Grad: 50581.625\n",
      "[Epoch 68, Batch 91/100] Loss: 0.0326 | RMSE: 0.0306 | Consistency: 0.0048 | SSIM: 0.0198 | Grad: 54650.164\n",
      "[Epoch 68, Batch 92/100] Loss: 0.0366 | RMSE: 0.0341 | Consistency: 0.0061 | SSIM: 0.0244 | Grad: 24988.090\n",
      "[Epoch 68, Batch 93/100] Loss: 0.0343 | RMSE: 0.0316 | Consistency: 0.0055 | SSIM: 0.0265 | Grad: 54092.238\n",
      "[Epoch 68, Batch 94/100] Loss: 0.0336 | RMSE: 0.0314 | Consistency: 0.0055 | SSIM: 0.0219 | Grad: 27691.678\n",
      "[Epoch 68, Batch 95/100] Loss: 0.0376 | RMSE: 0.0351 | Consistency: 0.0071 | SSIM: 0.0243 | Grad: 76111.688\n",
      "[Epoch 68, Batch 96/100] Loss: 0.0328 | RMSE: 0.0304 | Consistency: 0.0045 | SSIM: 0.0230 | Grad: 76582.852\n",
      "[Epoch 68, Batch 97/100] Loss: 0.0366 | RMSE: 0.0336 | Consistency: 0.0061 | SSIM: 0.0290 | Grad: 87869.844\n",
      "[Epoch 68, Batch 98/100] Loss: 0.0307 | RMSE: 0.0288 | Consistency: 0.0044 | SSIM: 0.0183 | Grad: 60798.008\n",
      "[Epoch 68, Batch 99/100] Loss: 0.0362 | RMSE: 0.0335 | Consistency: 0.0067 | SSIM: 0.0267 | Grad: 68406.328\n",
      "[Epoch 68, Batch 100/100] Loss: 0.0363 | RMSE: 0.0340 | Consistency: 0.0068 | SSIM: 0.0222 | Grad: 83002.328\n",
      "✅ Epoch 68 완료!\n",
      "   📈 평균 Loss: 0.035393\n",
      "   📊 평균 RMSE: 0.033006\n",
      "   ⚙️  학습률: 0.000067\n",
      "   🏆 NEW BEST! RMSE: 0.033006\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 69/80 시작...\n",
      "[Epoch 69, Batch 1/100] Loss: 0.0367 | RMSE: 0.0344 | Consistency: 0.0058 | SSIM: 0.0228 | Grad: 43163.781\n",
      "[Epoch 69, Batch 2/100] Loss: 0.0419 | RMSE: 0.0397 | Consistency: 0.0077 | SSIM: 0.0217 | Grad: 46627.227\n",
      "[Epoch 69, Batch 3/100] Loss: 0.0345 | RMSE: 0.0320 | Consistency: 0.0059 | SSIM: 0.0238 | Grad: 88004.477\n",
      "[Epoch 69, Batch 4/100] Loss: 0.0322 | RMSE: 0.0297 | Consistency: 0.0050 | SSIM: 0.0245 | Grad: 96433.297\n",
      "[Epoch 69, Batch 5/100] Loss: 0.0407 | RMSE: 0.0379 | Consistency: 0.0078 | SSIM: 0.0264 | Grad: 110691.023\n",
      "[Epoch 69, Batch 6/100] Loss: 0.0329 | RMSE: 0.0309 | Consistency: 0.0054 | SSIM: 0.0198 | Grad: 56381.352\n",
      "[Epoch 69, Batch 7/100] Loss: 0.0328 | RMSE: 0.0306 | Consistency: 0.0046 | SSIM: 0.0214 | Grad: 50675.852\n",
      "[Epoch 69, Batch 8/100] Loss: 0.0401 | RMSE: 0.0375 | Consistency: 0.0083 | SSIM: 0.0248 | Grad: 51681.664\n",
      "[Epoch 69, Batch 9/100] Loss: 0.0384 | RMSE: 0.0354 | Consistency: 0.0063 | SSIM: 0.0292 | Grad: 75313.828\n",
      "[Epoch 69, Batch 10/100] Loss: 0.0367 | RMSE: 0.0339 | Consistency: 0.0070 | SSIM: 0.0276 | Grad: 70781.133\n",
      "[Epoch 69, Batch 11/100] Loss: 0.0344 | RMSE: 0.0323 | Consistency: 0.0070 | SSIM: 0.0203 | Grad: 66420.688\n",
      "[Epoch 69, Batch 12/100] Loss: 0.0375 | RMSE: 0.0353 | Consistency: 0.0064 | SSIM: 0.0216 | Grad: 67178.000\n",
      "[Epoch 69, Batch 13/100] Loss: 0.0361 | RMSE: 0.0337 | Consistency: 0.0065 | SSIM: 0.0238 | Grad: 24719.602\n",
      "[Epoch 69, Batch 14/100] Loss: 0.0390 | RMSE: 0.0365 | Consistency: 0.0067 | SSIM: 0.0239 | Grad: 56404.531\n",
      "[Epoch 69, Batch 15/100] Loss: 0.0455 | RMSE: 0.0428 | Consistency: 0.0104 | SSIM: 0.0264 | Grad: 93964.727\n",
      "[Epoch 69, Batch 16/100] Loss: 0.0355 | RMSE: 0.0330 | Consistency: 0.0060 | SSIM: 0.0239 | Grad: 31287.818\n",
      "[Epoch 69, Batch 17/100] Loss: 0.0384 | RMSE: 0.0363 | Consistency: 0.0066 | SSIM: 0.0205 | Grad: 23529.686\n",
      "[Epoch 69, Batch 18/100] Loss: 0.0354 | RMSE: 0.0331 | Consistency: 0.0058 | SSIM: 0.0230 | Grad: 63305.824\n",
      "[Epoch 69, Batch 19/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0067 | SSIM: 0.0226 | Grad: 44445.508\n",
      "[Epoch 69, Batch 20/100] Loss: 0.0415 | RMSE: 0.0386 | Consistency: 0.0074 | SSIM: 0.0284 | Grad: 68908.648\n",
      "[Epoch 69, Batch 21/100] Loss: 0.0299 | RMSE: 0.0280 | Consistency: 0.0047 | SSIM: 0.0181 | Grad: 37990.117\n",
      "[Epoch 69, Batch 22/100] Loss: 0.0330 | RMSE: 0.0306 | Consistency: 0.0053 | SSIM: 0.0229 | Grad: 68038.227\n",
      "[Epoch 69, Batch 23/100] Loss: 0.0304 | RMSE: 0.0286 | Consistency: 0.0051 | SSIM: 0.0170 | Grad: 50659.672\n",
      "[Epoch 69, Batch 24/100] Loss: 0.0310 | RMSE: 0.0292 | Consistency: 0.0050 | SSIM: 0.0178 | Grad: 72987.742\n",
      "[Epoch 69, Batch 25/100] Loss: 0.0361 | RMSE: 0.0336 | Consistency: 0.0057 | SSIM: 0.0243 | Grad: 70951.539\n",
      "[Epoch 69, Batch 26/100] Loss: 0.0414 | RMSE: 0.0390 | Consistency: 0.0074 | SSIM: 0.0236 | Grad: 57808.289\n",
      "[Epoch 69, Batch 27/100] Loss: 0.0415 | RMSE: 0.0386 | Consistency: 0.0070 | SSIM: 0.0289 | Grad: 77879.664\n",
      "[Epoch 69, Batch 28/100] Loss: 0.0349 | RMSE: 0.0323 | Consistency: 0.0050 | SSIM: 0.0255 | Grad: 78813.805\n",
      "[Epoch 69, Batch 29/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0065 | SSIM: 0.0243 | Grad: 72061.617\n",
      "[Epoch 69, Batch 30/100] Loss: 0.0430 | RMSE: 0.0398 | Consistency: 0.0100 | SSIM: 0.0317 | Grad: 66572.109\n",
      "[Epoch 69, Batch 31/100] Loss: 0.0349 | RMSE: 0.0322 | Consistency: 0.0057 | SSIM: 0.0268 | Grad: 62502.023\n",
      "[Epoch 69, Batch 32/100] Loss: 0.0316 | RMSE: 0.0293 | Consistency: 0.0050 | SSIM: 0.0225 | Grad: 15905.643\n",
      "[Epoch 69, Batch 33/100] Loss: 0.0351 | RMSE: 0.0322 | Consistency: 0.0054 | SSIM: 0.0291 | Grad: 69657.766\n",
      "[Epoch 69, Batch 34/100] Loss: 0.0372 | RMSE: 0.0338 | Consistency: 0.0059 | SSIM: 0.0339 | Grad: 57196.582\n",
      "[Epoch 69, Batch 35/100] Loss: 0.0410 | RMSE: 0.0383 | Consistency: 0.0091 | SSIM: 0.0259 | Grad: 35419.723\n",
      "[Epoch 69, Batch 36/100] Loss: 0.0324 | RMSE: 0.0306 | Consistency: 0.0043 | SSIM: 0.0181 | Grad: 81385.523\n",
      "[Epoch 69, Batch 37/100] Loss: 0.0478 | RMSE: 0.0452 | Consistency: 0.0093 | SSIM: 0.0245 | Grad: 52293.352\n",
      "[Epoch 69, Batch 38/100] Loss: 0.0341 | RMSE: 0.0325 | Consistency: 0.0052 | SSIM: 0.0163 | Grad: 50855.180\n",
      "[Epoch 69, Batch 39/100] Loss: 0.0320 | RMSE: 0.0299 | Consistency: 0.0047 | SSIM: 0.0205 | Grad: 83179.133\n",
      "[Epoch 69, Batch 40/100] Loss: 0.0319 | RMSE: 0.0298 | Consistency: 0.0050 | SSIM: 0.0212 | Grad: 58646.465\n",
      "[Epoch 69, Batch 41/100] Loss: 0.0310 | RMSE: 0.0285 | Consistency: 0.0045 | SSIM: 0.0247 | Grad: 47925.348\n",
      "[Epoch 69, Batch 42/100] Loss: 0.0409 | RMSE: 0.0383 | Consistency: 0.0076 | SSIM: 0.0256 | Grad: 56059.531\n",
      "[Epoch 69, Batch 43/100] Loss: 0.0408 | RMSE: 0.0383 | Consistency: 0.0075 | SSIM: 0.0237 | Grad: 30327.412\n",
      "[Epoch 69, Batch 44/100] Loss: 0.0314 | RMSE: 0.0294 | Consistency: 0.0049 | SSIM: 0.0189 | Grad: 74422.758\n",
      "[Epoch 69, Batch 45/100] Loss: 0.0375 | RMSE: 0.0345 | Consistency: 0.0076 | SSIM: 0.0295 | Grad: 35048.172\n",
      "[Epoch 69, Batch 46/100] Loss: 0.0301 | RMSE: 0.0282 | Consistency: 0.0041 | SSIM: 0.0187 | Grad: 80728.430\n",
      "[Epoch 69, Batch 47/100] Loss: 0.0364 | RMSE: 0.0339 | Consistency: 0.0056 | SSIM: 0.0248 | Grad: 101373.266\n",
      "[Epoch 69, Batch 48/100] Loss: 0.0330 | RMSE: 0.0311 | Consistency: 0.0040 | SSIM: 0.0185 | Grad: 39344.590\n",
      "[Epoch 69, Batch 49/100] Loss: 0.0388 | RMSE: 0.0361 | Consistency: 0.0076 | SSIM: 0.0256 | Grad: 93857.023\n",
      "[Epoch 69, Batch 50/100] Loss: 0.0393 | RMSE: 0.0371 | Consistency: 0.0070 | SSIM: 0.0220 | Grad: 82163.570\n",
      "[Epoch 69, Batch 51/100] Loss: 0.0427 | RMSE: 0.0390 | Consistency: 0.0091 | SSIM: 0.0361 | Grad: 88162.203\n",
      "[Epoch 69, Batch 52/100] Loss: 0.0385 | RMSE: 0.0356 | Consistency: 0.0073 | SSIM: 0.0276 | Grad: 76054.266\n",
      "[Epoch 69, Batch 53/100] Loss: 0.0319 | RMSE: 0.0298 | Consistency: 0.0056 | SSIM: 0.0205 | Grad: 65885.367\n",
      "[Epoch 69, Batch 54/100] Loss: 0.0365 | RMSE: 0.0341 | Consistency: 0.0078 | SSIM: 0.0236 | Grad: 57032.672\n",
      "[Epoch 69, Batch 55/100] Loss: 0.0373 | RMSE: 0.0347 | Consistency: 0.0068 | SSIM: 0.0253 | Grad: 65371.949\n",
      "[Epoch 69, Batch 56/100] Loss: 0.0360 | RMSE: 0.0336 | Consistency: 0.0062 | SSIM: 0.0236 | Grad: 20882.543\n",
      "[Epoch 69, Batch 57/100] Loss: 0.0339 | RMSE: 0.0317 | Consistency: 0.0058 | SSIM: 0.0212 | Grad: 34214.195\n",
      "[Epoch 69, Batch 58/100] Loss: 0.0380 | RMSE: 0.0351 | Consistency: 0.0066 | SSIM: 0.0282 | Grad: 50789.707\n",
      "[Epoch 69, Batch 59/100] Loss: 0.0363 | RMSE: 0.0342 | Consistency: 0.0068 | SSIM: 0.0197 | Grad: 57292.289\n",
      "[Epoch 69, Batch 60/100] Loss: 0.0348 | RMSE: 0.0327 | Consistency: 0.0066 | SSIM: 0.0200 | Grad: 62973.344\n",
      "[Epoch 69, Batch 61/100] Loss: 0.0381 | RMSE: 0.0356 | Consistency: 0.0075 | SSIM: 0.0242 | Grad: 26889.461\n",
      "[Epoch 69, Batch 62/100] Loss: 0.0349 | RMSE: 0.0327 | Consistency: 0.0065 | SSIM: 0.0213 | Grad: 52299.398\n",
      "[Epoch 69, Batch 63/100] Loss: 0.0484 | RMSE: 0.0453 | Consistency: 0.0140 | SSIM: 0.0299 | Grad: 36447.090\n",
      "[Epoch 69, Batch 64/100] Loss: 0.0389 | RMSE: 0.0364 | Consistency: 0.0073 | SSIM: 0.0246 | Grad: 50413.406\n",
      "[Epoch 69, Batch 65/100] Loss: 0.0372 | RMSE: 0.0347 | Consistency: 0.0067 | SSIM: 0.0247 | Grad: 99600.719\n",
      "[Epoch 69, Batch 66/100] Loss: 0.0335 | RMSE: 0.0308 | Consistency: 0.0048 | SSIM: 0.0262 | Grad: 73485.789\n",
      "[Epoch 69, Batch 67/100] Loss: 0.0343 | RMSE: 0.0324 | Consistency: 0.0055 | SSIM: 0.0190 | Grad: 77022.031\n",
      "[Epoch 69, Batch 68/100] Loss: 0.0328 | RMSE: 0.0310 | Consistency: 0.0053 | SSIM: 0.0172 | Grad: 74410.531\n",
      "[Epoch 69, Batch 69/100] Loss: 0.0363 | RMSE: 0.0337 | Consistency: 0.0062 | SSIM: 0.0249 | Grad: 42358.402\n",
      "[Epoch 69, Batch 70/100] Loss: 0.0367 | RMSE: 0.0345 | Consistency: 0.0062 | SSIM: 0.0211 | Grad: 64226.910\n",
      "[Epoch 69, Batch 71/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0059 | SSIM: 0.0226 | Grad: 35963.352\n",
      "[Epoch 69, Batch 72/100] Loss: 0.0348 | RMSE: 0.0326 | Consistency: 0.0054 | SSIM: 0.0215 | Grad: 51334.062\n",
      "[Epoch 69, Batch 73/100] Loss: 0.0334 | RMSE: 0.0310 | Consistency: 0.0052 | SSIM: 0.0244 | Grad: 51814.777\n",
      "[Epoch 69, Batch 74/100] Loss: 0.0401 | RMSE: 0.0377 | Consistency: 0.0084 | SSIM: 0.0232 | Grad: 100902.016\n",
      "[Epoch 69, Batch 75/100] Loss: 0.0313 | RMSE: 0.0296 | Consistency: 0.0053 | SSIM: 0.0167 | Grad: 72185.297\n",
      "[Epoch 69, Batch 76/100] Loss: 0.0320 | RMSE: 0.0296 | Consistency: 0.0046 | SSIM: 0.0233 | Grad: 62970.328\n",
      "[Epoch 69, Batch 77/100] Loss: 0.0457 | RMSE: 0.0426 | Consistency: 0.0101 | SSIM: 0.0301 | Grad: 72366.414\n",
      "[Epoch 69, Batch 78/100] Loss: 0.0327 | RMSE: 0.0305 | Consistency: 0.0051 | SSIM: 0.0218 | Grad: 35818.406\n",
      "[Epoch 69, Batch 79/100] Loss: 0.0353 | RMSE: 0.0331 | Consistency: 0.0064 | SSIM: 0.0214 | Grad: 58934.660\n",
      "[Epoch 69, Batch 80/100] Loss: 0.0365 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0197 | Grad: 44056.844\n",
      "[Epoch 69, Batch 81/100] Loss: 0.0354 | RMSE: 0.0332 | Consistency: 0.0059 | SSIM: 0.0214 | Grad: 86979.234\n",
      "[Epoch 69, Batch 82/100] Loss: 0.0341 | RMSE: 0.0319 | Consistency: 0.0053 | SSIM: 0.0212 | Grad: 64116.699\n",
      "[Epoch 69, Batch 83/100] Loss: 0.0309 | RMSE: 0.0291 | Consistency: 0.0044 | SSIM: 0.0179 | Grad: 67138.391\n",
      "[Epoch 69, Batch 84/100] Loss: 0.0295 | RMSE: 0.0276 | Consistency: 0.0043 | SSIM: 0.0183 | Grad: 66614.477\n",
      "[Epoch 69, Batch 85/100] Loss: 0.0345 | RMSE: 0.0316 | Consistency: 0.0057 | SSIM: 0.0275 | Grad: 81516.836\n",
      "[Epoch 69, Batch 86/100] Loss: 0.0338 | RMSE: 0.0315 | Consistency: 0.0060 | SSIM: 0.0218 | Grad: 33924.641\n",
      "[Epoch 69, Batch 87/100] Loss: 0.0419 | RMSE: 0.0390 | Consistency: 0.0096 | SSIM: 0.0285 | Grad: 42544.199\n",
      "[Epoch 69, Batch 88/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0053 | SSIM: 0.0200 | Grad: 68994.867\n",
      "[Epoch 69, Batch 89/100] Loss: 0.0443 | RMSE: 0.0410 | Consistency: 0.0086 | SSIM: 0.0324 | Grad: 73270.695\n",
      "[Epoch 69, Batch 90/100] Loss: 0.0340 | RMSE: 0.0320 | Consistency: 0.0056 | SSIM: 0.0186 | Grad: 65674.211\n",
      "[Epoch 69, Batch 91/100] Loss: 0.0361 | RMSE: 0.0336 | Consistency: 0.0060 | SSIM: 0.0253 | Grad: 49058.121\n",
      "[Epoch 69, Batch 92/100] Loss: 0.0329 | RMSE: 0.0308 | Consistency: 0.0059 | SSIM: 0.0205 | Grad: 63637.906\n",
      "[Epoch 69, Batch 93/100] Loss: 0.0388 | RMSE: 0.0357 | Consistency: 0.0071 | SSIM: 0.0312 | Grad: 26373.824\n",
      "[Epoch 69, Batch 94/100] Loss: 0.0315 | RMSE: 0.0294 | Consistency: 0.0048 | SSIM: 0.0207 | Grad: 57473.969\n",
      "[Epoch 69, Batch 95/100] Loss: 0.0292 | RMSE: 0.0275 | Consistency: 0.0043 | SSIM: 0.0163 | Grad: 33187.785\n",
      "[Epoch 69, Batch 96/100] Loss: 0.0359 | RMSE: 0.0339 | Consistency: 0.0064 | SSIM: 0.0191 | Grad: 97291.305\n",
      "[Epoch 69, Batch 97/100] Loss: 0.0385 | RMSE: 0.0360 | Consistency: 0.0066 | SSIM: 0.0241 | Grad: 89166.570\n",
      "[Epoch 69, Batch 98/100] Loss: 0.0365 | RMSE: 0.0342 | Consistency: 0.0058 | SSIM: 0.0227 | Grad: 63342.516\n",
      "[Epoch 69, Batch 99/100] Loss: 0.0335 | RMSE: 0.0308 | Consistency: 0.0055 | SSIM: 0.0259 | Grad: 31211.131\n",
      "[Epoch 69, Batch 100/100] Loss: 0.0338 | RMSE: 0.0313 | Consistency: 0.0050 | SSIM: 0.0236 | Grad: 50685.969\n",
      "✅ Epoch 69 완료!\n",
      "   📈 평균 Loss: 0.036130\n",
      "   📊 평균 RMSE: 0.033726\n",
      "   ⚙️  학습률: 0.000056\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 70/80 시작...\n",
      "[Epoch 70, Batch 1/100] Loss: 0.0357 | RMSE: 0.0332 | Consistency: 0.0061 | SSIM: 0.0243 | Grad: 53284.129\n",
      "[Epoch 70, Batch 2/100] Loss: 0.0317 | RMSE: 0.0298 | Consistency: 0.0048 | SSIM: 0.0180 | Grad: 70591.500\n",
      "[Epoch 70, Batch 3/100] Loss: 0.0349 | RMSE: 0.0331 | Consistency: 0.0068 | SSIM: 0.0175 | Grad: 105355.398\n",
      "[Epoch 70, Batch 4/100] Loss: 0.0362 | RMSE: 0.0335 | Consistency: 0.0064 | SSIM: 0.0265 | Grad: 58991.094\n",
      "[Epoch 70, Batch 5/100] Loss: 0.0335 | RMSE: 0.0314 | Consistency: 0.0055 | SSIM: 0.0206 | Grad: 52950.887\n",
      "[Epoch 70, Batch 6/100] Loss: 0.0349 | RMSE: 0.0325 | Consistency: 0.0060 | SSIM: 0.0237 | Grad: 30795.283\n",
      "[Epoch 70, Batch 7/100] Loss: 0.0445 | RMSE: 0.0417 | Consistency: 0.0086 | SSIM: 0.0273 | Grad: 89333.102\n",
      "[Epoch 70, Batch 8/100] Loss: 0.0321 | RMSE: 0.0296 | Consistency: 0.0049 | SSIM: 0.0250 | Grad: 13073.055\n",
      "[Epoch 70, Batch 9/100] Loss: 0.0314 | RMSE: 0.0292 | Consistency: 0.0053 | SSIM: 0.0218 | Grad: 67876.656\n",
      "[Epoch 70, Batch 10/100] Loss: 0.0402 | RMSE: 0.0373 | Consistency: 0.0085 | SSIM: 0.0279 | Grad: 28204.607\n",
      "[Epoch 70, Batch 11/100] Loss: 0.0386 | RMSE: 0.0357 | Consistency: 0.0070 | SSIM: 0.0282 | Grad: 19895.818\n",
      "[Epoch 70, Batch 12/100] Loss: 0.0466 | RMSE: 0.0438 | Consistency: 0.0118 | SSIM: 0.0267 | Grad: 76559.117\n",
      "[Epoch 70, Batch 13/100] Loss: 0.0313 | RMSE: 0.0290 | Consistency: 0.0043 | SSIM: 0.0222 | Grad: 72714.672\n",
      "[Epoch 70, Batch 14/100] Loss: 0.0339 | RMSE: 0.0318 | Consistency: 0.0056 | SSIM: 0.0207 | Grad: 71503.875\n",
      "[Epoch 70, Batch 15/100] Loss: 0.0478 | RMSE: 0.0450 | Consistency: 0.0088 | SSIM: 0.0276 | Grad: 84889.031\n",
      "[Epoch 70, Batch 16/100] Loss: 0.0314 | RMSE: 0.0291 | Consistency: 0.0048 | SSIM: 0.0233 | Grad: 67025.742\n",
      "[Epoch 70, Batch 17/100] Loss: 0.0291 | RMSE: 0.0275 | Consistency: 0.0043 | SSIM: 0.0150 | Grad: 33408.668\n",
      "[Epoch 70, Batch 18/100] Loss: 0.0354 | RMSE: 0.0333 | Consistency: 0.0062 | SSIM: 0.0209 | Grad: 32539.238\n",
      "[Epoch 70, Batch 19/100] Loss: 0.0386 | RMSE: 0.0354 | Consistency: 0.0068 | SSIM: 0.0315 | Grad: 29960.197\n",
      "[Epoch 70, Batch 20/100] Loss: 0.0317 | RMSE: 0.0298 | Consistency: 0.0044 | SSIM: 0.0188 | Grad: 42767.914\n",
      "[Epoch 70, Batch 21/100] Loss: 0.0362 | RMSE: 0.0340 | Consistency: 0.0066 | SSIM: 0.0211 | Grad: 50074.117\n",
      "[Epoch 70, Batch 22/100] Loss: 0.0342 | RMSE: 0.0322 | Consistency: 0.0058 | SSIM: 0.0200 | Grad: 41402.250\n",
      "[Epoch 70, Batch 23/100] Loss: 0.0375 | RMSE: 0.0349 | Consistency: 0.0072 | SSIM: 0.0249 | Grad: 46749.102\n",
      "[Epoch 70, Batch 24/100] Loss: 0.0425 | RMSE: 0.0395 | Consistency: 0.0083 | SSIM: 0.0288 | Grad: 54851.750\n",
      "[Epoch 70, Batch 25/100] Loss: 0.0323 | RMSE: 0.0302 | Consistency: 0.0050 | SSIM: 0.0203 | Grad: 20640.498\n",
      "[Epoch 70, Batch 26/100] Loss: 0.0296 | RMSE: 0.0274 | Consistency: 0.0037 | SSIM: 0.0211 | Grad: 53646.230\n",
      "[Epoch 70, Batch 27/100] Loss: 0.0346 | RMSE: 0.0325 | Consistency: 0.0048 | SSIM: 0.0210 | Grad: 46955.965\n",
      "[Epoch 70, Batch 28/100] Loss: 0.0331 | RMSE: 0.0311 | Consistency: 0.0058 | SSIM: 0.0198 | Grad: 42935.996\n",
      "[Epoch 70, Batch 29/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0084 | SSIM: 0.0240 | Grad: 44212.352\n",
      "[Epoch 70, Batch 30/100] Loss: 0.0349 | RMSE: 0.0330 | Consistency: 0.0056 | SSIM: 0.0183 | Grad: 90989.820\n",
      "[Epoch 70, Batch 31/100] Loss: 0.0297 | RMSE: 0.0273 | Consistency: 0.0044 | SSIM: 0.0233 | Grad: 68244.680\n",
      "[Epoch 70, Batch 32/100] Loss: 0.0354 | RMSE: 0.0332 | Consistency: 0.0057 | SSIM: 0.0217 | Grad: 20048.318\n",
      "[Epoch 70, Batch 33/100] Loss: 0.0418 | RMSE: 0.0385 | Consistency: 0.0082 | SSIM: 0.0324 | Grad: 27458.047\n",
      "[Epoch 70, Batch 34/100] Loss: 0.0330 | RMSE: 0.0310 | Consistency: 0.0053 | SSIM: 0.0190 | Grad: 31921.561\n",
      "[Epoch 70, Batch 35/100] Loss: 0.0325 | RMSE: 0.0302 | Consistency: 0.0049 | SSIM: 0.0219 | Grad: 47654.906\n",
      "[Epoch 70, Batch 36/100] Loss: 0.0359 | RMSE: 0.0334 | Consistency: 0.0075 | SSIM: 0.0240 | Grad: 54634.914\n",
      "[Epoch 70, Batch 37/100] Loss: 0.0416 | RMSE: 0.0384 | Consistency: 0.0080 | SSIM: 0.0315 | Grad: 68562.750\n",
      "[Epoch 70, Batch 38/100] Loss: 0.0344 | RMSE: 0.0318 | Consistency: 0.0055 | SSIM: 0.0252 | Grad: 67771.297\n",
      "[Epoch 70, Batch 39/100] Loss: 0.0340 | RMSE: 0.0315 | Consistency: 0.0054 | SSIM: 0.0246 | Grad: 43318.129\n",
      "[Epoch 70, Batch 40/100] Loss: 0.0375 | RMSE: 0.0352 | Consistency: 0.0073 | SSIM: 0.0225 | Grad: 68911.039\n",
      "[Epoch 70, Batch 41/100] Loss: 0.0300 | RMSE: 0.0276 | Consistency: 0.0042 | SSIM: 0.0236 | Grad: 24331.844\n",
      "[Epoch 70, Batch 42/100] Loss: 0.0384 | RMSE: 0.0352 | Consistency: 0.0069 | SSIM: 0.0312 | Grad: 68628.016\n",
      "[Epoch 70, Batch 43/100] Loss: 0.0333 | RMSE: 0.0310 | Consistency: 0.0058 | SSIM: 0.0226 | Grad: 35917.977\n",
      "[Epoch 70, Batch 44/100] Loss: 0.0340 | RMSE: 0.0320 | Consistency: 0.0050 | SSIM: 0.0195 | Grad: 51859.547\n",
      "[Epoch 70, Batch 45/100] Loss: 0.0414 | RMSE: 0.0383 | Consistency: 0.0079 | SSIM: 0.0298 | Grad: 26154.557\n",
      "[Epoch 70, Batch 46/100] Loss: 0.0428 | RMSE: 0.0399 | Consistency: 0.0069 | SSIM: 0.0286 | Grad: 51160.926\n",
      "[Epoch 70, Batch 47/100] Loss: 0.0316 | RMSE: 0.0293 | Consistency: 0.0053 | SSIM: 0.0226 | Grad: 55396.004\n",
      "[Epoch 70, Batch 48/100] Loss: 0.0374 | RMSE: 0.0348 | Consistency: 0.0068 | SSIM: 0.0255 | Grad: 31215.207\n",
      "[Epoch 70, Batch 49/100] Loss: 0.0367 | RMSE: 0.0342 | Consistency: 0.0055 | SSIM: 0.0244 | Grad: 33219.980\n",
      "[Epoch 70, Batch 50/100] Loss: 0.0328 | RMSE: 0.0309 | Consistency: 0.0054 | SSIM: 0.0184 | Grad: 76147.234\n",
      "[Epoch 70, Batch 51/100] Loss: 0.0366 | RMSE: 0.0338 | Consistency: 0.0056 | SSIM: 0.0276 | Grad: 109748.406\n",
      "[Epoch 70, Batch 52/100] Loss: 0.0306 | RMSE: 0.0285 | Consistency: 0.0048 | SSIM: 0.0205 | Grad: 63181.531\n",
      "[Epoch 70, Batch 53/100] Loss: 0.0406 | RMSE: 0.0382 | Consistency: 0.0066 | SSIM: 0.0243 | Grad: 59062.461\n",
      "[Epoch 70, Batch 54/100] Loss: 0.0391 | RMSE: 0.0368 | Consistency: 0.0077 | SSIM: 0.0220 | Grad: 64453.215\n",
      "[Epoch 70, Batch 55/100] Loss: 0.0349 | RMSE: 0.0326 | Consistency: 0.0055 | SSIM: 0.0224 | Grad: 27840.199\n",
      "[Epoch 70, Batch 56/100] Loss: 0.0373 | RMSE: 0.0349 | Consistency: 0.0061 | SSIM: 0.0239 | Grad: 83120.617\n",
      "[Epoch 70, Batch 57/100] Loss: 0.0345 | RMSE: 0.0319 | Consistency: 0.0059 | SSIM: 0.0255 | Grad: 80590.453\n",
      "[Epoch 70, Batch 58/100] Loss: 0.0366 | RMSE: 0.0341 | Consistency: 0.0064 | SSIM: 0.0239 | Grad: 56798.215\n",
      "[Epoch 70, Batch 59/100] Loss: 0.0324 | RMSE: 0.0305 | Consistency: 0.0041 | SSIM: 0.0195 | Grad: 67771.742\n",
      "[Epoch 70, Batch 60/100] Loss: 0.0317 | RMSE: 0.0300 | Consistency: 0.0050 | SSIM: 0.0170 | Grad: 31921.312\n",
      "[Epoch 70, Batch 61/100] Loss: 0.0368 | RMSE: 0.0345 | Consistency: 0.0059 | SSIM: 0.0221 | Grad: 73026.484\n",
      "[Epoch 70, Batch 62/100] Loss: 0.0289 | RMSE: 0.0272 | Consistency: 0.0041 | SSIM: 0.0165 | Grad: 52754.656\n",
      "[Epoch 70, Batch 63/100] Loss: 0.0305 | RMSE: 0.0284 | Consistency: 0.0044 | SSIM: 0.0204 | Grad: 59953.758\n",
      "[Epoch 70, Batch 64/100] Loss: 0.0300 | RMSE: 0.0282 | Consistency: 0.0046 | SSIM: 0.0175 | Grad: 33008.797\n",
      "[Epoch 70, Batch 65/100] Loss: 0.0327 | RMSE: 0.0306 | Consistency: 0.0054 | SSIM: 0.0203 | Grad: 21627.518\n",
      "[Epoch 70, Batch 66/100] Loss: 0.0354 | RMSE: 0.0330 | Consistency: 0.0057 | SSIM: 0.0235 | Grad: 48849.539\n",
      "[Epoch 70, Batch 67/100] Loss: 0.0330 | RMSE: 0.0308 | Consistency: 0.0050 | SSIM: 0.0219 | Grad: 40049.496\n",
      "[Epoch 70, Batch 68/100] Loss: 0.0412 | RMSE: 0.0381 | Consistency: 0.0070 | SSIM: 0.0298 | Grad: 45509.059\n",
      "[Epoch 70, Batch 69/100] Loss: 0.0340 | RMSE: 0.0316 | Consistency: 0.0051 | SSIM: 0.0229 | Grad: 53506.734\n",
      "[Epoch 70, Batch 70/100] Loss: 0.0313 | RMSE: 0.0290 | Consistency: 0.0044 | SSIM: 0.0229 | Grad: 35760.344\n",
      "[Epoch 70, Batch 71/100] Loss: 0.0307 | RMSE: 0.0289 | Consistency: 0.0046 | SSIM: 0.0172 | Grad: 55726.387\n",
      "[Epoch 70, Batch 72/100] Loss: 0.0329 | RMSE: 0.0308 | Consistency: 0.0053 | SSIM: 0.0199 | Grad: 34735.074\n",
      "[Epoch 70, Batch 73/100] Loss: 0.0385 | RMSE: 0.0360 | Consistency: 0.0069 | SSIM: 0.0240 | Grad: 44325.574\n",
      "[Epoch 70, Batch 74/100] Loss: 0.0342 | RMSE: 0.0321 | Consistency: 0.0049 | SSIM: 0.0202 | Grad: 80245.164\n",
      "[Epoch 70, Batch 75/100] Loss: 0.0353 | RMSE: 0.0330 | Consistency: 0.0057 | SSIM: 0.0224 | Grad: 24424.107\n",
      "[Epoch 70, Batch 76/100] Loss: 0.0352 | RMSE: 0.0324 | Consistency: 0.0060 | SSIM: 0.0273 | Grad: 28131.582\n",
      "[Epoch 70, Batch 77/100] Loss: 0.0379 | RMSE: 0.0352 | Consistency: 0.0073 | SSIM: 0.0255 | Grad: 51309.645\n",
      "[Epoch 70, Batch 78/100] Loss: 0.0317 | RMSE: 0.0296 | Consistency: 0.0046 | SSIM: 0.0202 | Grad: 25708.387\n",
      "[Epoch 70, Batch 79/100] Loss: 0.0356 | RMSE: 0.0335 | Consistency: 0.0054 | SSIM: 0.0202 | Grad: 33931.590\n",
      "[Epoch 70, Batch 80/100] Loss: 0.0316 | RMSE: 0.0298 | Consistency: 0.0050 | SSIM: 0.0177 | Grad: 37472.281\n",
      "[Epoch 70, Batch 81/100] Loss: 0.0282 | RMSE: 0.0268 | Consistency: 0.0032 | SSIM: 0.0139 | Grad: 61774.207\n",
      "[Epoch 70, Batch 82/100] Loss: 0.0328 | RMSE: 0.0306 | Consistency: 0.0049 | SSIM: 0.0215 | Grad: 86710.992\n",
      "[Epoch 70, Batch 83/100] Loss: 0.0333 | RMSE: 0.0312 | Consistency: 0.0055 | SSIM: 0.0202 | Grad: 60072.438\n",
      "[Epoch 70, Batch 84/100] Loss: 0.0324 | RMSE: 0.0303 | Consistency: 0.0053 | SSIM: 0.0195 | Grad: 56543.168\n",
      "[Epoch 70, Batch 85/100] Loss: 0.0338 | RMSE: 0.0315 | Consistency: 0.0054 | SSIM: 0.0216 | Grad: 38618.059\n",
      "[Epoch 70, Batch 86/100] Loss: 0.0373 | RMSE: 0.0347 | Consistency: 0.0076 | SSIM: 0.0256 | Grad: 28526.311\n",
      "[Epoch 70, Batch 87/100] Loss: 0.0294 | RMSE: 0.0275 | Consistency: 0.0044 | SSIM: 0.0185 | Grad: 33822.195\n",
      "[Epoch 70, Batch 88/100] Loss: 0.0360 | RMSE: 0.0333 | Consistency: 0.0068 | SSIM: 0.0269 | Grad: 48650.164\n",
      "[Epoch 70, Batch 89/100] Loss: 0.0318 | RMSE: 0.0294 | Consistency: 0.0047 | SSIM: 0.0236 | Grad: 31589.150\n",
      "[Epoch 70, Batch 90/100] Loss: 0.0357 | RMSE: 0.0336 | Consistency: 0.0060 | SSIM: 0.0201 | Grad: 49178.227\n",
      "[Epoch 70, Batch 91/100] Loss: 0.0332 | RMSE: 0.0303 | Consistency: 0.0055 | SSIM: 0.0279 | Grad: 69154.359\n",
      "[Epoch 70, Batch 92/100] Loss: 0.0330 | RMSE: 0.0306 | Consistency: 0.0045 | SSIM: 0.0237 | Grad: 34938.914\n",
      "[Epoch 70, Batch 93/100] Loss: 0.0336 | RMSE: 0.0314 | Consistency: 0.0048 | SSIM: 0.0224 | Grad: 46796.746\n",
      "[Epoch 70, Batch 94/100] Loss: 0.0351 | RMSE: 0.0327 | Consistency: 0.0062 | SSIM: 0.0228 | Grad: 28310.676\n",
      "[Epoch 70, Batch 95/100] Loss: 0.0429 | RMSE: 0.0400 | Consistency: 0.0077 | SSIM: 0.0288 | Grad: 48229.656\n",
      "[Epoch 70, Batch 96/100] Loss: 0.0288 | RMSE: 0.0271 | Consistency: 0.0047 | SSIM: 0.0171 | Grad: 59243.918\n",
      "[Epoch 70, Batch 97/100] Loss: 0.0403 | RMSE: 0.0381 | Consistency: 0.0072 | SSIM: 0.0211 | Grad: 55970.852\n",
      "[Epoch 70, Batch 98/100] Loss: 0.0333 | RMSE: 0.0312 | Consistency: 0.0048 | SSIM: 0.0207 | Grad: 46890.430\n",
      "[Epoch 70, Batch 99/100] Loss: 0.0309 | RMSE: 0.0285 | Consistency: 0.0045 | SSIM: 0.0232 | Grad: 65632.461\n",
      "[Epoch 70, Batch 100/100] Loss: 0.0477 | RMSE: 0.0447 | Consistency: 0.0143 | SSIM: 0.0286 | Grad: 38378.004\n",
      "✅ Epoch 70 완료!\n",
      "   📈 평균 Loss: 0.035094\n",
      "   📊 평균 RMSE: 0.032749\n",
      "   ⚙️  학습률: 0.000047\n",
      "   🏆 NEW BEST! RMSE: 0.032749\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 71/80 시작...\n",
      "[Epoch 71, Batch 1/100] Loss: 0.0352 | RMSE: 0.0326 | Consistency: 0.0062 | SSIM: 0.0261 | Grad: 38480.664\n",
      "[Epoch 71, Batch 2/100] Loss: 0.0407 | RMSE: 0.0381 | Consistency: 0.0081 | SSIM: 0.0251 | Grad: 58696.926\n",
      "[Epoch 71, Batch 3/100] Loss: 0.0286 | RMSE: 0.0266 | Consistency: 0.0037 | SSIM: 0.0202 | Grad: 38680.148\n",
      "[Epoch 71, Batch 4/100] Loss: 0.0361 | RMSE: 0.0332 | Consistency: 0.0064 | SSIM: 0.0286 | Grad: 37361.199\n",
      "[Epoch 71, Batch 5/100] Loss: 0.0356 | RMSE: 0.0334 | Consistency: 0.0062 | SSIM: 0.0211 | Grad: 61237.141\n",
      "[Epoch 71, Batch 6/100] Loss: 0.0363 | RMSE: 0.0339 | Consistency: 0.0063 | SSIM: 0.0235 | Grad: 54914.008\n",
      "[Epoch 71, Batch 7/100] Loss: 0.0346 | RMSE: 0.0327 | Consistency: 0.0059 | SSIM: 0.0182 | Grad: 19472.285\n",
      "[Epoch 71, Batch 8/100] Loss: 0.0343 | RMSE: 0.0317 | Consistency: 0.0057 | SSIM: 0.0257 | Grad: 63893.262\n",
      "[Epoch 71, Batch 9/100] Loss: 0.0353 | RMSE: 0.0332 | Consistency: 0.0055 | SSIM: 0.0207 | Grad: 52508.066\n",
      "[Epoch 71, Batch 10/100] Loss: 0.0329 | RMSE: 0.0304 | Consistency: 0.0056 | SSIM: 0.0245 | Grad: 22212.541\n",
      "[Epoch 71, Batch 11/100] Loss: 0.0370 | RMSE: 0.0349 | Consistency: 0.0057 | SSIM: 0.0203 | Grad: 75535.664\n",
      "[Epoch 71, Batch 12/100] Loss: 0.0342 | RMSE: 0.0317 | Consistency: 0.0055 | SSIM: 0.0248 | Grad: 40199.223\n",
      "[Epoch 71, Batch 13/100] Loss: 0.0417 | RMSE: 0.0386 | Consistency: 0.0097 | SSIM: 0.0293 | Grad: 12995.681\n",
      "[Epoch 71, Batch 14/100] Loss: 0.0346 | RMSE: 0.0323 | Consistency: 0.0063 | SSIM: 0.0225 | Grad: 78487.359\n",
      "[Epoch 71, Batch 15/100] Loss: 0.0319 | RMSE: 0.0302 | Consistency: 0.0051 | SSIM: 0.0168 | Grad: 75643.273\n",
      "[Epoch 71, Batch 16/100] Loss: 0.0357 | RMSE: 0.0335 | Consistency: 0.0063 | SSIM: 0.0211 | Grad: 83292.461\n",
      "[Epoch 71, Batch 17/100] Loss: 0.0377 | RMSE: 0.0355 | Consistency: 0.0072 | SSIM: 0.0214 | Grad: 60148.727\n",
      "[Epoch 71, Batch 18/100] Loss: 0.0327 | RMSE: 0.0306 | Consistency: 0.0048 | SSIM: 0.0211 | Grad: 61036.316\n",
      "[Epoch 71, Batch 19/100] Loss: 0.0314 | RMSE: 0.0296 | Consistency: 0.0045 | SSIM: 0.0178 | Grad: 83985.336\n",
      "[Epoch 71, Batch 20/100] Loss: 0.0325 | RMSE: 0.0307 | Consistency: 0.0048 | SSIM: 0.0177 | Grad: 26363.424\n",
      "[Epoch 71, Batch 21/100] Loss: 0.0300 | RMSE: 0.0279 | Consistency: 0.0041 | SSIM: 0.0210 | Grad: 81814.078\n",
      "[Epoch 71, Batch 22/100] Loss: 0.0336 | RMSE: 0.0316 | Consistency: 0.0055 | SSIM: 0.0197 | Grad: 71193.922\n",
      "[Epoch 71, Batch 23/100] Loss: 0.0317 | RMSE: 0.0293 | Consistency: 0.0058 | SSIM: 0.0236 | Grad: 59203.887\n",
      "[Epoch 71, Batch 24/100] Loss: 0.0378 | RMSE: 0.0354 | Consistency: 0.0076 | SSIM: 0.0235 | Grad: 64541.223\n",
      "[Epoch 71, Batch 25/100] Loss: 0.0366 | RMSE: 0.0341 | Consistency: 0.0058 | SSIM: 0.0241 | Grad: 32631.156\n",
      "[Epoch 71, Batch 26/100] Loss: 0.0352 | RMSE: 0.0326 | Consistency: 0.0058 | SSIM: 0.0256 | Grad: 45471.477\n",
      "[Epoch 71, Batch 27/100] Loss: 0.0345 | RMSE: 0.0323 | Consistency: 0.0061 | SSIM: 0.0211 | Grad: 69875.273\n",
      "[Epoch 71, Batch 28/100] Loss: 0.0381 | RMSE: 0.0355 | Consistency: 0.0062 | SSIM: 0.0258 | Grad: 64269.660\n",
      "[Epoch 71, Batch 29/100] Loss: 0.0336 | RMSE: 0.0315 | Consistency: 0.0047 | SSIM: 0.0206 | Grad: 99283.578\n",
      "[Epoch 71, Batch 30/100] Loss: 0.0349 | RMSE: 0.0327 | Consistency: 0.0064 | SSIM: 0.0215 | Grad: 29819.438\n",
      "[Epoch 71, Batch 31/100] Loss: 0.0356 | RMSE: 0.0330 | Consistency: 0.0057 | SSIM: 0.0257 | Grad: 71483.695\n",
      "[Epoch 71, Batch 32/100] Loss: 0.0332 | RMSE: 0.0310 | Consistency: 0.0059 | SSIM: 0.0223 | Grad: 43640.621\n",
      "[Epoch 71, Batch 33/100] Loss: 0.0320 | RMSE: 0.0299 | Consistency: 0.0052 | SSIM: 0.0201 | Grad: 78486.305\n",
      "[Epoch 71, Batch 34/100] Loss: 0.0396 | RMSE: 0.0367 | Consistency: 0.0081 | SSIM: 0.0280 | Grad: 86436.742\n",
      "[Epoch 71, Batch 35/100] Loss: 0.0328 | RMSE: 0.0305 | Consistency: 0.0047 | SSIM: 0.0228 | Grad: 60817.379\n",
      "[Epoch 71, Batch 36/100] Loss: 0.0316 | RMSE: 0.0293 | Consistency: 0.0042 | SSIM: 0.0230 | Grad: 89345.188\n",
      "[Epoch 71, Batch 37/100] Loss: 0.0373 | RMSE: 0.0351 | Consistency: 0.0077 | SSIM: 0.0213 | Grad: 57272.586\n",
      "[Epoch 71, Batch 38/100] Loss: 0.0400 | RMSE: 0.0374 | Consistency: 0.0065 | SSIM: 0.0257 | Grad: 67151.531\n",
      "[Epoch 71, Batch 39/100] Loss: 0.0301 | RMSE: 0.0281 | Consistency: 0.0046 | SSIM: 0.0196 | Grad: 29784.641\n",
      "[Epoch 71, Batch 40/100] Loss: 0.0319 | RMSE: 0.0302 | Consistency: 0.0039 | SSIM: 0.0157 | Grad: 67074.625\n",
      "[Epoch 71, Batch 41/100] Loss: 0.0333 | RMSE: 0.0311 | Consistency: 0.0057 | SSIM: 0.0219 | Grad: 57479.047\n",
      "[Epoch 71, Batch 42/100] Loss: 0.0391 | RMSE: 0.0359 | Consistency: 0.0086 | SSIM: 0.0313 | Grad: 45774.605\n",
      "[Epoch 71, Batch 43/100] Loss: 0.0318 | RMSE: 0.0300 | Consistency: 0.0045 | SSIM: 0.0174 | Grad: 69387.109\n",
      "[Epoch 71, Batch 44/100] Loss: 0.0340 | RMSE: 0.0317 | Consistency: 0.0052 | SSIM: 0.0224 | Grad: 69767.648\n",
      "[Epoch 71, Batch 45/100] Loss: 0.0384 | RMSE: 0.0356 | Consistency: 0.0071 | SSIM: 0.0276 | Grad: 52984.996\n",
      "[Epoch 71, Batch 46/100] Loss: 0.0408 | RMSE: 0.0385 | Consistency: 0.0065 | SSIM: 0.0222 | Grad: 73368.562\n",
      "[Epoch 71, Batch 47/100] Loss: 0.0384 | RMSE: 0.0358 | Consistency: 0.0066 | SSIM: 0.0253 | Grad: 103847.359\n",
      "[Epoch 71, Batch 48/100] Loss: 0.0354 | RMSE: 0.0330 | Consistency: 0.0057 | SSIM: 0.0234 | Grad: 62961.898\n",
      "[Epoch 71, Batch 49/100] Loss: 0.0292 | RMSE: 0.0272 | Consistency: 0.0041 | SSIM: 0.0193 | Grad: 91984.609\n",
      "[Epoch 71, Batch 50/100] Loss: 0.0349 | RMSE: 0.0325 | Consistency: 0.0050 | SSIM: 0.0228 | Grad: 139437.906\n",
      "[Epoch 71, Batch 51/100] Loss: 0.0334 | RMSE: 0.0310 | Consistency: 0.0047 | SSIM: 0.0234 | Grad: 92226.289\n",
      "[Epoch 71, Batch 52/100] Loss: 0.0333 | RMSE: 0.0311 | Consistency: 0.0050 | SSIM: 0.0206 | Grad: 72187.625\n",
      "[Epoch 71, Batch 53/100] Loss: 0.0362 | RMSE: 0.0341 | Consistency: 0.0063 | SSIM: 0.0204 | Grad: 46088.191\n",
      "[Epoch 71, Batch 54/100] Loss: 0.0273 | RMSE: 0.0251 | Consistency: 0.0033 | SSIM: 0.0207 | Grad: 48959.504\n",
      "[Epoch 71, Batch 55/100] Loss: 0.0352 | RMSE: 0.0325 | Consistency: 0.0055 | SSIM: 0.0255 | Grad: 37418.219\n",
      "[Epoch 71, Batch 56/100] Loss: 0.0335 | RMSE: 0.0309 | Consistency: 0.0055 | SSIM: 0.0257 | Grad: 53523.027\n",
      "[Epoch 71, Batch 57/100] Loss: 0.0318 | RMSE: 0.0297 | Consistency: 0.0050 | SSIM: 0.0203 | Grad: 58874.496\n",
      "[Epoch 71, Batch 58/100] Loss: 0.0306 | RMSE: 0.0289 | Consistency: 0.0047 | SSIM: 0.0173 | Grad: 49902.168\n",
      "[Epoch 71, Batch 59/100] Loss: 0.0327 | RMSE: 0.0303 | Consistency: 0.0050 | SSIM: 0.0231 | Grad: 25701.684\n",
      "[Epoch 71, Batch 60/100] Loss: 0.0328 | RMSE: 0.0307 | Consistency: 0.0054 | SSIM: 0.0202 | Grad: 40383.672\n",
      "[Epoch 71, Batch 61/100] Loss: 0.0320 | RMSE: 0.0296 | Consistency: 0.0049 | SSIM: 0.0238 | Grad: 69575.547\n",
      "[Epoch 71, Batch 62/100] Loss: 0.0320 | RMSE: 0.0296 | Consistency: 0.0046 | SSIM: 0.0234 | Grad: 48527.836\n",
      "[Epoch 71, Batch 63/100] Loss: 0.0369 | RMSE: 0.0347 | Consistency: 0.0068 | SSIM: 0.0213 | Grad: 78432.602\n",
      "[Epoch 71, Batch 64/100] Loss: 0.0388 | RMSE: 0.0359 | Consistency: 0.0065 | SSIM: 0.0279 | Grad: 75677.516\n",
      "[Epoch 71, Batch 65/100] Loss: 0.0335 | RMSE: 0.0313 | Consistency: 0.0054 | SSIM: 0.0214 | Grad: 78826.820\n",
      "[Epoch 71, Batch 66/100] Loss: 0.0286 | RMSE: 0.0263 | Consistency: 0.0036 | SSIM: 0.0226 | Grad: 74317.625\n",
      "[Epoch 71, Batch 67/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0054 | SSIM: 0.0204 | Grad: 47943.766\n",
      "[Epoch 71, Batch 68/100] Loss: 0.0418 | RMSE: 0.0391 | Consistency: 0.0074 | SSIM: 0.0265 | Grad: 72363.070\n",
      "[Epoch 71, Batch 69/100] Loss: 0.0362 | RMSE: 0.0341 | Consistency: 0.0061 | SSIM: 0.0205 | Grad: 50507.484\n",
      "[Epoch 71, Batch 70/100] Loss: 0.0352 | RMSE: 0.0326 | Consistency: 0.0069 | SSIM: 0.0253 | Grad: 40208.480\n",
      "[Epoch 71, Batch 71/100] Loss: 0.0420 | RMSE: 0.0393 | Consistency: 0.0087 | SSIM: 0.0255 | Grad: 35046.246\n",
      "[Epoch 71, Batch 72/100] Loss: 0.0318 | RMSE: 0.0296 | Consistency: 0.0050 | SSIM: 0.0218 | Grad: 33171.855\n",
      "[Epoch 71, Batch 73/100] Loss: 0.0342 | RMSE: 0.0316 | Consistency: 0.0057 | SSIM: 0.0252 | Grad: 27184.199\n",
      "[Epoch 71, Batch 74/100] Loss: 0.0352 | RMSE: 0.0323 | Consistency: 0.0054 | SSIM: 0.0289 | Grad: 32717.381\n",
      "[Epoch 71, Batch 75/100] Loss: 0.0329 | RMSE: 0.0311 | Consistency: 0.0052 | SSIM: 0.0176 | Grad: 42356.621\n",
      "[Epoch 71, Batch 76/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0063 | SSIM: 0.0200 | Grad: 56920.340\n",
      "[Epoch 71, Batch 77/100] Loss: 0.0449 | RMSE: 0.0418 | Consistency: 0.0086 | SSIM: 0.0303 | Grad: 38036.539\n",
      "[Epoch 71, Batch 78/100] Loss: 0.0389 | RMSE: 0.0362 | Consistency: 0.0056 | SSIM: 0.0265 | Grad: 88663.422\n",
      "[Epoch 71, Batch 79/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0052 | SSIM: 0.0238 | Grad: 48919.352\n",
      "[Epoch 71, Batch 80/100] Loss: 0.0318 | RMSE: 0.0299 | Consistency: 0.0052 | SSIM: 0.0186 | Grad: 58125.633\n",
      "[Epoch 71, Batch 81/100] Loss: 0.0325 | RMSE: 0.0301 | Consistency: 0.0046 | SSIM: 0.0233 | Grad: 61585.480\n",
      "[Epoch 71, Batch 82/100] Loss: 0.0389 | RMSE: 0.0364 | Consistency: 0.0074 | SSIM: 0.0245 | Grad: 84675.492\n",
      "[Epoch 71, Batch 83/100] Loss: 0.0352 | RMSE: 0.0330 | Consistency: 0.0062 | SSIM: 0.0211 | Grad: 70372.977\n",
      "[Epoch 71, Batch 84/100] Loss: 0.0398 | RMSE: 0.0368 | Consistency: 0.0083 | SSIM: 0.0284 | Grad: 44008.262\n",
      "[Epoch 71, Batch 85/100] Loss: 0.0325 | RMSE: 0.0300 | Consistency: 0.0053 | SSIM: 0.0239 | Grad: 37316.023\n",
      "[Epoch 71, Batch 86/100] Loss: 0.0370 | RMSE: 0.0346 | Consistency: 0.0061 | SSIM: 0.0226 | Grad: 61403.488\n",
      "[Epoch 71, Batch 87/100] Loss: 0.0329 | RMSE: 0.0301 | Consistency: 0.0055 | SSIM: 0.0278 | Grad: 43553.473\n",
      "[Epoch 71, Batch 88/100] Loss: 0.0332 | RMSE: 0.0308 | Consistency: 0.0058 | SSIM: 0.0239 | Grad: 36183.484\n",
      "[Epoch 71, Batch 89/100] Loss: 0.0302 | RMSE: 0.0284 | Consistency: 0.0045 | SSIM: 0.0179 | Grad: 53875.547\n",
      "[Epoch 71, Batch 90/100] Loss: 0.0345 | RMSE: 0.0324 | Consistency: 0.0054 | SSIM: 0.0206 | Grad: 12218.604\n",
      "[Epoch 71, Batch 91/100] Loss: 0.0347 | RMSE: 0.0325 | Consistency: 0.0061 | SSIM: 0.0209 | Grad: 32856.828\n",
      "[Epoch 71, Batch 92/100] Loss: 0.0368 | RMSE: 0.0333 | Consistency: 0.0066 | SSIM: 0.0340 | Grad: 31708.721\n",
      "[Epoch 71, Batch 93/100] Loss: 0.0332 | RMSE: 0.0305 | Consistency: 0.0051 | SSIM: 0.0261 | Grad: 73120.961\n",
      "[Epoch 71, Batch 94/100] Loss: 0.0374 | RMSE: 0.0353 | Consistency: 0.0055 | SSIM: 0.0205 | Grad: 104637.781\n",
      "[Epoch 71, Batch 95/100] Loss: 0.0332 | RMSE: 0.0312 | Consistency: 0.0050 | SSIM: 0.0192 | Grad: 42473.199\n",
      "[Epoch 71, Batch 96/100] Loss: 0.0385 | RMSE: 0.0356 | Consistency: 0.0082 | SSIM: 0.0278 | Grad: 74254.414\n",
      "[Epoch 71, Batch 97/100] Loss: 0.0322 | RMSE: 0.0303 | Consistency: 0.0046 | SSIM: 0.0186 | Grad: 50602.695\n",
      "[Epoch 71, Batch 98/100] Loss: 0.0361 | RMSE: 0.0339 | Consistency: 0.0068 | SSIM: 0.0213 | Grad: 18763.418\n",
      "[Epoch 71, Batch 99/100] Loss: 0.0396 | RMSE: 0.0369 | Consistency: 0.0074 | SSIM: 0.0255 | Grad: 60719.012\n",
      "[Epoch 71, Batch 100/100] Loss: 0.0335 | RMSE: 0.0310 | Consistency: 0.0058 | SSIM: 0.0246 | Grad: 63736.844\n",
      "✅ Epoch 71 완료!\n",
      "   📈 평균 Loss: 0.034844\n",
      "   📊 평균 RMSE: 0.032495\n",
      "   ⚙️  학습률: 0.000038\n",
      "   🏆 NEW BEST! RMSE: 0.032495\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 72/80 시작...\n",
      "[Epoch 72, Batch 1/100] Loss: 0.0328 | RMSE: 0.0309 | Consistency: 0.0053 | SSIM: 0.0190 | Grad: 60003.945\n",
      "[Epoch 72, Batch 2/100] Loss: 0.0309 | RMSE: 0.0291 | Consistency: 0.0047 | SSIM: 0.0175 | Grad: 52782.328\n",
      "[Epoch 72, Batch 3/100] Loss: 0.0314 | RMSE: 0.0293 | Consistency: 0.0048 | SSIM: 0.0204 | Grad: 43870.301\n",
      "[Epoch 72, Batch 4/100] Loss: 0.0346 | RMSE: 0.0320 | Consistency: 0.0063 | SSIM: 0.0255 | Grad: 56108.758\n",
      "[Epoch 72, Batch 5/100] Loss: 0.0334 | RMSE: 0.0311 | Consistency: 0.0056 | SSIM: 0.0225 | Grad: 34580.117\n",
      "[Epoch 72, Batch 6/100] Loss: 0.0315 | RMSE: 0.0295 | Consistency: 0.0046 | SSIM: 0.0194 | Grad: 65777.531\n",
      "[Epoch 72, Batch 7/100] Loss: 0.0344 | RMSE: 0.0321 | Consistency: 0.0058 | SSIM: 0.0223 | Grad: 28231.631\n",
      "[Epoch 72, Batch 8/100] Loss: 0.0293 | RMSE: 0.0271 | Consistency: 0.0038 | SSIM: 0.0213 | Grad: 67233.703\n",
      "[Epoch 72, Batch 9/100] Loss: 0.0348 | RMSE: 0.0323 | Consistency: 0.0054 | SSIM: 0.0251 | Grad: 28160.533\n",
      "[Epoch 72, Batch 10/100] Loss: 0.0348 | RMSE: 0.0327 | Consistency: 0.0054 | SSIM: 0.0208 | Grad: 59395.879\n",
      "[Epoch 72, Batch 11/100] Loss: 0.0407 | RMSE: 0.0376 | Consistency: 0.0077 | SSIM: 0.0303 | Grad: 16828.525\n",
      "[Epoch 72, Batch 12/100] Loss: 0.0336 | RMSE: 0.0315 | Consistency: 0.0057 | SSIM: 0.0201 | Grad: 46600.391\n",
      "[Epoch 72, Batch 13/100] Loss: 0.0338 | RMSE: 0.0314 | Consistency: 0.0051 | SSIM: 0.0236 | Grad: 87509.078\n",
      "[Epoch 72, Batch 14/100] Loss: 0.0320 | RMSE: 0.0297 | Consistency: 0.0047 | SSIM: 0.0219 | Grad: 69815.922\n",
      "[Epoch 72, Batch 15/100] Loss: 0.0326 | RMSE: 0.0307 | Consistency: 0.0053 | SSIM: 0.0181 | Grad: 56007.527\n",
      "[Epoch 72, Batch 16/100] Loss: 0.0348 | RMSE: 0.0327 | Consistency: 0.0047 | SSIM: 0.0197 | Grad: 113615.672\n",
      "[Epoch 72, Batch 17/100] Loss: 0.0319 | RMSE: 0.0295 | Consistency: 0.0049 | SSIM: 0.0232 | Grad: 31995.301\n",
      "[Epoch 72, Batch 18/100] Loss: 0.0320 | RMSE: 0.0295 | Consistency: 0.0051 | SSIM: 0.0249 | Grad: 22197.646\n",
      "[Epoch 72, Batch 19/100] Loss: 0.0336 | RMSE: 0.0313 | Consistency: 0.0049 | SSIM: 0.0230 | Grad: 57804.773\n",
      "[Epoch 72, Batch 20/100] Loss: 0.0394 | RMSE: 0.0362 | Consistency: 0.0079 | SSIM: 0.0309 | Grad: 98603.742\n",
      "[Epoch 72, Batch 21/100] Loss: 0.0364 | RMSE: 0.0342 | Consistency: 0.0064 | SSIM: 0.0213 | Grad: 37003.227\n",
      "[Epoch 72, Batch 22/100] Loss: 0.0400 | RMSE: 0.0368 | Consistency: 0.0084 | SSIM: 0.0307 | Grad: 64613.871\n",
      "[Epoch 72, Batch 23/100] Loss: 0.0376 | RMSE: 0.0354 | Consistency: 0.0072 | SSIM: 0.0217 | Grad: 70080.617\n",
      "[Epoch 72, Batch 24/100] Loss: 0.0312 | RMSE: 0.0290 | Consistency: 0.0048 | SSIM: 0.0209 | Grad: 39643.875\n",
      "[Epoch 72, Batch 25/100] Loss: 0.0326 | RMSE: 0.0309 | Consistency: 0.0047 | SSIM: 0.0160 | Grad: 32467.215\n",
      "[Epoch 72, Batch 26/100] Loss: 0.0346 | RMSE: 0.0318 | Consistency: 0.0057 | SSIM: 0.0276 | Grad: 39836.508\n",
      "[Epoch 72, Batch 27/100] Loss: 0.0382 | RMSE: 0.0352 | Consistency: 0.0062 | SSIM: 0.0290 | Grad: 44323.145\n",
      "[Epoch 72, Batch 28/100] Loss: 0.0334 | RMSE: 0.0314 | Consistency: 0.0061 | SSIM: 0.0190 | Grad: 62600.395\n",
      "[Epoch 72, Batch 29/100] Loss: 0.0348 | RMSE: 0.0326 | Consistency: 0.0061 | SSIM: 0.0216 | Grad: 40903.328\n",
      "[Epoch 72, Batch 30/100] Loss: 0.0346 | RMSE: 0.0326 | Consistency: 0.0052 | SSIM: 0.0200 | Grad: 62715.160\n",
      "[Epoch 72, Batch 31/100] Loss: 0.0353 | RMSE: 0.0329 | Consistency: 0.0062 | SSIM: 0.0227 | Grad: 45840.258\n",
      "[Epoch 72, Batch 32/100] Loss: 0.0362 | RMSE: 0.0341 | Consistency: 0.0066 | SSIM: 0.0208 | Grad: 40460.887\n",
      "[Epoch 72, Batch 33/100] Loss: 0.0377 | RMSE: 0.0354 | Consistency: 0.0074 | SSIM: 0.0224 | Grad: 43319.488\n",
      "[Epoch 72, Batch 34/100] Loss: 0.0362 | RMSE: 0.0340 | Consistency: 0.0074 | SSIM: 0.0218 | Grad: 30221.320\n",
      "[Epoch 72, Batch 35/100] Loss: 0.0378 | RMSE: 0.0349 | Consistency: 0.0076 | SSIM: 0.0279 | Grad: 38829.742\n",
      "[Epoch 72, Batch 36/100] Loss: 0.0329 | RMSE: 0.0305 | Consistency: 0.0054 | SSIM: 0.0230 | Grad: 51623.465\n",
      "[Epoch 72, Batch 37/100] Loss: 0.0350 | RMSE: 0.0329 | Consistency: 0.0058 | SSIM: 0.0211 | Grad: 33923.383\n",
      "[Epoch 72, Batch 38/100] Loss: 0.0295 | RMSE: 0.0276 | Consistency: 0.0047 | SSIM: 0.0185 | Grad: 47624.750\n",
      "[Epoch 72, Batch 39/100] Loss: 0.0315 | RMSE: 0.0292 | Consistency: 0.0053 | SSIM: 0.0219 | Grad: 41265.184\n",
      "[Epoch 72, Batch 40/100] Loss: 0.0397 | RMSE: 0.0372 | Consistency: 0.0075 | SSIM: 0.0247 | Grad: 37985.867\n",
      "[Epoch 72, Batch 41/100] Loss: 0.0311 | RMSE: 0.0286 | Consistency: 0.0050 | SSIM: 0.0249 | Grad: 54636.359\n",
      "[Epoch 72, Batch 42/100] Loss: 0.0317 | RMSE: 0.0299 | Consistency: 0.0051 | SSIM: 0.0170 | Grad: 59501.012\n",
      "[Epoch 72, Batch 43/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0045 | SSIM: 0.0196 | Grad: 59494.832\n",
      "[Epoch 72, Batch 44/100] Loss: 0.0348 | RMSE: 0.0324 | Consistency: 0.0062 | SSIM: 0.0234 | Grad: 85816.172\n",
      "[Epoch 72, Batch 45/100] Loss: 0.0326 | RMSE: 0.0304 | Consistency: 0.0053 | SSIM: 0.0216 | Grad: 68135.422\n",
      "[Epoch 72, Batch 46/100] Loss: 0.0412 | RMSE: 0.0386 | Consistency: 0.0092 | SSIM: 0.0256 | Grad: 43321.094\n",
      "[Epoch 72, Batch 47/100] Loss: 0.0415 | RMSE: 0.0390 | Consistency: 0.0068 | SSIM: 0.0249 | Grad: 37242.707\n",
      "[Epoch 72, Batch 48/100] Loss: 0.0355 | RMSE: 0.0332 | Consistency: 0.0055 | SSIM: 0.0215 | Grad: 36373.602\n",
      "[Epoch 72, Batch 49/100] Loss: 0.0331 | RMSE: 0.0305 | Consistency: 0.0052 | SSIM: 0.0256 | Grad: 43837.891\n",
      "[Epoch 72, Batch 50/100] Loss: 0.0399 | RMSE: 0.0372 | Consistency: 0.0081 | SSIM: 0.0257 | Grad: 43050.082\n",
      "[Epoch 72, Batch 51/100] Loss: 0.0343 | RMSE: 0.0317 | Consistency: 0.0056 | SSIM: 0.0254 | Grad: 35822.555\n",
      "[Epoch 72, Batch 52/100] Loss: 0.0352 | RMSE: 0.0329 | Consistency: 0.0064 | SSIM: 0.0226 | Grad: 61760.938\n",
      "[Epoch 72, Batch 53/100] Loss: 0.0414 | RMSE: 0.0388 | Consistency: 0.0089 | SSIM: 0.0257 | Grad: 26555.799\n",
      "[Epoch 72, Batch 54/100] Loss: 0.0321 | RMSE: 0.0293 | Consistency: 0.0050 | SSIM: 0.0271 | Grad: 38692.953\n",
      "[Epoch 72, Batch 55/100] Loss: 0.0331 | RMSE: 0.0303 | Consistency: 0.0056 | SSIM: 0.0283 | Grad: 35476.234\n",
      "[Epoch 72, Batch 56/100] Loss: 0.0305 | RMSE: 0.0286 | Consistency: 0.0040 | SSIM: 0.0187 | Grad: 57598.484\n",
      "[Epoch 72, Batch 57/100] Loss: 0.0331 | RMSE: 0.0302 | Consistency: 0.0053 | SSIM: 0.0286 | Grad: 26927.641\n",
      "[Epoch 72, Batch 58/100] Loss: 0.0309 | RMSE: 0.0290 | Consistency: 0.0043 | SSIM: 0.0180 | Grad: 43336.152\n",
      "[Epoch 72, Batch 59/100] Loss: 0.0287 | RMSE: 0.0273 | Consistency: 0.0045 | SSIM: 0.0139 | Grad: 57176.113\n",
      "[Epoch 72, Batch 60/100] Loss: 0.0364 | RMSE: 0.0340 | Consistency: 0.0061 | SSIM: 0.0226 | Grad: 73976.211\n",
      "[Epoch 72, Batch 61/100] Loss: 0.0306 | RMSE: 0.0289 | Consistency: 0.0046 | SSIM: 0.0166 | Grad: 47601.754\n",
      "[Epoch 72, Batch 62/100] Loss: 0.0368 | RMSE: 0.0342 | Consistency: 0.0065 | SSIM: 0.0260 | Grad: 47160.492\n",
      "[Epoch 72, Batch 63/100] Loss: 0.0345 | RMSE: 0.0316 | Consistency: 0.0056 | SSIM: 0.0284 | Grad: 36608.152\n",
      "[Epoch 72, Batch 64/100] Loss: 0.0391 | RMSE: 0.0366 | Consistency: 0.0071 | SSIM: 0.0247 | Grad: 38948.383\n",
      "[Epoch 72, Batch 65/100] Loss: 0.0300 | RMSE: 0.0282 | Consistency: 0.0045 | SSIM: 0.0178 | Grad: 45510.703\n",
      "[Epoch 72, Batch 66/100] Loss: 0.0355 | RMSE: 0.0330 | Consistency: 0.0068 | SSIM: 0.0249 | Grad: 60369.250\n",
      "[Epoch 72, Batch 67/100] Loss: 0.0347 | RMSE: 0.0321 | Consistency: 0.0058 | SSIM: 0.0254 | Grad: 73471.281\n",
      "[Epoch 72, Batch 68/100] Loss: 0.0297 | RMSE: 0.0274 | Consistency: 0.0043 | SSIM: 0.0225 | Grad: 20116.676\n",
      "[Epoch 72, Batch 69/100] Loss: 0.0316 | RMSE: 0.0293 | Consistency: 0.0047 | SSIM: 0.0222 | Grad: 29671.127\n",
      "[Epoch 72, Batch 70/100] Loss: 0.0311 | RMSE: 0.0291 | Consistency: 0.0045 | SSIM: 0.0186 | Grad: 65323.676\n",
      "[Epoch 72, Batch 71/100] Loss: 0.0359 | RMSE: 0.0331 | Consistency: 0.0061 | SSIM: 0.0269 | Grad: 28588.336\n",
      "[Epoch 72, Batch 72/100] Loss: 0.0325 | RMSE: 0.0303 | Consistency: 0.0053 | SSIM: 0.0223 | Grad: 29987.330\n",
      "[Epoch 72, Batch 73/100] Loss: 0.0305 | RMSE: 0.0282 | Consistency: 0.0048 | SSIM: 0.0217 | Grad: 51864.145\n",
      "[Epoch 72, Batch 74/100] Loss: 0.0322 | RMSE: 0.0300 | Consistency: 0.0049 | SSIM: 0.0219 | Grad: 46397.160\n",
      "[Epoch 72, Batch 75/100] Loss: 0.0359 | RMSE: 0.0338 | Consistency: 0.0062 | SSIM: 0.0206 | Grad: 64314.801\n",
      "[Epoch 72, Batch 76/100] Loss: 0.0335 | RMSE: 0.0309 | Consistency: 0.0055 | SSIM: 0.0256 | Grad: 46415.641\n",
      "[Epoch 72, Batch 77/100] Loss: 0.0378 | RMSE: 0.0351 | Consistency: 0.0070 | SSIM: 0.0259 | Grad: 56370.637\n",
      "[Epoch 72, Batch 78/100] Loss: 0.0325 | RMSE: 0.0306 | Consistency: 0.0049 | SSIM: 0.0182 | Grad: 65414.895\n",
      "[Epoch 72, Batch 79/100] Loss: 0.0333 | RMSE: 0.0315 | Consistency: 0.0050 | SSIM: 0.0174 | Grad: 38409.594\n",
      "[Epoch 72, Batch 80/100] Loss: 0.0298 | RMSE: 0.0278 | Consistency: 0.0042 | SSIM: 0.0189 | Grad: 51023.977\n",
      "[Epoch 72, Batch 81/100] Loss: 0.0369 | RMSE: 0.0348 | Consistency: 0.0060 | SSIM: 0.0204 | Grad: 59031.395\n",
      "[Epoch 72, Batch 82/100] Loss: 0.0370 | RMSE: 0.0347 | Consistency: 0.0069 | SSIM: 0.0224 | Grad: 50357.277\n",
      "[Epoch 72, Batch 83/100] Loss: 0.0362 | RMSE: 0.0340 | Consistency: 0.0063 | SSIM: 0.0214 | Grad: 70161.805\n",
      "[Epoch 72, Batch 84/100] Loss: 0.0355 | RMSE: 0.0332 | Consistency: 0.0059 | SSIM: 0.0223 | Grad: 25171.490\n",
      "[Epoch 72, Batch 85/100] Loss: 0.0313 | RMSE: 0.0294 | Consistency: 0.0044 | SSIM: 0.0180 | Grad: 76802.367\n",
      "[Epoch 72, Batch 86/100] Loss: 0.0321 | RMSE: 0.0302 | Consistency: 0.0049 | SSIM: 0.0184 | Grad: 68535.938\n",
      "[Epoch 72, Batch 87/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0051 | SSIM: 0.0200 | Grad: 82465.656\n",
      "[Epoch 72, Batch 88/100] Loss: 0.0374 | RMSE: 0.0347 | Consistency: 0.0067 | SSIM: 0.0271 | Grad: 53264.578\n",
      "[Epoch 72, Batch 89/100] Loss: 0.0346 | RMSE: 0.0316 | Consistency: 0.0059 | SSIM: 0.0289 | Grad: 34814.031\n",
      "[Epoch 72, Batch 90/100] Loss: 0.0456 | RMSE: 0.0426 | Consistency: 0.0110 | SSIM: 0.0281 | Grad: 20503.217\n",
      "[Epoch 72, Batch 91/100] Loss: 0.0380 | RMSE: 0.0354 | Consistency: 0.0076 | SSIM: 0.0249 | Grad: 49923.203\n",
      "[Epoch 72, Batch 92/100] Loss: 0.0305 | RMSE: 0.0281 | Consistency: 0.0039 | SSIM: 0.0241 | Grad: 60760.176\n",
      "[Epoch 72, Batch 93/100] Loss: 0.0310 | RMSE: 0.0291 | Consistency: 0.0048 | SSIM: 0.0190 | Grad: 47780.508\n",
      "[Epoch 72, Batch 94/100] Loss: 0.0331 | RMSE: 0.0306 | Consistency: 0.0054 | SSIM: 0.0243 | Grad: 68922.359\n",
      "[Epoch 72, Batch 95/100] Loss: 0.0335 | RMSE: 0.0312 | Consistency: 0.0049 | SSIM: 0.0226 | Grad: 99702.195\n",
      "[Epoch 72, Batch 96/100] Loss: 0.0369 | RMSE: 0.0347 | Consistency: 0.0060 | SSIM: 0.0219 | Grad: 83145.258\n",
      "[Epoch 72, Batch 97/100] Loss: 0.0352 | RMSE: 0.0324 | Consistency: 0.0060 | SSIM: 0.0273 | Grad: 46111.547\n",
      "[Epoch 72, Batch 98/100] Loss: 0.0343 | RMSE: 0.0318 | Consistency: 0.0057 | SSIM: 0.0248 | Grad: 63983.910\n",
      "[Epoch 72, Batch 99/100] Loss: 0.0292 | RMSE: 0.0276 | Consistency: 0.0043 | SSIM: 0.0157 | Grad: 58863.223\n",
      "[Epoch 72, Batch 100/100] Loss: 0.0336 | RMSE: 0.0316 | Consistency: 0.0053 | SSIM: 0.0202 | Grad: 49666.812\n",
      "✅ Epoch 72 완료!\n",
      "   📈 평균 Loss: 0.034280\n",
      "   📊 평균 RMSE: 0.031961\n",
      "   ⚙️  학습률: 0.000030\n",
      "   🏆 NEW BEST! RMSE: 0.031961\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 73/80 시작...\n",
      "[Epoch 73, Batch 1/100] Loss: 0.0367 | RMSE: 0.0343 | Consistency: 0.0070 | SSIM: 0.0230 | Grad: 32048.523\n",
      "[Epoch 73, Batch 2/100] Loss: 0.0307 | RMSE: 0.0287 | Consistency: 0.0045 | SSIM: 0.0193 | Grad: 36932.031\n",
      "[Epoch 73, Batch 3/100] Loss: 0.0334 | RMSE: 0.0309 | Consistency: 0.0050 | SSIM: 0.0252 | Grad: 61626.832\n",
      "[Epoch 73, Batch 4/100] Loss: 0.0343 | RMSE: 0.0321 | Consistency: 0.0048 | SSIM: 0.0216 | Grad: 41526.145\n",
      "[Epoch 73, Batch 5/100] Loss: 0.0348 | RMSE: 0.0328 | Consistency: 0.0052 | SSIM: 0.0189 | Grad: 63105.418\n",
      "[Epoch 73, Batch 6/100] Loss: 0.0342 | RMSE: 0.0320 | Consistency: 0.0060 | SSIM: 0.0218 | Grad: 14487.688\n",
      "[Epoch 73, Batch 7/100] Loss: 0.0367 | RMSE: 0.0342 | Consistency: 0.0060 | SSIM: 0.0251 | Grad: 19985.732\n",
      "[Epoch 73, Batch 8/100] Loss: 0.0354 | RMSE: 0.0330 | Consistency: 0.0062 | SSIM: 0.0230 | Grad: 45729.711\n",
      "[Epoch 73, Batch 9/100] Loss: 0.0341 | RMSE: 0.0320 | Consistency: 0.0062 | SSIM: 0.0212 | Grad: 53224.457\n",
      "[Epoch 73, Batch 10/100] Loss: 0.0357 | RMSE: 0.0332 | Consistency: 0.0057 | SSIM: 0.0248 | Grad: 49356.547\n",
      "[Epoch 73, Batch 11/100] Loss: 0.0409 | RMSE: 0.0381 | Consistency: 0.0088 | SSIM: 0.0274 | Grad: 65108.441\n",
      "[Epoch 73, Batch 12/100] Loss: 0.0339 | RMSE: 0.0314 | Consistency: 0.0052 | SSIM: 0.0238 | Grad: 99009.383\n",
      "[Epoch 73, Batch 13/100] Loss: 0.0353 | RMSE: 0.0324 | Consistency: 0.0059 | SSIM: 0.0282 | Grad: 57125.305\n",
      "[Epoch 73, Batch 14/100] Loss: 0.0317 | RMSE: 0.0292 | Consistency: 0.0053 | SSIM: 0.0243 | Grad: 66791.625\n",
      "[Epoch 73, Batch 15/100] Loss: 0.0314 | RMSE: 0.0292 | Consistency: 0.0047 | SSIM: 0.0222 | Grad: 45919.277\n",
      "[Epoch 73, Batch 16/100] Loss: 0.0325 | RMSE: 0.0302 | Consistency: 0.0051 | SSIM: 0.0224 | Grad: 30964.133\n",
      "[Epoch 73, Batch 17/100] Loss: 0.0400 | RMSE: 0.0362 | Consistency: 0.0069 | SSIM: 0.0370 | Grad: 33081.008\n",
      "[Epoch 73, Batch 18/100] Loss: 0.0341 | RMSE: 0.0318 | Consistency: 0.0054 | SSIM: 0.0220 | Grad: 86635.352\n",
      "[Epoch 73, Batch 19/100] Loss: 0.0314 | RMSE: 0.0292 | Consistency: 0.0046 | SSIM: 0.0217 | Grad: 70106.750\n",
      "[Epoch 73, Batch 20/100] Loss: 0.0382 | RMSE: 0.0355 | Consistency: 0.0063 | SSIM: 0.0258 | Grad: 54328.738\n",
      "[Epoch 73, Batch 21/100] Loss: 0.0297 | RMSE: 0.0279 | Consistency: 0.0047 | SSIM: 0.0170 | Grad: 53990.004\n",
      "[Epoch 73, Batch 22/100] Loss: 0.0318 | RMSE: 0.0301 | Consistency: 0.0049 | SSIM: 0.0173 | Grad: 78771.859\n",
      "[Epoch 73, Batch 23/100] Loss: 0.0382 | RMSE: 0.0352 | Consistency: 0.0074 | SSIM: 0.0290 | Grad: 34418.078\n",
      "[Epoch 73, Batch 24/100] Loss: 0.0364 | RMSE: 0.0340 | Consistency: 0.0062 | SSIM: 0.0240 | Grad: 44099.711\n",
      "[Epoch 73, Batch 25/100] Loss: 0.0324 | RMSE: 0.0304 | Consistency: 0.0049 | SSIM: 0.0192 | Grad: 65025.203\n",
      "[Epoch 73, Batch 26/100] Loss: 0.0326 | RMSE: 0.0306 | Consistency: 0.0049 | SSIM: 0.0190 | Grad: 30981.006\n",
      "[Epoch 73, Batch 27/100] Loss: 0.0362 | RMSE: 0.0337 | Consistency: 0.0067 | SSIM: 0.0240 | Grad: 22908.137\n",
      "[Epoch 73, Batch 28/100] Loss: 0.0332 | RMSE: 0.0314 | Consistency: 0.0051 | SSIM: 0.0176 | Grad: 48161.977\n",
      "[Epoch 73, Batch 29/100] Loss: 0.0360 | RMSE: 0.0334 | Consistency: 0.0057 | SSIM: 0.0258 | Grad: 67328.180\n",
      "[Epoch 73, Batch 30/100] Loss: 0.0368 | RMSE: 0.0343 | Consistency: 0.0064 | SSIM: 0.0243 | Grad: 29422.281\n",
      "[Epoch 73, Batch 31/100] Loss: 0.0305 | RMSE: 0.0281 | Consistency: 0.0046 | SSIM: 0.0234 | Grad: 34488.992\n",
      "[Epoch 73, Batch 32/100] Loss: 0.0385 | RMSE: 0.0358 | Consistency: 0.0073 | SSIM: 0.0266 | Grad: 13763.885\n",
      "[Epoch 73, Batch 33/100] Loss: 0.0402 | RMSE: 0.0375 | Consistency: 0.0073 | SSIM: 0.0266 | Grad: 45553.543\n",
      "[Epoch 73, Batch 34/100] Loss: 0.0365 | RMSE: 0.0343 | Consistency: 0.0078 | SSIM: 0.0207 | Grad: 71456.586\n",
      "[Epoch 73, Batch 35/100] Loss: 0.0307 | RMSE: 0.0290 | Consistency: 0.0046 | SSIM: 0.0166 | Grad: 36362.137\n",
      "[Epoch 73, Batch 36/100] Loss: 0.0306 | RMSE: 0.0280 | Consistency: 0.0048 | SSIM: 0.0250 | Grad: 13134.023\n",
      "[Epoch 73, Batch 37/100] Loss: 0.0345 | RMSE: 0.0323 | Consistency: 0.0060 | SSIM: 0.0210 | Grad: 71380.711\n",
      "[Epoch 73, Batch 38/100] Loss: 0.0461 | RMSE: 0.0427 | Consistency: 0.0103 | SSIM: 0.0322 | Grad: 27691.354\n",
      "[Epoch 73, Batch 39/100] Loss: 0.0311 | RMSE: 0.0293 | Consistency: 0.0044 | SSIM: 0.0180 | Grad: 49451.895\n",
      "[Epoch 73, Batch 40/100] Loss: 0.0373 | RMSE: 0.0348 | Consistency: 0.0049 | SSIM: 0.0243 | Grad: 72607.312\n",
      "[Epoch 73, Batch 41/100] Loss: 0.0320 | RMSE: 0.0302 | Consistency: 0.0047 | SSIM: 0.0180 | Grad: 43595.520\n",
      "[Epoch 73, Batch 42/100] Loss: 0.0355 | RMSE: 0.0335 | Consistency: 0.0066 | SSIM: 0.0203 | Grad: 80327.359\n",
      "[Epoch 73, Batch 43/100] Loss: 0.0533 | RMSE: 0.0500 | Consistency: 0.0154 | SSIM: 0.0310 | Grad: 35812.547\n",
      "[Epoch 73, Batch 44/100] Loss: 0.0375 | RMSE: 0.0344 | Consistency: 0.0077 | SSIM: 0.0304 | Grad: 64012.512\n",
      "[Epoch 73, Batch 45/100] Loss: 0.0397 | RMSE: 0.0364 | Consistency: 0.0082 | SSIM: 0.0327 | Grad: 41407.559\n",
      "[Epoch 73, Batch 46/100] Loss: 0.0353 | RMSE: 0.0334 | Consistency: 0.0062 | SSIM: 0.0184 | Grad: 44875.953\n",
      "[Epoch 73, Batch 47/100] Loss: 0.0320 | RMSE: 0.0295 | Consistency: 0.0049 | SSIM: 0.0241 | Grad: 72492.234\n",
      "[Epoch 73, Batch 48/100] Loss: 0.0269 | RMSE: 0.0253 | Consistency: 0.0037 | SSIM: 0.0155 | Grad: 35749.141\n",
      "[Epoch 73, Batch 49/100] Loss: 0.0368 | RMSE: 0.0348 | Consistency: 0.0064 | SSIM: 0.0191 | Grad: 88776.125\n",
      "[Epoch 73, Batch 50/100] Loss: 0.0390 | RMSE: 0.0365 | Consistency: 0.0065 | SSIM: 0.0249 | Grad: 49688.543\n",
      "[Epoch 73, Batch 51/100] Loss: 0.0321 | RMSE: 0.0297 | Consistency: 0.0052 | SSIM: 0.0243 | Grad: 59128.727\n",
      "[Epoch 73, Batch 52/100] Loss: 0.0348 | RMSE: 0.0324 | Consistency: 0.0064 | SSIM: 0.0233 | Grad: 45031.988\n",
      "[Epoch 73, Batch 53/100] Loss: 0.0313 | RMSE: 0.0295 | Consistency: 0.0046 | SSIM: 0.0172 | Grad: 36110.027\n",
      "[Epoch 73, Batch 54/100] Loss: 0.0386 | RMSE: 0.0361 | Consistency: 0.0071 | SSIM: 0.0246 | Grad: 47929.918\n",
      "[Epoch 73, Batch 55/100] Loss: 0.0340 | RMSE: 0.0321 | Consistency: 0.0054 | SSIM: 0.0187 | Grad: 69076.219\n",
      "[Epoch 73, Batch 56/100] Loss: 0.0366 | RMSE: 0.0345 | Consistency: 0.0061 | SSIM: 0.0210 | Grad: 82435.469\n",
      "[Epoch 73, Batch 57/100] Loss: 0.0327 | RMSE: 0.0307 | Consistency: 0.0047 | SSIM: 0.0196 | Grad: 99204.156\n",
      "[Epoch 73, Batch 58/100] Loss: 0.0345 | RMSE: 0.0321 | Consistency: 0.0064 | SSIM: 0.0236 | Grad: 39054.180\n",
      "[Epoch 73, Batch 59/100] Loss: 0.0329 | RMSE: 0.0310 | Consistency: 0.0056 | SSIM: 0.0185 | Grad: 54898.703\n",
      "[Epoch 73, Batch 60/100] Loss: 0.0343 | RMSE: 0.0320 | Consistency: 0.0060 | SSIM: 0.0218 | Grad: 76820.578\n",
      "[Epoch 73, Batch 61/100] Loss: 0.0326 | RMSE: 0.0301 | Consistency: 0.0050 | SSIM: 0.0244 | Grad: 106591.820\n",
      "[Epoch 73, Batch 62/100] Loss: 0.0313 | RMSE: 0.0296 | Consistency: 0.0048 | SSIM: 0.0165 | Grad: 34041.457\n",
      "[Epoch 73, Batch 63/100] Loss: 0.0353 | RMSE: 0.0328 | Consistency: 0.0057 | SSIM: 0.0248 | Grad: 59263.336\n",
      "[Epoch 73, Batch 64/100] Loss: 0.0329 | RMSE: 0.0307 | Consistency: 0.0059 | SSIM: 0.0218 | Grad: 50982.391\n",
      "[Epoch 73, Batch 65/100] Loss: 0.0390 | RMSE: 0.0362 | Consistency: 0.0073 | SSIM: 0.0270 | Grad: 27072.834\n",
      "[Epoch 73, Batch 66/100] Loss: 0.0350 | RMSE: 0.0324 | Consistency: 0.0063 | SSIM: 0.0263 | Grad: 18884.137\n",
      "[Epoch 73, Batch 67/100] Loss: 0.0338 | RMSE: 0.0313 | Consistency: 0.0056 | SSIM: 0.0247 | Grad: 50873.137\n",
      "[Epoch 73, Batch 68/100] Loss: 0.0334 | RMSE: 0.0309 | Consistency: 0.0059 | SSIM: 0.0240 | Grad: 44728.008\n",
      "[Epoch 73, Batch 69/100] Loss: 0.0317 | RMSE: 0.0296 | Consistency: 0.0039 | SSIM: 0.0203 | Grad: 41817.160\n",
      "[Epoch 73, Batch 70/100] Loss: 0.0351 | RMSE: 0.0326 | Consistency: 0.0057 | SSIM: 0.0250 | Grad: 30261.514\n",
      "[Epoch 73, Batch 71/100] Loss: 0.0276 | RMSE: 0.0258 | Consistency: 0.0036 | SSIM: 0.0169 | Grad: 47525.496\n",
      "[Epoch 73, Batch 72/100] Loss: 0.0306 | RMSE: 0.0290 | Consistency: 0.0048 | SSIM: 0.0147 | Grad: 29355.645\n",
      "[Epoch 73, Batch 73/100] Loss: 0.0401 | RMSE: 0.0372 | Consistency: 0.0067 | SSIM: 0.0274 | Grad: 81123.289\n",
      "[Epoch 73, Batch 74/100] Loss: 0.0326 | RMSE: 0.0306 | Consistency: 0.0057 | SSIM: 0.0195 | Grad: 27635.158\n",
      "[Epoch 73, Batch 75/100] Loss: 0.0356 | RMSE: 0.0331 | Consistency: 0.0056 | SSIM: 0.0239 | Grad: 36377.109\n",
      "[Epoch 73, Batch 76/100] Loss: 0.0391 | RMSE: 0.0364 | Consistency: 0.0078 | SSIM: 0.0262 | Grad: 53440.512\n",
      "[Epoch 73, Batch 77/100] Loss: 0.0377 | RMSE: 0.0355 | Consistency: 0.0072 | SSIM: 0.0217 | Grad: 40119.324\n",
      "[Epoch 73, Batch 78/100] Loss: 0.0346 | RMSE: 0.0321 | Consistency: 0.0060 | SSIM: 0.0243 | Grad: 46232.180\n",
      "[Epoch 73, Batch 79/100] Loss: 0.0373 | RMSE: 0.0349 | Consistency: 0.0065 | SSIM: 0.0230 | Grad: 21314.775\n",
      "[Epoch 73, Batch 80/100] Loss: 0.0366 | RMSE: 0.0345 | Consistency: 0.0060 | SSIM: 0.0203 | Grad: 54148.945\n",
      "[Epoch 73, Batch 81/100] Loss: 0.0287 | RMSE: 0.0267 | Consistency: 0.0044 | SSIM: 0.0195 | Grad: 41954.340\n",
      "[Epoch 73, Batch 82/100] Loss: 0.0361 | RMSE: 0.0341 | Consistency: 0.0061 | SSIM: 0.0200 | Grad: 84884.320\n",
      "[Epoch 73, Batch 83/100] Loss: 0.0354 | RMSE: 0.0331 | Consistency: 0.0048 | SSIM: 0.0225 | Grad: 60463.781\n",
      "[Epoch 73, Batch 84/100] Loss: 0.0315 | RMSE: 0.0293 | Consistency: 0.0047 | SSIM: 0.0210 | Grad: 49777.988\n",
      "[Epoch 73, Batch 85/100] Loss: 0.0355 | RMSE: 0.0334 | Consistency: 0.0061 | SSIM: 0.0206 | Grad: 43961.137\n",
      "[Epoch 73, Batch 86/100] Loss: 0.0337 | RMSE: 0.0316 | Consistency: 0.0054 | SSIM: 0.0203 | Grad: 27569.867\n",
      "[Epoch 73, Batch 87/100] Loss: 0.0365 | RMSE: 0.0337 | Consistency: 0.0070 | SSIM: 0.0279 | Grad: 15568.522\n",
      "[Epoch 73, Batch 88/100] Loss: 0.0340 | RMSE: 0.0314 | Consistency: 0.0058 | SSIM: 0.0252 | Grad: 36315.828\n",
      "[Epoch 73, Batch 89/100] Loss: 0.0351 | RMSE: 0.0324 | Consistency: 0.0053 | SSIM: 0.0265 | Grad: 36227.145\n",
      "[Epoch 73, Batch 90/100] Loss: 0.0308 | RMSE: 0.0286 | Consistency: 0.0044 | SSIM: 0.0212 | Grad: 61133.801\n",
      "[Epoch 73, Batch 91/100] Loss: 0.0317 | RMSE: 0.0300 | Consistency: 0.0052 | SSIM: 0.0168 | Grad: 76591.344\n",
      "[Epoch 73, Batch 92/100] Loss: 0.0338 | RMSE: 0.0315 | Consistency: 0.0045 | SSIM: 0.0223 | Grad: 48108.480\n",
      "[Epoch 73, Batch 93/100] Loss: 0.0336 | RMSE: 0.0316 | Consistency: 0.0056 | SSIM: 0.0188 | Grad: 21364.641\n",
      "[Epoch 73, Batch 94/100] Loss: 0.0325 | RMSE: 0.0301 | Consistency: 0.0047 | SSIM: 0.0235 | Grad: 59590.902\n",
      "[Epoch 73, Batch 95/100] Loss: 0.0380 | RMSE: 0.0357 | Consistency: 0.0061 | SSIM: 0.0225 | Grad: 43527.027\n",
      "[Epoch 73, Batch 96/100] Loss: 0.0343 | RMSE: 0.0322 | Consistency: 0.0057 | SSIM: 0.0206 | Grad: 71079.492\n",
      "[Epoch 73, Batch 97/100] Loss: 0.0348 | RMSE: 0.0324 | Consistency: 0.0059 | SSIM: 0.0230 | Grad: 25729.402\n",
      "[Epoch 73, Batch 98/100] Loss: 0.0342 | RMSE: 0.0321 | Consistency: 0.0053 | SSIM: 0.0203 | Grad: 91054.773\n",
      "[Epoch 73, Batch 99/100] Loss: 0.0324 | RMSE: 0.0302 | Consistency: 0.0047 | SSIM: 0.0218 | Grad: 68172.531\n",
      "[Epoch 73, Batch 100/100] Loss: 0.0324 | RMSE: 0.0303 | Consistency: 0.0054 | SSIM: 0.0209 | Grad: 58946.902\n",
      "✅ Epoch 73 완료!\n",
      "   📈 평균 Loss: 0.034712\n",
      "   📊 평균 RMSE: 0.032388\n",
      "   ⚙️  학습률: 0.000023\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 74/80 시작...\n",
      "[Epoch 74, Batch 1/100] Loss: 0.0366 | RMSE: 0.0344 | Consistency: 0.0065 | SSIM: 0.0214 | Grad: 21293.459\n",
      "[Epoch 74, Batch 2/100] Loss: 0.0367 | RMSE: 0.0345 | Consistency: 0.0063 | SSIM: 0.0220 | Grad: 77156.117\n",
      "[Epoch 74, Batch 3/100] Loss: 0.0296 | RMSE: 0.0276 | Consistency: 0.0043 | SSIM: 0.0189 | Grad: 31213.918\n",
      "[Epoch 74, Batch 4/100] Loss: 0.0334 | RMSE: 0.0314 | Consistency: 0.0056 | SSIM: 0.0200 | Grad: 67727.688\n",
      "[Epoch 74, Batch 5/100] Loss: 0.0314 | RMSE: 0.0291 | Consistency: 0.0048 | SSIM: 0.0230 | Grad: 50107.297\n",
      "[Epoch 74, Batch 6/100] Loss: 0.0369 | RMSE: 0.0344 | Consistency: 0.0064 | SSIM: 0.0239 | Grad: 55962.699\n",
      "[Epoch 74, Batch 7/100] Loss: 0.0380 | RMSE: 0.0353 | Consistency: 0.0075 | SSIM: 0.0263 | Grad: 39246.203\n",
      "[Epoch 74, Batch 8/100] Loss: 0.0418 | RMSE: 0.0389 | Consistency: 0.0075 | SSIM: 0.0281 | Grad: 88285.141\n",
      "[Epoch 74, Batch 9/100] Loss: 0.0323 | RMSE: 0.0301 | Consistency: 0.0048 | SSIM: 0.0216 | Grad: 63684.051\n",
      "[Epoch 74, Batch 10/100] Loss: 0.0294 | RMSE: 0.0274 | Consistency: 0.0041 | SSIM: 0.0197 | Grad: 19118.938\n",
      "[Epoch 74, Batch 11/100] Loss: 0.0342 | RMSE: 0.0317 | Consistency: 0.0062 | SSIM: 0.0242 | Grad: 45009.617\n",
      "[Epoch 74, Batch 12/100] Loss: 0.0328 | RMSE: 0.0308 | Consistency: 0.0051 | SSIM: 0.0196 | Grad: 45737.883\n",
      "[Epoch 74, Batch 13/100] Loss: 0.0311 | RMSE: 0.0294 | Consistency: 0.0049 | SSIM: 0.0171 | Grad: 28860.881\n",
      "[Epoch 74, Batch 14/100] Loss: 0.0324 | RMSE: 0.0305 | Consistency: 0.0047 | SSIM: 0.0185 | Grad: 74813.664\n",
      "[Epoch 74, Batch 15/100] Loss: 0.0314 | RMSE: 0.0294 | Consistency: 0.0045 | SSIM: 0.0197 | Grad: 46367.938\n",
      "[Epoch 74, Batch 16/100] Loss: 0.0299 | RMSE: 0.0283 | Consistency: 0.0041 | SSIM: 0.0162 | Grad: 20608.803\n",
      "[Epoch 74, Batch 17/100] Loss: 0.0372 | RMSE: 0.0351 | Consistency: 0.0052 | SSIM: 0.0203 | Grad: 81891.477\n",
      "[Epoch 74, Batch 18/100] Loss: 0.0341 | RMSE: 0.0317 | Consistency: 0.0062 | SSIM: 0.0233 | Grad: 60939.094\n",
      "[Epoch 74, Batch 19/100] Loss: 0.0448 | RMSE: 0.0413 | Consistency: 0.0103 | SSIM: 0.0340 | Grad: 72622.117\n",
      "[Epoch 74, Batch 20/100] Loss: 0.0339 | RMSE: 0.0317 | Consistency: 0.0055 | SSIM: 0.0214 | Grad: 44032.879\n",
      "[Epoch 74, Batch 21/100] Loss: 0.0323 | RMSE: 0.0302 | Consistency: 0.0050 | SSIM: 0.0205 | Grad: 19771.828\n",
      "[Epoch 74, Batch 22/100] Loss: 0.0323 | RMSE: 0.0296 | Consistency: 0.0049 | SSIM: 0.0266 | Grad: 68799.188\n",
      "[Epoch 74, Batch 23/100] Loss: 0.0344 | RMSE: 0.0318 | Consistency: 0.0050 | SSIM: 0.0249 | Grad: 45483.500\n",
      "[Epoch 74, Batch 24/100] Loss: 0.0315 | RMSE: 0.0296 | Consistency: 0.0052 | SSIM: 0.0188 | Grad: 49473.578\n",
      "[Epoch 74, Batch 25/100] Loss: 0.0326 | RMSE: 0.0306 | Consistency: 0.0055 | SSIM: 0.0195 | Grad: 15588.158\n",
      "[Epoch 74, Batch 26/100] Loss: 0.0363 | RMSE: 0.0333 | Consistency: 0.0067 | SSIM: 0.0290 | Grad: 53962.117\n",
      "[Epoch 74, Batch 27/100] Loss: 0.0321 | RMSE: 0.0299 | Consistency: 0.0051 | SSIM: 0.0214 | Grad: 41238.152\n",
      "[Epoch 74, Batch 28/100] Loss: 0.0326 | RMSE: 0.0306 | Consistency: 0.0054 | SSIM: 0.0187 | Grad: 67147.586\n",
      "[Epoch 74, Batch 29/100] Loss: 0.0406 | RMSE: 0.0377 | Consistency: 0.0076 | SSIM: 0.0276 | Grad: 48121.398\n",
      "[Epoch 74, Batch 30/100] Loss: 0.0369 | RMSE: 0.0349 | Consistency: 0.0056 | SSIM: 0.0195 | Grad: 25063.330\n",
      "[Epoch 74, Batch 31/100] Loss: 0.0350 | RMSE: 0.0327 | Consistency: 0.0058 | SSIM: 0.0222 | Grad: 61913.098\n",
      "[Epoch 74, Batch 32/100] Loss: 0.0382 | RMSE: 0.0356 | Consistency: 0.0062 | SSIM: 0.0251 | Grad: 50584.016\n",
      "[Epoch 74, Batch 33/100] Loss: 0.0430 | RMSE: 0.0398 | Consistency: 0.0093 | SSIM: 0.0309 | Grad: 70683.188\n",
      "[Epoch 74, Batch 34/100] Loss: 0.0302 | RMSE: 0.0282 | Consistency: 0.0045 | SSIM: 0.0191 | Grad: 41933.215\n",
      "[Epoch 74, Batch 35/100] Loss: 0.0319 | RMSE: 0.0298 | Consistency: 0.0042 | SSIM: 0.0210 | Grad: 69003.750\n",
      "[Epoch 74, Batch 36/100] Loss: 0.0364 | RMSE: 0.0342 | Consistency: 0.0061 | SSIM: 0.0217 | Grad: 77487.211\n",
      "[Epoch 74, Batch 37/100] Loss: 0.0327 | RMSE: 0.0307 | Consistency: 0.0045 | SSIM: 0.0199 | Grad: 24812.682\n",
      "[Epoch 74, Batch 38/100] Loss: 0.0379 | RMSE: 0.0356 | Consistency: 0.0067 | SSIM: 0.0224 | Grad: 43500.133\n",
      "[Epoch 74, Batch 39/100] Loss: 0.0456 | RMSE: 0.0429 | Consistency: 0.0107 | SSIM: 0.0262 | Grad: 37968.859\n",
      "[Epoch 74, Batch 40/100] Loss: 0.0351 | RMSE: 0.0325 | Consistency: 0.0054 | SSIM: 0.0248 | Grad: 49028.176\n",
      "[Epoch 74, Batch 41/100] Loss: 0.0333 | RMSE: 0.0311 | Consistency: 0.0051 | SSIM: 0.0212 | Grad: 17373.354\n",
      "[Epoch 74, Batch 42/100] Loss: 0.0283 | RMSE: 0.0265 | Consistency: 0.0040 | SSIM: 0.0181 | Grad: 53543.555\n",
      "[Epoch 74, Batch 43/100] Loss: 0.0317 | RMSE: 0.0301 | Consistency: 0.0042 | SSIM: 0.0155 | Grad: 60043.523\n",
      "[Epoch 74, Batch 44/100] Loss: 0.0371 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0253 | Grad: 52986.488\n",
      "[Epoch 74, Batch 45/100] Loss: 0.0378 | RMSE: 0.0356 | Consistency: 0.0072 | SSIM: 0.0212 | Grad: 13729.366\n",
      "[Epoch 74, Batch 46/100] Loss: 0.0362 | RMSE: 0.0336 | Consistency: 0.0066 | SSIM: 0.0259 | Grad: 85910.484\n",
      "[Epoch 74, Batch 47/100] Loss: 0.0333 | RMSE: 0.0308 | Consistency: 0.0047 | SSIM: 0.0245 | Grad: 41145.895\n",
      "[Epoch 74, Batch 48/100] Loss: 0.0325 | RMSE: 0.0298 | Consistency: 0.0053 | SSIM: 0.0261 | Grad: 29359.195\n",
      "[Epoch 74, Batch 49/100] Loss: 0.0376 | RMSE: 0.0349 | Consistency: 0.0065 | SSIM: 0.0265 | Grad: 21993.244\n",
      "[Epoch 74, Batch 50/100] Loss: 0.0358 | RMSE: 0.0335 | Consistency: 0.0068 | SSIM: 0.0224 | Grad: 19802.059\n",
      "[Epoch 74, Batch 51/100] Loss: 0.0293 | RMSE: 0.0277 | Consistency: 0.0038 | SSIM: 0.0154 | Grad: 64015.750\n",
      "[Epoch 74, Batch 52/100] Loss: 0.0363 | RMSE: 0.0343 | Consistency: 0.0065 | SSIM: 0.0197 | Grad: 87990.039\n",
      "[Epoch 74, Batch 53/100] Loss: 0.0360 | RMSE: 0.0336 | Consistency: 0.0055 | SSIM: 0.0230 | Grad: 92863.727\n",
      "[Epoch 74, Batch 54/100] Loss: 0.0316 | RMSE: 0.0296 | Consistency: 0.0052 | SSIM: 0.0190 | Grad: 64404.434\n",
      "[Epoch 74, Batch 55/100] Loss: 0.0378 | RMSE: 0.0340 | Consistency: 0.0065 | SSIM: 0.0371 | Grad: 68579.117\n",
      "[Epoch 74, Batch 56/100] Loss: 0.0403 | RMSE: 0.0374 | Consistency: 0.0072 | SSIM: 0.0282 | Grad: 60744.809\n",
      "[Epoch 74, Batch 57/100] Loss: 0.0321 | RMSE: 0.0299 | Consistency: 0.0056 | SSIM: 0.0216 | Grad: 37485.703\n",
      "[Epoch 74, Batch 58/100] Loss: 0.0341 | RMSE: 0.0309 | Consistency: 0.0053 | SSIM: 0.0314 | Grad: 58406.191\n",
      "[Epoch 74, Batch 59/100] Loss: 0.0355 | RMSE: 0.0327 | Consistency: 0.0065 | SSIM: 0.0275 | Grad: 75668.430\n",
      "[Epoch 74, Batch 60/100] Loss: 0.0390 | RMSE: 0.0366 | Consistency: 0.0082 | SSIM: 0.0227 | Grad: 86579.305\n",
      "[Epoch 74, Batch 61/100] Loss: 0.0299 | RMSE: 0.0277 | Consistency: 0.0043 | SSIM: 0.0215 | Grad: 38352.336\n",
      "[Epoch 74, Batch 62/100] Loss: 0.0325 | RMSE: 0.0304 | Consistency: 0.0044 | SSIM: 0.0203 | Grad: 75918.789\n",
      "[Epoch 74, Batch 63/100] Loss: 0.0311 | RMSE: 0.0291 | Consistency: 0.0049 | SSIM: 0.0196 | Grad: 55146.836\n",
      "[Epoch 74, Batch 64/100] Loss: 0.0302 | RMSE: 0.0285 | Consistency: 0.0048 | SSIM: 0.0165 | Grad: 36399.676\n",
      "[Epoch 74, Batch 65/100] Loss: 0.0380 | RMSE: 0.0352 | Consistency: 0.0069 | SSIM: 0.0278 | Grad: 34552.926\n",
      "[Epoch 74, Batch 66/100] Loss: 0.0387 | RMSE: 0.0365 | Consistency: 0.0070 | SSIM: 0.0210 | Grad: 53481.152\n",
      "[Epoch 74, Batch 67/100] Loss: 0.0346 | RMSE: 0.0327 | Consistency: 0.0056 | SSIM: 0.0183 | Grad: 78738.234\n",
      "[Epoch 74, Batch 68/100] Loss: 0.0323 | RMSE: 0.0302 | Consistency: 0.0054 | SSIM: 0.0206 | Grad: 33164.027\n",
      "[Epoch 74, Batch 69/100] Loss: 0.0344 | RMSE: 0.0321 | Consistency: 0.0050 | SSIM: 0.0219 | Grad: 61466.887\n",
      "[Epoch 74, Batch 70/100] Loss: 0.0337 | RMSE: 0.0313 | Consistency: 0.0051 | SSIM: 0.0230 | Grad: 24316.402\n",
      "[Epoch 74, Batch 71/100] Loss: 0.0346 | RMSE: 0.0321 | Consistency: 0.0054 | SSIM: 0.0243 | Grad: 28742.496\n",
      "[Epoch 74, Batch 72/100] Loss: 0.0336 | RMSE: 0.0312 | Consistency: 0.0057 | SSIM: 0.0232 | Grad: 33715.812\n",
      "[Epoch 74, Batch 73/100] Loss: 0.0343 | RMSE: 0.0320 | Consistency: 0.0060 | SSIM: 0.0220 | Grad: 56076.254\n",
      "[Epoch 74, Batch 74/100] Loss: 0.0332 | RMSE: 0.0312 | Consistency: 0.0053 | SSIM: 0.0194 | Grad: 53824.773\n",
      "[Epoch 74, Batch 75/100] Loss: 0.0337 | RMSE: 0.0315 | Consistency: 0.0055 | SSIM: 0.0215 | Grad: 49819.238\n",
      "[Epoch 74, Batch 76/100] Loss: 0.0354 | RMSE: 0.0327 | Consistency: 0.0058 | SSIM: 0.0268 | Grad: 38042.652\n",
      "[Epoch 74, Batch 77/100] Loss: 0.0317 | RMSE: 0.0297 | Consistency: 0.0052 | SSIM: 0.0196 | Grad: 62991.207\n",
      "[Epoch 74, Batch 78/100] Loss: 0.0319 | RMSE: 0.0299 | Consistency: 0.0043 | SSIM: 0.0195 | Grad: 55446.613\n",
      "[Epoch 74, Batch 79/100] Loss: 0.0366 | RMSE: 0.0345 | Consistency: 0.0070 | SSIM: 0.0203 | Grad: 23488.699\n",
      "[Epoch 74, Batch 80/100] Loss: 0.0324 | RMSE: 0.0298 | Consistency: 0.0053 | SSIM: 0.0247 | Grad: 33270.199\n",
      "[Epoch 74, Batch 81/100] Loss: 0.0354 | RMSE: 0.0331 | Consistency: 0.0056 | SSIM: 0.0231 | Grad: 49737.625\n",
      "[Epoch 74, Batch 82/100] Loss: 0.0351 | RMSE: 0.0331 | Consistency: 0.0056 | SSIM: 0.0203 | Grad: 29294.953\n",
      "[Epoch 74, Batch 83/100] Loss: 0.0382 | RMSE: 0.0361 | Consistency: 0.0065 | SSIM: 0.0205 | Grad: 39380.871\n",
      "[Epoch 74, Batch 84/100] Loss: 0.0258 | RMSE: 0.0244 | Consistency: 0.0032 | SSIM: 0.0130 | Grad: 21516.930\n",
      "[Epoch 74, Batch 85/100] Loss: 0.0303 | RMSE: 0.0284 | Consistency: 0.0049 | SSIM: 0.0189 | Grad: 43182.711\n",
      "[Epoch 74, Batch 86/100] Loss: 0.0364 | RMSE: 0.0340 | Consistency: 0.0067 | SSIM: 0.0231 | Grad: 51978.934\n",
      "[Epoch 74, Batch 87/100] Loss: 0.0390 | RMSE: 0.0364 | Consistency: 0.0088 | SSIM: 0.0243 | Grad: 24738.416\n",
      "[Epoch 74, Batch 88/100] Loss: 0.0329 | RMSE: 0.0307 | Consistency: 0.0045 | SSIM: 0.0219 | Grad: 48705.633\n",
      "[Epoch 74, Batch 89/100] Loss: 0.0324 | RMSE: 0.0303 | Consistency: 0.0054 | SSIM: 0.0208 | Grad: 71168.516\n",
      "[Epoch 74, Batch 90/100] Loss: 0.0328 | RMSE: 0.0308 | Consistency: 0.0051 | SSIM: 0.0197 | Grad: 39995.879\n",
      "[Epoch 74, Batch 91/100] Loss: 0.0333 | RMSE: 0.0313 | Consistency: 0.0048 | SSIM: 0.0194 | Grad: 39717.871\n",
      "[Epoch 74, Batch 92/100] Loss: 0.0329 | RMSE: 0.0308 | Consistency: 0.0052 | SSIM: 0.0209 | Grad: 64122.719\n",
      "[Epoch 74, Batch 93/100] Loss: 0.0306 | RMSE: 0.0285 | Consistency: 0.0044 | SSIM: 0.0206 | Grad: 51219.438\n",
      "[Epoch 74, Batch 94/100] Loss: 0.0322 | RMSE: 0.0301 | Consistency: 0.0047 | SSIM: 0.0203 | Grad: 17373.631\n",
      "[Epoch 74, Batch 95/100] Loss: 0.0366 | RMSE: 0.0340 | Consistency: 0.0067 | SSIM: 0.0253 | Grad: 53246.168\n",
      "[Epoch 74, Batch 96/100] Loss: 0.0320 | RMSE: 0.0303 | Consistency: 0.0048 | SSIM: 0.0165 | Grad: 18988.410\n",
      "[Epoch 74, Batch 97/100] Loss: 0.0446 | RMSE: 0.0420 | Consistency: 0.0100 | SSIM: 0.0252 | Grad: 81181.398\n",
      "[Epoch 74, Batch 98/100] Loss: 0.0381 | RMSE: 0.0358 | Consistency: 0.0057 | SSIM: 0.0215 | Grad: 70943.922\n",
      "[Epoch 74, Batch 99/100] Loss: 0.0333 | RMSE: 0.0310 | Consistency: 0.0059 | SSIM: 0.0219 | Grad: 50949.680\n",
      "[Epoch 74, Batch 100/100] Loss: 0.0359 | RMSE: 0.0336 | Consistency: 0.0063 | SSIM: 0.0215 | Grad: 42229.105\n",
      "✅ Epoch 74 완료!\n",
      "   📈 평균 Loss: 0.034514\n",
      "   📊 평균 RMSE: 0.032235\n",
      "   ⚙️  학습률: 0.000017\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 75/80 시작...\n",
      "[Epoch 75, Batch 1/100] Loss: 0.0388 | RMSE: 0.0362 | Consistency: 0.0075 | SSIM: 0.0254 | Grad: 24921.689\n",
      "[Epoch 75, Batch 2/100] Loss: 0.0436 | RMSE: 0.0410 | Consistency: 0.0091 | SSIM: 0.0249 | Grad: 53080.059\n",
      "[Epoch 75, Batch 3/100] Loss: 0.0365 | RMSE: 0.0338 | Consistency: 0.0067 | SSIM: 0.0260 | Grad: 13601.898\n",
      "[Epoch 75, Batch 4/100] Loss: 0.0328 | RMSE: 0.0307 | Consistency: 0.0049 | SSIM: 0.0212 | Grad: 13003.028\n",
      "[Epoch 75, Batch 5/100] Loss: 0.0464 | RMSE: 0.0436 | Consistency: 0.0103 | SSIM: 0.0268 | Grad: 55920.016\n",
      "[Epoch 75, Batch 6/100] Loss: 0.0367 | RMSE: 0.0344 | Consistency: 0.0052 | SSIM: 0.0225 | Grad: 84491.023\n",
      "[Epoch 75, Batch 7/100] Loss: 0.0366 | RMSE: 0.0346 | Consistency: 0.0061 | SSIM: 0.0192 | Grad: 54401.926\n",
      "[Epoch 75, Batch 8/100] Loss: 0.0363 | RMSE: 0.0338 | Consistency: 0.0063 | SSIM: 0.0249 | Grad: 36912.535\n",
      "[Epoch 75, Batch 9/100] Loss: 0.0374 | RMSE: 0.0352 | Consistency: 0.0060 | SSIM: 0.0212 | Grad: 61731.211\n",
      "[Epoch 75, Batch 10/100] Loss: 0.0347 | RMSE: 0.0327 | Consistency: 0.0050 | SSIM: 0.0196 | Grad: 13567.044\n",
      "[Epoch 75, Batch 11/100] Loss: 0.0376 | RMSE: 0.0353 | Consistency: 0.0067 | SSIM: 0.0225 | Grad: 53622.523\n",
      "[Epoch 75, Batch 12/100] Loss: 0.0352 | RMSE: 0.0329 | Consistency: 0.0055 | SSIM: 0.0228 | Grad: 44768.723\n",
      "[Epoch 75, Batch 13/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0067 | SSIM: 0.0221 | Grad: 79762.117\n",
      "[Epoch 75, Batch 14/100] Loss: 0.0323 | RMSE: 0.0303 | Consistency: 0.0050 | SSIM: 0.0195 | Grad: 49407.957\n",
      "[Epoch 75, Batch 15/100] Loss: 0.0304 | RMSE: 0.0286 | Consistency: 0.0051 | SSIM: 0.0176 | Grad: 29086.799\n",
      "[Epoch 75, Batch 16/100] Loss: 0.0287 | RMSE: 0.0269 | Consistency: 0.0039 | SSIM: 0.0173 | Grad: 43548.777\n",
      "[Epoch 75, Batch 17/100] Loss: 0.0401 | RMSE: 0.0377 | Consistency: 0.0073 | SSIM: 0.0227 | Grad: 58859.020\n",
      "[Epoch 75, Batch 18/100] Loss: 0.0472 | RMSE: 0.0442 | Consistency: 0.0139 | SSIM: 0.0286 | Grad: 76052.500\n",
      "[Epoch 75, Batch 19/100] Loss: 0.0325 | RMSE: 0.0304 | Consistency: 0.0049 | SSIM: 0.0200 | Grad: 75199.250\n",
      "[Epoch 75, Batch 20/100] Loss: 0.0311 | RMSE: 0.0292 | Consistency: 0.0053 | SSIM: 0.0185 | Grad: 36470.938\n",
      "[Epoch 75, Batch 21/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0056 | SSIM: 0.0222 | Grad: 47268.203\n",
      "[Epoch 75, Batch 22/100] Loss: 0.0326 | RMSE: 0.0301 | Consistency: 0.0050 | SSIM: 0.0238 | Grad: 24153.654\n",
      "[Epoch 75, Batch 23/100] Loss: 0.0393 | RMSE: 0.0369 | Consistency: 0.0062 | SSIM: 0.0232 | Grad: 66166.422\n",
      "[Epoch 75, Batch 24/100] Loss: 0.0344 | RMSE: 0.0322 | Consistency: 0.0057 | SSIM: 0.0212 | Grad: 76208.789\n",
      "[Epoch 75, Batch 25/100] Loss: 0.0313 | RMSE: 0.0293 | Consistency: 0.0052 | SSIM: 0.0192 | Grad: 34277.336\n",
      "[Epoch 75, Batch 26/100] Loss: 0.0389 | RMSE: 0.0365 | Consistency: 0.0079 | SSIM: 0.0231 | Grad: 16763.256\n",
      "[Epoch 75, Batch 27/100] Loss: 0.0322 | RMSE: 0.0302 | Consistency: 0.0050 | SSIM: 0.0201 | Grad: 56477.176\n",
      "[Epoch 75, Batch 28/100] Loss: 0.0379 | RMSE: 0.0356 | Consistency: 0.0069 | SSIM: 0.0223 | Grad: 44991.000\n",
      "[Epoch 75, Batch 29/100] Loss: 0.0295 | RMSE: 0.0278 | Consistency: 0.0042 | SSIM: 0.0169 | Grad: 62909.961\n",
      "[Epoch 75, Batch 30/100] Loss: 0.0328 | RMSE: 0.0304 | Consistency: 0.0044 | SSIM: 0.0233 | Grad: 64508.180\n",
      "[Epoch 75, Batch 31/100] Loss: 0.0346 | RMSE: 0.0323 | Consistency: 0.0055 | SSIM: 0.0224 | Grad: 23754.010\n",
      "[Epoch 75, Batch 32/100] Loss: 0.0355 | RMSE: 0.0335 | Consistency: 0.0060 | SSIM: 0.0194 | Grad: 18106.502\n",
      "[Epoch 75, Batch 33/100] Loss: 0.0352 | RMSE: 0.0331 | Consistency: 0.0056 | SSIM: 0.0209 | Grad: 83996.586\n",
      "[Epoch 75, Batch 34/100] Loss: 0.0305 | RMSE: 0.0286 | Consistency: 0.0049 | SSIM: 0.0194 | Grad: 60361.262\n",
      "[Epoch 75, Batch 35/100] Loss: 0.0280 | RMSE: 0.0263 | Consistency: 0.0035 | SSIM: 0.0166 | Grad: 68981.906\n",
      "[Epoch 75, Batch 36/100] Loss: 0.0360 | RMSE: 0.0335 | Consistency: 0.0059 | SSIM: 0.0248 | Grad: 34868.539\n",
      "[Epoch 75, Batch 37/100] Loss: 0.0311 | RMSE: 0.0293 | Consistency: 0.0044 | SSIM: 0.0172 | Grad: 57930.152\n",
      "[Epoch 75, Batch 38/100] Loss: 0.0331 | RMSE: 0.0306 | Consistency: 0.0055 | SSIM: 0.0251 | Grad: 51969.383\n",
      "[Epoch 75, Batch 39/100] Loss: 0.0316 | RMSE: 0.0295 | Consistency: 0.0051 | SSIM: 0.0206 | Grad: 58929.426\n",
      "[Epoch 75, Batch 40/100] Loss: 0.0374 | RMSE: 0.0345 | Consistency: 0.0070 | SSIM: 0.0283 | Grad: 38994.906\n",
      "[Epoch 75, Batch 41/100] Loss: 0.0378 | RMSE: 0.0350 | Consistency: 0.0064 | SSIM: 0.0277 | Grad: 46945.766\n",
      "[Epoch 75, Batch 42/100] Loss: 0.0284 | RMSE: 0.0267 | Consistency: 0.0041 | SSIM: 0.0167 | Grad: 85930.664\n",
      "[Epoch 75, Batch 43/100] Loss: 0.0332 | RMSE: 0.0307 | Consistency: 0.0049 | SSIM: 0.0239 | Grad: 36630.730\n",
      "[Epoch 75, Batch 44/100] Loss: 0.0298 | RMSE: 0.0280 | Consistency: 0.0045 | SSIM: 0.0176 | Grad: 48000.359\n",
      "[Epoch 75, Batch 45/100] Loss: 0.0334 | RMSE: 0.0307 | Consistency: 0.0054 | SSIM: 0.0257 | Grad: 36467.547\n",
      "[Epoch 75, Batch 46/100] Loss: 0.0396 | RMSE: 0.0368 | Consistency: 0.0068 | SSIM: 0.0276 | Grad: 51054.949\n",
      "[Epoch 75, Batch 47/100] Loss: 0.0338 | RMSE: 0.0318 | Consistency: 0.0050 | SSIM: 0.0195 | Grad: 25038.705\n",
      "[Epoch 75, Batch 48/100] Loss: 0.0320 | RMSE: 0.0297 | Consistency: 0.0047 | SSIM: 0.0222 | Grad: 25963.623\n",
      "[Epoch 75, Batch 49/100] Loss: 0.0363 | RMSE: 0.0341 | Consistency: 0.0044 | SSIM: 0.0221 | Grad: 89530.289\n",
      "[Epoch 75, Batch 50/100] Loss: 0.0358 | RMSE: 0.0333 | Consistency: 0.0076 | SSIM: 0.0243 | Grad: 84685.922\n",
      "[Epoch 75, Batch 51/100] Loss: 0.0342 | RMSE: 0.0320 | Consistency: 0.0050 | SSIM: 0.0215 | Grad: 67573.836\n",
      "[Epoch 75, Batch 52/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0057 | SSIM: 0.0219 | Grad: 69641.062\n",
      "[Epoch 75, Batch 53/100] Loss: 0.0416 | RMSE: 0.0386 | Consistency: 0.0091 | SSIM: 0.0284 | Grad: 57074.523\n",
      "[Epoch 75, Batch 54/100] Loss: 0.0327 | RMSE: 0.0307 | Consistency: 0.0062 | SSIM: 0.0185 | Grad: 62944.129\n",
      "[Epoch 75, Batch 55/100] Loss: 0.0347 | RMSE: 0.0323 | Consistency: 0.0068 | SSIM: 0.0227 | Grad: 66585.500\n",
      "[Epoch 75, Batch 56/100] Loss: 0.0312 | RMSE: 0.0290 | Consistency: 0.0042 | SSIM: 0.0207 | Grad: 64425.707\n",
      "[Epoch 75, Batch 57/100] Loss: 0.0350 | RMSE: 0.0325 | Consistency: 0.0060 | SSIM: 0.0241 | Grad: 65985.109\n",
      "[Epoch 75, Batch 58/100] Loss: 0.0331 | RMSE: 0.0310 | Consistency: 0.0055 | SSIM: 0.0208 | Grad: 57741.418\n",
      "[Epoch 75, Batch 59/100] Loss: 0.0343 | RMSE: 0.0319 | Consistency: 0.0056 | SSIM: 0.0238 | Grad: 59747.734\n",
      "[Epoch 75, Batch 60/100] Loss: 0.0328 | RMSE: 0.0304 | Consistency: 0.0054 | SSIM: 0.0235 | Grad: 73054.625\n",
      "[Epoch 75, Batch 61/100] Loss: 0.0335 | RMSE: 0.0313 | Consistency: 0.0055 | SSIM: 0.0210 | Grad: 68574.258\n",
      "[Epoch 75, Batch 62/100] Loss: 0.0320 | RMSE: 0.0293 | Consistency: 0.0049 | SSIM: 0.0262 | Grad: 21282.486\n",
      "[Epoch 75, Batch 63/100] Loss: 0.0343 | RMSE: 0.0317 | Consistency: 0.0051 | SSIM: 0.0248 | Grad: 59196.824\n",
      "[Epoch 75, Batch 64/100] Loss: 0.0308 | RMSE: 0.0285 | Consistency: 0.0048 | SSIM: 0.0226 | Grad: 56591.301\n",
      "[Epoch 75, Batch 65/100] Loss: 0.0361 | RMSE: 0.0338 | Consistency: 0.0057 | SSIM: 0.0229 | Grad: 90080.578\n",
      "[Epoch 75, Batch 66/100] Loss: 0.0288 | RMSE: 0.0265 | Consistency: 0.0042 | SSIM: 0.0224 | Grad: 69449.438\n",
      "[Epoch 75, Batch 67/100] Loss: 0.0291 | RMSE: 0.0273 | Consistency: 0.0047 | SSIM: 0.0178 | Grad: 50450.336\n",
      "[Epoch 75, Batch 68/100] Loss: 0.0343 | RMSE: 0.0316 | Consistency: 0.0053 | SSIM: 0.0262 | Grad: 24760.139\n",
      "[Epoch 75, Batch 69/100] Loss: 0.0298 | RMSE: 0.0278 | Consistency: 0.0046 | SSIM: 0.0190 | Grad: 35369.789\n",
      "[Epoch 75, Batch 70/100] Loss: 0.0342 | RMSE: 0.0318 | Consistency: 0.0052 | SSIM: 0.0231 | Grad: 61248.312\n",
      "[Epoch 75, Batch 71/100] Loss: 0.0313 | RMSE: 0.0292 | Consistency: 0.0048 | SSIM: 0.0208 | Grad: 26256.990\n",
      "[Epoch 75, Batch 72/100] Loss: 0.0341 | RMSE: 0.0318 | Consistency: 0.0056 | SSIM: 0.0225 | Grad: 27135.371\n",
      "[Epoch 75, Batch 73/100] Loss: 0.0390 | RMSE: 0.0358 | Consistency: 0.0076 | SSIM: 0.0316 | Grad: 47419.820\n",
      "[Epoch 75, Batch 74/100] Loss: 0.0285 | RMSE: 0.0263 | Consistency: 0.0037 | SSIM: 0.0220 | Grad: 65059.160\n",
      "[Epoch 75, Batch 75/100] Loss: 0.0329 | RMSE: 0.0302 | Consistency: 0.0051 | SSIM: 0.0266 | Grad: 41084.098\n",
      "[Epoch 75, Batch 76/100] Loss: 0.0325 | RMSE: 0.0304 | Consistency: 0.0051 | SSIM: 0.0203 | Grad: 36353.453\n",
      "[Epoch 75, Batch 77/100] Loss: 0.0369 | RMSE: 0.0341 | Consistency: 0.0061 | SSIM: 0.0269 | Grad: 50859.633\n",
      "[Epoch 75, Batch 78/100] Loss: 0.0369 | RMSE: 0.0341 | Consistency: 0.0067 | SSIM: 0.0276 | Grad: 36199.668\n",
      "[Epoch 75, Batch 79/100] Loss: 0.0436 | RMSE: 0.0409 | Consistency: 0.0084 | SSIM: 0.0259 | Grad: 79430.359\n",
      "[Epoch 75, Batch 80/100] Loss: 0.0317 | RMSE: 0.0295 | Consistency: 0.0043 | SSIM: 0.0215 | Grad: 75040.297\n",
      "[Epoch 75, Batch 81/100] Loss: 0.0333 | RMSE: 0.0312 | Consistency: 0.0059 | SSIM: 0.0207 | Grad: 13390.854\n",
      "[Epoch 75, Batch 82/100] Loss: 0.0365 | RMSE: 0.0338 | Consistency: 0.0068 | SSIM: 0.0259 | Grad: 47321.840\n",
      "[Epoch 75, Batch 83/100] Loss: 0.0367 | RMSE: 0.0342 | Consistency: 0.0070 | SSIM: 0.0242 | Grad: 14549.375\n",
      "[Epoch 75, Batch 84/100] Loss: 0.0322 | RMSE: 0.0295 | Consistency: 0.0050 | SSIM: 0.0262 | Grad: 19394.486\n",
      "[Epoch 75, Batch 85/100] Loss: 0.0376 | RMSE: 0.0349 | Consistency: 0.0067 | SSIM: 0.0264 | Grad: 56477.750\n",
      "[Epoch 75, Batch 86/100] Loss: 0.0361 | RMSE: 0.0339 | Consistency: 0.0059 | SSIM: 0.0208 | Grad: 30494.531\n",
      "[Epoch 75, Batch 87/100] Loss: 0.0348 | RMSE: 0.0324 | Consistency: 0.0064 | SSIM: 0.0235 | Grad: 36983.172\n",
      "[Epoch 75, Batch 88/100] Loss: 0.0326 | RMSE: 0.0305 | Consistency: 0.0048 | SSIM: 0.0198 | Grad: 48998.895\n",
      "[Epoch 75, Batch 89/100] Loss: 0.0300 | RMSE: 0.0275 | Consistency: 0.0042 | SSIM: 0.0245 | Grad: 28790.875\n",
      "[Epoch 75, Batch 90/100] Loss: 0.0325 | RMSE: 0.0304 | Consistency: 0.0051 | SSIM: 0.0211 | Grad: 30346.207\n",
      "[Epoch 75, Batch 91/100] Loss: 0.0333 | RMSE: 0.0312 | Consistency: 0.0057 | SSIM: 0.0200 | Grad: 66213.359\n",
      "[Epoch 75, Batch 92/100] Loss: 0.0351 | RMSE: 0.0321 | Consistency: 0.0064 | SSIM: 0.0296 | Grad: 48245.852\n",
      "[Epoch 75, Batch 93/100] Loss: 0.0352 | RMSE: 0.0329 | Consistency: 0.0063 | SSIM: 0.0222 | Grad: 27524.426\n",
      "[Epoch 75, Batch 94/100] Loss: 0.0328 | RMSE: 0.0309 | Consistency: 0.0045 | SSIM: 0.0180 | Grad: 56618.098\n",
      "[Epoch 75, Batch 95/100] Loss: 0.0370 | RMSE: 0.0343 | Consistency: 0.0072 | SSIM: 0.0257 | Grad: 73100.258\n",
      "[Epoch 75, Batch 96/100] Loss: 0.0361 | RMSE: 0.0333 | Consistency: 0.0057 | SSIM: 0.0273 | Grad: 22847.971\n",
      "[Epoch 75, Batch 97/100] Loss: 0.0306 | RMSE: 0.0285 | Consistency: 0.0043 | SSIM: 0.0198 | Grad: 26118.744\n",
      "[Epoch 75, Batch 98/100] Loss: 0.0390 | RMSE: 0.0363 | Consistency: 0.0064 | SSIM: 0.0265 | Grad: 40756.133\n",
      "[Epoch 75, Batch 99/100] Loss: 0.0380 | RMSE: 0.0355 | Consistency: 0.0068 | SSIM: 0.0247 | Grad: 36614.020\n",
      "[Epoch 75, Batch 100/100] Loss: 0.0377 | RMSE: 0.0357 | Consistency: 0.0058 | SSIM: 0.0188 | Grad: 76051.438\n",
      "✅ Epoch 75 완료!\n",
      "   📈 평균 Loss: 0.034605\n",
      "   📊 평균 RMSE: 0.032283\n",
      "   ⚙️  학습률: 0.000012\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 76/80 시작...\n",
      "[Epoch 76, Batch 1/100] Loss: 0.0332 | RMSE: 0.0310 | Consistency: 0.0060 | SSIM: 0.0214 | Grad: 26049.641\n",
      "[Epoch 76, Batch 2/100] Loss: 0.0406 | RMSE: 0.0378 | Consistency: 0.0087 | SSIM: 0.0278 | Grad: 63603.809\n",
      "[Epoch 76, Batch 3/100] Loss: 0.0325 | RMSE: 0.0305 | Consistency: 0.0051 | SSIM: 0.0195 | Grad: 65352.168\n",
      "[Epoch 76, Batch 4/100] Loss: 0.0341 | RMSE: 0.0316 | Consistency: 0.0055 | SSIM: 0.0240 | Grad: 92654.031\n",
      "[Epoch 76, Batch 5/100] Loss: 0.0371 | RMSE: 0.0346 | Consistency: 0.0060 | SSIM: 0.0243 | Grad: 59939.227\n",
      "[Epoch 76, Batch 6/100] Loss: 0.0362 | RMSE: 0.0334 | Consistency: 0.0055 | SSIM: 0.0271 | Grad: 59814.363\n",
      "[Epoch 76, Batch 7/100] Loss: 0.0331 | RMSE: 0.0308 | Consistency: 0.0052 | SSIM: 0.0228 | Grad: 68226.156\n",
      "[Epoch 76, Batch 8/100] Loss: 0.0343 | RMSE: 0.0320 | Consistency: 0.0063 | SSIM: 0.0231 | Grad: 63114.371\n",
      "[Epoch 76, Batch 9/100] Loss: 0.0340 | RMSE: 0.0321 | Consistency: 0.0056 | SSIM: 0.0191 | Grad: 37742.109\n",
      "[Epoch 76, Batch 10/100] Loss: 0.0392 | RMSE: 0.0371 | Consistency: 0.0064 | SSIM: 0.0209 | Grad: 33258.316\n",
      "[Epoch 76, Batch 11/100] Loss: 0.0262 | RMSE: 0.0246 | Consistency: 0.0032 | SSIM: 0.0160 | Grad: 41433.395\n",
      "[Epoch 76, Batch 12/100] Loss: 0.0336 | RMSE: 0.0315 | Consistency: 0.0045 | SSIM: 0.0204 | Grad: 53584.359\n",
      "[Epoch 76, Batch 13/100] Loss: 0.0336 | RMSE: 0.0309 | Consistency: 0.0052 | SSIM: 0.0261 | Grad: 56371.188\n",
      "[Epoch 76, Batch 14/100] Loss: 0.0377 | RMSE: 0.0345 | Consistency: 0.0067 | SSIM: 0.0314 | Grad: 13734.814\n",
      "[Epoch 76, Batch 15/100] Loss: 0.0322 | RMSE: 0.0298 | Consistency: 0.0052 | SSIM: 0.0241 | Grad: 50964.480\n",
      "[Epoch 76, Batch 16/100] Loss: 0.0312 | RMSE: 0.0289 | Consistency: 0.0046 | SSIM: 0.0227 | Grad: 37893.434\n",
      "[Epoch 76, Batch 17/100] Loss: 0.0334 | RMSE: 0.0312 | Consistency: 0.0055 | SSIM: 0.0213 | Grad: 61845.836\n",
      "[Epoch 76, Batch 18/100] Loss: 0.0408 | RMSE: 0.0385 | Consistency: 0.0069 | SSIM: 0.0222 | Grad: 45180.301\n",
      "[Epoch 76, Batch 19/100] Loss: 0.0321 | RMSE: 0.0299 | Consistency: 0.0052 | SSIM: 0.0206 | Grad: 77415.773\n",
      "[Epoch 76, Batch 20/100] Loss: 0.0357 | RMSE: 0.0330 | Consistency: 0.0060 | SSIM: 0.0260 | Grad: 34996.742\n",
      "[Epoch 76, Batch 21/100] Loss: 0.0312 | RMSE: 0.0292 | Consistency: 0.0045 | SSIM: 0.0203 | Grad: 51824.285\n",
      "[Epoch 76, Batch 22/100] Loss: 0.0334 | RMSE: 0.0308 | Consistency: 0.0051 | SSIM: 0.0257 | Grad: 40450.152\n",
      "[Epoch 76, Batch 23/100] Loss: 0.0379 | RMSE: 0.0350 | Consistency: 0.0067 | SSIM: 0.0275 | Grad: 55474.242\n",
      "[Epoch 76, Batch 24/100] Loss: 0.0395 | RMSE: 0.0366 | Consistency: 0.0079 | SSIM: 0.0286 | Grad: 45552.809\n",
      "[Epoch 76, Batch 25/100] Loss: 0.0381 | RMSE: 0.0354 | Consistency: 0.0083 | SSIM: 0.0256 | Grad: 56169.012\n",
      "[Epoch 76, Batch 26/100] Loss: 0.0313 | RMSE: 0.0291 | Consistency: 0.0049 | SSIM: 0.0218 | Grad: 77848.719\n",
      "[Epoch 76, Batch 27/100] Loss: 0.0319 | RMSE: 0.0296 | Consistency: 0.0045 | SSIM: 0.0222 | Grad: 49869.715\n",
      "[Epoch 76, Batch 28/100] Loss: 0.0374 | RMSE: 0.0352 | Consistency: 0.0064 | SSIM: 0.0221 | Grad: 41157.762\n",
      "[Epoch 76, Batch 29/100] Loss: 0.0357 | RMSE: 0.0332 | Consistency: 0.0061 | SSIM: 0.0247 | Grad: 47936.938\n",
      "[Epoch 76, Batch 30/100] Loss: 0.0334 | RMSE: 0.0312 | Consistency: 0.0051 | SSIM: 0.0218 | Grad: 41869.816\n",
      "[Epoch 76, Batch 31/100] Loss: 0.0341 | RMSE: 0.0315 | Consistency: 0.0053 | SSIM: 0.0250 | Grad: 55653.480\n",
      "[Epoch 76, Batch 32/100] Loss: 0.0335 | RMSE: 0.0310 | Consistency: 0.0058 | SSIM: 0.0244 | Grad: 49365.926\n",
      "[Epoch 76, Batch 33/100] Loss: 0.0335 | RMSE: 0.0310 | Consistency: 0.0045 | SSIM: 0.0251 | Grad: 43085.129\n",
      "[Epoch 76, Batch 34/100] Loss: 0.0397 | RMSE: 0.0369 | Consistency: 0.0080 | SSIM: 0.0273 | Grad: 43838.688\n",
      "[Epoch 76, Batch 35/100] Loss: 0.0380 | RMSE: 0.0355 | Consistency: 0.0068 | SSIM: 0.0245 | Grad: 25940.709\n",
      "[Epoch 76, Batch 36/100] Loss: 0.0327 | RMSE: 0.0306 | Consistency: 0.0056 | SSIM: 0.0200 | Grad: 58222.730\n",
      "[Epoch 76, Batch 37/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0064 | SSIM: 0.0201 | Grad: 33957.559\n",
      "[Epoch 76, Batch 38/100] Loss: 0.0332 | RMSE: 0.0309 | Consistency: 0.0054 | SSIM: 0.0221 | Grad: 69559.156\n",
      "[Epoch 76, Batch 39/100] Loss: 0.0339 | RMSE: 0.0317 | Consistency: 0.0059 | SSIM: 0.0212 | Grad: 36501.430\n",
      "[Epoch 76, Batch 40/100] Loss: 0.0325 | RMSE: 0.0301 | Consistency: 0.0047 | SSIM: 0.0238 | Grad: 45289.297\n",
      "[Epoch 76, Batch 41/100] Loss: 0.0341 | RMSE: 0.0320 | Consistency: 0.0059 | SSIM: 0.0205 | Grad: 39569.609\n",
      "[Epoch 76, Batch 42/100] Loss: 0.0384 | RMSE: 0.0359 | Consistency: 0.0061 | SSIM: 0.0240 | Grad: 82375.375\n",
      "[Epoch 76, Batch 43/100] Loss: 0.0319 | RMSE: 0.0297 | Consistency: 0.0053 | SSIM: 0.0214 | Grad: 27219.012\n",
      "[Epoch 76, Batch 44/100] Loss: 0.0323 | RMSE: 0.0301 | Consistency: 0.0045 | SSIM: 0.0221 | Grad: 58925.027\n",
      "[Epoch 76, Batch 45/100] Loss: 0.0292 | RMSE: 0.0267 | Consistency: 0.0042 | SSIM: 0.0246 | Grad: 22163.793\n",
      "[Epoch 76, Batch 46/100] Loss: 0.0309 | RMSE: 0.0290 | Consistency: 0.0044 | SSIM: 0.0194 | Grad: 31632.975\n",
      "[Epoch 76, Batch 47/100] Loss: 0.0354 | RMSE: 0.0332 | Consistency: 0.0057 | SSIM: 0.0206 | Grad: 57298.855\n",
      "[Epoch 76, Batch 48/100] Loss: 0.0353 | RMSE: 0.0328 | Consistency: 0.0069 | SSIM: 0.0247 | Grad: 37133.375\n",
      "[Epoch 76, Batch 49/100] Loss: 0.0354 | RMSE: 0.0327 | Consistency: 0.0062 | SSIM: 0.0256 | Grad: 40887.531\n",
      "[Epoch 76, Batch 50/100] Loss: 0.0340 | RMSE: 0.0319 | Consistency: 0.0053 | SSIM: 0.0207 | Grad: 66964.227\n",
      "[Epoch 76, Batch 51/100] Loss: 0.0317 | RMSE: 0.0295 | Consistency: 0.0050 | SSIM: 0.0223 | Grad: 33232.230\n",
      "[Epoch 76, Batch 52/100] Loss: 0.0306 | RMSE: 0.0288 | Consistency: 0.0045 | SSIM: 0.0176 | Grad: 75735.945\n",
      "[Epoch 76, Batch 53/100] Loss: 0.0350 | RMSE: 0.0329 | Consistency: 0.0059 | SSIM: 0.0205 | Grad: 75994.438\n",
      "[Epoch 76, Batch 54/100] Loss: 0.0324 | RMSE: 0.0302 | Consistency: 0.0049 | SSIM: 0.0224 | Grad: 75005.156\n",
      "[Epoch 76, Batch 55/100] Loss: 0.0427 | RMSE: 0.0400 | Consistency: 0.0094 | SSIM: 0.0259 | Grad: 39424.375\n",
      "[Epoch 76, Batch 56/100] Loss: 0.0344 | RMSE: 0.0324 | Consistency: 0.0051 | SSIM: 0.0198 | Grad: 40106.953\n",
      "[Epoch 76, Batch 57/100] Loss: 0.0356 | RMSE: 0.0330 | Consistency: 0.0064 | SSIM: 0.0251 | Grad: 12774.396\n",
      "[Epoch 76, Batch 58/100] Loss: 0.0302 | RMSE: 0.0283 | Consistency: 0.0043 | SSIM: 0.0187 | Grad: 49727.500\n",
      "[Epoch 76, Batch 59/100] Loss: 0.0339 | RMSE: 0.0316 | Consistency: 0.0055 | SSIM: 0.0221 | Grad: 20805.074\n",
      "[Epoch 76, Batch 60/100] Loss: 0.0316 | RMSE: 0.0296 | Consistency: 0.0044 | SSIM: 0.0199 | Grad: 31819.883\n",
      "[Epoch 76, Batch 61/100] Loss: 0.0357 | RMSE: 0.0336 | Consistency: 0.0062 | SSIM: 0.0204 | Grad: 16755.275\n",
      "[Epoch 76, Batch 62/100] Loss: 0.0356 | RMSE: 0.0328 | Consistency: 0.0055 | SSIM: 0.0281 | Grad: 77562.922\n",
      "[Epoch 76, Batch 63/100] Loss: 0.0387 | RMSE: 0.0368 | Consistency: 0.0094 | SSIM: 0.0186 | Grad: 62591.402\n",
      "[Epoch 76, Batch 64/100] Loss: 0.0333 | RMSE: 0.0314 | Consistency: 0.0047 | SSIM: 0.0184 | Grad: 65541.625\n",
      "[Epoch 76, Batch 65/100] Loss: 0.0377 | RMSE: 0.0356 | Consistency: 0.0053 | SSIM: 0.0203 | Grad: 59001.105\n",
      "[Epoch 76, Batch 66/100] Loss: 0.0349 | RMSE: 0.0322 | Consistency: 0.0066 | SSIM: 0.0258 | Grad: 29458.084\n",
      "[Epoch 76, Batch 67/100] Loss: 0.0290 | RMSE: 0.0270 | Consistency: 0.0040 | SSIM: 0.0194 | Grad: 37050.211\n",
      "[Epoch 76, Batch 68/100] Loss: 0.0344 | RMSE: 0.0323 | Consistency: 0.0061 | SSIM: 0.0204 | Grad: 52066.770\n",
      "[Epoch 76, Batch 69/100] Loss: 0.0356 | RMSE: 0.0331 | Consistency: 0.0062 | SSIM: 0.0250 | Grad: 50231.355\n",
      "[Epoch 76, Batch 70/100] Loss: 0.0319 | RMSE: 0.0295 | Consistency: 0.0054 | SSIM: 0.0236 | Grad: 21421.365\n",
      "[Epoch 76, Batch 71/100] Loss: 0.0317 | RMSE: 0.0297 | Consistency: 0.0057 | SSIM: 0.0192 | Grad: 65031.438\n",
      "[Epoch 76, Batch 72/100] Loss: 0.0385 | RMSE: 0.0357 | Consistency: 0.0061 | SSIM: 0.0274 | Grad: 37057.789\n",
      "[Epoch 76, Batch 73/100] Loss: 0.0326 | RMSE: 0.0307 | Consistency: 0.0050 | SSIM: 0.0177 | Grad: 33318.086\n",
      "[Epoch 76, Batch 74/100] Loss: 0.0315 | RMSE: 0.0291 | Consistency: 0.0047 | SSIM: 0.0237 | Grad: 44331.621\n",
      "[Epoch 76, Batch 75/100] Loss: 0.0359 | RMSE: 0.0334 | Consistency: 0.0070 | SSIM: 0.0244 | Grad: 54668.012\n",
      "[Epoch 76, Batch 76/100] Loss: 0.0335 | RMSE: 0.0312 | Consistency: 0.0052 | SSIM: 0.0224 | Grad: 80451.172\n",
      "[Epoch 76, Batch 77/100] Loss: 0.0392 | RMSE: 0.0367 | Consistency: 0.0074 | SSIM: 0.0245 | Grad: 29334.877\n",
      "[Epoch 76, Batch 78/100] Loss: 0.0308 | RMSE: 0.0286 | Consistency: 0.0043 | SSIM: 0.0220 | Grad: 63353.633\n",
      "[Epoch 76, Batch 79/100] Loss: 0.0336 | RMSE: 0.0314 | Consistency: 0.0062 | SSIM: 0.0214 | Grad: 60615.914\n",
      "[Epoch 76, Batch 80/100] Loss: 0.0308 | RMSE: 0.0290 | Consistency: 0.0051 | SSIM: 0.0175 | Grad: 47084.980\n",
      "[Epoch 76, Batch 81/100] Loss: 0.0402 | RMSE: 0.0377 | Consistency: 0.0073 | SSIM: 0.0248 | Grad: 47704.535\n",
      "[Epoch 76, Batch 82/100] Loss: 0.0328 | RMSE: 0.0306 | Consistency: 0.0045 | SSIM: 0.0216 | Grad: 48886.293\n",
      "[Epoch 76, Batch 83/100] Loss: 0.0314 | RMSE: 0.0291 | Consistency: 0.0050 | SSIM: 0.0219 | Grad: 19320.330\n",
      "[Epoch 76, Batch 84/100] Loss: 0.0287 | RMSE: 0.0268 | Consistency: 0.0037 | SSIM: 0.0190 | Grad: 66319.188\n",
      "[Epoch 76, Batch 85/100] Loss: 0.0322 | RMSE: 0.0303 | Consistency: 0.0045 | SSIM: 0.0180 | Grad: 32252.203\n",
      "[Epoch 76, Batch 86/100] Loss: 0.0350 | RMSE: 0.0329 | Consistency: 0.0062 | SSIM: 0.0207 | Grad: 56176.410\n",
      "[Epoch 76, Batch 87/100] Loss: 0.0316 | RMSE: 0.0297 | Consistency: 0.0049 | SSIM: 0.0184 | Grad: 94734.398\n",
      "[Epoch 76, Batch 88/100] Loss: 0.0305 | RMSE: 0.0287 | Consistency: 0.0043 | SSIM: 0.0177 | Grad: 75889.133\n",
      "[Epoch 76, Batch 89/100] Loss: 0.0367 | RMSE: 0.0343 | Consistency: 0.0057 | SSIM: 0.0227 | Grad: 26074.662\n",
      "[Epoch 76, Batch 90/100] Loss: 0.0321 | RMSE: 0.0299 | Consistency: 0.0045 | SSIM: 0.0224 | Grad: 42626.086\n",
      "[Epoch 76, Batch 91/100] Loss: 0.0306 | RMSE: 0.0285 | Consistency: 0.0043 | SSIM: 0.0207 | Grad: 50975.172\n",
      "[Epoch 76, Batch 92/100] Loss: 0.0369 | RMSE: 0.0346 | Consistency: 0.0066 | SSIM: 0.0221 | Grad: 67393.320\n",
      "[Epoch 76, Batch 93/100] Loss: 0.0338 | RMSE: 0.0316 | Consistency: 0.0054 | SSIM: 0.0215 | Grad: 47977.777\n",
      "[Epoch 76, Batch 94/100] Loss: 0.0375 | RMSE: 0.0350 | Consistency: 0.0069 | SSIM: 0.0244 | Grad: 42408.332\n",
      "[Epoch 76, Batch 95/100] Loss: 0.0326 | RMSE: 0.0307 | Consistency: 0.0048 | SSIM: 0.0186 | Grad: 55349.621\n",
      "[Epoch 76, Batch 96/100] Loss: 0.0344 | RMSE: 0.0322 | Consistency: 0.0060 | SSIM: 0.0213 | Grad: 56017.453\n",
      "[Epoch 76, Batch 97/100] Loss: 0.0337 | RMSE: 0.0311 | Consistency: 0.0057 | SSIM: 0.0253 | Grad: 21105.957\n",
      "[Epoch 76, Batch 98/100] Loss: 0.0304 | RMSE: 0.0282 | Consistency: 0.0043 | SSIM: 0.0216 | Grad: 61129.086\n",
      "[Epoch 76, Batch 99/100] Loss: 0.0379 | RMSE: 0.0351 | Consistency: 0.0059 | SSIM: 0.0279 | Grad: 68287.656\n",
      "[Epoch 76, Batch 100/100] Loss: 0.0396 | RMSE: 0.0364 | Consistency: 0.0085 | SSIM: 0.0313 | Grad: 73757.055\n",
      "✅ Epoch 76 완료!\n",
      "   📈 평균 Loss: 0.034250\n",
      "   📊 평균 RMSE: 0.031938\n",
      "   ⚙️  학습률: 0.000008\n",
      "   🏆 NEW BEST! RMSE: 0.031938\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 77/80 시작...\n",
      "[Epoch 77, Batch 1/100] Loss: 0.0374 | RMSE: 0.0352 | Consistency: 0.0070 | SSIM: 0.0214 | Grad: 72302.578\n",
      "[Epoch 77, Batch 2/100] Loss: 0.0425 | RMSE: 0.0398 | Consistency: 0.0087 | SSIM: 0.0257 | Grad: 78804.805\n",
      "[Epoch 77, Batch 3/100] Loss: 0.0370 | RMSE: 0.0329 | Consistency: 0.0066 | SSIM: 0.0402 | Grad: 50661.484\n",
      "[Epoch 77, Batch 4/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0052 | SSIM: 0.0201 | Grad: 11509.905\n",
      "[Epoch 77, Batch 5/100] Loss: 0.0398 | RMSE: 0.0365 | Consistency: 0.0079 | SSIM: 0.0322 | Grad: 31519.523\n",
      "[Epoch 77, Batch 6/100] Loss: 0.0372 | RMSE: 0.0348 | Consistency: 0.0056 | SSIM: 0.0229 | Grad: 20191.135\n",
      "[Epoch 77, Batch 7/100] Loss: 0.0291 | RMSE: 0.0274 | Consistency: 0.0044 | SSIM: 0.0166 | Grad: 64279.398\n",
      "[Epoch 77, Batch 8/100] Loss: 0.0348 | RMSE: 0.0325 | Consistency: 0.0054 | SSIM: 0.0230 | Grad: 49899.480\n",
      "[Epoch 77, Batch 9/100] Loss: 0.0329 | RMSE: 0.0305 | Consistency: 0.0057 | SSIM: 0.0230 | Grad: 36652.574\n",
      "[Epoch 77, Batch 10/100] Loss: 0.0319 | RMSE: 0.0295 | Consistency: 0.0050 | SSIM: 0.0233 | Grad: 31323.404\n",
      "[Epoch 77, Batch 11/100] Loss: 0.0321 | RMSE: 0.0300 | Consistency: 0.0053 | SSIM: 0.0199 | Grad: 43384.961\n",
      "[Epoch 77, Batch 12/100] Loss: 0.0410 | RMSE: 0.0385 | Consistency: 0.0066 | SSIM: 0.0245 | Grad: 49813.062\n",
      "[Epoch 77, Batch 13/100] Loss: 0.0286 | RMSE: 0.0261 | Consistency: 0.0039 | SSIM: 0.0240 | Grad: 30908.188\n",
      "[Epoch 77, Batch 14/100] Loss: 0.0356 | RMSE: 0.0334 | Consistency: 0.0054 | SSIM: 0.0221 | Grad: 60753.438\n",
      "[Epoch 77, Batch 15/100] Loss: 0.0361 | RMSE: 0.0335 | Consistency: 0.0064 | SSIM: 0.0258 | Grad: 30387.736\n",
      "[Epoch 77, Batch 16/100] Loss: 0.0344 | RMSE: 0.0321 | Consistency: 0.0057 | SSIM: 0.0222 | Grad: 35599.211\n",
      "[Epoch 77, Batch 17/100] Loss: 0.0313 | RMSE: 0.0296 | Consistency: 0.0047 | SSIM: 0.0166 | Grad: 52002.941\n",
      "[Epoch 77, Batch 18/100] Loss: 0.0333 | RMSE: 0.0314 | Consistency: 0.0043 | SSIM: 0.0191 | Grad: 107563.562\n",
      "[Epoch 77, Batch 19/100] Loss: 0.0535 | RMSE: 0.0499 | Consistency: 0.0154 | SSIM: 0.0341 | Grad: 77424.938\n",
      "[Epoch 77, Batch 20/100] Loss: 0.0339 | RMSE: 0.0321 | Consistency: 0.0053 | SSIM: 0.0176 | Grad: 34799.465\n",
      "[Epoch 77, Batch 21/100] Loss: 0.0357 | RMSE: 0.0338 | Consistency: 0.0056 | SSIM: 0.0178 | Grad: 81054.008\n",
      "[Epoch 77, Batch 22/100] Loss: 0.0303 | RMSE: 0.0285 | Consistency: 0.0044 | SSIM: 0.0175 | Grad: 60955.453\n",
      "[Epoch 77, Batch 23/100] Loss: 0.0314 | RMSE: 0.0292 | Consistency: 0.0049 | SSIM: 0.0207 | Grad: 12000.931\n",
      "[Epoch 77, Batch 24/100] Loss: 0.0334 | RMSE: 0.0309 | Consistency: 0.0059 | SSIM: 0.0241 | Grad: 55099.387\n",
      "[Epoch 77, Batch 25/100] Loss: 0.0295 | RMSE: 0.0272 | Consistency: 0.0039 | SSIM: 0.0229 | Grad: 42523.094\n",
      "[Epoch 77, Batch 26/100] Loss: 0.0360 | RMSE: 0.0336 | Consistency: 0.0064 | SSIM: 0.0231 | Grad: 70846.875\n",
      "[Epoch 77, Batch 27/100] Loss: 0.0334 | RMSE: 0.0312 | Consistency: 0.0049 | SSIM: 0.0210 | Grad: 70992.539\n",
      "[Epoch 77, Batch 28/100] Loss: 0.0331 | RMSE: 0.0311 | Consistency: 0.0055 | SSIM: 0.0197 | Grad: 61537.133\n",
      "[Epoch 77, Batch 29/100] Loss: 0.0306 | RMSE: 0.0286 | Consistency: 0.0048 | SSIM: 0.0196 | Grad: 36676.309\n",
      "[Epoch 77, Batch 30/100] Loss: 0.0338 | RMSE: 0.0320 | Consistency: 0.0059 | SSIM: 0.0173 | Grad: 62926.242\n",
      "[Epoch 77, Batch 31/100] Loss: 0.0377 | RMSE: 0.0353 | Consistency: 0.0070 | SSIM: 0.0238 | Grad: 38435.188\n",
      "[Epoch 77, Batch 32/100] Loss: 0.0366 | RMSE: 0.0335 | Consistency: 0.0062 | SSIM: 0.0305 | Grad: 52357.812\n",
      "[Epoch 77, Batch 33/100] Loss: 0.0333 | RMSE: 0.0314 | Consistency: 0.0059 | SSIM: 0.0193 | Grad: 26284.938\n",
      "[Epoch 77, Batch 34/100] Loss: 0.0302 | RMSE: 0.0283 | Consistency: 0.0042 | SSIM: 0.0184 | Grad: 54888.395\n",
      "[Epoch 77, Batch 35/100] Loss: 0.0329 | RMSE: 0.0312 | Consistency: 0.0061 | SSIM: 0.0166 | Grad: 19269.977\n",
      "[Epoch 77, Batch 36/100] Loss: 0.0347 | RMSE: 0.0326 | Consistency: 0.0056 | SSIM: 0.0200 | Grad: 26108.717\n",
      "[Epoch 77, Batch 37/100] Loss: 0.0370 | RMSE: 0.0343 | Consistency: 0.0070 | SSIM: 0.0259 | Grad: 79106.641\n",
      "[Epoch 77, Batch 38/100] Loss: 0.0272 | RMSE: 0.0255 | Consistency: 0.0039 | SSIM: 0.0166 | Grad: 53052.426\n",
      "[Epoch 77, Batch 39/100] Loss: 0.0369 | RMSE: 0.0346 | Consistency: 0.0064 | SSIM: 0.0227 | Grad: 56028.031\n",
      "[Epoch 77, Batch 40/100] Loss: 0.0377 | RMSE: 0.0350 | Consistency: 0.0048 | SSIM: 0.0262 | Grad: 48707.168\n",
      "[Epoch 77, Batch 41/100] Loss: 0.0336 | RMSE: 0.0314 | Consistency: 0.0056 | SSIM: 0.0216 | Grad: 62793.977\n",
      "[Epoch 77, Batch 42/100] Loss: 0.0354 | RMSE: 0.0329 | Consistency: 0.0056 | SSIM: 0.0252 | Grad: 65613.586\n",
      "[Epoch 77, Batch 43/100] Loss: 0.0333 | RMSE: 0.0306 | Consistency: 0.0057 | SSIM: 0.0263 | Grad: 14038.057\n",
      "[Epoch 77, Batch 44/100] Loss: 0.0394 | RMSE: 0.0366 | Consistency: 0.0051 | SSIM: 0.0276 | Grad: 75397.445\n",
      "[Epoch 77, Batch 45/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0053 | SSIM: 0.0216 | Grad: 40294.867\n",
      "[Epoch 77, Batch 46/100] Loss: 0.0316 | RMSE: 0.0294 | Consistency: 0.0049 | SSIM: 0.0214 | Grad: 46496.793\n",
      "[Epoch 77, Batch 47/100] Loss: 0.0344 | RMSE: 0.0318 | Consistency: 0.0059 | SSIM: 0.0261 | Grad: 37745.801\n",
      "[Epoch 77, Batch 48/100] Loss: 0.0359 | RMSE: 0.0332 | Consistency: 0.0057 | SSIM: 0.0266 | Grad: 35733.477\n",
      "[Epoch 77, Batch 49/100] Loss: 0.0334 | RMSE: 0.0314 | Consistency: 0.0060 | SSIM: 0.0195 | Grad: 31508.762\n",
      "[Epoch 77, Batch 50/100] Loss: 0.0338 | RMSE: 0.0312 | Consistency: 0.0054 | SSIM: 0.0256 | Grad: 65901.062\n",
      "[Epoch 77, Batch 51/100] Loss: 0.0344 | RMSE: 0.0319 | Consistency: 0.0048 | SSIM: 0.0245 | Grad: 18390.428\n",
      "[Epoch 77, Batch 52/100] Loss: 0.0303 | RMSE: 0.0281 | Consistency: 0.0052 | SSIM: 0.0218 | Grad: 27976.023\n",
      "[Epoch 77, Batch 53/100] Loss: 0.0350 | RMSE: 0.0324 | Consistency: 0.0054 | SSIM: 0.0261 | Grad: 26568.516\n",
      "[Epoch 77, Batch 54/100] Loss: 0.0300 | RMSE: 0.0282 | Consistency: 0.0043 | SSIM: 0.0174 | Grad: 39889.375\n",
      "[Epoch 77, Batch 55/100] Loss: 0.0404 | RMSE: 0.0377 | Consistency: 0.0071 | SSIM: 0.0263 | Grad: 42309.703\n",
      "[Epoch 77, Batch 56/100] Loss: 0.0317 | RMSE: 0.0294 | Consistency: 0.0040 | SSIM: 0.0230 | Grad: 33009.297\n",
      "[Epoch 77, Batch 57/100] Loss: 0.0379 | RMSE: 0.0350 | Consistency: 0.0062 | SSIM: 0.0278 | Grad: 43016.531\n",
      "[Epoch 77, Batch 58/100] Loss: 0.0373 | RMSE: 0.0349 | Consistency: 0.0069 | SSIM: 0.0231 | Grad: 67100.883\n",
      "[Epoch 77, Batch 59/100] Loss: 0.0450 | RMSE: 0.0423 | Consistency: 0.0128 | SSIM: 0.0256 | Grad: 79270.234\n",
      "[Epoch 77, Batch 60/100] Loss: 0.0311 | RMSE: 0.0293 | Consistency: 0.0048 | SSIM: 0.0176 | Grad: 42511.441\n",
      "[Epoch 77, Batch 61/100] Loss: 0.0336 | RMSE: 0.0313 | Consistency: 0.0061 | SSIM: 0.0227 | Grad: 68487.688\n",
      "[Epoch 77, Batch 62/100] Loss: 0.0292 | RMSE: 0.0269 | Consistency: 0.0039 | SSIM: 0.0229 | Grad: 75451.328\n",
      "[Epoch 77, Batch 63/100] Loss: 0.0333 | RMSE: 0.0310 | Consistency: 0.0054 | SSIM: 0.0223 | Grad: 70479.664\n",
      "[Epoch 77, Batch 64/100] Loss: 0.0416 | RMSE: 0.0390 | Consistency: 0.0082 | SSIM: 0.0248 | Grad: 63162.520\n",
      "[Epoch 77, Batch 65/100] Loss: 0.0293 | RMSE: 0.0274 | Consistency: 0.0039 | SSIM: 0.0189 | Grad: 33543.629\n",
      "[Epoch 77, Batch 66/100] Loss: 0.0329 | RMSE: 0.0307 | Consistency: 0.0048 | SSIM: 0.0214 | Grad: 66437.758\n",
      "[Epoch 77, Batch 67/100] Loss: 0.0359 | RMSE: 0.0334 | Consistency: 0.0059 | SSIM: 0.0245 | Grad: 24627.326\n",
      "[Epoch 77, Batch 68/100] Loss: 0.0318 | RMSE: 0.0296 | Consistency: 0.0049 | SSIM: 0.0215 | Grad: 20874.340\n",
      "[Epoch 77, Batch 69/100] Loss: 0.0354 | RMSE: 0.0331 | Consistency: 0.0055 | SSIM: 0.0228 | Grad: 17699.799\n",
      "[Epoch 77, Batch 70/100] Loss: 0.0350 | RMSE: 0.0323 | Consistency: 0.0061 | SSIM: 0.0257 | Grad: 50829.848\n",
      "[Epoch 77, Batch 71/100] Loss: 0.0356 | RMSE: 0.0331 | Consistency: 0.0063 | SSIM: 0.0246 | Grad: 32126.139\n",
      "[Epoch 77, Batch 72/100] Loss: 0.0339 | RMSE: 0.0320 | Consistency: 0.0054 | SSIM: 0.0182 | Grad: 87036.328\n",
      "[Epoch 77, Batch 73/100] Loss: 0.0333 | RMSE: 0.0313 | Consistency: 0.0049 | SSIM: 0.0190 | Grad: 58982.992\n",
      "[Epoch 77, Batch 74/100] Loss: 0.0413 | RMSE: 0.0385 | Consistency: 0.0070 | SSIM: 0.0274 | Grad: 20930.242\n",
      "[Epoch 77, Batch 75/100] Loss: 0.0309 | RMSE: 0.0287 | Consistency: 0.0048 | SSIM: 0.0218 | Grad: 32739.553\n",
      "[Epoch 77, Batch 76/100] Loss: 0.0337 | RMSE: 0.0314 | Consistency: 0.0064 | SSIM: 0.0228 | Grad: 15748.471\n",
      "[Epoch 77, Batch 77/100] Loss: 0.0325 | RMSE: 0.0304 | Consistency: 0.0051 | SSIM: 0.0208 | Grad: 58310.984\n",
      "[Epoch 77, Batch 78/100] Loss: 0.0302 | RMSE: 0.0283 | Consistency: 0.0045 | SSIM: 0.0182 | Grad: 15365.639\n",
      "[Epoch 77, Batch 79/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0054 | SSIM: 0.0199 | Grad: 24157.723\n",
      "[Epoch 77, Batch 80/100] Loss: 0.0302 | RMSE: 0.0285 | Consistency: 0.0042 | SSIM: 0.0173 | Grad: 35408.875\n",
      "[Epoch 77, Batch 81/100] Loss: 0.0312 | RMSE: 0.0294 | Consistency: 0.0045 | SSIM: 0.0179 | Grad: 55127.598\n",
      "[Epoch 77, Batch 82/100] Loss: 0.0345 | RMSE: 0.0322 | Consistency: 0.0062 | SSIM: 0.0223 | Grad: 36813.660\n",
      "[Epoch 77, Batch 83/100] Loss: 0.0339 | RMSE: 0.0313 | Consistency: 0.0059 | SSIM: 0.0261 | Grad: 48820.164\n",
      "[Epoch 77, Batch 84/100] Loss: 0.0327 | RMSE: 0.0305 | Consistency: 0.0053 | SSIM: 0.0217 | Grad: 44673.238\n",
      "[Epoch 77, Batch 85/100] Loss: 0.0361 | RMSE: 0.0335 | Consistency: 0.0064 | SSIM: 0.0248 | Grad: 33569.320\n",
      "[Epoch 77, Batch 86/100] Loss: 0.0381 | RMSE: 0.0357 | Consistency: 0.0082 | SSIM: 0.0231 | Grad: 20491.344\n",
      "[Epoch 77, Batch 87/100] Loss: 0.0435 | RMSE: 0.0409 | Consistency: 0.0080 | SSIM: 0.0254 | Grad: 76153.203\n",
      "[Epoch 77, Batch 88/100] Loss: 0.0317 | RMSE: 0.0292 | Consistency: 0.0053 | SSIM: 0.0249 | Grad: 17212.553\n",
      "[Epoch 77, Batch 89/100] Loss: 0.0339 | RMSE: 0.0314 | Consistency: 0.0061 | SSIM: 0.0240 | Grad: 11410.408\n",
      "[Epoch 77, Batch 90/100] Loss: 0.0289 | RMSE: 0.0269 | Consistency: 0.0037 | SSIM: 0.0197 | Grad: 60543.566\n",
      "[Epoch 77, Batch 91/100] Loss: 0.0311 | RMSE: 0.0287 | Consistency: 0.0053 | SSIM: 0.0239 | Grad: 27476.857\n",
      "[Epoch 77, Batch 92/100] Loss: 0.0290 | RMSE: 0.0270 | Consistency: 0.0042 | SSIM: 0.0188 | Grad: 28560.430\n",
      "[Epoch 77, Batch 93/100] Loss: 0.0326 | RMSE: 0.0306 | Consistency: 0.0056 | SSIM: 0.0195 | Grad: 24634.523\n",
      "[Epoch 77, Batch 94/100] Loss: 0.0357 | RMSE: 0.0332 | Consistency: 0.0056 | SSIM: 0.0247 | Grad: 52783.621\n",
      "[Epoch 77, Batch 95/100] Loss: 0.0353 | RMSE: 0.0331 | Consistency: 0.0063 | SSIM: 0.0222 | Grad: 27040.828\n",
      "[Epoch 77, Batch 96/100] Loss: 0.0330 | RMSE: 0.0310 | Consistency: 0.0047 | SSIM: 0.0199 | Grad: 52768.609\n",
      "[Epoch 77, Batch 97/100] Loss: 0.0341 | RMSE: 0.0314 | Consistency: 0.0053 | SSIM: 0.0262 | Grad: 49282.570\n",
      "[Epoch 77, Batch 98/100] Loss: 0.0355 | RMSE: 0.0334 | Consistency: 0.0058 | SSIM: 0.0205 | Grad: 22336.779\n",
      "[Epoch 77, Batch 99/100] Loss: 0.0315 | RMSE: 0.0290 | Consistency: 0.0046 | SSIM: 0.0242 | Grad: 29059.725\n",
      "[Epoch 77, Batch 100/100] Loss: 0.0293 | RMSE: 0.0272 | Consistency: 0.0041 | SSIM: 0.0200 | Grad: 15644.048\n",
      "✅ Epoch 77 완료!\n",
      "   📈 평균 Loss: 0.034268\n",
      "   📊 평균 RMSE: 0.031951\n",
      "   ⚙️  학습률: 0.000004\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 78/80 시작...\n",
      "[Epoch 78, Batch 1/100] Loss: 0.0319 | RMSE: 0.0299 | Consistency: 0.0052 | SSIM: 0.0194 | Grad: 27194.518\n",
      "[Epoch 78, Batch 2/100] Loss: 0.0288 | RMSE: 0.0271 | Consistency: 0.0046 | SSIM: 0.0164 | Grad: 40861.898\n",
      "[Epoch 78, Batch 3/100] Loss: 0.0307 | RMSE: 0.0290 | Consistency: 0.0047 | SSIM: 0.0172 | Grad: 53703.793\n",
      "[Epoch 78, Batch 4/100] Loss: 0.0332 | RMSE: 0.0308 | Consistency: 0.0050 | SSIM: 0.0242 | Grad: 45501.242\n",
      "[Epoch 78, Batch 5/100] Loss: 0.0331 | RMSE: 0.0307 | Consistency: 0.0056 | SSIM: 0.0230 | Grad: 38316.453\n",
      "[Epoch 78, Batch 6/100] Loss: 0.0324 | RMSE: 0.0303 | Consistency: 0.0052 | SSIM: 0.0198 | Grad: 32869.586\n",
      "[Epoch 78, Batch 7/100] Loss: 0.0355 | RMSE: 0.0336 | Consistency: 0.0064 | SSIM: 0.0188 | Grad: 65900.523\n",
      "[Epoch 78, Batch 8/100] Loss: 0.0316 | RMSE: 0.0292 | Consistency: 0.0048 | SSIM: 0.0232 | Grad: 36421.438\n",
      "[Epoch 78, Batch 9/100] Loss: 0.0308 | RMSE: 0.0288 | Consistency: 0.0049 | SSIM: 0.0194 | Grad: 14179.121\n",
      "[Epoch 78, Batch 10/100] Loss: 0.0357 | RMSE: 0.0329 | Consistency: 0.0058 | SSIM: 0.0277 | Grad: 58505.711\n",
      "[Epoch 78, Batch 11/100] Loss: 0.0296 | RMSE: 0.0277 | Consistency: 0.0042 | SSIM: 0.0191 | Grad: 79451.266\n",
      "[Epoch 78, Batch 12/100] Loss: 0.0323 | RMSE: 0.0302 | Consistency: 0.0055 | SSIM: 0.0205 | Grad: 44350.059\n",
      "[Epoch 78, Batch 13/100] Loss: 0.0310 | RMSE: 0.0291 | Consistency: 0.0050 | SSIM: 0.0181 | Grad: 16226.630\n",
      "[Epoch 78, Batch 14/100] Loss: 0.0374 | RMSE: 0.0345 | Consistency: 0.0064 | SSIM: 0.0283 | Grad: 36727.867\n",
      "[Epoch 78, Batch 15/100] Loss: 0.0299 | RMSE: 0.0275 | Consistency: 0.0041 | SSIM: 0.0239 | Grad: 70192.758\n",
      "[Epoch 78, Batch 16/100] Loss: 0.0301 | RMSE: 0.0283 | Consistency: 0.0043 | SSIM: 0.0179 | Grad: 46023.820\n",
      "[Epoch 78, Batch 17/100] Loss: 0.0351 | RMSE: 0.0329 | Consistency: 0.0067 | SSIM: 0.0220 | Grad: 30786.773\n",
      "[Epoch 78, Batch 18/100] Loss: 0.0290 | RMSE: 0.0271 | Consistency: 0.0044 | SSIM: 0.0191 | Grad: 78221.812\n",
      "[Epoch 78, Batch 19/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0053 | SSIM: 0.0221 | Grad: 44880.070\n",
      "[Epoch 78, Batch 20/100] Loss: 0.0493 | RMSE: 0.0457 | Consistency: 0.0101 | SSIM: 0.0355 | Grad: 26265.416\n",
      "[Epoch 78, Batch 21/100] Loss: 0.0377 | RMSE: 0.0356 | Consistency: 0.0049 | SSIM: 0.0201 | Grad: 29462.244\n",
      "[Epoch 78, Batch 22/100] Loss: 0.0335 | RMSE: 0.0313 | Consistency: 0.0060 | SSIM: 0.0216 | Grad: 22326.318\n",
      "[Epoch 78, Batch 23/100] Loss: 0.0364 | RMSE: 0.0341 | Consistency: 0.0064 | SSIM: 0.0216 | Grad: 20958.441\n",
      "[Epoch 78, Batch 24/100] Loss: 0.0287 | RMSE: 0.0269 | Consistency: 0.0037 | SSIM: 0.0177 | Grad: 40863.242\n",
      "[Epoch 78, Batch 25/100] Loss: 0.0324 | RMSE: 0.0301 | Consistency: 0.0056 | SSIM: 0.0221 | Grad: 35256.777\n",
      "[Epoch 78, Batch 26/100] Loss: 0.0340 | RMSE: 0.0313 | Consistency: 0.0063 | SSIM: 0.0259 | Grad: 34570.336\n",
      "[Epoch 78, Batch 27/100] Loss: 0.0354 | RMSE: 0.0327 | Consistency: 0.0055 | SSIM: 0.0267 | Grad: 60353.105\n",
      "[Epoch 78, Batch 28/100] Loss: 0.0334 | RMSE: 0.0312 | Consistency: 0.0057 | SSIM: 0.0209 | Grad: 75301.773\n",
      "[Epoch 78, Batch 29/100] Loss: 0.0329 | RMSE: 0.0308 | Consistency: 0.0052 | SSIM: 0.0203 | Grad: 41683.543\n",
      "[Epoch 78, Batch 30/100] Loss: 0.0379 | RMSE: 0.0355 | Consistency: 0.0058 | SSIM: 0.0234 | Grad: 54080.434\n",
      "[Epoch 78, Batch 31/100] Loss: 0.0426 | RMSE: 0.0402 | Consistency: 0.0074 | SSIM: 0.0229 | Grad: 72263.031\n",
      "[Epoch 78, Batch 32/100] Loss: 0.0340 | RMSE: 0.0319 | Consistency: 0.0061 | SSIM: 0.0212 | Grad: 39056.484\n",
      "[Epoch 78, Batch 33/100] Loss: 0.0307 | RMSE: 0.0285 | Consistency: 0.0048 | SSIM: 0.0222 | Grad: 40448.602\n",
      "[Epoch 78, Batch 34/100] Loss: 0.0278 | RMSE: 0.0260 | Consistency: 0.0034 | SSIM: 0.0175 | Grad: 56810.859\n",
      "[Epoch 78, Batch 35/100] Loss: 0.0349 | RMSE: 0.0323 | Consistency: 0.0049 | SSIM: 0.0249 | Grad: 74007.875\n",
      "[Epoch 78, Batch 36/100] Loss: 0.0313 | RMSE: 0.0295 | Consistency: 0.0049 | SSIM: 0.0179 | Grad: 40352.707\n",
      "[Epoch 78, Batch 37/100] Loss: 0.0375 | RMSE: 0.0349 | Consistency: 0.0068 | SSIM: 0.0252 | Grad: 94897.703\n",
      "[Epoch 78, Batch 38/100] Loss: 0.0345 | RMSE: 0.0319 | Consistency: 0.0054 | SSIM: 0.0252 | Grad: 26192.645\n",
      "[Epoch 78, Batch 39/100] Loss: 0.0424 | RMSE: 0.0395 | Consistency: 0.0092 | SSIM: 0.0280 | Grad: 91462.406\n",
      "[Epoch 78, Batch 40/100] Loss: 0.0287 | RMSE: 0.0267 | Consistency: 0.0039 | SSIM: 0.0192 | Grad: 41209.066\n",
      "[Epoch 78, Batch 41/100] Loss: 0.0379 | RMSE: 0.0356 | Consistency: 0.0067 | SSIM: 0.0226 | Grad: 26845.949\n",
      "[Epoch 78, Batch 42/100] Loss: 0.0381 | RMSE: 0.0358 | Consistency: 0.0061 | SSIM: 0.0231 | Grad: 45946.746\n",
      "[Epoch 78, Batch 43/100] Loss: 0.0375 | RMSE: 0.0351 | Consistency: 0.0068 | SSIM: 0.0239 | Grad: 16950.072\n",
      "[Epoch 78, Batch 44/100] Loss: 0.0342 | RMSE: 0.0321 | Consistency: 0.0061 | SSIM: 0.0206 | Grad: 61279.281\n",
      "[Epoch 78, Batch 45/100] Loss: 0.0385 | RMSE: 0.0358 | Consistency: 0.0066 | SSIM: 0.0258 | Grad: 63278.016\n",
      "[Epoch 78, Batch 46/100] Loss: 0.0317 | RMSE: 0.0295 | Consistency: 0.0047 | SSIM: 0.0217 | Grad: 32036.658\n",
      "[Epoch 78, Batch 47/100] Loss: 0.0424 | RMSE: 0.0400 | Consistency: 0.0092 | SSIM: 0.0236 | Grad: 80004.086\n",
      "[Epoch 78, Batch 48/100] Loss: 0.0384 | RMSE: 0.0357 | Consistency: 0.0078 | SSIM: 0.0265 | Grad: 36834.188\n",
      "[Epoch 78, Batch 49/100] Loss: 0.0373 | RMSE: 0.0347 | Consistency: 0.0075 | SSIM: 0.0249 | Grad: 28655.562\n",
      "[Epoch 78, Batch 50/100] Loss: 0.0379 | RMSE: 0.0354 | Consistency: 0.0069 | SSIM: 0.0244 | Grad: 55070.199\n",
      "[Epoch 78, Batch 51/100] Loss: 0.0313 | RMSE: 0.0293 | Consistency: 0.0049 | SSIM: 0.0195 | Grad: 38687.676\n",
      "[Epoch 78, Batch 52/100] Loss: 0.0329 | RMSE: 0.0307 | Consistency: 0.0054 | SSIM: 0.0214 | Grad: 31936.635\n",
      "[Epoch 78, Batch 53/100] Loss: 0.0326 | RMSE: 0.0302 | Consistency: 0.0049 | SSIM: 0.0230 | Grad: 68182.125\n",
      "[Epoch 78, Batch 54/100] Loss: 0.0278 | RMSE: 0.0261 | Consistency: 0.0039 | SSIM: 0.0172 | Grad: 38443.027\n",
      "[Epoch 78, Batch 55/100] Loss: 0.0382 | RMSE: 0.0361 | Consistency: 0.0070 | SSIM: 0.0199 | Grad: 88861.922\n",
      "[Epoch 78, Batch 56/100] Loss: 0.0313 | RMSE: 0.0291 | Consistency: 0.0050 | SSIM: 0.0222 | Grad: 16876.119\n",
      "[Epoch 78, Batch 57/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0060 | SSIM: 0.0213 | Grad: 58213.844\n",
      "[Epoch 78, Batch 58/100] Loss: 0.0351 | RMSE: 0.0328 | Consistency: 0.0057 | SSIM: 0.0219 | Grad: 64808.258\n",
      "[Epoch 78, Batch 59/100] Loss: 0.0389 | RMSE: 0.0362 | Consistency: 0.0067 | SSIM: 0.0268 | Grad: 18725.736\n",
      "[Epoch 78, Batch 60/100] Loss: 0.0273 | RMSE: 0.0255 | Consistency: 0.0038 | SSIM: 0.0175 | Grad: 47311.422\n",
      "[Epoch 78, Batch 61/100] Loss: 0.0326 | RMSE: 0.0305 | Consistency: 0.0055 | SSIM: 0.0207 | Grad: 32317.969\n",
      "[Epoch 78, Batch 62/100] Loss: 0.0285 | RMSE: 0.0265 | Consistency: 0.0039 | SSIM: 0.0189 | Grad: 25002.639\n",
      "[Epoch 78, Batch 63/100] Loss: 0.0317 | RMSE: 0.0294 | Consistency: 0.0044 | SSIM: 0.0228 | Grad: 83565.555\n",
      "[Epoch 78, Batch 64/100] Loss: 0.0369 | RMSE: 0.0349 | Consistency: 0.0055 | SSIM: 0.0195 | Grad: 78262.039\n",
      "[Epoch 78, Batch 65/100] Loss: 0.0343 | RMSE: 0.0322 | Consistency: 0.0048 | SSIM: 0.0205 | Grad: 30780.865\n",
      "[Epoch 78, Batch 66/100] Loss: 0.0338 | RMSE: 0.0316 | Consistency: 0.0057 | SSIM: 0.0209 | Grad: 53516.680\n",
      "[Epoch 78, Batch 67/100] Loss: 0.0329 | RMSE: 0.0299 | Consistency: 0.0053 | SSIM: 0.0300 | Grad: 74470.484\n",
      "[Epoch 78, Batch 68/100] Loss: 0.0336 | RMSE: 0.0317 | Consistency: 0.0062 | SSIM: 0.0185 | Grad: 26923.988\n",
      "[Epoch 78, Batch 69/100] Loss: 0.0337 | RMSE: 0.0313 | Consistency: 0.0052 | SSIM: 0.0237 | Grad: 56347.809\n",
      "[Epoch 78, Batch 70/100] Loss: 0.0297 | RMSE: 0.0280 | Consistency: 0.0039 | SSIM: 0.0168 | Grad: 39012.328\n",
      "[Epoch 78, Batch 71/100] Loss: 0.0313 | RMSE: 0.0293 | Consistency: 0.0053 | SSIM: 0.0193 | Grad: 34607.324\n",
      "[Epoch 78, Batch 72/100] Loss: 0.0361 | RMSE: 0.0334 | Consistency: 0.0069 | SSIM: 0.0259 | Grad: 50725.875\n",
      "[Epoch 78, Batch 73/100] Loss: 0.0329 | RMSE: 0.0305 | Consistency: 0.0056 | SSIM: 0.0240 | Grad: 25256.514\n",
      "[Epoch 78, Batch 74/100] Loss: 0.0347 | RMSE: 0.0324 | Consistency: 0.0051 | SSIM: 0.0228 | Grad: 35655.699\n",
      "[Epoch 78, Batch 75/100] Loss: 0.0326 | RMSE: 0.0304 | Consistency: 0.0045 | SSIM: 0.0222 | Grad: 48002.160\n",
      "[Epoch 78, Batch 76/100] Loss: 0.0303 | RMSE: 0.0285 | Consistency: 0.0048 | SSIM: 0.0174 | Grad: 45421.953\n",
      "[Epoch 78, Batch 77/100] Loss: 0.0334 | RMSE: 0.0312 | Consistency: 0.0053 | SSIM: 0.0209 | Grad: 70502.703\n",
      "[Epoch 78, Batch 78/100] Loss: 0.0365 | RMSE: 0.0340 | Consistency: 0.0069 | SSIM: 0.0236 | Grad: 27772.465\n",
      "[Epoch 78, Batch 79/100] Loss: 0.0330 | RMSE: 0.0310 | Consistency: 0.0049 | SSIM: 0.0199 | Grad: 41604.992\n",
      "[Epoch 78, Batch 80/100] Loss: 0.0300 | RMSE: 0.0284 | Consistency: 0.0048 | SSIM: 0.0156 | Grad: 71819.055\n",
      "[Epoch 78, Batch 81/100] Loss: 0.0333 | RMSE: 0.0313 | Consistency: 0.0050 | SSIM: 0.0194 | Grad: 31991.215\n",
      "[Epoch 78, Batch 82/100] Loss: 0.0313 | RMSE: 0.0290 | Consistency: 0.0051 | SSIM: 0.0228 | Grad: 25934.760\n",
      "[Epoch 78, Batch 83/100] Loss: 0.0310 | RMSE: 0.0295 | Consistency: 0.0046 | SSIM: 0.0151 | Grad: 87020.414\n",
      "[Epoch 78, Batch 84/100] Loss: 0.0343 | RMSE: 0.0320 | Consistency: 0.0060 | SSIM: 0.0221 | Grad: 41787.324\n",
      "[Epoch 78, Batch 85/100] Loss: 0.0488 | RMSE: 0.0450 | Consistency: 0.0125 | SSIM: 0.0364 | Grad: 78402.391\n",
      "[Epoch 78, Batch 86/100] Loss: 0.0359 | RMSE: 0.0331 | Consistency: 0.0063 | SSIM: 0.0272 | Grad: 22182.289\n",
      "[Epoch 78, Batch 87/100] Loss: 0.0384 | RMSE: 0.0359 | Consistency: 0.0075 | SSIM: 0.0250 | Grad: 58984.824\n",
      "[Epoch 78, Batch 88/100] Loss: 0.0375 | RMSE: 0.0355 | Consistency: 0.0064 | SSIM: 0.0196 | Grad: 32090.504\n",
      "[Epoch 78, Batch 89/100] Loss: 0.0353 | RMSE: 0.0328 | Consistency: 0.0059 | SSIM: 0.0245 | Grad: 63746.426\n",
      "[Epoch 78, Batch 90/100] Loss: 0.0364 | RMSE: 0.0339 | Consistency: 0.0072 | SSIM: 0.0241 | Grad: 33241.672\n",
      "[Epoch 78, Batch 91/100] Loss: 0.0425 | RMSE: 0.0401 | Consistency: 0.0087 | SSIM: 0.0229 | Grad: 74865.523\n",
      "[Epoch 78, Batch 92/100] Loss: 0.0363 | RMSE: 0.0333 | Consistency: 0.0060 | SSIM: 0.0292 | Grad: 17161.416\n",
      "[Epoch 78, Batch 93/100] Loss: 0.0308 | RMSE: 0.0289 | Consistency: 0.0046 | SSIM: 0.0189 | Grad: 27113.951\n",
      "[Epoch 78, Batch 94/100] Loss: 0.0339 | RMSE: 0.0311 | Consistency: 0.0056 | SSIM: 0.0272 | Grad: 23005.869\n",
      "[Epoch 78, Batch 95/100] Loss: 0.0373 | RMSE: 0.0347 | Consistency: 0.0051 | SSIM: 0.0253 | Grad: 95505.828\n",
      "[Epoch 78, Batch 96/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0056 | SSIM: 0.0241 | Grad: 32890.230\n",
      "[Epoch 78, Batch 97/100] Loss: 0.0327 | RMSE: 0.0307 | Consistency: 0.0049 | SSIM: 0.0195 | Grad: 37724.301\n",
      "[Epoch 78, Batch 98/100] Loss: 0.0289 | RMSE: 0.0267 | Consistency: 0.0045 | SSIM: 0.0211 | Grad: 12333.604\n",
      "[Epoch 78, Batch 99/100] Loss: 0.0400 | RMSE: 0.0374 | Consistency: 0.0095 | SSIM: 0.0253 | Grad: 28637.771\n",
      "[Epoch 78, Batch 100/100] Loss: 0.0289 | RMSE: 0.0272 | Consistency: 0.0041 | SSIM: 0.0167 | Grad: 68207.398\n",
      "✅ Epoch 78 완료!\n",
      "   📈 평균 Loss: 0.034213\n",
      "   📊 평균 RMSE: 0.031938\n",
      "   ⚙️  학습률: 0.000002\n",
      "   🏆 NEW BEST! RMSE: 0.031938\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 79/80 시작...\n",
      "[Epoch 79, Batch 1/100] Loss: 0.0376 | RMSE: 0.0352 | Consistency: 0.0062 | SSIM: 0.0230 | Grad: 29533.107\n",
      "[Epoch 79, Batch 2/100] Loss: 0.0334 | RMSE: 0.0312 | Consistency: 0.0060 | SSIM: 0.0218 | Grad: 30395.820\n",
      "[Epoch 79, Batch 3/100] Loss: 0.0288 | RMSE: 0.0270 | Consistency: 0.0037 | SSIM: 0.0182 | Grad: 48919.500\n",
      "[Epoch 79, Batch 4/100] Loss: 0.0307 | RMSE: 0.0286 | Consistency: 0.0048 | SSIM: 0.0197 | Grad: 37069.238\n",
      "[Epoch 79, Batch 5/100] Loss: 0.0355 | RMSE: 0.0326 | Consistency: 0.0064 | SSIM: 0.0276 | Grad: 27247.740\n",
      "[Epoch 79, Batch 6/100] Loss: 0.0368 | RMSE: 0.0345 | Consistency: 0.0074 | SSIM: 0.0225 | Grad: 42545.832\n",
      "[Epoch 79, Batch 7/100] Loss: 0.0338 | RMSE: 0.0318 | Consistency: 0.0059 | SSIM: 0.0195 | Grad: 31910.363\n",
      "[Epoch 79, Batch 8/100] Loss: 0.0325 | RMSE: 0.0303 | Consistency: 0.0055 | SSIM: 0.0215 | Grad: 77629.836\n",
      "[Epoch 79, Batch 9/100] Loss: 0.0291 | RMSE: 0.0269 | Consistency: 0.0040 | SSIM: 0.0208 | Grad: 34744.289\n",
      "[Epoch 79, Batch 10/100] Loss: 0.0308 | RMSE: 0.0290 | Consistency: 0.0046 | SSIM: 0.0177 | Grad: 52357.707\n",
      "[Epoch 79, Batch 11/100] Loss: 0.0325 | RMSE: 0.0304 | Consistency: 0.0053 | SSIM: 0.0206 | Grad: 29707.705\n",
      "[Epoch 79, Batch 12/100] Loss: 0.0348 | RMSE: 0.0325 | Consistency: 0.0066 | SSIM: 0.0221 | Grad: 38582.180\n",
      "[Epoch 79, Batch 13/100] Loss: 0.0364 | RMSE: 0.0337 | Consistency: 0.0059 | SSIM: 0.0263 | Grad: 75099.805\n",
      "[Epoch 79, Batch 14/100] Loss: 0.0384 | RMSE: 0.0358 | Consistency: 0.0068 | SSIM: 0.0259 | Grad: 69233.766\n",
      "[Epoch 79, Batch 15/100] Loss: 0.0337 | RMSE: 0.0311 | Consistency: 0.0054 | SSIM: 0.0254 | Grad: 26918.139\n",
      "[Epoch 79, Batch 16/100] Loss: 0.0359 | RMSE: 0.0337 | Consistency: 0.0051 | SSIM: 0.0211 | Grad: 26607.029\n",
      "[Epoch 79, Batch 17/100] Loss: 0.0312 | RMSE: 0.0289 | Consistency: 0.0040 | SSIM: 0.0218 | Grad: 21462.713\n",
      "[Epoch 79, Batch 18/100] Loss: 0.0330 | RMSE: 0.0305 | Consistency: 0.0050 | SSIM: 0.0252 | Grad: 31112.867\n",
      "[Epoch 79, Batch 19/100] Loss: 0.0344 | RMSE: 0.0320 | Consistency: 0.0060 | SSIM: 0.0240 | Grad: 36532.500\n",
      "[Epoch 79, Batch 20/100] Loss: 0.0300 | RMSE: 0.0280 | Consistency: 0.0044 | SSIM: 0.0196 | Grad: 23080.172\n",
      "[Epoch 79, Batch 21/100] Loss: 0.0298 | RMSE: 0.0281 | Consistency: 0.0044 | SSIM: 0.0166 | Grad: 39836.652\n",
      "[Epoch 79, Batch 22/100] Loss: 0.0318 | RMSE: 0.0300 | Consistency: 0.0050 | SSIM: 0.0174 | Grad: 41782.184\n",
      "[Epoch 79, Batch 23/100] Loss: 0.0335 | RMSE: 0.0314 | Consistency: 0.0057 | SSIM: 0.0207 | Grad: 35492.234\n",
      "[Epoch 79, Batch 24/100] Loss: 0.0368 | RMSE: 0.0342 | Consistency: 0.0067 | SSIM: 0.0249 | Grad: 8895.755\n",
      "[Epoch 79, Batch 25/100] Loss: 0.0303 | RMSE: 0.0285 | Consistency: 0.0043 | SSIM: 0.0177 | Grad: 97192.102\n",
      "[Epoch 79, Batch 26/100] Loss: 0.0275 | RMSE: 0.0259 | Consistency: 0.0038 | SSIM: 0.0157 | Grad: 51209.395\n",
      "[Epoch 79, Batch 27/100] Loss: 0.0352 | RMSE: 0.0324 | Consistency: 0.0065 | SSIM: 0.0274 | Grad: 24423.689\n",
      "[Epoch 79, Batch 28/100] Loss: 0.0332 | RMSE: 0.0309 | Consistency: 0.0056 | SSIM: 0.0225 | Grad: 21021.705\n",
      "[Epoch 79, Batch 29/100] Loss: 0.0351 | RMSE: 0.0328 | Consistency: 0.0069 | SSIM: 0.0222 | Grad: 45626.344\n",
      "[Epoch 79, Batch 30/100] Loss: 0.0330 | RMSE: 0.0307 | Consistency: 0.0057 | SSIM: 0.0225 | Grad: 50607.465\n",
      "[Epoch 79, Batch 31/100] Loss: 0.0323 | RMSE: 0.0303 | Consistency: 0.0050 | SSIM: 0.0193 | Grad: 90868.531\n",
      "[Epoch 79, Batch 32/100] Loss: 0.0340 | RMSE: 0.0315 | Consistency: 0.0055 | SSIM: 0.0240 | Grad: 24982.352\n",
      "[Epoch 79, Batch 33/100] Loss: 0.0366 | RMSE: 0.0339 | Consistency: 0.0067 | SSIM: 0.0264 | Grad: 42713.594\n",
      "[Epoch 79, Batch 34/100] Loss: 0.0335 | RMSE: 0.0313 | Consistency: 0.0057 | SSIM: 0.0210 | Grad: 37848.395\n",
      "[Epoch 79, Batch 35/100] Loss: 0.0433 | RMSE: 0.0406 | Consistency: 0.0083 | SSIM: 0.0262 | Grad: 43142.359\n",
      "[Epoch 79, Batch 36/100] Loss: 0.0308 | RMSE: 0.0284 | Consistency: 0.0044 | SSIM: 0.0234 | Grad: 64159.590\n",
      "[Epoch 79, Batch 37/100] Loss: 0.0319 | RMSE: 0.0301 | Consistency: 0.0050 | SSIM: 0.0179 | Grad: 39881.840\n",
      "[Epoch 79, Batch 38/100] Loss: 0.0348 | RMSE: 0.0324 | Consistency: 0.0061 | SSIM: 0.0238 | Grad: 68391.305\n",
      "[Epoch 79, Batch 39/100] Loss: 0.0311 | RMSE: 0.0293 | Consistency: 0.0047 | SSIM: 0.0175 | Grad: 39749.738\n",
      "[Epoch 79, Batch 40/100] Loss: 0.0368 | RMSE: 0.0344 | Consistency: 0.0069 | SSIM: 0.0229 | Grad: 74540.461\n",
      "[Epoch 79, Batch 41/100] Loss: 0.0323 | RMSE: 0.0303 | Consistency: 0.0055 | SSIM: 0.0194 | Grad: 43743.867\n",
      "[Epoch 79, Batch 42/100] Loss: 0.0383 | RMSE: 0.0353 | Consistency: 0.0078 | SSIM: 0.0293 | Grad: 67373.250\n",
      "[Epoch 79, Batch 43/100] Loss: 0.0312 | RMSE: 0.0290 | Consistency: 0.0050 | SSIM: 0.0209 | Grad: 71723.352\n",
      "[Epoch 79, Batch 44/100] Loss: 0.0350 | RMSE: 0.0326 | Consistency: 0.0064 | SSIM: 0.0230 | Grad: 39154.777\n",
      "[Epoch 79, Batch 45/100] Loss: 0.0325 | RMSE: 0.0305 | Consistency: 0.0052 | SSIM: 0.0193 | Grad: 51935.090\n",
      "[Epoch 79, Batch 46/100] Loss: 0.0322 | RMSE: 0.0299 | Consistency: 0.0049 | SSIM: 0.0222 | Grad: 38922.434\n",
      "[Epoch 79, Batch 47/100] Loss: 0.0375 | RMSE: 0.0355 | Consistency: 0.0056 | SSIM: 0.0194 | Grad: 50877.691\n",
      "[Epoch 79, Batch 48/100] Loss: 0.0392 | RMSE: 0.0362 | Consistency: 0.0079 | SSIM: 0.0301 | Grad: 59441.312\n",
      "[Epoch 79, Batch 49/100] Loss: 0.0328 | RMSE: 0.0305 | Consistency: 0.0056 | SSIM: 0.0223 | Grad: 61763.395\n",
      "[Epoch 79, Batch 50/100] Loss: 0.0334 | RMSE: 0.0311 | Consistency: 0.0050 | SSIM: 0.0219 | Grad: 35312.875\n",
      "[Epoch 79, Batch 51/100] Loss: 0.0346 | RMSE: 0.0323 | Consistency: 0.0066 | SSIM: 0.0228 | Grad: 44177.512\n",
      "[Epoch 79, Batch 52/100] Loss: 0.0346 | RMSE: 0.0323 | Consistency: 0.0058 | SSIM: 0.0229 | Grad: 35208.211\n",
      "[Epoch 79, Batch 53/100] Loss: 0.0328 | RMSE: 0.0306 | Consistency: 0.0051 | SSIM: 0.0219 | Grad: 11115.835\n",
      "[Epoch 79, Batch 54/100] Loss: 0.0331 | RMSE: 0.0306 | Consistency: 0.0050 | SSIM: 0.0240 | Grad: 55897.965\n",
      "[Epoch 79, Batch 55/100] Loss: 0.0315 | RMSE: 0.0295 | Consistency: 0.0044 | SSIM: 0.0196 | Grad: 53111.570\n",
      "[Epoch 79, Batch 56/100] Loss: 0.0353 | RMSE: 0.0330 | Consistency: 0.0062 | SSIM: 0.0222 | Grad: 50392.523\n",
      "[Epoch 79, Batch 57/100] Loss: 0.0315 | RMSE: 0.0291 | Consistency: 0.0047 | SSIM: 0.0237 | Grad: 26403.414\n",
      "[Epoch 79, Batch 58/100] Loss: 0.0355 | RMSE: 0.0326 | Consistency: 0.0061 | SSIM: 0.0290 | Grad: 44326.777\n",
      "[Epoch 79, Batch 59/100] Loss: 0.0330 | RMSE: 0.0305 | Consistency: 0.0057 | SSIM: 0.0244 | Grad: 39349.816\n",
      "[Epoch 79, Batch 60/100] Loss: 0.0357 | RMSE: 0.0330 | Consistency: 0.0049 | SSIM: 0.0264 | Grad: 40475.137\n",
      "[Epoch 79, Batch 61/100] Loss: 0.0357 | RMSE: 0.0337 | Consistency: 0.0065 | SSIM: 0.0196 | Grad: 23711.775\n",
      "[Epoch 79, Batch 62/100] Loss: 0.0416 | RMSE: 0.0387 | Consistency: 0.0087 | SSIM: 0.0275 | Grad: 38397.215\n",
      "[Epoch 79, Batch 63/100] Loss: 0.0281 | RMSE: 0.0265 | Consistency: 0.0037 | SSIM: 0.0157 | Grad: 61484.430\n",
      "[Epoch 79, Batch 64/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0057 | SSIM: 0.0237 | Grad: 53833.645\n",
      "[Epoch 79, Batch 65/100] Loss: 0.0366 | RMSE: 0.0341 | Consistency: 0.0065 | SSIM: 0.0236 | Grad: 28396.213\n",
      "[Epoch 79, Batch 66/100] Loss: 0.0341 | RMSE: 0.0321 | Consistency: 0.0061 | SSIM: 0.0201 | Grad: 34650.281\n",
      "[Epoch 79, Batch 67/100] Loss: 0.0340 | RMSE: 0.0318 | Consistency: 0.0061 | SSIM: 0.0216 | Grad: 13668.542\n",
      "[Epoch 79, Batch 68/100] Loss: 0.0351 | RMSE: 0.0328 | Consistency: 0.0070 | SSIM: 0.0222 | Grad: 52458.250\n",
      "[Epoch 79, Batch 69/100] Loss: 0.0323 | RMSE: 0.0304 | Consistency: 0.0053 | SSIM: 0.0194 | Grad: 55028.766\n",
      "[Epoch 79, Batch 70/100] Loss: 0.0370 | RMSE: 0.0343 | Consistency: 0.0063 | SSIM: 0.0257 | Grad: 38416.488\n",
      "[Epoch 79, Batch 71/100] Loss: 0.0345 | RMSE: 0.0326 | Consistency: 0.0060 | SSIM: 0.0192 | Grad: 41891.340\n",
      "[Epoch 79, Batch 72/100] Loss: 0.0370 | RMSE: 0.0344 | Consistency: 0.0055 | SSIM: 0.0251 | Grad: 32635.664\n",
      "[Epoch 79, Batch 73/100] Loss: 0.0380 | RMSE: 0.0351 | Consistency: 0.0067 | SSIM: 0.0284 | Grad: 119442.555\n",
      "[Epoch 79, Batch 74/100] Loss: 0.0328 | RMSE: 0.0306 | Consistency: 0.0054 | SSIM: 0.0223 | Grad: 43271.609\n",
      "[Epoch 79, Batch 75/100] Loss: 0.0354 | RMSE: 0.0328 | Consistency: 0.0059 | SSIM: 0.0257 | Grad: 41627.172\n",
      "[Epoch 79, Batch 76/100] Loss: 0.0298 | RMSE: 0.0274 | Consistency: 0.0044 | SSIM: 0.0243 | Grad: 66803.461\n",
      "[Epoch 79, Batch 77/100] Loss: 0.0311 | RMSE: 0.0292 | Consistency: 0.0045 | SSIM: 0.0180 | Grad: 76991.938\n",
      "[Epoch 79, Batch 78/100] Loss: 0.0370 | RMSE: 0.0349 | Consistency: 0.0066 | SSIM: 0.0211 | Grad: 87173.594\n",
      "[Epoch 79, Batch 79/100] Loss: 0.0373 | RMSE: 0.0350 | Consistency: 0.0065 | SSIM: 0.0221 | Grad: 91046.555\n",
      "[Epoch 79, Batch 80/100] Loss: 0.0417 | RMSE: 0.0391 | Consistency: 0.0080 | SSIM: 0.0261 | Grad: 19968.836\n",
      "[Epoch 79, Batch 81/100] Loss: 0.0290 | RMSE: 0.0274 | Consistency: 0.0042 | SSIM: 0.0156 | Grad: 59100.562\n",
      "[Epoch 79, Batch 82/100] Loss: 0.0355 | RMSE: 0.0325 | Consistency: 0.0055 | SSIM: 0.0286 | Grad: 45342.258\n",
      "[Epoch 79, Batch 83/100] Loss: 0.0309 | RMSE: 0.0290 | Consistency: 0.0045 | SSIM: 0.0180 | Grad: 49354.184\n",
      "[Epoch 79, Batch 84/100] Loss: 0.0338 | RMSE: 0.0317 | Consistency: 0.0057 | SSIM: 0.0202 | Grad: 43237.973\n",
      "[Epoch 79, Batch 85/100] Loss: 0.0346 | RMSE: 0.0323 | Consistency: 0.0055 | SSIM: 0.0224 | Grad: 34167.520\n",
      "[Epoch 79, Batch 86/100] Loss: 0.0340 | RMSE: 0.0319 | Consistency: 0.0056 | SSIM: 0.0202 | Grad: 44303.375\n",
      "[Epoch 79, Batch 87/100] Loss: 0.0368 | RMSE: 0.0341 | Consistency: 0.0065 | SSIM: 0.0260 | Grad: 36643.996\n",
      "[Epoch 79, Batch 88/100] Loss: 0.0306 | RMSE: 0.0287 | Consistency: 0.0045 | SSIM: 0.0184 | Grad: 25987.465\n",
      "[Epoch 79, Batch 89/100] Loss: 0.0356 | RMSE: 0.0329 | Consistency: 0.0055 | SSIM: 0.0265 | Grad: 40393.211\n",
      "[Epoch 79, Batch 90/100] Loss: 0.0352 | RMSE: 0.0329 | Consistency: 0.0062 | SSIM: 0.0232 | Grad: 44546.113\n",
      "[Epoch 79, Batch 91/100] Loss: 0.0351 | RMSE: 0.0321 | Consistency: 0.0062 | SSIM: 0.0296 | Grad: 30191.064\n",
      "[Epoch 79, Batch 92/100] Loss: 0.0263 | RMSE: 0.0247 | Consistency: 0.0033 | SSIM: 0.0157 | Grad: 62600.805\n",
      "[Epoch 79, Batch 93/100] Loss: 0.0309 | RMSE: 0.0289 | Consistency: 0.0040 | SSIM: 0.0199 | Grad: 24109.363\n",
      "[Epoch 79, Batch 94/100] Loss: 0.0337 | RMSE: 0.0314 | Consistency: 0.0055 | SSIM: 0.0223 | Grad: 55017.930\n",
      "[Epoch 79, Batch 95/100] Loss: 0.0345 | RMSE: 0.0319 | Consistency: 0.0063 | SSIM: 0.0247 | Grad: 19226.314\n",
      "[Epoch 79, Batch 96/100] Loss: 0.0348 | RMSE: 0.0325 | Consistency: 0.0051 | SSIM: 0.0224 | Grad: 67421.930\n",
      "[Epoch 79, Batch 97/100] Loss: 0.0371 | RMSE: 0.0346 | Consistency: 0.0061 | SSIM: 0.0243 | Grad: 33027.730\n",
      "[Epoch 79, Batch 98/100] Loss: 0.0374 | RMSE: 0.0347 | Consistency: 0.0067 | SSIM: 0.0267 | Grad: 12072.485\n",
      "[Epoch 79, Batch 99/100] Loss: 0.0295 | RMSE: 0.0274 | Consistency: 0.0042 | SSIM: 0.0209 | Grad: 42113.098\n",
      "[Epoch 79, Batch 100/100] Loss: 0.0372 | RMSE: 0.0338 | Consistency: 0.0066 | SSIM: 0.0331 | Grad: 53888.094\n",
      "✅ Epoch 79 완료!\n",
      "   📈 평균 Loss: 0.034001\n",
      "   📊 평균 RMSE: 0.031695\n",
      "   ⚙️  학습률: 0.000000\n",
      "   🏆 NEW BEST! RMSE: 0.031695\n",
      "------------------------------------------------------------\n",
      "\n",
      "📊 Epoch 80/80 시작...\n",
      "[Epoch 80, Batch 1/100] Loss: 0.0394 | RMSE: 0.0369 | Consistency: 0.0084 | SSIM: 0.0239 | Grad: 52962.621\n",
      "[Epoch 80, Batch 2/100] Loss: 0.0407 | RMSE: 0.0385 | Consistency: 0.0066 | SSIM: 0.0221 | Grad: 33052.598\n",
      "[Epoch 80, Batch 3/100] Loss: 0.0370 | RMSE: 0.0341 | Consistency: 0.0061 | SSIM: 0.0287 | Grad: 43341.348\n",
      "[Epoch 80, Batch 4/100] Loss: 0.0358 | RMSE: 0.0333 | Consistency: 0.0062 | SSIM: 0.0237 | Grad: 51495.359\n",
      "[Epoch 80, Batch 5/100] Loss: 0.0340 | RMSE: 0.0320 | Consistency: 0.0060 | SSIM: 0.0197 | Grad: 31535.121\n",
      "[Epoch 80, Batch 6/100] Loss: 0.0335 | RMSE: 0.0308 | Consistency: 0.0053 | SSIM: 0.0264 | Grad: 52307.434\n",
      "[Epoch 80, Batch 7/100] Loss: 0.0370 | RMSE: 0.0342 | Consistency: 0.0061 | SSIM: 0.0274 | Grad: 30332.754\n",
      "[Epoch 80, Batch 8/100] Loss: 0.0378 | RMSE: 0.0353 | Consistency: 0.0067 | SSIM: 0.0242 | Grad: 37886.562\n",
      "[Epoch 80, Batch 9/100] Loss: 0.0519 | RMSE: 0.0485 | Consistency: 0.0114 | SSIM: 0.0334 | Grad: 43867.848\n",
      "[Epoch 80, Batch 10/100] Loss: 0.0348 | RMSE: 0.0325 | Consistency: 0.0063 | SSIM: 0.0230 | Grad: 49657.867\n",
      "[Epoch 80, Batch 11/100] Loss: 0.0345 | RMSE: 0.0322 | Consistency: 0.0045 | SSIM: 0.0225 | Grad: 25474.168\n",
      "[Epoch 80, Batch 12/100] Loss: 0.0339 | RMSE: 0.0314 | Consistency: 0.0061 | SSIM: 0.0242 | Grad: 48407.410\n",
      "[Epoch 80, Batch 13/100] Loss: 0.0326 | RMSE: 0.0303 | Consistency: 0.0057 | SSIM: 0.0227 | Grad: 39339.555\n",
      "[Epoch 80, Batch 14/100] Loss: 0.0347 | RMSE: 0.0320 | Consistency: 0.0056 | SSIM: 0.0273 | Grad: 44564.676\n",
      "[Epoch 80, Batch 15/100] Loss: 0.0325 | RMSE: 0.0307 | Consistency: 0.0045 | SSIM: 0.0173 | Grad: 12535.906\n",
      "[Epoch 80, Batch 16/100] Loss: 0.0339 | RMSE: 0.0318 | Consistency: 0.0061 | SSIM: 0.0200 | Grad: 28628.803\n",
      "[Epoch 80, Batch 17/100] Loss: 0.0346 | RMSE: 0.0327 | Consistency: 0.0056 | SSIM: 0.0189 | Grad: 15212.104\n",
      "[Epoch 80, Batch 18/100] Loss: 0.0417 | RMSE: 0.0388 | Consistency: 0.0092 | SSIM: 0.0282 | Grad: 59005.672\n",
      "[Epoch 80, Batch 19/100] Loss: 0.0360 | RMSE: 0.0337 | Consistency: 0.0071 | SSIM: 0.0227 | Grad: 46614.766\n",
      "[Epoch 80, Batch 20/100] Loss: 0.0305 | RMSE: 0.0283 | Consistency: 0.0048 | SSIM: 0.0208 | Grad: 54706.727\n",
      "[Epoch 80, Batch 21/100] Loss: 0.0307 | RMSE: 0.0289 | Consistency: 0.0047 | SSIM: 0.0184 | Grad: 28686.514\n",
      "[Epoch 80, Batch 22/100] Loss: 0.0317 | RMSE: 0.0291 | Consistency: 0.0049 | SSIM: 0.0260 | Grad: 37414.609\n",
      "[Epoch 80, Batch 23/100] Loss: 0.0365 | RMSE: 0.0339 | Consistency: 0.0079 | SSIM: 0.0246 | Grad: 28780.242\n",
      "[Epoch 80, Batch 24/100] Loss: 0.0337 | RMSE: 0.0312 | Consistency: 0.0056 | SSIM: 0.0242 | Grad: 40627.523\n",
      "[Epoch 80, Batch 25/100] Loss: 0.0314 | RMSE: 0.0292 | Consistency: 0.0046 | SSIM: 0.0213 | Grad: 32612.775\n",
      "[Epoch 80, Batch 26/100] Loss: 0.0353 | RMSE: 0.0331 | Consistency: 0.0062 | SSIM: 0.0209 | Grad: 68555.414\n",
      "[Epoch 80, Batch 27/100] Loss: 0.0328 | RMSE: 0.0310 | Consistency: 0.0050 | SSIM: 0.0178 | Grad: 56233.285\n",
      "[Epoch 80, Batch 28/100] Loss: 0.0389 | RMSE: 0.0366 | Consistency: 0.0080 | SSIM: 0.0225 | Grad: 50449.555\n",
      "[Epoch 80, Batch 29/100] Loss: 0.0330 | RMSE: 0.0311 | Consistency: 0.0053 | SSIM: 0.0186 | Grad: 25523.029\n",
      "[Epoch 80, Batch 30/100] Loss: 0.0306 | RMSE: 0.0289 | Consistency: 0.0036 | SSIM: 0.0174 | Grad: 46419.875\n",
      "[Epoch 80, Batch 31/100] Loss: 0.0306 | RMSE: 0.0284 | Consistency: 0.0044 | SSIM: 0.0214 | Grad: 20916.760\n",
      "[Epoch 80, Batch 32/100] Loss: 0.0329 | RMSE: 0.0310 | Consistency: 0.0040 | SSIM: 0.0184 | Grad: 28775.656\n",
      "[Epoch 80, Batch 33/100] Loss: 0.0407 | RMSE: 0.0380 | Consistency: 0.0091 | SSIM: 0.0262 | Grad: 53874.895\n",
      "[Epoch 80, Batch 34/100] Loss: 0.0339 | RMSE: 0.0320 | Consistency: 0.0057 | SSIM: 0.0182 | Grad: 49304.449\n",
      "[Epoch 80, Batch 35/100] Loss: 0.0317 | RMSE: 0.0298 | Consistency: 0.0050 | SSIM: 0.0191 | Grad: 54368.605\n",
      "[Epoch 80, Batch 36/100] Loss: 0.0317 | RMSE: 0.0296 | Consistency: 0.0040 | SSIM: 0.0211 | Grad: 30948.816\n",
      "[Epoch 80, Batch 37/100] Loss: 0.0311 | RMSE: 0.0295 | Consistency: 0.0040 | SSIM: 0.0159 | Grad: 56840.707\n",
      "[Epoch 80, Batch 38/100] Loss: 0.0321 | RMSE: 0.0301 | Consistency: 0.0044 | SSIM: 0.0199 | Grad: 63910.418\n",
      "[Epoch 80, Batch 39/100] Loss: 0.0339 | RMSE: 0.0320 | Consistency: 0.0057 | SSIM: 0.0189 | Grad: 54064.430\n",
      "[Epoch 80, Batch 40/100] Loss: 0.0400 | RMSE: 0.0375 | Consistency: 0.0074 | SSIM: 0.0244 | Grad: 33933.762\n",
      "[Epoch 80, Batch 41/100] Loss: 0.0325 | RMSE: 0.0303 | Consistency: 0.0048 | SSIM: 0.0213 | Grad: 38855.875\n",
      "[Epoch 80, Batch 42/100] Loss: 0.0372 | RMSE: 0.0344 | Consistency: 0.0061 | SSIM: 0.0277 | Grad: 34611.188\n",
      "[Epoch 80, Batch 43/100] Loss: 0.0336 | RMSE: 0.0315 | Consistency: 0.0056 | SSIM: 0.0212 | Grad: 40121.074\n",
      "[Epoch 80, Batch 44/100] Loss: 0.0362 | RMSE: 0.0339 | Consistency: 0.0058 | SSIM: 0.0218 | Grad: 30434.033\n",
      "[Epoch 80, Batch 45/100] Loss: 0.0443 | RMSE: 0.0414 | Consistency: 0.0115 | SSIM: 0.0270 | Grad: 28513.959\n",
      "[Epoch 80, Batch 46/100] Loss: 0.0387 | RMSE: 0.0354 | Consistency: 0.0073 | SSIM: 0.0320 | Grad: 14421.828\n",
      "[Epoch 80, Batch 47/100] Loss: 0.0311 | RMSE: 0.0292 | Consistency: 0.0052 | SSIM: 0.0189 | Grad: 48392.535\n",
      "[Epoch 80, Batch 48/100] Loss: 0.0381 | RMSE: 0.0355 | Consistency: 0.0071 | SSIM: 0.0248 | Grad: 45646.055\n",
      "[Epoch 80, Batch 49/100] Loss: 0.0328 | RMSE: 0.0307 | Consistency: 0.0052 | SSIM: 0.0205 | Grad: 39016.742\n",
      "[Epoch 80, Batch 50/100] Loss: 0.0383 | RMSE: 0.0349 | Consistency: 0.0071 | SSIM: 0.0324 | Grad: 33571.914\n",
      "[Epoch 80, Batch 51/100] Loss: 0.0317 | RMSE: 0.0293 | Consistency: 0.0050 | SSIM: 0.0226 | Grad: 44640.836\n",
      "[Epoch 80, Batch 52/100] Loss: 0.0325 | RMSE: 0.0305 | Consistency: 0.0051 | SSIM: 0.0188 | Grad: 45772.906\n",
      "[Epoch 80, Batch 53/100] Loss: 0.0328 | RMSE: 0.0303 | Consistency: 0.0055 | SSIM: 0.0240 | Grad: 23903.479\n",
      "[Epoch 80, Batch 54/100] Loss: 0.0320 | RMSE: 0.0296 | Consistency: 0.0053 | SSIM: 0.0231 | Grad: 69615.203\n",
      "[Epoch 80, Batch 55/100] Loss: 0.0313 | RMSE: 0.0295 | Consistency: 0.0046 | SSIM: 0.0177 | Grad: 34478.906\n",
      "[Epoch 80, Batch 56/100] Loss: 0.0309 | RMSE: 0.0287 | Consistency: 0.0048 | SSIM: 0.0212 | Grad: 38430.738\n",
      "[Epoch 80, Batch 57/100] Loss: 0.0339 | RMSE: 0.0317 | Consistency: 0.0060 | SSIM: 0.0211 | Grad: 61872.566\n",
      "[Epoch 80, Batch 58/100] Loss: 0.0312 | RMSE: 0.0294 | Consistency: 0.0045 | SSIM: 0.0172 | Grad: 33250.590\n",
      "[Epoch 80, Batch 59/100] Loss: 0.0420 | RMSE: 0.0389 | Consistency: 0.0092 | SSIM: 0.0301 | Grad: 51775.707\n",
      "[Epoch 80, Batch 60/100] Loss: 0.0331 | RMSE: 0.0309 | Consistency: 0.0058 | SSIM: 0.0218 | Grad: 39700.484\n",
      "[Epoch 80, Batch 61/100] Loss: 0.0382 | RMSE: 0.0356 | Consistency: 0.0064 | SSIM: 0.0252 | Grad: 42100.699\n",
      "[Epoch 80, Batch 62/100] Loss: 0.0332 | RMSE: 0.0311 | Consistency: 0.0056 | SSIM: 0.0209 | Grad: 50747.535\n",
      "[Epoch 80, Batch 63/100] Loss: 0.0329 | RMSE: 0.0309 | Consistency: 0.0051 | SSIM: 0.0190 | Grad: 28111.586\n",
      "[Epoch 80, Batch 64/100] Loss: 0.0324 | RMSE: 0.0303 | Consistency: 0.0052 | SSIM: 0.0208 | Grad: 60592.664\n",
      "[Epoch 80, Batch 65/100] Loss: 0.0358 | RMSE: 0.0334 | Consistency: 0.0060 | SSIM: 0.0230 | Grad: 36323.691\n",
      "[Epoch 80, Batch 66/100] Loss: 0.0287 | RMSE: 0.0270 | Consistency: 0.0034 | SSIM: 0.0165 | Grad: 67955.703\n",
      "[Epoch 80, Batch 67/100] Loss: 0.0340 | RMSE: 0.0315 | Consistency: 0.0058 | SSIM: 0.0241 | Grad: 24583.193\n",
      "[Epoch 80, Batch 68/100] Loss: 0.0296 | RMSE: 0.0276 | Consistency: 0.0040 | SSIM: 0.0201 | Grad: 44654.074\n",
      "[Epoch 80, Batch 69/100] Loss: 0.0354 | RMSE: 0.0328 | Consistency: 0.0057 | SSIM: 0.0253 | Grad: 50749.230\n",
      "[Epoch 80, Batch 70/100] Loss: 0.0404 | RMSE: 0.0375 | Consistency: 0.0077 | SSIM: 0.0288 | Grad: 44901.855\n",
      "[Epoch 80, Batch 71/100] Loss: 0.0311 | RMSE: 0.0293 | Consistency: 0.0047 | SSIM: 0.0183 | Grad: 23653.807\n",
      "[Epoch 80, Batch 72/100] Loss: 0.0325 | RMSE: 0.0301 | Consistency: 0.0049 | SSIM: 0.0234 | Grad: 22807.627\n",
      "[Epoch 80, Batch 73/100] Loss: 0.0329 | RMSE: 0.0312 | Consistency: 0.0047 | SSIM: 0.0169 | Grad: 43732.789\n",
      "[Epoch 80, Batch 74/100] Loss: 0.0386 | RMSE: 0.0357 | Consistency: 0.0072 | SSIM: 0.0284 | Grad: 63059.789\n",
      "[Epoch 80, Batch 75/100] Loss: 0.0335 | RMSE: 0.0312 | Consistency: 0.0062 | SSIM: 0.0226 | Grad: 41314.523\n",
      "[Epoch 80, Batch 76/100] Loss: 0.0308 | RMSE: 0.0283 | Consistency: 0.0047 | SSIM: 0.0241 | Grad: 39145.230\n",
      "[Epoch 80, Batch 77/100] Loss: 0.0320 | RMSE: 0.0296 | Consistency: 0.0055 | SSIM: 0.0228 | Grad: 51477.551\n",
      "[Epoch 80, Batch 78/100] Loss: 0.0294 | RMSE: 0.0272 | Consistency: 0.0043 | SSIM: 0.0216 | Grad: 13088.101\n",
      "[Epoch 80, Batch 79/100] Loss: 0.0408 | RMSE: 0.0378 | Consistency: 0.0088 | SSIM: 0.0291 | Grad: 42245.535\n",
      "[Epoch 80, Batch 80/100] Loss: 0.0299 | RMSE: 0.0282 | Consistency: 0.0046 | SSIM: 0.0172 | Grad: 27982.514\n",
      "[Epoch 80, Batch 81/100] Loss: 0.0367 | RMSE: 0.0342 | Consistency: 0.0055 | SSIM: 0.0247 | Grad: 61068.840\n",
      "[Epoch 80, Batch 82/100] Loss: 0.0333 | RMSE: 0.0308 | Consistency: 0.0054 | SSIM: 0.0238 | Grad: 43255.520\n",
      "[Epoch 80, Batch 83/100] Loss: 0.0320 | RMSE: 0.0300 | Consistency: 0.0043 | SSIM: 0.0204 | Grad: 25331.150\n",
      "[Epoch 80, Batch 84/100] Loss: 0.0309 | RMSE: 0.0293 | Consistency: 0.0051 | SSIM: 0.0163 | Grad: 37086.602\n",
      "[Epoch 80, Batch 85/100] Loss: 0.0297 | RMSE: 0.0281 | Consistency: 0.0051 | SSIM: 0.0160 | Grad: 25963.523\n",
      "[Epoch 80, Batch 86/100] Loss: 0.0454 | RMSE: 0.0430 | Consistency: 0.0096 | SSIM: 0.0231 | Grad: 56133.727\n",
      "[Epoch 80, Batch 87/100] Loss: 0.0375 | RMSE: 0.0349 | Consistency: 0.0055 | SSIM: 0.0251 | Grad: 50815.359\n",
      "[Epoch 80, Batch 88/100] Loss: 0.0376 | RMSE: 0.0353 | Consistency: 0.0070 | SSIM: 0.0221 | Grad: 43465.227\n",
      "[Epoch 80, Batch 89/100] Loss: 0.0302 | RMSE: 0.0283 | Consistency: 0.0047 | SSIM: 0.0183 | Grad: 20129.166\n",
      "[Epoch 80, Batch 90/100] Loss: 0.0376 | RMSE: 0.0352 | Consistency: 0.0059 | SSIM: 0.0237 | Grad: 78013.336\n",
      "[Epoch 80, Batch 91/100] Loss: 0.0346 | RMSE: 0.0321 | Consistency: 0.0057 | SSIM: 0.0245 | Grad: 58176.602\n",
      "[Epoch 80, Batch 92/100] Loss: 0.0319 | RMSE: 0.0296 | Consistency: 0.0053 | SSIM: 0.0225 | Grad: 24685.055\n",
      "[Epoch 80, Batch 93/100] Loss: 0.0352 | RMSE: 0.0328 | Consistency: 0.0054 | SSIM: 0.0237 | Grad: 44179.758\n",
      "[Epoch 80, Batch 94/100] Loss: 0.0361 | RMSE: 0.0339 | Consistency: 0.0052 | SSIM: 0.0217 | Grad: 62797.867\n",
      "[Epoch 80, Batch 95/100] Loss: 0.0329 | RMSE: 0.0306 | Consistency: 0.0058 | SSIM: 0.0224 | Grad: 69589.797\n",
      "[Epoch 80, Batch 96/100] Loss: 0.0304 | RMSE: 0.0288 | Consistency: 0.0051 | SSIM: 0.0157 | Grad: 51384.102\n",
      "[Epoch 80, Batch 97/100] Loss: 0.0307 | RMSE: 0.0285 | Consistency: 0.0046 | SSIM: 0.0213 | Grad: 31100.324\n",
      "[Epoch 80, Batch 98/100] Loss: 0.0348 | RMSE: 0.0323 | Consistency: 0.0052 | SSIM: 0.0246 | Grad: 10468.218\n",
      "[Epoch 80, Batch 99/100] Loss: 0.0360 | RMSE: 0.0336 | Consistency: 0.0060 | SSIM: 0.0236 | Grad: 42322.301\n",
      "[Epoch 80, Batch 100/100] Loss: 0.0389 | RMSE: 0.0366 | Consistency: 0.0069 | SSIM: 0.0227 | Grad: 27140.805\n",
      "✅ Epoch 80 완료!\n",
      "   📈 평균 Loss: 0.034587\n",
      "   📊 평균 RMSE: 0.032287\n",
      "   ⚙️  학습률: 0.000000\n",
      "------------------------------------------------------------\n",
      "모델이 'best_model.pth'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 훈련 루프 설정\n",
    "# =============================================================================\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "max_batches = min(100, len(train_loader))\n",
    "log_interval = 1\n",
    "print(f\"총 샘플 수: {len(train_dataset)}\")\n",
    "print(f\"배치 크기: {batch_size}\")\n",
    "print(f\"총 배치 개수: {max_batches}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    steps_per_epoch=max_batches,\n",
    "    epochs=training_epochs,\n",
    "    pct_start=0.1\n",
    ")\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_rmse_sum = 0.0\n",
    "\n",
    "    print(f\"\\n📊 Epoch {epoch + 1}/{training_epochs} 시작...\")\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for i, (input_phase, target_phases) in enumerate(train_loader):\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "        input_phase = input_phase.to(device)         # shape: (B, 1, H, W)\n",
    "        target_phase1 = target_phases[:, 0:1].to(device)  # shape: (B, 1, H, W)\n",
    "        target_phase2 = target_phases[:, 1:2].to(device)\n",
    "        target_phase3 = target_phases[:, 2:3].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # 모델 예측\n",
    "            output1, output2, output3 = model(input_phase)\n",
    "            # 손실 계산\n",
    "            loss, loss_details = improved_physics_loss(\n",
    "                output1, target_phase1,\n",
    "                output2, target_phase2,\n",
    "                output3, target_phase3,\n",
    "                epoch=epoch\n",
    "            )\n",
    "\n",
    "        # 역전파 및 업데이트\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)  # AMP에서도 가능\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        epoch_rmse_sum += loss_details['rmse']\n",
    "\n",
    "        # ✅ 로그 출력\n",
    "        print(f\"[Epoch {epoch + 1}, Batch {i + 1}/{max_batches}] \"\n",
    "              f\"Loss: {loss.item():.4f} | \"\n",
    "              f\"RMSE: {loss_details['rmse']:.4f} | \"\n",
    "              f\"Consistency: {loss_details['consistency']:.4f} | \"\n",
    "              f\"SSIM: {loss_details['ssim']:.4f} | \"\n",
    "              f\"Grad: {grad_norm:.3f}\")\n",
    "\n",
    "\n",
    "        # 에포크 마무리\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        avg_loss = running_loss / max_batches\n",
    "        avg_rmse = epoch_rmse_sum / max_batches\n",
    "\n",
    "    print(f\"✅ Epoch {epoch + 1} 완료!\")\n",
    "    print(f\"   📈 평균 Loss: {avg_loss:.6f}\")\n",
    "    print(f\"   📊 평균 RMSE: {avg_rmse:.6f}\")\n",
    "    print(f\"   ⚙️  학습률: {current_lr:.6f}\")\n",
    "\n",
    "    # 모델 저장 조건\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_noise.pth')\n",
    "        print(f\"   🏆 NEW BEST! RMSE: {avg_rmse:.6f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # 조기 종료 조건\n",
    "    if patience_counter >= patience_limit:\n",
    "        print(f\"🛑 조기 종료! {patience_limit} 에포크 개선 없음\")\n",
    "        break\n",
    "\n",
    "    if avg_rmse <= 0.0036:\n",
    "        print(f\"🎊 목표 달성! RMSE: {avg_rmse:.6f} <= 0.0036\")\n",
    "        break\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "print(\"모델이 'best_model_noise.pth'로 저장되었습니다.\")\t  \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ae459-0046-4d8d-bec9-94b580528791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
