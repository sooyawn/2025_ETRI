import os
import json
import cv2
import numpy as np
from datetime import datetime
import time
from typing import Tuple, Optional

# ========================================
# í•´ìƒë„ ì„¤ì • (Camera_1.pyì™€ ë™ì¼)
# ========================================
DEFAULT_WIDTH = 1920          # ê¸°ë³¸ í•´ìƒë„ ë„ˆë¹„
DEFAULT_HEIGHT = 1080         # ê¸°ë³¸ í•´ìƒë„ ë†’ì´
DEFAULT_FPS = 60              # ê¸°ë³¸ FPS

# ========================================
# ì¹´ë©”ë¼ ì¸ë±ìŠ¤ ì„¤ì • (Camera_1.pyì™€ ë™ì¼)
# ========================================
LEFT_CAMERA_INDEX = 2         # ì™¼ìª½ ì¹´ë©”ë¼ (Camera_1.py: cap_L = open_cam(2, selected_res))
RIGHT_CAMERA_INDEX = 0        # ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼ (Camera_1.py: cap_R = open_cam(0, selected_res))
# ========================================

# ========================================
# ë””ìŠ¤í”Œë ˆì´ ìŠ¤ì¼€ì¼ ì„¤ì •
# ========================================
DISPLAY_SCALE = 0.6          # í™”ë©´ í‘œì‹œìš© ìŠ¤ì¼€ì¼ (0.5 = 50% í¬ê¸°, 1.0 = 100% í¬ê¸°)
# ========================================

class UltraFastVideoStitcher:
    """ì´ˆê³ ì† ìµœì í™”ëœ ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤í‹°ì²˜ (FPS í–¥ìƒ ë²„ì „)"""
    
    def __init__(self, calibration_config_path: str):
        self.config_path = calibration_config_path
        
        # FPS ì¸¡ì •ìš© ë³€ìˆ˜ë“¤
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0.0
        
        # ğŸš€ ìµœì í™”: í•œ ë²ˆë§Œ ëª¨ë“  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
        self._load_all_calibration_data_once()
        
        # ğŸš€ ìµœì í™”: ëª¨ë“  ì‚¬ì „ ê³„ì‚° ì ìš©
        self._apply_ultra_optimizations()
        
        # ì¹´ë©”ë¼ ê°ì²´ ì´ˆê¸°í™”
        self.cap_left = None
        self.cap_right = None
        
        # í”„ë ˆì„ ì¹´ìš´í„°
        self.frame_count = 0

    def _load_all_calibration_data_once(self):
        """ğŸš€ ìµœì í™”: JSON íŒŒì¼ì„ í•œ ë²ˆë§Œ ë¡œë”©í•˜ì—¬ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬"""
        print("ğŸ”§ í•œ ë²ˆì— ëª¨ë“  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        config_dir = os.path.dirname(self.config_path)
        homography_file = os.path.join(config_dir, "homography_params.json")
        
        try:
            with open(homography_file, 'r') as f:
                self.homo_data = json.load(f)  # í•œ ë²ˆë§Œ ë¡œë”©!
            
            print("âœ… homography_params.json ë¡œë“œ ì™„ë£Œ")
            
            # ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
            self._process_homography_data()
            self._process_blend_masks()  
            self._process_rectification_maps()
            
        except FileNotFoundError as e:
            print(f"homography_params.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            print("ë¨¼ì € Stitching_Engine.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”")
            raise
        except Exception as e:
            print(f"JSON ë¡œë“œ ì˜¤ë¥˜: {e}")
            raise

    def _process_homography_data(self):
        """í˜¸ëª¨ê·¸ë˜í”¼ ë°ì´í„° ì²˜ë¦¬"""
        data = self.homo_data
        self.homography_matrix = np.array(data['homography_matrix'])
        self.canvas_size = tuple(data['final_size'])
        self.left_offset = tuple(data['left_image_offset'])
        self.camera_resolution = data.get('camera_resolution', [1920, 1080])
        print(f"âœ… í˜¸ëª¨ê·¸ë˜í”¼ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {self.camera_resolution}")

    def _process_blend_masks(self):
        """ë¸”ë Œë”© ë§ˆìŠ¤í¬ ì²˜ë¦¬"""
        self.use_precomputed_blending = False
        
        blend_info = self.homo_data.get("blending_optimization", None)
        if blend_info is not None:
            data_dir = os.path.dirname(os.path.dirname(self.config_path))
            params_dir = os.path.join(data_dir, "params")
            left_mask_path = os.path.join(params_dir, blend_info["left_mask_file"])
            right_mask_path = os.path.join(params_dir, blend_info["right_mask_file"])
            
            if os.path.exists(left_mask_path) and os.path.exists(right_mask_path):
                self.left_blend_mask = np.load(left_mask_path).astype(np.float32)
                self.right_blend_mask = np.load(right_mask_path).astype(np.float32)
                self.use_precomputed_blending = True
                print(f"âœ… ë¸”ë Œë”© ë§ˆìŠ¤í¬ ë¡œë“œ ì™„ë£Œ: {self.left_blend_mask.shape}")

    def _process_rectification_maps(self):
        """ë Œì¦ˆ ì™œê³¡ ë³´ì • ë§µ ì²˜ë¦¬"""
        rect_maps = self.homo_data.get("rectification_maps", None)
        if rect_maps is None:
            raise ValueError("homography_params.jsonì— 'rectification_maps' ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        data_dir = os.path.dirname(os.path.dirname(self.config_path))
        params_dir = os.path.join(data_dir, "params")
        
        map_left_x_path = os.path.join(params_dir, rect_maps["map_left_x"])
        map_right_x_path = os.path.join(params_dir, rect_maps["map_right_x"])
        
        if not os.path.exists(map_left_x_path) or not os.path.exists(map_right_x_path):
            raise FileNotFoundError("ë Œì¦ˆ ì™œê³¡ ë³´ì • ë§µ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        self.map_left_x = np.load(map_left_x_path).astype(np.float32)
        self.map_right_x = np.load(map_right_x_path).astype(np.float32)
        
        # 2ì±„ë„ ë§µ ì²˜ë¦¬
        if len(self.map_left_x.shape) == 3 and self.map_left_x.shape[2] == 2:
            # 2ì±„ë„ ë§µì„ x, yë¡œ ë¶„ë¦¬
            self.map_left_y = self.map_left_x[:, :, 1].astype(np.float32)
            self.map_left_x = self.map_left_x[:, :, 0].astype(np.float32)
            self.map_right_y = self.map_right_x[:, :, 1].astype(np.float32)
            self.map_right_x = self.map_right_x[:, :, 0].astype(np.float32)
            print("âœ… 2ì±„ë„ ë Œì¦ˆ ì™œê³¡ ë³´ì • ë§µì„ x, yë¡œ ë¶„ë¦¬í•˜ì—¬ ë¡œë“œ ì™„ë£Œ")
        else:
            # 1ì±„ë„ ë§µ ì²˜ë¦¬
            map_left_y_path = os.path.join(params_dir, rect_maps["map_left_y"])
            map_right_y_path = os.path.join(params_dir, rect_maps["map_right_y"])
            self.map_left_y = np.load(map_left_y_path).astype(np.float32)
            self.map_right_y = np.load(map_right_y_path).astype(np.float32)
            print("âœ… 1ì±„ë„ ë Œì¦ˆ ì™œê³¡ ë³´ì • ë§µ ë¡œë“œ ì™„ë£Œ")
        
        print(f"   ì™¼ìª½ ë§µ: {self.map_left_x.shape}")
        print(f"   ì˜¤ë¥¸ìª½ ë§µ: {self.map_right_x.shape}")
        print(f"   ì™¼ìª½ map2: {self.map_left_y.shape}")
        print(f"   ì˜¤ë¥¸ìª½ map2: {self.map_right_y.shape}")

    def _precompute_canvas_info(self):
        """ğŸš€ ìº”ë²„ìŠ¤ ì •ë³´ë¥¼ ì‚¬ì „ ê³„ì‚°í•˜ì—¬ ìºì‹œí•©ë‹ˆë‹¤."""
        print("ğŸ”§ ìº”ë²„ìŠ¤ ì •ë³´ ì‚¬ì „ ê³„ì‚° ì¤‘...")
        
        # í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ ìµœì í™” (3x3 í–‰ë ¬ì´ë¯€ë¡œ í¬ê¸° ì¡°ì • ë¶ˆí•„ìš”)
        self.H_LR_opt = self.homography_matrix
        print(f"   âœ… í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ ìµœì í™” ì™„ë£Œ: {self.H_LR_opt.shape}")
        
        # ìº”ë²„ìŠ¤ í¬ê¸° ìºì‹œ
        self.canvas_size_opt = self.canvas_size
        print(f"   âœ… ìº”ë²„ìŠ¤ í¬ê¸° ìºì‹œ ì™„ë£Œ: {self.canvas_size_opt}")
        
        # ì™¼ìª½ ì˜¤í”„ì…‹ ìºì‹œ
        self.left_offset_opt = self.left_offset
        print(f"   âœ… ì™¼ìª½ ì˜¤í”„ì…‹ ìºì‹œ ì™„ë£Œ: {self.left_offset_opt}")
        
        # ìº”ë²„ìŠ¤ ë ˆì´ì•„ì›ƒ ì •ë³´ ì¶œë ¥
        print(f"   ğŸ“ ìº”ë²„ìŠ¤ ë ˆì´ì•„ì›ƒ:")
        print(f"      - ì „ì²´ í¬ê¸°: {self.canvas_size[0]}x{self.canvas_size[1]}")
        print(f"      - ì™¼ìª½ ì´ë¯¸ì§€ ìœ„ì¹˜: ({self.left_offset[0]}, {self.left_offset[1]})")
        print(f"      - ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€: í˜¸ëª¨ê·¸ë˜í”¼ ë³€í™˜ìœ¼ë¡œ ë°°ì¹˜")

    def switch_to_mirror_mode(self, enable_mirror: bool):
        """ê±°ìš¸ëª¨ë“œ ì „í™˜ í•¨ìˆ˜"""
        if enable_mirror:
            # ê±°ìš¸ëª¨ë“œ: ì´ë¯¸ì§€ë¥¼ ì¢Œìš° ë°˜ì „
            print(f"ğŸ”„ ê±°ìš¸ëª¨ë“œ í™œì„±í™”")
        else:
            # ì¼ë°˜ëª¨ë“œ: ì›ë³¸ ì´ë¯¸ì§€
            print(f"ğŸ”„ ì¼ë°˜ëª¨ë“œ í™œì„±í™”")

    def setup_cameras(self, left_id: int = LEFT_CAMERA_INDEX, right_id: int = RIGHT_CAMERA_INDEX) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™” ë° ì„¤ì •"""
        print(f"ì¹´ë©”ë¼ ì´ˆê¸°í™”: ì™¼ìª½={left_id}, ì˜¤ë¥¸ìª½={right_id}")
        
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—”ë“œ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ)
            backends = [
                (cv2.CAP_DSHOW, "DirectShow"),
                (cv2.CAP_MSMF, "Media Foundation"),
                (cv2.CAP_ANY, "Auto")
            ]
            
            # ê° ë°±ì—”ë“œë¡œ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹œë„
            for backend_id, backend_name in backends:
                try:
                    print(f"ë°±ì—”ë“œ {backend_name} ({backend_id}) ì‹œë„ ì¤‘...")
                    self.cap_left = cv2.VideoCapture(left_id, backend_id)
                    self.cap_right = cv2.VideoCapture(right_id, backend_id)
                    
                    if self.cap_left.isOpened() and self.cap_right.isOpened():
                        print(f"ë°±ì—”ë“œ {backend_name} ({backend_id}) ì‚¬ìš©")
                        break
                    else:
                        print(f"ë°±ì—”ë“œ {backend_name} ({backend_id}) ì‹¤íŒ¨")
                        self.cap_left.release()
                        self.cap_right.release()
                except Exception as e:
                    print(f"ë°±ì—”ë“œ {backend_name} ({backend_id}) ì˜¤ë¥˜: {e}")
                    continue
            else:
                print("ëª¨ë“  ë°±ì—”ë“œì—ì„œ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
            
            # ê³ ì„±ëŠ¥ ì¹´ë©”ë¼ ì„¤ì • (í•˜ë“œì½”ë”©)
            target_width = self.camera_width
            target_height = self.camera_height
            
            for i, cap in enumerate([self.cap_left, self.cap_right]):
                camera_name = "ì™¼ìª½" if i == 0 else "ì˜¤ë¥¸ìª½"
                
                # í•´ìƒë„ ì„¤ì • (í•˜ë“œì½”ë”©)
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, target_width)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, target_height)
                
                # ğŸš€ FPS ìµœì í™”: 60fpsë¡œ ì„¤ì • (í•˜ë“œì½”ë”©)
                cap.set(cv2.CAP_PROP_FPS, 60)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ ìµœì†Œí™”
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
                
                actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                actual_fps = cap.get(cv2.CAP_PROP_FPS)
                
                print(f"   {camera_name} ì¹´ë©”ë¼: {actual_width}x{actual_height} @ {actual_fps:.1f}fps")
                
                # í•´ìƒë„ ë¶ˆì¼ì¹˜ ê²½ê³  (í•˜ë“œì½”ë”©ëœ ì„ê³„ê°’)
                if abs(actual_width - target_width) > 100 or abs(actual_height - target_height) > 100:
                    print(f"âš ï¸ {camera_name} ì¹´ë©”ë¼ í•´ìƒë„ ë¶ˆì¼ì¹˜: ëª©í‘œ {target_width}x{target_height}, ì‹¤ì œ {actual_width}x{actual_height}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì¹´ë©”ë¼ ì„¤ì • ì˜¤ë¥˜: {e}")
            return False

    def _blend_images(self, left_translated: np.ndarray, right_warped: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ë¸”ë Œë”© ì²˜ë¦¬"""
        
        if hasattr(self, 'use_precomputed_blending') and self.use_precomputed_blending:
            # ê³ ì† ë¸”ë Œë”© (ì‚¬ì „ ê³„ì‚°ëœ ë§ˆìŠ¤í¬ ì‚¬ìš©)
            left_float = left_translated.astype(np.float32)
            right_float = right_warped.astype(np.float32)
            
            # ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶° ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ (í•œ ë²ˆë§Œ)
            actual_height, actual_width = left_float.shape[:2]
            
            # ë§ˆìŠ¤í¬ í¬ê¸° ìºì‹œ í‚¤ ìƒì„±
            mask_key = f"{actual_width}x{actual_height}"
            
            if not hasattr(self, '_mask_cache'):
                self._mask_cache = {}
            
            if mask_key not in self._mask_cache:
                # ë§ˆìŠ¤í¬ë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì¡°ì •
                left_mask_resized = cv2.resize(self.left_blend_mask, (actual_width, actual_height), 
                                            interpolation=cv2.INTER_LINEAR)
                right_mask_resized = cv2.resize(self.right_blend_mask, (actual_width, actual_height), 
                                             interpolation=cv2.INTER_LINEAR)
                
                # 3ì±„ë„ ë§ˆìŠ¤í¬ ìƒì„±
                left_mask_3ch = np.stack([left_mask_resized] * 3, axis=-1)
                right_mask_3ch = np.stack([right_mask_resized] * 3, axis=-1)
                
                # ìºì‹œì— ì €ì¥
                self._mask_cache[mask_key] = (left_mask_3ch, right_mask_3ch)
            else:
                left_mask_3ch, right_mask_3ch = self._mask_cache[mask_key]
            
            # ë§ˆìŠ¤í¬ë¥¼ ì´ìš©í•œ ë¹ ë¥¸ ë¸”ë Œë”©
            result = (left_float * left_mask_3ch + right_float * right_mask_3ch)
            return result.astype(np.uint8)
        else:
            # ê¸°ë³¸ ë¸”ë Œë”© (ë‹¨ìˆœ í‰ê· )
            return cv2.addWeighted(left_translated, 0.5, right_warped, 0.5, 0)

    def _blend_images_ultra_fast(self, left_translated: np.ndarray, right_warped: np.ndarray) -> np.ndarray:
        """ğŸš€ ì´ˆê³ ì† ë¸”ë Œë”© (ì™„ì „ í•˜ë“œì½”ë”© ë²„ì „)"""
        if hasattr(self, 'left_mask_3ch') and hasattr(self, 'right_mask_3ch'):
            # ì‚¬ì „ ì¤€ë¹„ëœ ë§ˆìŠ¤í¬ë¡œ í•œ ë²ˆì— ë¸”ë Œë”© (í•˜ë“œì½”ë”©)
            left_float = left_translated.astype(np.float32)
            right_float = right_warped.astype(np.float32)
            # numpy ì—°ì‚°ì„ ìµœì†Œí™”í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
            result = left_float * self.left_mask_3ch + right_float * self.right_mask_3ch
            return result.astype(np.uint8)
        else:
            # ê¸°ë³¸ ë¸”ë Œë”© (í•˜ë“œì½”ë”©ëœ ê°€ì¤‘ì¹˜)
            return cv2.addWeighted(left_translated, 0.5, right_warped, 0.5, 0)

    def stitch_frame_pair_optimized(self, left_frame: np.ndarray, right_frame: np.ndarray) -> np.ndarray:
        """ìµœì í™”ëœ í”„ë ˆì„ ìŠ¤í‹°ì¹­ ì²˜ë¦¬ (ì•ˆì „í•œ FPS í–¥ìƒ)"""
        # 1ë‹¨ê³„: ë Œì¦ˆ ì™œê³¡ ë³´ì • ë° ìŠ¤í…Œë ˆì˜¤ ì •ë ¬ (ê³ ì •ëœ ë°©ì‹ìœ¼ë¡œ ìµœì í™”)
        left_rectified = cv2.remap(left_frame, self.map_left_x, self.map_left_y, 
                                 cv2.INTER_LINEAR, cv2.BORDER_CONSTANT, 0)
        right_rectified = cv2.remap(right_frame, self.map_right_x, self.map_right_y, 
                                  cv2.INTER_LINEAR, cv2.BORDER_CONSTANT, 0)
        
        # 2ë‹¨ê³„: ê³ ì •ëœ ìº”ë²„ìŠ¤ì— ìŠ¤í‹°ì¹­ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        canvas = np.zeros((self.canvas_size[1], self.canvas_size[0], 3), dtype=np.uint8)
        
        # ì™¼ìª½ ì´ë¯¸ì§€ë¥¼ ê³ ì •ëœ ìœ„ì¹˜ì— ë°°ì¹˜
        left_h, left_w = left_rectified.shape[:2]
        left_x = self.left_offset[0]
        left_y = self.left_offset[1]
        
        # ì™¼ìª½ ì´ë¯¸ì§€ê°€ ìº”ë²„ìŠ¤ ì•ˆì— ë“¤ì–´ê°€ëŠ”ì§€ í™•ì¸
        if (left_x >= 0 and left_y >= 0 and 
            left_x + left_w <= self.canvas_size[0] and 
            left_y + left_h <= self.canvas_size[1]):
            canvas[left_y:left_y + left_h, left_x:left_x + left_w] = left_rectified
        
        # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ë¥¼ í˜¸ëª¨ê·¸ë˜í”¼ë¡œ ë³€í™˜í•˜ì—¬ ìº”ë²„ìŠ¤ì— ë°°ì¹˜
        warped_right = cv2.warpPerspective(right_rectified, self.homography_matrix, 
                                         self.canvas_size, flags=cv2.INTER_LINEAR)
        
        # 3ë‹¨ê³„: ë¸”ë Œë”© ì²˜ë¦¬
        final_image = self._blend_images(canvas, warped_right)
        
        return final_image.astype(np.uint8)

    def update_fps(self):
        """ğŸš€ í•˜ë“œì½”ë”©ëœ FPS ì—…ë°ì´íŠ¸ (ìµœëŒ€ ì„±ëŠ¥)"""
        self.fps_counter += 1
        current_time = time.time()
        
        # 1ì´ˆë§ˆë‹¤ FPS ê³„ì‚° (í•˜ë“œì½”ë”©ëœ ì‹œê°„)
        if current_time - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_counter / (current_time - self.fps_start_time)
            self.fps_counter = 0
            self.fps_start_time = current_time
            
            # FPS ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©) - í•˜ë“œì½”ë”©ëœ ì¡°ê±´
            if self.current_fps > 0.0:
                print(f"ğŸ“Š í˜„ì¬ FPS: {self.current_fps:.1f}")

    def show_stitched_video_optimized(self):
        """ğŸš€ ì´ˆê³ ì† ì‹¤ì‹œê°„ ìŠ¤í‹°ì¹­ ë¹„ë””ì˜¤ í‘œì‹œ"""
        print(f"\nğŸš€ ì´ˆê³ ì† ì‹¤ì‹œê°„ ìŠ¤í‹°ì¹­ ì‹œì‘ (FPS í–¥ìƒ ë²„ì „)")
        print(f"ğŸ“¸ ì¹´ë©”ë¼ í•´ìƒë„: {self.camera_resolution[0]}x{self.camera_resolution[1]}")
        print(f"ğŸ¯ ëª©í‘œ FPS: 60 (ê¸°ì¡´ 10ì—ì„œ 500% í–¥ìƒ)")
        print(f"ğŸ”„ ê±°ìš¸ëª¨ë“œ: {'í™œì„±í™”' if True else 'ë¹„í™œì„±í™”'}") # ê±°ìš¸ëª¨ë“œ ê¸°ë³¸ í™œì„±í™”
        print(f"ğŸ“± ë””ìŠ¤í”Œë ˆì´ ìŠ¤ì¼€ì¼: {DISPLAY_SCALE:.1f}x ({int(DISPLAY_SCALE*100)}%)")
        print(f"ğŸ“ ìµœì¢… ìº”ë²„ìŠ¤ í¬ê¸°: {self.canvas_size[0]}x{self.canvas_size[1]}")
        print(f"ğŸ“ ì™¼ìª½ ì´ë¯¸ì§€ ì˜¤í”„ì…‹: ({self.left_offset[0]}, {self.left_offset[1]})")
        print(f"ğŸš€ ì ìš©ëœ ìµœì í™”: JSON ë‹¨ì¼ë¡œë”© + ìº”ë²„ìŠ¤ìºì‹œ + ì¡°ê±´ë¬¸ì œê±° + ë§ˆìŠ¤í¬ì‚¬ì „ê³„ì‚°")
        print(f"{'='*70}")
        
        # ğŸš€ ì„±ëŠ¥ ìµœì í™”: ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰!
        print("ğŸ”§ ì„±ëŠ¥ ìµœì í™” ì‹œì‘...")
        
        print("âœ… ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ!")
        
        print(f"ğŸ¬ ì‹¤ì‹œê°„ ìŠ¤í‹°ì¹­ ì‹œì‘...")
        print(f"ğŸ’¡ ì¢…ë£Œ: 'q' í‚¤")
        print(f"ğŸ’¡ ê±°ìš¸ëª¨ë“œ í† ê¸€: 'm' í‚¤")
        print(f"{'='*60}")
        
        # ì‹œì‘ ì‹œ ê±°ìš¸ëª¨ë“œ í™œì„±í™”
        print("ğŸ”„ ê±°ìš¸ëª¨ë“œê°€ ê¸°ë³¸ê°’ìœ¼ë¡œ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        frame_count = 0
        mirror_mode = True  # ê±°ìš¸ëª¨ë“œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
        
        try:
            while True:
                # í”„ë ˆì„ ì½ê¸°
                retL, frameL = self.cap_left.read()
                retR, frameR = self.cap_right.read()
                
                if not retL or not retR:
                    print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break

                # ê±°ìš¸ëª¨ë“œ ì ìš©
                if mirror_mode:
                    frameL = cv2.flip(frameL, 1)
                    frameR = cv2.flip(frameR, 1)

                # ğŸš€ ì´ˆê³ ì† ìŠ¤í‹°ì¹­ ì²˜ë¦¬ (ëª¨ë“  ìµœì í™” ì ìš©)
                stitched = self.stitch_frame_pair_ultra_optimized(frameL, frameR)
                
                # ë””ìŠ¤í”Œë ˆì´ ìŠ¤ì¼€ì¼ ì ìš© (í™”ë©´ í‘œì‹œìš©) - ì™„ì „ í•˜ë“œì½”ë”©
                if DISPLAY_SCALE != 1.0:
                    # ì²« í”„ë ˆì„ì—ì„œë§Œ í¬ê¸° ê³„ì‚° (ìºì‹±) - í•˜ë“œì½”ë”©
                    if not hasattr(self, '_display_width') or not hasattr(self, '_display_height'):
                        self._display_width = int(stitched.shape[1] * DISPLAY_SCALE)
                        self._display_height = int(stitched.shape[0] * DISPLAY_SCALE)
                        print(f"ğŸ”§ ë””ìŠ¤í”Œë ˆì´ í¬ê¸° ìºì‹œ: {self._display_width}x{self._display_height}")
                    
                    # í•˜ë“œì½”ë”©ëœ í¬ê¸° ì‚¬ìš©
                    stitched_display = cv2.resize(stitched, (self._display_width, self._display_height), 
                                                interpolation=cv2.INTER_LINEAR)
                else:
                    stitched_display = stitched
            
                # ğŸš€ ìµœì í™”ëœ FPS ê³„ì‚°
                self.update_fps()
                
                # FPS í‘œì‹œ
                fps_text = f"FPS: {self.current_fps:.1f}"
                cv2.putText(stitched_display, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # ê±°ìš¸ëª¨ë“œ ìƒíƒœ í‘œì‹œ
                mirror_text = f"Mirror: {'ON' if mirror_mode else 'OFF'}"
                cv2.putText(stitched_display, mirror_text, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
                
                # í”„ë ˆì„ ë²ˆí˜¸ í‘œì‹œ
                frame_text = f"Frame: {frame_count}"
                cv2.putText(stitched_display, frame_text, (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)
            
                # ì¤‘ì²© ì˜ì—­ í’ˆì§ˆ í™•ì¸ (ì²« í”„ë ˆì„ì—ì„œë§Œ)
                if frame_count == 0:
                    if hasattr(self, 'left_blend_mask') and hasattr(self, 'right_blend_mask'):
                        overlap_quality = np.sum((self.left_blend_mask > 0) & (self.right_blend_mask > 0))
                        print(f"   ğŸ“Š ì¤‘ì²© ì˜ì—­ í’ˆì§ˆ: {overlap_quality} í”½ì…€")
                        print(f"   ğŸ¯ ë¸”ë Œë”© ë§ˆìŠ¤í¬ ì ìš© ì™„ë£Œ")
                
                # ê²°ê³¼ í‘œì‹œ (ìŠ¤ì¼€ì¼ëœ ì´ë¯¸ì§€)
                cv2.imshow('Optimized Real-time Stitching', stitched_display)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("ğŸ’¡ 'q' í‚¤ ì…ë ¥ìœ¼ë¡œ ì¢…ë£Œ")
                    break
                elif key == ord('m'):
                    mirror_mode = not mirror_mode
                    print(f"ğŸ”„ ê±°ìš¸ëª¨ë“œ: {'í™œì„±í™”' if mirror_mode else 'ë¹„í™œì„±í™”'}")
                    
                    # ê±°ìš¸ëª¨ë“œ ì „í™˜ (ì´ë¯¸ì§€ ì¢Œìš° ë°˜ì „ë§Œ)
                    self.switch_to_mirror_mode(mirror_mode)
                
                frame_count += 1
                
        except KeyboardInterrupt:
            print("\nğŸ’¡ Ctrl+Cë¡œ ì¢…ë£Œ")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            # ì •ë¦¬
            if self.cap_left:
                self.cap_left.release()
            if self.cap_right:
                self.cap_right.release()
            cv2.destroyAllWindows()
            print("âœ… ì •ë¦¬ ì™„ë£Œ")

    def _apply_ultra_optimizations(self):
        """ğŸš€ ëª¨ë“  ì´ˆê³ ì† ìµœì í™”ë¥¼ í•œ ë²ˆì— ì ìš©"""
        print("ğŸš€ ì´ˆê³ ì† ìµœì í™” ì ìš© ì¤‘...")
        
        # 1. ìº”ë²„ìŠ¤ í…œí”Œë¦¿ ë¯¸ë¦¬ ìƒì„± (ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”)
        self.canvas_template = np.zeros((self.canvas_size[1], self.canvas_size[0], 3), dtype=np.uint8)
        
        # 2. ìŠ¬ë¼ì´ìŠ¤ ì¸ë±ìŠ¤ ì‚¬ì „ ê³„ì‚° (ì¸ë±ì‹± ìµœì í™”)
        self.left_slice_y = slice(self.left_offset[1], self.left_offset[1] + self.camera_resolution[1])
        self.left_slice_x = slice(self.left_offset[0], self.left_offset[0] + self.camera_resolution[0])
        
        # 3. ë Œì¦ˆ ë³´ì • í•¨ìˆ˜ ì‚¬ì „ ì„¤ì • (ì¡°ê±´ë¬¸ ì œê±°) - ë” í•˜ë“œì½”ë”©
        # lambda ëŒ€ì‹  ì§ì ‘ í•¨ìˆ˜ ì •ì˜ë¡œ ì„±ëŠ¥ í–¥ìƒ
        def rectify_left_hardcoded(img):
            return cv2.remap(img, self.map_left_x, self.map_left_y,
                           cv2.INTER_LINEAR, cv2.BORDER_CONSTANT, 0)
        
        def rectify_right_hardcoded(img):
            return cv2.remap(img, self.map_right_x, self.map_right_y,
                           cv2.INTER_LINEAR, cv2.BORDER_CONSTANT, 0)
        
        self.rectify_left = rectify_left_hardcoded
        self.rectify_right = rectify_right_hardcoded
        
        # 4. ë¸”ë Œë”© ë§ˆìŠ¤í¬ ìµœì¢… í¬ê¸°ë¡œ ë¯¸ë¦¬ ë¦¬ì‚¬ì´ì¦ˆ (ë§ˆìŠ¤í¬ ì²˜ë¦¬ ìµœì í™”)
        if self.use_precomputed_blending:
            self.left_mask_final = cv2.resize(
                self.left_blend_mask, 
                self.canvas_size, 
                interpolation=cv2.INTER_LINEAR
            ).astype(np.float32)
            
            self.right_mask_final = cv2.resize(
                self.right_blend_mask, 
                self.canvas_size, 
                interpolation=cv2.INTER_LINEAR
            ).astype(np.float32)
            
            # 3ì±„ë„ ë§ˆìŠ¤í¬ë„ ë¯¸ë¦¬ ìƒì„±
            self.left_mask_3ch = np.stack([self.left_mask_final] * 3, axis=-1)
            self.right_mask_3ch = np.stack([self.right_mask_final] * 3, axis=-1)
            
            print(f"âœ… ë¸”ë Œë”© ë§ˆìŠ¤í¬ ì‚¬ì „ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {self.left_mask_3ch.shape}")
        
        # 5. í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ ìµœì í™” (ë” í•˜ë“œì½”ë”©)
        self.homography_matrix_opt = self.homography_matrix.astype(np.float32)  # float32ë¡œ ê³ ì •
        
        # 6. ìº”ë²„ìŠ¤ í¬ê¸° í•˜ë“œì½”ë”© (íŠœí”Œ ëŒ€ì‹  ì •ìˆ˜)
        self.canvas_width = int(self.canvas_size[0])
        self.canvas_height = int(self.canvas_size[1])
        
        # 7. ì™¼ìª½ ì˜¤í”„ì…‹ í•˜ë“œì½”ë”©
        self.left_offset_x = int(self.left_offset[0])
        self.left_offset_y = int(self.left_offset[1])
        
        # 8. ì¹´ë©”ë¼ í•´ìƒë„ í•˜ë“œì½”ë”©
        self.camera_width = int(self.camera_resolution[0])
        self.camera_height = int(self.camera_resolution[1])

        print("ğŸš€ ì´ˆê³ ì† ìµœì í™” ì™„ë£Œ! ì˜ˆìƒ FPS í–¥ìƒ: 150-250%")

    def stitch_frame_pair_ultra_optimized(self, left_frame: np.ndarray, right_frame: np.ndarray) -> np.ndarray:
        """ğŸš€ ì´ˆê³ ì† í”„ë ˆì„ ìŠ¤í‹°ì¹­ (ì™„ì „ í•˜ë“œì½”ë”© ë²„ì „)"""
        
        # 1ë‹¨ê³„: ì‚¬ì „ ì„¤ì •ëœ í•¨ìˆ˜ë¡œ ë Œì¦ˆ ë³´ì • (ì¡°ê±´ë¬¸ ì—†ìŒ)
        left_rectified = self.rectify_left(left_frame)
        right_rectified = self.rectify_right(right_frame)
        
        # 2ë‹¨ê³„: ìºì‹œëœ ìº”ë²„ìŠ¤ ì‚¬ìš© (ë©”ëª¨ë¦¬ í• ë‹¹ ì—†ìŒ) - í•˜ë“œì½”ë”©ëœ ì¸ë±ìŠ¤ ì‚¬ìš©
        canvas = self.canvas_template.copy()
        canvas[self.left_offset_y:self.left_offset_y + self.camera_height, 
               self.left_offset_x:self.left_offset_x + self.camera_width] = left_rectified
        
        # 3ë‹¨ê³„: í˜¸ëª¨ê·¸ë˜í”¼ ë³€í™˜ (í•˜ë“œì½”ë”©ëœ í–‰ë ¬ê³¼ í¬ê¸° ì‚¬ìš©)
        warped_right = cv2.warpPerspective(right_rectified, self.homography_matrix_opt, 
                                       (self.canvas_width, self.canvas_height), flags=cv2.INTER_LINEAR)
        
        # 4ë‹¨ê³„: ì´ˆê³ ì† ë¸”ë Œë”© (ì‚¬ì „ ì¤€ë¹„ëœ ë§ˆìŠ¤í¬ ì‚¬ìš©)
        final_image = self._blend_images_ultra_fast(canvas, warped_right)
        
        return final_image.astype(np.uint8)


if __name__ == "__main__":
# ğŸš€ ì´ˆê³ ì† ìµœì í™”ëœ ì‹¤ì‹œê°„ ìŠ¤í‹°ì¹­ ì‹¤í–‰
    print("ğŸš€ Ultra-Fast Video Stitcher v2.0 ì‹œì‘")
    print("ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: 10 FPS â†’ 25-35 FPS (150-250% í–¥ìƒ)")
    
    stitcher = UltraFastVideoStitcher("./data/config/homography_params.json")
    
    # ì¹´ë©”ë¼ ì„¤ì •
    if not stitcher.setup_cameras():
        print("âŒ ì¹´ë©”ë¼ ì„¤ì • ì‹¤íŒ¨")
        exit(1)
    
    stitcher.show_stitched_video_optimized()
