import cv2
import numpy as np
import os
import json


CHESSBOARD_SIZE = (3, 9)      # ì²´í¬ë³´ë“œ í¬ê¸° (ê°€ë¡œ, ì„¸ë¡œ) - ë‚´ë¶€ ì½”ë„ˆ ê°œìˆ˜

# ========================================
# ì¹´ë©”ë¼ ì¸ë±ìŠ¤ ì„¤ì • (Camera_1.pyì™€ ë™ì¼)
# ========================================
LEFT_CAMERA_INDEX = 2         # ì™¼ìª½ ì¹´ë©”ë¼
CENTER_CAMERA_INDEX = 1       # ì¤‘ì•™ ì¹´ë©”ë¼
RIGHT_CAMERA_INDEX = 0        # ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼

# ========================================
# ë””ìŠ¤í”Œë ˆì´ ì„¤ì • (Realtime_Video_4.pyì™€ ë™ì¼)
# ========================================
DISPLAY_SCALE = 0.5          # í™”ë©´ í‘œì‹œìš© ìŠ¤ì¼€ì¼ (0.5 = 50% í¬ê¸°, 1.0 = 100% í¬ê¸°)

def load_calibration_config(config_file):
    """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"\nğŸ“ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì • ë¡œë“œ: {config_file}")
    
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°
    left_mtx = np.array(config['left_camera']['intrinsic_matrix'])
    left_dist = np.array(config['left_camera']['distortion_coefficients'])
    right_mtx = np.array(config['right_camera']['intrinsic_matrix'])
    right_dist = np.array(config['right_camera']['distortion_coefficients'])
    
    # ìŠ¤í…Œë ˆì˜¤ ê´€ê³„
    R = np.array(config['stereo_calibration']['rotation_matrix'])
    T = np.array(config['stereo_calibration']['translation_vector'])
    
    # ì •ë ¬ ë§µ ë¡œë“œ
    config_dir = os.path.dirname(config_file)
    pair_name = config['pair_name']
    maps_file = os.path.join(config_dir, f"{pair_name}_rectification_maps.npz")
    
    if os.path.exists(maps_file):
        maps_data = np.load(maps_file)
        left_map1_x = np.array(maps_data['left_map1_x'], dtype=np.float32)
        right_map1_x = np.array(maps_data['right_map1_x'], dtype=np.float32)
        print(f"   âœ… ì •ë ¬ ë§µ ë¡œë“œ ì„±ê³µ")
    else:
        raise FileNotFoundError(f"ì •ë ¬ ë§µ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {maps_file}")
    
    return {
        'left_mtx': left_mtx, 'left_dist': left_dist,
        'right_mtx': right_mtx, 'right_dist': right_dist,
        'R': R, 'T': T,
        'left_map1_x': left_map1_x, 'right_map1_x': right_map1_x
    }

def apply_rectification_maps(left_img, right_img, config_LC, config_CR):
    """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì •ë ¬í•©ë‹ˆë‹¤."""
    print(f"\nğŸ”„ ì´ë¯¸ì§€ ì •ë ¬ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë§µ ì ìš©)")
    
    # LCì˜ Left ì¹´ë©”ë¼ ì •ë ¬ ë§µ ì‚¬ìš©
    left_rectified = cv2.remap(left_img, config_LC['left_map1_x'], None, 
                               cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)
    
    # CRì˜ Right ì¹´ë©”ë¼ ì •ë ¬ ë§µ ì‚¬ìš©
    right_rectified = cv2.remap(right_img, config_CR['right_map1_x'], None, 
                                cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)
    
    print(f"   âœ… ì´ë¯¸ì§€ ì •ë ¬ ì™„ë£Œ")
    return left_rectified, right_rectified

# Helper functions from Stitching_Engine_3.py
def preprocess_image_for_chessboard(gray):
    """ì²´ì»¤ë³´ë“œ ê²€ì¶œì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (Calibration_2.pyì™€ ë™ì¼í•œ ê°•í™”ëœ ë°©ì‹)"""
    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¡œ ëŒ€ë¹„ í–¥ìƒ
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(blurred)
    
    # ì¶”ê°€ í•„í„°ë§ ì˜µì…˜ë“¤
    gaussian_3x3 = cv2.GaussianBlur(gray, (3, 3), 0)
    median_5 = cv2.medianBlur(gray, 5)
    
    # ì´ì§„í™” (ì ì‘ì  ì„ê³„ê°’)
    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                  cv2.THRESH_BINARY, 11, 2)
    
    return enhanced, binary, gaussian_3x3, median_5

def validate_chessboard_corners(corners, pattern_size, gray):
    """ê²€ì¶œëœ ì½”ë„ˆì˜ ìœ íš¨ì„± ê²€ì¦"""
    cols, rows = pattern_size
    
    if corners is None or len(corners) != cols * rows:
        return False
    
    # ì½”ë„ˆ ê°„ê²© ì¼ê´€ì„± ê²€ì‚¬
    corners_reshaped = corners.reshape(rows, cols, 2)
    
    # ìˆ˜í‰ ê°„ê²© ê²€ì‚¬
    for row in range(rows):
        for col in range(1, cols):
            dist = np.linalg.norm(corners_reshaped[row, col] - corners_reshaped[row, col-1])
            if dist < 10:  # ìµœì†Œ ê°„ê²©
                return False
    
    # ìˆ˜ì§ ê°„ê²© ê²€ì‚¬
    for col in range(cols):
        for row in range(1, rows):
            dist = np.linalg.norm(corners_reshaped[row, col] - corners_reshaped[row-1, col])
            if dist < 10:  # ìµœì†Œ ê°„ê²©
                return False
    
    return True

def detect_chessboard_multiscale(gray, pattern_size, max_attempts=3):
    """ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ì—ì„œ ì²´ì»¤ë³´ë“œ ê²€ì¶œ ì‹œë„ (Calibration_2.pyì™€ ë™ì¼í•œ ê°•í™”ëœ ë°©ì‹)"""
    # Calibration_2.pyì™€ ë™ì¼í•œ ìŠ¤ì¼€ì¼ ì‹œë„
    scales = [0.5, 0.75, 1.5, 2.0]
    
    for scale in scales:
        if scale != 1.0:
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            h, w = gray.shape
            new_h, new_w = int(h * scale), int(w * scale)
            resized = cv2.resize(gray, (new_w, new_h))
            
            # ê²€ì¶œ ì‹œë„
            ret, corners = cv2.findChessboardCorners(resized, pattern_size, 
                                                    cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE)
            if ret:
                # ì›ë³¸ í¬ê¸°ë¡œ ì¢Œí‘œ ë³€í™˜
                corners = corners / scale
                print(f"           âœ… í¬ê¸° ì¡°ì • {scale}x ì„±ê³µ: {len(corners)}ê°œ")
                return True, corners
    
    print(f"           âŒ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ ì‹¤íŒ¨")
    return False, None

def save_debug_images(gray, enhanced, binary, gaussian_3x3, median_5, img_name, pattern_size):
    """ë””ë²„ê¹…ì„ ìœ„í•œ ì´ë¯¸ì§€ ì €ì¥ (Calibration_2.pyì™€ ë™ì¼í•œ ê°•í™”ëœ ë°©ì‹)"""
    debug_dir = './data/debug_images'
    os.makedirs(debug_dir, exist_ok=True)
    
    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
    cv2.imwrite(os.path.join(debug_dir, f'{img_name}_original.png'), gray)
    
    # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë“¤ ì €ì¥
    cv2.imwrite(os.path.join(debug_dir, f'{img_name}_enhanced.png'), enhanced)
    cv2.imwrite(os.path.join(debug_dir, f'{img_name}_binary.png'), binary)
    cv2.imwrite(os.path.join(debug_dir, f'{img_name}_gaussian_3x3.png'), gaussian_3x3)
    cv2.imwrite(os.path.join(debug_dir, f'{img_name}_median_5.png'), median_5)
    
    # ì²´ì»¤ë³´ë“œ íŒ¨í„´ ì •ë³´ ì €ì¥
    with open(os.path.join(debug_dir, f'{img_name}_pattern_info.txt'), 'w') as f:
        f.write(f"Pattern Size: {pattern_size}\n")
        f.write(f"Image Shape: {gray.shape}\n")
        f.write(f"Image Type: {gray.dtype}\n")
        f.write(f"Enhanced: blurred + CLAHE\n")
        f.write(f"Gaussian 3x3: ë…¸ì´ì¦ˆ ì œê±°\n")
        f.write(f"Median 5: ë…¸ì´ì¦ˆ ì œê±°\n")
    
    print(f"         ğŸ’¾ ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥: {debug_dir}")

def detect_chessboard_corners_simple(gray, img_name, pattern_size):
    """Stitching_Engine_3.pyì™€ ì™„ì „íˆ ë™ì¼í•œ ì²´í¬ë³´ë“œ ê²€ì¶œ (fallback ì œì™¸)"""
    base_cols, base_rows = int(pattern_size[0]), int(pattern_size[1])
    print(f"       ğŸ” OpenCV ì²´í¬ë³´ë“œ ì½”ë„ˆ ê²€ì¶œ ì‹œì‘... (ìš”ì²­: {base_cols}x{base_rows})")

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (Calibration_2.pyì™€ ë™ì¼í•œ ê°•í™”ëœ ë°©ì‹)
    print(f"         ğŸ¨ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
    enhanced, binary, gaussian_3x3, median_5 = preprocess_image_for_chessboard(gray)
    
    # Calibration_2.pyì™€ ë™ì¼í•œ ê°•í™”ëœ ê²€ì¶œ í”Œë˜ê·¸ ì¡°í•©
    flags_combinations = [
        cv2.CALIB_CB_ADAPTIVE_THRESH,
        cv2.CALIB_CB_NORMALIZE_IMAGE,
        cv2.CALIB_CB_FAST_CHECK,
        cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE,
        cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK,
        cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK,
        cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK
    ]

    # 0) ì˜¤ë²„ë© ê°€ì¥ìë¦¬ ROI ìš°ì„  ì‹œë„ (ì²´ì»¤ë³´ë“œê°€ ì‘ì•„ì¡Œì„ ë•Œ ë³´ì´ëŠ” ê°€ì¥ìë¦¬ë§Œ í™•ëŒ€ íƒìƒ‰)
    h, w = gray.shape
    side = 'left' if 'ì™¼ìª½' in str(img_name) else 'right'
    roi_width = max(100, int(w * 0.18))
    if side == 'left':
        roi = gray[:, :roi_width]
        roi_x0 = 0
    else:
        roi = gray[:, w - roi_width:]
        roi_x0 = w - roi_width

    # ROI ì—…ìŠ¤ì¼€ì¼ íƒìƒ‰ (ì‘ì€ ë³´ë“œ ëŒ€ì‘)
    upscale_scales = [1.5, 2.0, 2.5, 3.0, 3.5]
    # ROI ì „ì²˜ë¦¬(ë¸”ëŸ¬+CLAHE)
    roi_blurred = cv2.GaussianBlur(roi, (5, 5), 0)
    roi_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(roi_blurred)
    for scale in upscale_scales:
        roi_src = roi_clahe
        roi_resized = cv2.resize(roi_src, (int(roi_src.shape[1] * scale), int(roi_src.shape[0] * scale)))

        # 0) SB ë¨¼ì € ì‹œë„ (ê°•ê²€ì¶œ)
        sb_flags_list = [
            0,
            cv2.CALIB_CB_NORMALIZE_IMAGE,
            cv2.CALIB_CB_EXHAUSTIVE if hasattr(cv2, 'CALIB_CB_EXHAUSTIVE') else 0,
            (cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_EXHAUSTIVE) if hasattr(cv2, 'CALIB_CB_EXHAUSTIVE') else cv2.CALIB_CB_NORMALIZE_IMAGE,
            cv2.CALIB_CB_ACCURACY if hasattr(cv2, 'CALIB_CB_ACCURACY') else 0
        ]
        found = False
        corners_roi = None
        for sbf in sb_flags_list:
            if sbf == 0 and sb_flags_list.count(0) > 1:
                pass
            try:
                ret_roi, c = cv2.findChessboardCornersSB(roi_resized, (base_cols, base_rows), flags=sbf)
            except Exception:
                ret_roi, c = False, None
            if ret_roi:
                corners_roi = c
                found = True
                break

        # 1) í‘œì¤€ìœ¼ë¡œë„ ì‹œë„
        if not found:
            for flg in flags_combinations:
                ret_roi, c = cv2.findChessboardCorners(roi_resized, (base_cols, base_rows), flg)
                if ret_roi:
                    corners_roi = c
                    found = True
                    break

        if found and corners_roi is not None:
            # ì›ë³¸ ì¢Œí‘œë¡œ ë³µì›
            corners_roi = corners_roi / scale
            corners_roi[:, 0, 0] += roi_x0
            # ì„œë¸Œí”½ì…€ ì •ë°€ë„ í–¥ìƒ
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 0.0001)
            corners_roi = cv2.cornerSubPix(gray, corners_roi, (15, 15), (-1, -1), criteria)

            if validate_chessboard_corners(corners_roi, (base_cols, base_rows), gray):
                corners_xy = corners_roi.reshape(-1, 2)
                corners_grid = corners_xy.reshape(base_rows, base_cols, 2)
                col_means_x = [float(np.mean(corners_grid[:, j, 0])) for j in range(base_cols)]
                if 'ì™¼ìª½' in str(img_name):
                    col_index = int(np.argmax(col_means_x))
                elif 'ì˜¤ë¥¸ìª½' in str(img_name):
                    col_index = int(np.argmin(col_means_x))
                else:
                    col_index = int(np.argmin(col_means_x))
                indices = [r * base_cols + col_index for r in range(base_rows)]
                selected_corners = corners_xy[indices]
                order = np.argsort(selected_corners[:, 1])
                selected_corners = selected_corners[order]
                print(f"           âœ… ROI ì—…ìŠ¤ì¼€ì¼({scale:.1f}x) ê²€ì¶œ ì„±ê³µ - {img_name}")
                return selected_corners

    # colsë§Œ ì¤„ì—¬ê°€ë©° ì¬ì‹œë„ (rowsëŠ” ê³ ì •)
    for cols in range(base_cols, 2, -1):  # OpenCV ì¡°ê±´: cols, rows > 2
        rows = base_rows
        print(f"         ğŸ” ì‹œë„: {cols}x{rows} (cols ê°ì†Œ ì¬ì‹œë„)")
        
        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ ì‹œë„
        print(f"           ğŸ” ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ ì‹œë„ ì¤‘...")
        multiscale_ret, multiscale_corners = detect_chessboard_multiscale(gray, (cols, rows))
        if multiscale_ret:
            print(f"           âœ… ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ ì„±ê³µ!")
            # ì½”ë„ˆ ê²€ì¦ ë° ì²˜ë¦¬
            # ì„œë¸Œí”½ì…€ ì •ë°€ë„ í–¥ìƒ
            try:
                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 0.0001)
                multiscale_corners = cv2.cornerSubPix(gray, multiscale_corners, (15, 15), (-1, -1), criteria)
            except Exception:
                pass
            if validate_chessboard_corners(multiscale_corners, (cols, rows), gray):
                corners_xy = multiscale_corners.reshape(-1, 2)
                # ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì—´ ì„ íƒ (3.pyì™€ ë™ì¼ ë¡œì§)
                corners_grid = corners_xy.reshape(rows, cols, 2)
                col_means_x = [float(np.mean(corners_grid[:, j, 0])) for j in range(cols)]
                if 'ì™¼ìª½' in str(img_name):
                    col_index = int(np.argmax(col_means_x))  # ì™¼ìª½: ì‹¤ì œ ê°€ì¥ ì˜¤ë¥¸ìª½ ì—´
                elif 'ì˜¤ë¥¸ìª½' in str(img_name):
                    col_index = int(np.argmin(col_means_x))  # ì˜¤ë¥¸ìª½: ì‹¤ì œ ê°€ì¥ ì™¼ìª½ ì—´
                else:
                    col_index = int(np.argmin(col_means_x))

                indices = [r * cols + col_index for r in range(rows)]
                selected_corners = corners_xy[indices]
                # í–‰ ì •ë ¬ í‘œì¤€í™”: y ì˜¤ë¦„ì°¨ìˆœ(ìœ„â†’ì•„ë˜)
                order = np.argsort(selected_corners[:, 1])
                selected_corners = selected_corners[order]
                
                # ğŸ” ë””ë²„ê¹…: ì„ íƒëœ ì½”ë„ˆë“¤ì˜ X ì¢Œí‘œ ì¶œë ¥
                print(f"           âœ… {img_name}: ì—´ {col_index} ì„ íƒ, {len(selected_corners)}ê°œ ì½”ë„ˆ ì¶”ì¶œ (ë‹¤ì¤‘ ìŠ¤ì¼€ì¼)")
                print(f"           ğŸ“ ì„ íƒëœ ì½”ë„ˆ Xì¢Œí‘œ: {[f'{corner[0]:.1f}' for corner in selected_corners]}")
                print(f"           ğŸ“ ì „ì²´ ì½”ë„ˆ Xì¢Œí‘œ ë²”ìœ„: {corners_xy[:, 0].min():.1f} ~ {corners_xy[:, 0].max():.1f}")
                return selected_corners
            else:
                print(f"           âš ï¸ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨")
        else:
            print(f"           â„¹ï¸ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ ì‹¤íŒ¨, í‘œì¤€ ë°©ë²•ìœ¼ë¡œ ì§„í–‰")

        # 1) SB ì•Œê³ ë¦¬ì¦˜ ìš°ì„  ì‹œë„ (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©)
        try:
            sb_flags_list = [
                0,
                cv2.CALIB_CB_NORMALIZE_IMAGE,
                cv2.CALIB_CB_EXHAUSTIVE if hasattr(cv2, 'CALIB_CB_EXHAUSTIVE') else 0,
                (cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_EXHAUSTIVE) if hasattr(cv2, 'CALIB_CB_EXHAUSTIVE') else cv2.CALIB_CB_NORMALIZE_IMAGE,
                cv2.CALIB_CB_ACCURACY if hasattr(cv2, 'CALIB_CB_ACCURACY') else 0
            ]
            for sb_flags in sb_flags_list:
                if sb_flags == 0 and sb_flags_list.count(0) > 1:
                    # ì¤‘ë³µ 0 ì œê±° ëª©ì ì˜ continue
                    pass
                print(f"           ğŸ“ SB ì‹œë„ (flags={sb_flags})")
                
                # Calibration_2.pyì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë“¤ë¡œ ê²€ì¶œ ì‹œë„
                detection_methods = [
                    ("ê¸°ë³¸", gray),
                    ("ë¸”ëŸ¬", enhanced),  # enhancedëŠ” ì´ë¯¸ blurred + CLAHE
                    ("ëŒ€ë¹„í–¥ìƒ", enhanced),
                    ("ê°€ìš°ì‹œì•ˆ", gaussian_3x3),
                    ("ì¤‘ê°„ê°’í•„í„°", median_5)
                ]
                
                for method_name, processed_img in detection_methods:
                    ret, corners = cv2.findChessboardCornersSB(processed_img, (cols, rows), flags=sb_flags)
                    if ret:
                        print(f"           âœ… SB ì„±ê³µ ({cols}x{rows}) - {method_name} ì´ë¯¸ì§€ ì‚¬ìš©")
                        
                        # ì½”ë„ˆ ì„œë¸Œí”½ì…€ ì •ë°€ë„ í–¥ìƒ (ë” ì •ë°€í•œ íŒŒë¼ë¯¸í„°)
                        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 0.0001)
                        corners = cv2.cornerSubPix(gray, corners, (15, 15), (-1, -1), criteria)
                        
                        # ì½”ë„ˆ ê²€ì¦
                        if validate_chessboard_corners(corners, (cols, rows), gray):
                            corners_xy = corners.reshape(-1, 2)
                            total_corners = corners_xy.shape[0]
                            expected_corners = cols * rows
                            
                            if total_corners >= expected_corners:
                                # ì¢Œí‘œ ê¸°ë°˜ ì—´ ì„ íƒ (3.pyì™€ ë™ì¼)
                                corners_grid = corners_xy.reshape(rows, cols, 2)
                                col_means_x = [float(np.mean(corners_grid[:, j, 0])) for j in range(cols)]
                                if 'ì™¼ìª½' in str(img_name):
                                    col_index = int(np.argmax(col_means_x))
                                elif 'ì˜¤ë¥¸ìª½' in str(img_name):
                                    col_index = int(np.argmin(col_means_x))
                                else:
                                    col_index = int(np.argmin(col_means_x))

                                indices = [r * cols + col_index for r in range(rows)]
                                selected_corners = corners_xy[indices]
                                # í–‰ ì •ë ¬ í‘œì¤€í™”
                                order = np.argsort(selected_corners[:, 1])
                                selected_corners = selected_corners[order]
                                
                                # ğŸ” ë””ë²„ê¹…: ì„ íƒëœ ì½”ë„ˆë“¤ì˜ X ì¢Œí‘œ ì¶œë ¥
                                print(f"           âœ… {img_name}: ì—´ {col_index} ì„ íƒ, {len(selected_corners)}ê°œ ì½”ë„ˆ ì¶”ì¶œ")
                                print(f"           ğŸ“ ì„ íƒëœ ì½”ë„ˆ Xì¢Œí‘œ: {[f'{corner[0]:.1f}' for corner in selected_corners]}")
                                print(f"           ğŸ“ ì „ì²´ ì½”ë„ˆ Xì¢Œí‘œ ë²”ìœ„: {corners_xy[:, 0].min():.1f} ~ {corners_xy[:, 0].max():.1f}")
                                return selected_corners
                            else:
                                print(f"           âš ï¸ {img_name}: ì½”ë„ˆ ê°œìˆ˜ ë¶€ì¡± ({total_corners}/{expected_corners})")
                        else:
                            print(f"           âš ï¸ {img_name}: ì½”ë„ˆ ê²€ì¦ ì‹¤íŒ¨")
                            continue
        except AttributeError:
            print(f"           â„¹ï¸ SB ì•Œê³ ë¦¬ì¦˜ ë¯¸ì§€ì›(OpenCV ë²„ì „)")
        except Exception as e:
            print(f"           âŒ SB ì˜¤ë¥˜: {e}")

        # 2) í‘œì¤€ ì•Œê³ ë¦¬ì¦˜ í”Œë˜ê·¸ ì¡°í•© ì‹œë„ (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë“¤ë¡œ)
        for i, flags in enumerate(flags_combinations):
            print(f"           ğŸ“ ë°©ë²• {i+1} ì‹œë„ ì¤‘... (í”Œë˜ê·¸: {flags})")

            # Calibration_2.pyì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë“¤ë¡œ ê²€ì¶œ ì‹œë„
            detection_methods = [
                ("ê¸°ë³¸", gray),
                ("ë¸”ëŸ¬", enhanced),  # enhancedëŠ” ì´ë¯¸ blurred + CLAHE
                ("ëŒ€ë¹„í–¥ìƒ", enhanced),
                ("ê°€ìš°ì‹œì•ˆ", gaussian_3x3),
                ("ì¤‘ê°„ê°’í•„í„°", median_5)
            ]
            
            for method_name, processed_img in detection_methods:
                try:
                    ret, corners = cv2.findChessboardCorners(processed_img, (cols, rows), flags=flags)

                    if ret:
                        print(f"           âœ… {img_name}: ì²´í¬ë³´ë“œ ê²€ì¶œ ì„±ê³µ ({cols}x{rows}) - {method_name} ì´ë¯¸ì§€ ì‚¬ìš©!")

                        # ì½”ë„ˆ ì„œë¸Œí”½ì…€ ì •ë°€ë„ í–¥ìƒ (ë” ì •ë°€í•œ íŒŒë¼ë¯¸í„°)
                        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 0.0001)
                        corners = cv2.cornerSubPix(gray, corners, (15, 15), (-1, -1), criteria)

                        # ì½”ë„ˆ ê²€ì¦
                        if validate_chessboard_corners(corners, (cols, rows), gray):
                            # Nx1x2 -> Nx2
                            corners_xy = corners.reshape(-1, 2)

                            total_corners = corners_xy.shape[0]
                            expected_corners = cols * rows

                            if total_corners >= expected_corners:
                                # ì¢Œí‘œ ê¸°ë°˜ ì—´ ì„ íƒ (3.pyì™€ ë™ì¼)
                                corners_grid = corners_xy.reshape(rows, cols, 2)
                                col_means_x = [float(np.mean(corners_grid[:, j, 0])) for j in range(cols)]
                                if 'ì™¼ìª½' in str(img_name):
                                    col_index = int(np.argmax(col_means_x))
                                elif 'ì˜¤ë¥¸ìª½' in str(img_name):
                                    col_index = int(np.argmin(col_means_x))
                                else:
                                    col_index = int(np.argmin(col_means_x))

                                indices = [r * cols + col_index for r in range(rows)]
                                selected_corners = corners_xy[indices]
                                # í–‰ ì •ë ¬ í‘œì¤€í™”
                                order = np.argsort(selected_corners[:, 1])
                                selected_corners = selected_corners[order]
                                
                                # ğŸ” ë””ë²„ê¹…: ì„ íƒëœ ì½”ë„ˆë“¤ì˜ X ì¢Œí‘œ ì¶œë ¥
                                print(f"           âœ… {img_name}: ì—´ {col_index} ì„ íƒ, {len(selected_corners)}ê°œ ì½”ë„ˆ ì¶”ì¶œ")
                                print(f"           ğŸ“ ì„ íƒëœ ì½”ë„ˆ Xì¢Œí‘œ: {[f'{corner[0]:.1f}' for corner in selected_corners]}")
                                print(f"           ğŸ“ ì „ì²´ ì½”ë„ˆ Xì¢Œí‘œ ë²”ìœ„: {corners_xy[:, 0].min():.1f} ~ {corners_xy[:, 0].max():.1f}")
                                return selected_corners
                            else:
                                print(f"           âš ï¸ {img_name}: ì½”ë„ˆ ê°œìˆ˜ ë¶€ì¡± ({total_corners}/{expected_corners})")
                                # ì´ ê²½ìš°ë„ ë‹¤ìŒ colsë¡œ ì¬ì‹œë„
                        else:
                            print(f"           âš ï¸ {img_name}: ì½”ë„ˆ ê²€ì¦ ì‹¤íŒ¨")
                            continue
                    else:
                        print(f"           âŒ {img_name}: ë°©ë²• {i+1} ì‹¤íŒ¨ ({method_name} ì´ë¯¸ì§€)")

                except Exception as e:
                    print(f"           âŒ {img_name}: ë°©ë²• {i+1} ì˜¤ë¥˜ - {e}")
                    continue

    print(f"       âŒ {img_name}: ëª¨ë“  cols ê°ì†Œ ì¬ì‹œë„ ì‹¤íŒ¨ (ìµœì¢… {base_cols}â†’3)")
    return None

def detect_overlap_features(rectified_left, rectified_right, pattern_size=(1, 9)):
    """ì •ë ¬ëœ ì´ë¯¸ì§€ì—ì„œ ì¤‘ì²© ì˜ì—­ì˜ ì²´í¬ë³´ë“œ ì½”ë„ˆë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤."""
    print(f"\nğŸ¯ ì¤‘ì²© ì˜ì—­ ì²´í¬ë³´ë“œ ì½”ë„ˆ ê²€ì¶œ")
    print(f"   ğŸ’¡ ì™¼ìª½ ì´ë¯¸ì§€: 4Ã—9 íŒ¨í„´, ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€: 4Ã—9 íŒ¨í„´ (ë™ì¼í•œ íŒ¨í„´ í¬ê¸°)")
    print(f"   ì™¼ìª½ ì´ë¯¸ì§€ í¬ê¸°: {rectified_left.shape}")
    print(f"   ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ í¬ê¸°: {rectified_right.shape}")
    print(f"   ğŸ’¡ ì¤‘ì²© ì˜ì—­: chessboard in overlap area")
    
    def extract_overlap_corners(img, img_name, specific_pattern_size):
        """ì´ë¯¸ì§€ì—ì„œ ì¤‘ì²© ì˜ì—­ì˜ ì²´í¬ë³´ë“œ ì½”ë„ˆ ì¶”ì¶œ"""
        print(f"   ğŸ” {img_name} ì´ë¯¸ì§€ ì¤‘ì²© ì˜ì—­ ì½”ë„ˆ ì¶”ì¶œ ì‹œì‘...")
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img
        
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ (OpenCVëŠ” height, width ìˆœì„œ)
        h, w = gray.shape
        print(f"     ì´ë¯¸ì§€ í¬ê¸°: {w} x {h} (width x height)")
        
        # ì²´í¬ë³´ë“œ OpenCV í‘œì¤€ ê²€ì¶œ (ê° ì´ë¯¸ì§€ë³„ íŒ¨í„´ ì‚¬ìš©)
        print(f"     ğŸ” Chessboard detection start... ({specific_pattern_size[0]}x{specific_pattern_size[1]})")
        
        # OpenCV ì²´í¬ë³´ë“œ ê²€ì¶œ ì‚¬ìš©
        corners = detect_chessboard_corners_simple(gray, img_name, specific_pattern_size)
        if corners is not None:
            return corners
        
        print(f"     âŒ {img_name}: ì²´í¬ë³´ë“œ ê²€ì¶œ ì‹¤íŒ¨")
        return None
    
    # ì™¼ìª½ ì´ë¯¸ì§€ì—ì„œ ì¤‘ì²© ì˜ì—­ ì½”ë„ˆ ì¶”ì¶œ (4Ã—9 íŒ¨í„´)
    left_pattern_size = (4, 9)
    left_corners = extract_overlap_corners(rectified_left, "ì™¼ìª½", left_pattern_size)
    
    # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ì—ì„œ ì¤‘ì²© ì˜ì—­ ì½”ë„ˆ ì¶”ì¶œ (3Ã—9 íŒ¨í„´)
    right_pattern_size = (3, 9)
    right_corners = extract_overlap_corners(rectified_right, "ì˜¤ë¥¸ìª½", right_pattern_size)
    
    # ê²°ê³¼ í™•ì¸
    if left_corners is None or right_corners is None:
        print(f"   âŒ ì¤‘ì²© ì˜ì—­ ì½”ë„ˆ ì¶”ì¶œ ì‹¤íŒ¨")
        print(f"   ğŸ’¡ í•´ê²° ë°©ë²•:")
        print(f"     1. ì²´í¬ë³´ë“œê°€ ì •ë ¬ëœ ì´ë¯¸ì§€ì— ì™„ì „íˆ ë³´ì´ëŠ”ì§€ í™•ì¸")
        print(f"     2. ì²´í¬ë³´ë“œ í¬ê¸° í™•ì¸: ì™¼ìª½ 4Ã—9, ì˜¤ë¥¸ìª½ 4Ã—9")
        print(f"     3. ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ : ì„ ëª…í•˜ê²Œ, ì¶©ë¶„í•œ ì¡°ëª…ìœ¼ë¡œ")
        print(f"     4. ê°€ìš´ë° í™”ì‚´í‘œê°€ ìˆëŠ” ì¤‘ì²© ì˜ì—­ì´ ì–‘ìª½ ì´ë¯¸ì§€ì— ë³´ì´ëŠ”ì§€ í™•ì¸")
        return None, None
    
    print(f"   âœ… ì–‘ìª½ ì´ë¯¸ì§€ ëª¨ë‘ ì¤‘ì²© ì˜ì—­ ì½”ë„ˆ ì¶”ì¶œ ì„±ê³µ!")
    print(f"   ì™¼ìª½ (4Ã—9): {len(left_corners)}ê°œ ì ")
    print(f"   ì˜¤ë¥¸ìª½ (4Ã—9): {len(right_corners)}ê°œ ì ")
    print(f"   ğŸ’¡ ì¤‘ì²© ì˜ì—­ì˜ ê³µí†µ íŠ¹ì§•ì ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° ê°€ëŠ¥!")
    
    return left_corners, right_corners

def calculate_homography_from_overlap_corners(left_corners, right_corners, left_img=None, right_img=None):
    """ì¤‘ì²© ì˜ì—­ ì½”ë„ˆë¡œë¶€í„° í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    print(f"\nğŸ”— í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°")
    
    left_pts = np.float32(left_corners.reshape(-1, 2))
    right_pts = np.float32(right_corners.reshape(-1, 2))
    
    if len(left_pts) < 4 or len(right_pts) < 4:
        print(f"   âŒ íŠ¹ì§•ì ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 4ê°œ í•„ìš”)")
        return None
    
    try:
        # ìœ ì‚¬ë³€í™˜ ì¶”ì •
        A, inliers = cv2.estimateAffinePartial2D(
            right_pts, left_pts, 
            method=cv2.RANSAC, 
            ransacReprojThreshold=2.0,
            maxIters=2000,
            confidence=0.99
        )
        
        if A is not None:
            # ìˆ˜í‰ ì˜¤í”„ì…‹ ë³´ì •: ì˜ˆì¸¡ ì¢Œí‘œì™€ ì‹¤ì œ ì¢Œí‘œì˜ x-ì”ì°¨ì˜ ì¤‘ì•™ê°’ì„ txì— ë°˜ì˜
            try:
                pred = (right_pts @ A[:, :2].T) + A[:, 2]
                residuals = left_pts - pred
                median_dx = float(np.median(residuals[:, 0]))
                # tx ë³´ì •ë§Œ ìˆ˜í–‰ (ìˆ˜ì§ ì •í•©ì€ ì´ë¯¸ ì–‘í˜¸)
                A[0, 2] += median_dx
                print(f"   ğŸ”§ ìˆ˜í‰ ë°”ì´ì–´ìŠ¤ ë³´ì •: Î”tx={median_dx:.2f} px")
            except Exception:
                pass

            H = np.vstack([A, [0, 0, 1]]).astype(np.float64)
            print(f"   âœ… í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° ì„±ê³µ")
            return H, inliers
        else:
            # ë‹¨ìˆœ ì´ë™ìœ¼ë¡œ fallback
            deltas = left_pts - right_pts
            mean_delta = np.mean(deltas, axis=0)
            tx, ty = float(mean_delta[0]), float(mean_delta[1])
            H = np.array([[1.0, 0.0, tx], [0.0, 1.0, ty], [0.0, 0.0, 1.0]], dtype=np.float64)
            print(f"   â†”ï¸ Fallback ì´ë™ ë³€í™˜: (tx,ty)=({tx:.2f},{ty:.2f})")
            return H, None
            
    except Exception as e:
        print(f"   âŒ í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return None

def compute_canvas_with_translation(left_img, right_img, H):
    """ìº”ë²„ìŠ¤ í¬ê¸°ì™€ ì˜¤í”„ì…‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    h1, w1 = left_img.shape[:2]
    h2, w2 = right_img.shape[:2]

    # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ë„¤ ëª¨ì„œë¦¬ë¥¼ Hë¡œ ë³€í™˜
    corners = np.float32([[0, 0], [w2, 0], [w2, h2], [0, h2]]).reshape(-1, 1, 2)
    warped = cv2.perspectiveTransform(corners, H).reshape(-1, 2)

    # ì¢Œí‘œê³„ í†µí•©
    all_x = np.concatenate([np.array([0, w1]), warped[:, 0]])
    all_y = np.concatenate([np.array([0, h1]), warped[:, 1]])

    min_x, min_y = np.min(all_x), np.min(all_y)
    max_x, max_y = np.max(all_x), np.max(all_y)

    # ëª¨ë‘ ì–‘ìˆ˜ë¡œ ì´ë™ì‹œí‚¤ëŠ” translation
    tx = -min(0.0, float(min_x))
    ty = -min(0.0, float(min_y))

    T = np.array([[1.0, 0.0, tx], [0.0, 1.0, ty], [0.0, 0.0, 1.0]], dtype=np.float64)
    H_canvas = T @ H

    # ìº”ë²„ìŠ¤ í¬ê¸° ê³„ì‚°
    canvas_w = max(int(np.ceil(max_x + tx)), w1 + int(np.ceil(tx)))
    canvas_h = max(int(np.ceil(max_y + ty)), h1 + int(np.ceil(ty)))
    canvas_size = (canvas_w, canvas_h)

    left_offset = (int(np.floor(tx)), int(np.floor(ty)))
    
    print(f"   ìº”ë²„ìŠ¤ í¬ê¸°: {canvas_size}, ì™¼ìª½ ì˜¤í”„ì…‹: {left_offset}")
    return H_canvas, canvas_size, left_offset, 0

def create_blending_masks(left_img, right_img, H, canvas_size, left_offset=(0,0)):
    """ë¸”ë Œë”© ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    h, w = left_img.shape[:2]
    
    # ì™¼ìª½ ì´ë¯¸ì§€ë¥¼ ìº”ë²„ìŠ¤ì— ë°°ì¹˜
    left_canvas = np.zeros((canvas_size[1], canvas_size[0], 3), dtype=np.uint8)
    ox, oy = int(left_offset[0]), int(left_offset[1])
    left_canvas[oy:oy+h, ox:ox+w] = left_img
    
    # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ì—¬ ìº”ë²„ìŠ¤ì— ë°°ì¹˜
    right_transformed = cv2.warpPerspective(right_img, H, canvas_size)
    
    # ë¸”ë Œë”© ë§ˆìŠ¤í¬ ìƒì„±
    left_mask = (left_canvas.sum(axis=2) > 0).astype(np.float32)
    right_mask = (right_transformed.sum(axis=2) > 0).astype(np.float32)
    
    # ì¤‘ì²© ì˜ì—­ì—ì„œ ê°€ì¤‘ì¹˜ ì¡°ì •
    overlap = np.logical_and(left_mask > 0, right_mask > 0)
    left_blend_mask = left_mask.copy()
    right_blend_mask = right_mask.copy()
    
    # ì¤‘ì²© ì˜ì—­ì—ì„œëŠ” 0.5ì”© í• ë‹¹
    left_blend_mask[overlap] = 0.5
    right_blend_mask[overlap] = 0.5
    
    return left_blend_mask, right_blend_mask

def perform_stitching(left_img, right_img, H, canvas_size, left_offset, left_blend_mask, right_blend_mask):
    """ì´ë¯¸ì§€ë¥¼ ìŠ¤í‹°ì¹­í•©ë‹ˆë‹¤."""
    print(f"\nğŸ”— ì´ë¯¸ì§€ ìŠ¤í‹°ì¹­ ì‹¤í–‰")
    
    h, w = left_img.shape[:2]
    
    # ì™¼ìª½ ì´ë¯¸ì§€ë¥¼ ìº”ë²„ìŠ¤ì— ë°°ì¹˜
    left_canvas = np.zeros((canvas_size[1], canvas_size[0], 3), dtype=np.uint8)
    ox, oy = int(left_offset[0]), int(left_offset[1])
    left_canvas[oy:oy+h, ox:ox+w] = left_img
    
    # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ì—¬ ìº”ë²„ìŠ¤ì— ë°°ì¹˜
    right_transformed = cv2.warpPerspective(right_img, H, canvas_size)
    
    # ë¸”ë Œë”©
    left_mask_3ch = left_blend_mask[:, :, np.newaxis]
    right_mask_3ch = right_blend_mask[:, :, np.newaxis]
    
    left_weighted = (left_canvas.astype(np.float32) * left_mask_3ch).astype(np.uint8)
    right_weighted = (right_transformed.astype(np.float32) * right_mask_3ch).astype(np.uint8)
    
    final_result = cv2.add(left_weighted, right_weighted)
    
    print(f"   âœ… ìŠ¤í‹°ì¹­ ì™„ë£Œ")
    return final_result, left_canvas, right_transformed

def save_stitching_parameters(H, canvas_size, left_offset, left_blend_mask, right_blend_mask, config_dir='./data/config'):
    """ğŸš« ë¶ˆí•„ìš”í•œ LR_stitching_parameters.json ìƒì„± ì œê±° (ì‹¤ì‹œê°„ ì½”ë“œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)"""
    print(f"\nğŸ’¾ ìŠ¤í‹°ì¹­ íŒŒë¼ë¯¸í„° ì €ì¥ (homography_params.jsonë§Œ ìƒì„±)")
    
    # LR_stitching_parameters.jsonì€ ì‹¤ì‹œê°„ ì½”ë“œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ìƒì„±í•˜ì§€ ì•ŠìŒ
    print(f"   â„¹ï¸ LR_stitching_parameters.json ìƒì„± ê±´ë„ˆëœ€ (ì‹¤ì‹œê°„ ì½”ë“œì—ì„œ ë¯¸ì‚¬ìš©)")
    return None

def save_unified_homography_params(H, canvas_size, left_offset, config_LC_file, config_CR_file, config_dir='./data/config'):
    """ì‹¤ì‹œê°„ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” homography_params.jsonë§Œ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        with open(config_LC_file, 'r') as f:
            config_LC = json.load(f)
        camera_resolution = config_LC.get('camera_resolution', [1920, 1080])
    except:
        camera_resolution = [1920, 1080]
    
    # ğŸ¯ ì‹¤ì‹œê°„ ì½”ë“œì—ì„œ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” íŒŒë¼ë¯¸í„°ë§Œ ì €ì¥
    unified_params = {
        'homography_matrix': H.tolist(),
        'final_size': [int(canvas_size[0]), int(canvas_size[1])],
        'camera_resolution': camera_resolution,
        'left_image_offset': [int(left_offset[0]), int(left_offset[1])],
        'rectification_maps': {
            'map_left_x': 'stereo_map_left_x.npy',
            'map_right_x': 'stereo_map_right_x.npy'
        },
        'blending_optimization': {
            'left_mask_file': 'left_blend_mask.npy',
            'right_mask_file': 'right_blend_mask.npy'
        }
    }
    
    unified_file = os.path.join(config_dir, "homography_params.json")
    with open(unified_file, 'w') as f:
        json.dump(unified_params, f, indent=2)
    
    print(f"   âœ… ì‹¤ì‹œê°„ ì½”ë“œìš© íŒŒë¼ë¯¸í„° ì €ì¥: {unified_file}")
    return unified_file

def save_stitching_results(left_canvas, right_transformed, final_result, left_blend_mask, right_blend_mask, output_dir='./data/stitching_results'):
    """ìŠ¤í‹°ì¹­ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    os.makedirs(output_dir, exist_ok=True)
    
    cv2.imwrite(os.path.join(output_dir, "left_canvas.png"), left_canvas)
    cv2.imwrite(os.path.join(output_dir, "right_transformed.png"), right_transformed)
    cv2.imwrite(os.path.join(output_dir, "final_stitched.png"), final_result)
    cv2.imwrite(os.path.join(output_dir, "left_blend_mask.png"), (left_blend_mask * 255).astype(np.uint8))
    cv2.imwrite(os.path.join(output_dir, "right_blend_mask.png"), (right_blend_mask * 255).astype(np.uint8))
    
    print(f"   âœ… ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_dir}")

# ========================================
# ì‹œê°í™” í•¨ìˆ˜ë“¤ (í•„ìˆ˜ 4ê°œ)
# ========================================

def create_pipeline_visualization_1(left_original, right_original, left_rectified, right_rectified):
    """1ë‹¨ê³„: ì›ë³¸ ì´ë¯¸ì§€ â†’ ì •ë ¬ëœ ì´ë¯¸ì§€ ì‹œê°í™”"""
    print(f"\nğŸ¨ 1ë‹¨ê³„ ì‹œê°í™”: ì›ë³¸ â†’ ì •ë ¬")
    
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print(f"   âŒ matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install matplotlib")
        return
    
    # BGRì„ RGBë¡œ ë³€í™˜
    if len(left_original.shape) == 3:
        left_orig_rgb = cv2.cvtColor(left_original, cv2.COLOR_BGR2RGB)
        right_orig_rgb = cv2.cvtColor(right_original, cv2.COLOR_BGR2RGB)
        left_rect_rgb = cv2.cvtColor(left_rectified, cv2.COLOR_BGR2RGB)
        right_rect_rgb = cv2.cvtColor(right_rectified, cv2.COLOR_BGR2RGB)
    else:
        left_orig_rgb = left_original
        right_orig_rgb = right_original
        left_rect_rgb = left_rectified
        right_rect_rgb = right_rectified
    
    # 2x2 ì„œë¸Œí”Œë¡¯ ìƒì„±
    fig, axes = plt.subplots(2, 2, figsize=(20, 12))
    
    axes[0, 0].imshow(left_orig_rgb)
    axes[0, 0].set_title('1. Original Left Image', fontsize=16, fontweight='bold')
    axes[0, 0].axis('off')
    
    axes[0, 1].imshow(right_orig_rgb)
    axes[0, 1].set_title('2. Original Right Image', fontsize=16, fontweight='bold')
    axes[0, 1].axis('off')
    
    axes[1, 0].imshow(left_rect_rgb)
    axes[1, 0].set_title('3. Rectified Left Image', fontsize=16, fontweight='bold')
    axes[1, 0].axis('off')
    
    axes[1, 1].imshow(right_rect_rgb)
    axes[1, 1].set_title('4. Rectified Right Image', fontsize=16, fontweight='bold')
    axes[1, 1].axis('off')
    
    plt.tight_layout()
    
    output_dir = './data/visualization'
    os.makedirs(output_dir, exist_ok=True)
    plot_file = os.path.join(output_dir, '1_calibration_rectification.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"   ğŸ’¾ 1ë‹¨ê³„ ì‹œê°í™” ì €ì¥: {plot_file}")
    plt.show()

def create_pipeline_visualization_2(left_img, right_img, left_corners, right_corners):
    """2ë‹¨ê³„: íŠ¹ì§•ì  ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
    print(f"\nğŸ¨ 2ë‹¨ê³„ ì‹œê°í™”: íŠ¹ì§•ì  ê²€ì¶œ")
    
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print(f"   âŒ matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install matplotlib")
        return
    
    # BGRì„ RGBë¡œ ë³€í™˜
    if len(left_img.shape) == 3:
        left_rgb = cv2.cvtColor(left_img, cv2.COLOR_BGR2RGB)
        right_rgb = cv2.cvtColor(right_img, cv2.COLOR_BGR2RGB)
    else:
        left_rgb = left_img
        right_rgb = right_img
    
    # ì½”ë„ˆì ì„ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
    left_with_corners = left_rgb.copy()
    right_with_corners = right_rgb.copy()
    
    # ì™¼ìª½ ì´ë¯¸ì§€ì— ì½”ë„ˆì  í‘œì‹œ
    for i, corner in enumerate(left_corners):
        x, y = int(corner[0]), int(corner[1])
        cv2.circle(left_with_corners, (x, y), 3, (255, 0, 0), -1)
        cv2.circle(left_with_corners, (x, y), 5, (255, 255, 255), 2)
        cv2.putText(left_with_corners, str(i), (x+15, y+5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ì— ì½”ë„ˆì  í‘œì‹œ
    for i, corner in enumerate(right_corners):
        x, y = int(corner[0]), int(corner[1])
        cv2.circle(right_with_corners, (x, y), 3, (0, 255, 0), -1)
        cv2.circle(right_with_corners, (x, y), 5, (255, 255, 255), 2)
        cv2.putText(right_with_corners, str(i), (x+15, y+5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # ì‹œê°í™”
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
    
    ax1.imshow(left_with_corners)
    ax1.set_title(f'1. Left Image - Detected Corners ({len(left_corners)} points)', 
                  fontsize=16, fontweight='bold')
    ax1.axis('off')
    
    ax2.imshow(right_with_corners)
    ax2.set_title(f'2. Right Image - Detected Corners ({len(right_corners)} points)', 
                  fontsize=16, fontweight='bold')
    ax2.axis('off')
    
    plt.tight_layout()
    
    output_dir = './data/visualization'
    os.makedirs(output_dir, exist_ok=True)
    plot_file = os.path.join(output_dir, '2_feature_detection.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"   ğŸ’¾ 2ë‹¨ê³„ ì‹œê°í™” ì €ì¥: {plot_file}")
    plt.show()

def create_pipeline_visualization_3(left_img, right_img, left_corners, right_corners, H):
    """3ë‹¨ê³„: í˜¸ëª¨ê·¸ë˜í”¼ ë§¤ì¹­ ê²°ê³¼ ì‹œê°í™”"""
    print(f"\nğŸ¨ 3ë‹¨ê³„ ì‹œê°í™”: í˜¸ëª¨ê·¸ë˜í”¼ ë§¤ì¹­")
    
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print(f"   âŒ matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install matplotlib")
        return
    
    left_rgb = cv2.cvtColor(left_img, cv2.COLOR_BGR2RGB) if len(left_img.shape) == 3 else left_img
    right_rgb = cv2.cvtColor(right_img, cv2.COLOR_BGR2RGB) if len(right_img.shape) == 3 else right_img
    
    h1, w1 = left_rgb.shape[:2]
    h2, w2 = right_rgb.shape[:2]
    Hh = max(h1, h2)
    pad_left = np.zeros((Hh - h1, w1, 3), dtype=left_rgb.dtype) if h1 < Hh else None
    pad_right = np.zeros((Hh - h2, w2, 3), dtype=right_rgb.dtype) if h2 < Hh else None
    left_pad = np.vstack([left_rgb, pad_left]) if pad_left is not None else left_rgb
    right_pad = np.vstack([right_rgb, pad_right]) if pad_right is not None else right_rgb
    concat = np.hstack([left_pad, right_pad])
    
    fig, ax = plt.subplots(1, 1, figsize=(20, 10))
    ax.imshow(concat)
    ax.set_title('Homography Matching - Left-Right Correspondence', fontsize=16, fontweight='bold')
    ax.axis('off')
    
    # ì™¼ìª½ ì´ë¯¸ì§€ì™€ ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ê°„ ë§¤ì¹­ì„  ê·¸ë¦¬ê¸°
    for i, (lp, rp) in enumerate(zip(left_corners, right_corners)):
        lx, ly = float(lp[0]), float(lp[1])  # ì™¼ìª½ ì´ë¯¸ì§€ì˜ ì½”ë„ˆ
        rx, ry = float(rp[0]) + w1, float(rp[1])  # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ì˜ ì½”ë„ˆ (xì¢Œí‘œì— w1 ì˜¤í”„ì…‹)
        
        # ì™¼ìª½ê³¼ ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ê°„ ë§¤ì¹­ì„ 
        ax.plot([lx, rx], [ly, ry], '-', color='yellow', linewidth=2, alpha=0.8)
        
        # ì½”ë„ˆì  í‘œì‹œ
        ax.plot(lx, ly, 'ro', markersize=8, markeredgecolor='white', markeredgewidth=2)
        ax.plot(rx, ry, 'bo', markersize=8, markeredgecolor='white', markeredgewidth=2)
        
        # ì½”ë„ˆì  ë²ˆí˜¸ í‘œì‹œ
        ax.text(lx+10, ly-10, str(i), color='white', fontsize=10, fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.7))
        ax.text(rx+10, ry-10, str(i), color='white', fontsize=10, fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='blue', alpha=0.7))
    
    plt.tight_layout()
    
    output_dir = './data/visualization'
    os.makedirs(output_dir, exist_ok=True)
    plot_file = os.path.join(output_dir, '3_homography_matching.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"   ğŸ’¾ 3ë‹¨ê³„ ì‹œê°í™” ì €ì¥: {plot_file}")
    plt.show()

def create_pipeline_visualization_4(left_img, right_img, final_result):
    """4ë‹¨ê³„: ìµœì¢… ìŠ¤í‹°ì¹­ ê²°ê³¼ ì‹œê°í™”"""
    print(f"\nğŸ¨ 4ë‹¨ê³„ ì‹œê°í™”: ìµœì¢… ìŠ¤í‹°ì¹­ ê²°ê³¼")
    
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print(f"   âŒ matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install matplotlib")
        return
    
    # BGRì„ RGBë¡œ ë³€í™˜
    final_rgb = cv2.cvtColor(final_result, cv2.COLOR_BGR2RGB) if len(final_result.shape) == 3 else final_result
    
    # 1x1 ì„œë¸Œí”Œë¡¯ ìƒì„± (ìµœì¢… ê²°ê³¼ë§Œ)
    fig, ax = plt.subplots(1, 1, figsize=(16, 10))
    
    ax.imshow(final_rgb)
    ax.set_title('Final Stitched Result', fontsize=18, fontweight='bold')
    ax.axis('off')
    
    plt.tight_layout()
    
    output_dir = './data/visualization'
    os.makedirs(output_dir, exist_ok=True)
    plot_file = os.path.join(output_dir, '4_final_stitching.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"   ğŸ’¾ 4ë‹¨ê³„ ì‹œê°í™” ì €ì¥: {plot_file}")
    plt.show()

# ========================================
# ROI ì„ íƒ ê¸°ëŠ¥ (í•„ìˆ˜)
# ========================================

def interactive_roi_selection(final_result, output_dir='./data/params'):
    """ì‚¬ìš©ìê°€ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ROIë¥¼ ì§ì ‘ ì§€ì •í•  ìˆ˜ ìˆëŠ” ì¸í„°ë™í‹°ë¸Œ í•¨ìˆ˜"""
    print(f"\nğŸ¯ ì¸í„°ë™í‹°ë¸Œ ROI ì„ íƒ ëª¨ë“œ")
    print(f"ğŸ’¡ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ í‘œì‹œí•  ì˜ì—­ì„ ì„ íƒí•˜ì„¸ìš”")
    print(f"ğŸ’¡ ì„ íƒ ì™„ë£Œ í›„ 'Enter' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”")
    print(f"ğŸ’¡ ì·¨ì†Œí•˜ë ¤ë©´ 'ESC' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”")
    
    # ROI ì„ íƒì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
    roi_coords = {'start': None, 'end': None}
    drawing = False
    
    # DISPLAY_SCALE ì ìš©í•˜ì—¬ í‘œì‹œìš© ì´ë¯¸ì§€ ìƒì„±
    if DISPLAY_SCALE != 1.0:
        display_width = int(final_result.shape[1] * DISPLAY_SCALE)
        display_height = int(final_result.shape[0] * DISPLAY_SCALE)
        display_img = cv2.resize(final_result, (display_width, display_height))
    else:
        display_img = final_result.copy()
        display_width = final_result.shape[1]
        display_height = final_result.shape[0]
    
    temp_img = display_img.copy()
    
    def mouse_callback(event, x, y, flags, param):
        nonlocal roi_coords, drawing, temp_img
        
        if event == cv2.EVENT_LBUTTONDOWN:
            roi_coords['start'] = (x, y)
            drawing = True
            temp_img = display_img.copy()
            
        elif event == cv2.EVENT_MOUSEMOVE and drawing:
            temp_img = display_img.copy()
            cv2.rectangle(temp_img, roi_coords['start'], (x, y), (0, 255, 0), 2)
            
        elif event == cv2.EVENT_LBUTTONUP:
            roi_coords['end'] = (x, y)
            drawing = False
            
            temp_img = display_img.copy()
            x1, y1 = roi_coords['start']
            x2, y2 = roi_coords['end']
            
            x1, x2 = min(x1, x2), max(x1, x2)
            y1, y2 = min(y1, y2), max(y1, y2)
            
            cv2.rectangle(temp_img, (x1, y1), (x2, y2), (0, 255, 0), 3)
            cv2.putText(temp_img, f"ROI: {x2-x1}x{y2-y1}", (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    # ìœˆë„ìš° ìƒì„± ë° ë§ˆìš°ìŠ¤ ì½œë°± ì„¤ì •
    window_name = "Interactive ROI Selection - Drag to select area, Press Enter to confirm"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, display_width, display_height)
    cv2.setMouseCallback(window_name, mouse_callback)
    cv2.imshow(window_name, display_img)
    
    print(f"ğŸ¯ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ì˜ì—­ì„ ì„ íƒí•˜ì„¸ìš”...")
    
    while True:
        cv2.imshow(window_name, temp_img)
        key = cv2.waitKey(1) & 0xFF
        
        if key == 13:  # Enter í‚¤
            if roi_coords['start'] and roi_coords['end']:
                break
            else:
                print("âš ï¸ ë¨¼ì € ì˜ì—­ì„ ì„ íƒí•´ì£¼ì„¸ìš”")
        elif key == 27:  # ESC í‚¤
            print("âŒ ROI ì„ íƒ ì·¨ì†Œë¨")
            cv2.destroyAllWindows()
            return None
        elif key == ord('r'):  # R í‚¤ë¡œ ë¦¬ì…‹
            roi_coords = {'start': None, 'end': None}
            temp_img = display_img.copy()
            print("ğŸ”„ ROI ì„ íƒ ë¦¬ì…‹ë¨")
    
    # ìµœì¢… ROI ì¢Œí‘œ ê³„ì‚° (ìŠ¤ì¼€ì¼ëœ ì¢Œí‘œë¥¼ ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜)
    x1, y1 = roi_coords['start']
    x2, y2 = roi_coords['end']
    x1, x2 = min(x1, x2), max(x1, x2)
    y1, y2 = min(y1, y2), max(y1, y2)
    
    # ìŠ¤ì¼€ì¼ëœ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
    scale_factor = 1.0 / DISPLAY_SCALE if DISPLAY_SCALE != 1.0 else 1.0
    orig_x1 = int(x1 * scale_factor)
    orig_y1 = int(y1 * scale_factor)
    orig_x2 = int(x2 * scale_factor)
    orig_y2 = int(y2 * scale_factor)
    
    # ROI ë§ˆìŠ¤í¬ ìƒì„± (ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ)
    roi_mask = np.zeros(final_result.shape[:2], dtype=np.uint8)
    roi_mask[orig_y1:orig_y2, orig_x1:orig_x2] = 255
    
    # ROI ì •ë³´ (ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œ ê¸°ì¤€)
    roi_info = {
        'x1': int(orig_x1), 'y1': int(orig_y1), 'x2': int(orig_x2), 'y2': int(orig_y2),
        'width': int(orig_x2 - orig_x1), 'height': int(orig_y2 - orig_y1),
        'area': int((orig_x2 - orig_x1) * (orig_y2 - orig_y1)),
        'total_area': int(final_result.shape[0] * final_result.shape[1]),
        'area_ratio': float(((orig_x2 - orig_x1) * (orig_y2 - orig_y1)) / (final_result.shape[0] * final_result.shape[1]) * 100)
    }
    
    print(f"âœ… ROI ì„ íƒ ì™„ë£Œ!")
    print(f"   ì„ íƒ ì˜ì—­: {roi_info['width']}x{roi_info['height']}")
    print(f"   ì˜ì—­ ë¹„ìœ¨: {roi_info['area_ratio']:.1f}%")
    
    # ROI ë§ˆìŠ¤í¬ ì €ì¥
    os.makedirs(output_dir, exist_ok=True)
    mask_file = os.path.join(output_dir, 'user_roi_mask.npy')
    np.save(mask_file, roi_mask)
    
    # ROI ì •ë³´ JSON ì €ì¥
    roi_file = os.path.join(output_dir, 'user_roi_info.json')
    with open(roi_file, 'w') as f:
        json.dump(roi_info, f, indent=2)
    
    # ROI ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ì €ì¥
    preview_img = final_result.copy()
    cv2.rectangle(preview_img, (orig_x1, orig_y1), (orig_x2, orig_y2), (0, 255, 0), 3)
    cv2.putText(preview_img, f"USER SELECTED ROI: {orig_x2-orig_x1}x{orig_y2-orig_y1}", (orig_x1, orig_y1-10), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    preview_file = os.path.join(output_dir, 'user_roi_preview.png')
    cv2.imwrite(preview_file, preview_img)
    
    print(f"ğŸ’¾ ROI ì •ë³´ ì €ì¥ ì™„ë£Œ:")
    print(f"   ë§ˆìŠ¤í¬: {mask_file}")
    print(f"   ì •ë³´: {roi_file}")
    print(f"   ë¯¸ë¦¬ë³´ê¸°: {preview_file}")
    
    cv2.destroyAllWindows()
    return roi_info, roi_mask

def create_roi_based_blending_parameters(final_result, roi_info, homography, canvas_size, left_offset, output_dir='./data/params'):
    """ROI ì˜ì—­ì— ë§ì¶˜ ë¸”ë Œë”© íŒŒë¼ë¯¸í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print(f"\nğŸ¨ ROI ê¸°ë°˜ ë¸”ë Œë”© íŒŒë¼ë¯¸í„° ìƒì„±")
    
    roi_x1, roi_y1 = roi_info['x1'], roi_info['y1']
    roi_x2, roi_y2 = roi_info['x2'], roi_info['y2']
    roi_width, roi_height = roi_info['width'], roi_info['height']
    
    # ROI í¬ê¸°ë¡œ ë¸”ë Œë”© ë§ˆìŠ¤í¬ ìƒì„±
    roi_left_blend_mask = np.zeros((roi_height, roi_width), dtype=np.float32)
    roi_right_blend_mask = np.zeros((roi_height, roi_width), dtype=np.float32)
    
    # ì™¼ìª½ ì´ë¯¸ì§€ê°€ ROIì™€ ê²¹ì¹˜ëŠ” ì˜ì—­ ê³„ì‚°
    left_img_start_x = max(roi_x1, left_offset[0])
    left_img_end_x = min(roi_x2, left_offset[0] + 1920)
    left_img_start_y = max(roi_y1, left_offset[1])
    left_img_end_y = min(roi_y2, left_offset[1] + 1080)
    
    roi_left_width = max(0, left_img_end_x - left_img_start_x)
    roi_left_height = max(0, left_img_end_y - left_img_start_y)
    roi_left_offset_x = left_img_start_x - roi_x1
    roi_left_offset_y = left_img_start_y - roi_y1
    
    # ROI ë‚´ì—ì„œì˜ ì™¼ìª½ ì´ë¯¸ì§€ ì˜ì—­ ì„¤ì •
    if roi_left_width > 0 and roi_left_height > 0:
        roi_left_blend_mask[roi_left_offset_y:roi_left_offset_y + roi_left_height, 
                           roi_left_offset_x:roi_left_offset_x + roi_left_width] = 1.0
    
    # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ê°€ì¤‘ì¹˜ ì„¤ì •
    for y in range(roi_height):
        for x in range(roi_width):
            left_weight = roi_left_blend_mask[y, x]
            if left_weight > 0:
                roi_right_blend_mask[y, x] = 1.0 - left_weight
            else:
                roi_right_blend_mask[y, x] = 1.0
    
    # ë¸”ë Œë”© íŒŒë¼ë¯¸í„° ì €ì¥
    roi_blending_params = {
        'roi_info': roi_info,
        'roi_left_offset': [int(roi_left_offset_x), int(roi_left_offset_y)],
        'roi_left_size': [int(roi_left_width), int(roi_left_height)],
        'roi_canvas_size': [int(roi_width), int(roi_height)],
        'roi_left_blend_mask': roi_left_blend_mask.tolist(),
        'roi_right_blend_mask': roi_right_blend_mask.tolist()
    }
    
    os.makedirs(output_dir, exist_ok=True)
    params_file = os.path.join(output_dir, 'roi_blending_params.json')
    
    with open(params_file, 'w') as f:
        json.dump(roi_blending_params, f, indent=2)
    
    # ROI ë¸”ë Œë”© ë§ˆìŠ¤í¬ë¥¼ NPYë¡œë„ ì €ì¥
    np.save(os.path.join(output_dir, 'roi_left_blend_mask.npy'), roi_left_blend_mask)
    np.save(os.path.join(output_dir, 'roi_right_blend_mask.npy'), roi_right_blend_mask)
    
    print(f"   âœ… ROI ë¸”ë Œë”© íŒŒë¼ë¯¸í„° ìƒì„± ì™„ë£Œ: {params_file}")
    return roi_blending_params

# ========================================
# íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ë“¤
# ========================================

def print_pipeline_progress(step, total_steps, title, description=""):
    """íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    progress_bar = 'â–ˆ' * step + 'â–‘' * (total_steps - step)
    percentage = (step / total_steps) * 100
    print(f"\n{'='*60}")
    print(f"ğŸš€ ë‹¨ê³„ {step}/{total_steps}: {title}")
    print(f"ğŸ“‹ ì§„í–‰ë„: [{progress_bar}] {percentage:.1f}%")
    if description:
        print(f"ğŸ’¡ {description}")
    print(f"{'='*60}")

def create_stitching_pipeline(config_LC_file, config_CR_file, left_img, right_img, pattern_size=(1, 10)):
    """ì „ì²´ ìŠ¤í‹°ì¹­ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print(f"\nğŸ¯ Left â†” Right ìŠ¤í‹°ì¹­ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print(f"{'='*60}")
    print(f"ğŸ¯ ì²´í¬ë³´ë“œ íŒ¨í„´: {pattern_size[0]} x {pattern_size[1]}")
    print(f"ğŸ’¡ ë‚´ë¶€ ì½”ë„ˆ: {pattern_size[0]} x {pattern_size[1]}")
    print(f"ğŸ’¡ method: homography from overlap chessboard + minimal overlap stitching")
    print(f"{'='*60}")
    
    total_steps = 4
    
    # 1ë‹¨ê³„: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì • ë¡œë“œ ë° ì´ë¯¸ì§€ ì •ë ¬
    print_pipeline_progress(1, total_steps, "ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì • ë¡œë“œ ë° ì´ë¯¸ì§€ ì •ë ¬", 
                           "ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì´ë¯¸ì§€ë¥¼ ì •ë ¬í•©ë‹ˆë‹¤")
    config_LC = load_calibration_config(config_LC_file)
    config_CR = load_calibration_config(config_CR_file)
    left_rectified, right_rectified = apply_rectification_maps(left_img, right_img, config_LC, config_CR)
    
    create_pipeline_visualization_1(left_img, right_img, left_rectified, right_rectified)
    
    # 2ë‹¨ê³„: íŠ¹ì§•ì  ê²€ì¶œ
    print_pipeline_progress(2, total_steps, "íŠ¹ì§•ì  ê²€ì¶œ", 
                           "ì¤‘ì²© ì˜ì—­ì—ì„œ ì²´í¬ë³´ë“œ ì½”ë„ˆë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤")
    left_corners, right_corners = detect_overlap_features(left_rectified, right_rectified, pattern_size)
    
    if left_corners is None or right_corners is None:
        print(f"âŒ ì¤‘ì²© ì˜ì—­ ì²´í¬ë³´ë“œ ì½”ë„ˆ ê²€ì¶œ ì‹¤íŒ¨")
        return None
    
    create_pipeline_visualization_2(left_rectified, right_rectified, left_corners, right_corners)
    
    # 3ë‹¨ê³„: í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° ë° ë§¤ì¹­
    print_pipeline_progress(3, total_steps, "í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° ë° ë§¤ì¹­", 
                           "íŠ¹ì§•ì ì„ ì‚¬ìš©í•˜ì—¬ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤")
    result = calculate_homography_from_overlap_corners(left_corners, right_corners, left_rectified, right_rectified)
    if result is None:
        print(f"âŒ í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚° ì‹¤íŒ¨")
        return None
    
    H, mask = result
    create_pipeline_visualization_3(left_rectified, right_rectified, left_corners, right_corners, H)
    
    # 4ë‹¨ê³„: ìŠ¤í‹°ì¹­ ê²°ê³¼ ìƒì„±
    print_pipeline_progress(4, total_steps, "ìŠ¤í‹°ì¹­ ê²°ê³¼ ìƒì„±", 
                           "í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìŠ¤í‹°ì¹­í•©ë‹ˆë‹¤")
    H_canvas, canvas_size, left_offset, overlap_area = compute_canvas_with_translation(left_rectified, right_rectified, H)
    left_blend_mask, right_blend_mask = create_blending_masks(
        left_rectified, right_rectified, H_canvas, canvas_size, left_offset
    )
    final_result, left_canvas, right_transformed = perform_stitching(
        left_rectified, right_rectified, H_canvas, canvas_size, left_offset,
        left_blend_mask, right_blend_mask
    )
    
    create_pipeline_visualization_4(left_rectified, right_rectified, final_result)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥ (ì‹¤ì‹œê°„ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒë§Œ)
    print(f"\nğŸ’¾ ì‹¤ì‹œê°„ ì½”ë“œìš© íŒŒë¼ë¯¸í„° ì €ì¥")
    save_stitching_parameters(H_canvas, canvas_size, left_offset, left_blend_mask, right_blend_mask)  # ë¶ˆí•„ìš”í•œ íŒŒì¼ ìƒì„± ì•ˆí•¨
    unified_file = save_unified_homography_params(H_canvas, canvas_size, left_offset, config_LC_file, config_CR_file)
    
    # NPY íŒŒì¼ë“¤ ìƒì„±
    params_dir = './data/params'
    os.makedirs(params_dir, exist_ok=True)
    np.save(os.path.join(params_dir, 'stereo_map_left_x.npy'), config_LC['left_map1_x'])
    np.save(os.path.join(params_dir, 'stereo_map_right_x.npy'), config_CR['right_map1_x'])
    np.save(os.path.join(params_dir, 'left_blend_mask.npy'), left_blend_mask)
    np.save(os.path.join(params_dir, 'right_blend_mask.npy'), right_blend_mask)
    
    # ê²°ê³¼ ì €ì¥
    save_stitching_results(left_canvas, right_transformed, final_result, 
                          left_blend_mask, right_blend_mask)
    
    print(f"\nğŸ‰ Left â†” Right ìŠ¤í‹°ì¹­ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print(f"ğŸ“ ì‹¤ì‹œê°„ ì½”ë“œìš© íŒŒë¼ë¯¸í„°: {unified_file}")
    print(f"ğŸ“Š ì¤‘ì²© ì˜ì—­: {overlap_area} í”½ì…€")
    
    return {
        'params_file': unified_file,
        'homography': H,
        'canvas_size': canvas_size,
        'left_offset': left_offset,
        'overlap_area': overlap_area,
        'final_result': final_result
    }

def main():
    """ë©”ì¸ í•¨ìˆ˜: Left â†” Right ìŠ¤í‹°ì¹­ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print(f"\nğŸ¯ Left â†” Right stitching engine (ê°„ì†Œí™” ë²„ì „)")
    print(f"{'='*60}")
    print(f"ğŸ’¡ method: homography from overlap chessboard + minimal overlap stitching")
    print(f"ğŸ’¡ ëª©ì : ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤í‹°ì¹­ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ìƒì„±")
    print(f"ğŸ¯ ì²´í¬ë³´ë“œ íŒ¨í„´: {CHESSBOARD_SIZE[0]} x {CHESSBOARD_SIZE[1]} (ì‹¤ì œ ì²´ì»¤ë³´ë“œ)")
    print(f"ğŸ’¡ íŠ¹ì§•ì : ì¤‘ì²© ì˜ì—­ì˜ ê³µí†µ ì²´í¬ë³´ë“œ ì½”ë„ˆë¡œ seamless ì—°ê²°")
    print(f"{'='*60}")
    
    # ì„¤ì • íŒŒì¼ ê²½ë¡œ
    config_LC_file = "./data/config/LC_calibration_config.json"
    config_CR_file = "./data/config/CR_calibration_config.json"
    
    # ì„¤ì • íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(config_LC_file):
        print(f"âŒ LC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_LC_file}")
        print(f"ğŸ’¡ ë¨¼ì € Calibration.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return
    
    if not os.path.exists(config_CR_file):
        print(f"âŒ CR ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_CR_file}")
        print(f"ğŸ’¡ ë¨¼ì € Calibration.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return
    
    # Left-Right ìŒ ì´ë¯¸ì§€ ë¡œë“œ
    left_img = cv2.imread("./data/images/pair_LR/left/img00.png")
    right_img = cv2.imread("./data/images/pair_LR/right/img00.png")
    
    if left_img is None or right_img is None:
        print(f"âŒ Left-Right ìŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ğŸ’¡ ë¨¼ì € Camera_1.py ëª¨ë“œ 2ë¡œ Left-Right ìŒ ì´ë¯¸ì§€ë¥¼ ì´¬ì˜í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"âœ… Left-Right ìŒ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ:")
    print(f"   ì™¼ìª½: {left_img.shape}")
    print(f"   ì˜¤ë¥¸ìª½: {right_img.shape}")
    
    try:
        # ìŠ¤í‹°ì¹­ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = create_stitching_pipeline(
            config_LC_file, config_CR_file, 
            left_img, right_img, pattern_size=CHESSBOARD_SIZE
        )
        
        if result:
            print(f"\n{'='*60}")
            print(f"ğŸ‰ ìŠ¤í‹°ì¹­ ì—”ì§„ ì‹¤í–‰ ì™„ë£Œ!")
            print(f"{'='*60}")
            print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
            print(f"   â€¢ ì‹¤ì‹œê°„ ì½”ë“œìš© íŒŒë¼ë¯¸í„°: {result['params_file']}")
            print(f"   â€¢ ê²°ê³¼ ì´ë¯¸ì§€: ./data/stitching_results/")
            print(f"   â€¢ NPY íŒŒì¼ë“¤: ./data/params/")
            
            # ROI ì„ íƒ ê¸°ëŠ¥
            print(f"\nğŸ¯ ì‚¬ìš©ì ì§€ì • ROI ì„ íƒ ëª¨ë“œ")
            print(f"ğŸ’¡ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ì‹¤ì‹œê°„ ìŠ¤í‹°ì¹­ì—ì„œ í‘œì‹œí•  ì˜ì—­ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            print(f"ğŸ’¡ ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ ê²€ì€ ì˜ì—­ì„ ì œê±°í•˜ê³  FPSë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            user_input = input(f"\nğŸ¯ ROI ì„ íƒì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            
            if user_input in ['y', 'yes', 'ã…‡']:
                print(f"\nğŸ¯ ROI ì„ íƒ ëª¨ë“œ ì‹œì‘...")
                print(f"ğŸ’¡ ìµœì¢… ìŠ¤í‹°ì¹­ ê²°ê³¼ ì´ë¯¸ì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤")
                print(f"ğŸ’¡ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ì›í•˜ëŠ” ì˜ì—­ì„ ì„ íƒí•˜ì„¸ìš”")
                
                # ROI ì„ íƒ ì‹¤í–‰
                roi_result = interactive_roi_selection(result['final_result'])
                
                if roi_result:
                    roi_info, roi_mask = roi_result
                    
                    print(f"\nğŸ¯ ROI ì„ íƒ ì™„ë£Œ! ì´ì œ ROI ê¸°ë°˜ ë¸”ë Œë”© íŒŒë¼ë¯¸í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
                    
                    # ROI ê¸°ë°˜ ë¸”ë Œë”© íŒŒë¼ë¯¸í„° ìƒì„±
                    roi_blending_params = create_roi_based_blending_parameters(
                        result['final_result'], roi_info, result['homography'], 
                        result['canvas_size'], result['left_offset']
                    )
                    
                    print(f"\n{'='*60}")
                    print(f"ğŸ‰ ROI ìµœì í™” ì™„ë£Œ!")
                    print(f"{'='*60}")
                    print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
                    print(f"   â€¢ ROI ì •ë³´: ./data/params/user_roi_info.json")
                    print(f"   â€¢ ROI ë§ˆìŠ¤í¬: ./data/params/user_roi_mask.npy")
                    print(f"   â€¢ ROI ë¸”ë Œë”© íŒŒë¼ë¯¸í„°: ./data/params/roi_blending_params.json")
                    print(f"   â€¢ ROI ë¯¸ë¦¬ë³´ê¸°: ./data/params/user_roi_preview.png")
                else:
                    print(f"âš ï¸ ROI ì„ íƒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
            else:
                print(f"â„¹ï¸ ROI ì„ íƒì„ ê±´ë„ˆëœë‹ˆë‹¤")
            
            print(f"\n{'='*60}")
            print(f"ğŸ‰ ìŠ¤í‹°ì¹­ ì—”ì§„ ì‹¤í–‰ ì™„ë£Œ!")
            print(f"{'='*60}")
        else:
            print(f"\nâŒ ìŠ¤í‹°ì¹­ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")
        
    except Exception as e:
        print(f"\nâŒ ìŠ¤í‹°ì¹­ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        raise e

if __name__ == "__main__":
    main()
